{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = 'SE_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 11:54:53,836]\u001b[0m A new study created in RDB with name: SE_4_2018\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:55:10,879]\u001b[0m Trial 0 finished with value: 4.6277236240314155 and parameters: {'n_hidden': 4, 'learning_rate': 0.01964219392381131, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2631298459593683, 'dropout_rate_Layer_2': 0.37217768275567337, 'dropout_rate_Layer_3': 0.23356429238410611, 'dropout_rate_Layer_4': 0.2895177235751562, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012792200211888852, 'l1_Layer_2': 0.012110013329057133, 'l1_Layer_3': 0.0032357461094841447, 'l1_Layer_4': 2.5278958822460455e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 235, 'n_units_Layer_3': 195, 'n_units_Layer_4': 195}. Best is trial 0 with value: 4.6277236240314155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 14.21% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 10.96 | sMAPE for Test Set is: 25.28% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 11:55:51,969]\u001b[0m Trial 1 finished with value: 4.943370790117502 and parameters: {'n_hidden': 4, 'learning_rate': 0.06565668274609418, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04935183554893055, 'dropout_rate_Layer_2': 0.3489223544960258, 'dropout_rate_Layer_3': 0.3973398508480647, 'dropout_rate_Layer_4': 0.35895232416739825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.721154410662058e-05, 'l1_Layer_2': 0.011397007896641838, 'l1_Layer_3': 1.1482993363518403e-05, 'l1_Layer_4': 0.034348763313160335, 'n_units_Layer_1': 75, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270, 'n_units_Layer_4': 55}. Best is trial 0 with value: 4.6277236240314155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 14.93% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.39 | sMAPE for Test Set is: 19.31% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 11:56:24,071]\u001b[0m Trial 2 finished with value: 4.770256347718408 and parameters: {'n_hidden': 3, 'learning_rate': 0.02043439289550321, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1669226097601424, 'dropout_rate_Layer_2': 0.2883681312389442, 'dropout_rate_Layer_3': 0.019627450864788412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019638194370642372, 'l1_Layer_2': 0.0009449992203604101, 'l1_Layer_3': 1.7508089836152578e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 150, 'n_units_Layer_3': 230}. Best is trial 0 with value: 4.6277236240314155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 13.60 | sMAPE for Test Set is: 31.96% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 11:56:28,250]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:56:36,301]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:56:39,632]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:57:25,842]\u001b[0m Trial 6 finished with value: 4.141032434903932 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018587276846634376, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13438212346518613, 'dropout_rate_Layer_2': 0.34303608373935657, 'dropout_rate_Layer_3': 0.2869303017026118, 'dropout_rate_Layer_4': 0.07404787993368181, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032985313997028823, 'l1_Layer_2': 0.0006837745913772087, 'l1_Layer_3': 0.019025392329337712, 'l1_Layer_4': 3.733517467726048e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145, 'n_units_Layer_4': 60}. Best is trial 6 with value: 4.141032434903932.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 12.57% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.25 | sMAPE for Test Set is: 18.38% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 11:57:30,514]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:58:19,394]\u001b[0m Trial 8 finished with value: 3.707153043422841 and parameters: {'n_hidden': 4, 'learning_rate': 0.004173660796937017, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12502254715619876, 'dropout_rate_Layer_2': 0.3507047191569168, 'dropout_rate_Layer_3': 0.0742395847728644, 'dropout_rate_Layer_4': 0.1555727965869839, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004149825295680265, 'l1_Layer_2': 5.7743772398847734e-05, 'l1_Layer_3': 0.000124010863661017, 'l1_Layer_4': 0.00027108563561846754, 'n_units_Layer_1': 135, 'n_units_Layer_2': 235, 'n_units_Layer_3': 170, 'n_units_Layer_4': 150}. Best is trial 8 with value: 3.707153043422841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 11.28% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 24.86% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 11:58:22,482]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:58:26,843]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:58:29,439]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:58:32,759]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:58:56,368]\u001b[0m Trial 13 finished with value: 7.397924448293902 and parameters: {'n_hidden': 4, 'learning_rate': 0.008813847397476806, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18638017846974644, 'dropout_rate_Layer_2': 0.3252330590438051, 'dropout_rate_Layer_3': 0.26795399100806233, 'dropout_rate_Layer_4': 0.03394276368306697, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.038137385232229586, 'l1_Layer_2': 0.07420290404245296, 'l1_Layer_3': 0.002940519963928322, 'l1_Layer_4': 0.015156016391941113, 'n_units_Layer_1': 265, 'n_units_Layer_2': 295, 'n_units_Layer_3': 125, 'n_units_Layer_4': 85}. Best is trial 8 with value: 3.707153043422841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.40 | sMAPE for Validation Set is: 23.78% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 21.65 | sMAPE for Test Set is: 57.05% | rMAE for Test Set is: 2.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 11:59:00,873]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:59:05,108]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:59:08,207]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:59:11,144]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:59:16,171]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:59:20,396]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:59:26,722]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:59:32,029]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:59:40,014]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:59:43,020]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 11:59:51,372]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:00:09,085]\u001b[0m Trial 25 finished with value: 4.207438824714007 and parameters: {'n_hidden': 4, 'learning_rate': 0.03156845800894597, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12486955291850653, 'dropout_rate_Layer_2': 0.024942759762131984, 'dropout_rate_Layer_3': 0.12156830119179562, 'dropout_rate_Layer_4': 0.09764335152081244, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.5127556275347514e-05, 'l1_Layer_2': 7.0687819722672e-05, 'l1_Layer_3': 1.4936742686338737e-05, 'l1_Layer_4': 0.0009323900861565763, 'n_units_Layer_1': 50, 'n_units_Layer_2': 245, 'n_units_Layer_3': 115, 'n_units_Layer_4': 280}. Best is trial 8 with value: 3.707153043422841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.86 | sMAPE for Test Set is: 25.22% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:00:12,986]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:00:17,038]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:00:20,633]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:00:26,754]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:00:38,178]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:00:42,880]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:00:46,997]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:00:51,994]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:00:55,592]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:00:58,824]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:01:03,629]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:01:08,894]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:01:12,158]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:01:29,609]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:01:35,559]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:01:42,321]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:01:48,154]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:01:53,634]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:01:58,204]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:02:08,276]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:02:11,330]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:02:17,531]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:02:22,408]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:02:26,899]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:03:16,071]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:03:23,228]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:03:30,673]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:03:36,283]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:03:41,832]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:03:45,429]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:03:49,813]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:04:33,125]\u001b[0m Trial 57 finished with value: 4.03671371230866 and parameters: {'n_hidden': 4, 'learning_rate': 0.003267694460908537, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33726793115832243, 'dropout_rate_Layer_2': 0.16095295494234652, 'dropout_rate_Layer_3': 0.3973211359346755, 'dropout_rate_Layer_4': 0.3244025148013542, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00027815017586418716, 'l1_Layer_2': 1.7411810700119418e-05, 'l1_Layer_3': 0.0005811332956930782, 'l1_Layer_4': 0.05639922460967419, 'n_units_Layer_1': 130, 'n_units_Layer_2': 270, 'n_units_Layer_3': 215, 'n_units_Layer_4': 185}. Best is trial 8 with value: 3.707153043422841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 12.33% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.90 | sMAPE for Test Set is: 22.49% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:04:37,659]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:04:42,156]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:04:45,200]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:04:48,543]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:04:52,001]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:04:55,879]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:04:59,990]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:05:03,641]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:05:07,233]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:05:11,706]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:05:16,073]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:05:20,080]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:05:23,675]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:05:26,985]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:05:31,491]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:05:34,578]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:05:38,968]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:05:56,599]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:06:05,955]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:06:11,973]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:06:15,129]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:06:18,967]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:06:28,346]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:07:13,638]\u001b[0m Trial 81 finished with value: 4.007530305736336 and parameters: {'n_hidden': 3, 'learning_rate': 0.012378266929213263, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17731811827459382, 'dropout_rate_Layer_2': 0.23234774012146248, 'dropout_rate_Layer_3': 0.1849034585825749, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.898471861869908e-05, 'l1_Layer_2': 0.0008169033555203084, 'l1_Layer_3': 0.004989319945715307, 'n_units_Layer_1': 185, 'n_units_Layer_2': 155, 'n_units_Layer_3': 205}. Best is trial 8 with value: 3.707153043422841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 12.20% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.20 | sMAPE for Test Set is: 23.28% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:08:00,089]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:08:03,870]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:08:13,786]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:08:21,185]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:09:33,352]\u001b[0m Trial 86 finished with value: 4.05185885718415 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016188432781604712, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2373086255988658, 'dropout_rate_Layer_2': 0.3802072790214623, 'dropout_rate_Layer_3': 0.215973342715516, 'dropout_rate_Layer_4': 0.13182206332989935, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014296022155760583, 'l1_Layer_2': 0.008557170575668353, 'l1_Layer_3': 0.00013656933160956897, 'l1_Layer_4': 4.154039389616468e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 210, 'n_units_Layer_3': 80, 'n_units_Layer_4': 140}. Best is trial 8 with value: 3.707153043422841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 12.31% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.88 | sMAPE for Test Set is: 22.40% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:09:37,009]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:10:03,952]\u001b[0m Trial 88 finished with value: 3.9101785627290524 and parameters: {'n_hidden': 3, 'learning_rate': 0.010182073255131027, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18917256451624404, 'dropout_rate_Layer_2': 0.21945511047444116, 'dropout_rate_Layer_3': 0.18696479573303734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00023998984471977785, 'l1_Layer_2': 0.000464664730020931, 'l1_Layer_3': 0.007560043618668711, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 200}. Best is trial 8 with value: 3.707153043422841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.50 | sMAPE for Test Set is: 24.10% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:10:25,141]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:10:30,606]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:10:43,079]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:10:53,586]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:11:06,712]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:11:10,626]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:11:29,009]\u001b[0m Trial 95 finished with value: 4.040865676593959 and parameters: {'n_hidden': 4, 'learning_rate': 0.016438174596653872, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15804535934379108, 'dropout_rate_Layer_2': 0.29918439321559365, 'dropout_rate_Layer_3': 0.06351282333965183, 'dropout_rate_Layer_4': 0.001249913668409576, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.02581210270672527, 'l1_Layer_2': 0.0006136461176190571, 'l1_Layer_3': 0.0049373864133361875, 'l1_Layer_4': 0.0038207964657228153, 'n_units_Layer_1': 270, 'n_units_Layer_2': 210, 'n_units_Layer_3': 85, 'n_units_Layer_4': 120}. Best is trial 8 with value: 3.707153043422841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.02 | sMAPE for Test Set is: 25.22% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:11:52,704]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:11:59,374]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:12:05,604]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:12:09,412]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:12:19,045]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:12:30,155]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:13:15,313]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:13:51,151]\u001b[0m Trial 103 finished with value: 3.7350339027312436 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019113705052765397, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13665111311465422, 'dropout_rate_Layer_2': 0.12247590185815055, 'dropout_rate_Layer_3': 0.14216337208080074, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.5381625435910063e-05, 'l1_Layer_2': 0.012104527660465257, 'l1_Layer_3': 0.002841343798468324, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230}. Best is trial 8 with value: 3.707153043422841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 11.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.84 | sMAPE for Test Set is: 22.88% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:13:55,690]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:14:06,076]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:14:09,862]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:14:19,514]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:14:23,038]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:15:05,189]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:15:10,304]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:15:22,422]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:15:29,092]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:15:36,356]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:15:43,462]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:15:57,637]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:16:03,410]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:16:24,654]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:16:29,221]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:16:32,235]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:16:35,876]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:16:42,065]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:16:46,743]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:16:52,831]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:16:56,977]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:17:04,201]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:17:10,258]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:17:16,879]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:17:22,486]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:17:26,010]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:17:45,240]\u001b[0m Trial 130 finished with value: 4.133610440628044 and parameters: {'n_hidden': 4, 'learning_rate': 0.012291394988869511, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13189479961030054, 'dropout_rate_Layer_2': 0.28255309582654764, 'dropout_rate_Layer_3': 0.04203261764939592, 'dropout_rate_Layer_4': 0.05394448116584958, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.011346229374229905, 'l1_Layer_2': 0.0002472456028198946, 'l1_Layer_3': 0.0021818497971629225, 'l1_Layer_4': 0.0329133803290799, 'n_units_Layer_1': 280, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160, 'n_units_Layer_4': 145}. Best is trial 8 with value: 3.707153043422841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 12.55% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.88 | sMAPE for Test Set is: 22.37% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:17:48,829]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:17:53,334]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:02,717]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:06,167]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:11,170]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:15,297]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:18,769]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:23,276]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:27,965]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:31,511]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:34,721]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:38,387]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:43,603]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:48,569]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:52,540]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:18:57,016]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:19:04,736]\u001b[0m Trial 147 finished with value: 5.337247478753274 and parameters: {'n_hidden': 3, 'learning_rate': 0.02012628767284269, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1741971370849053, 'dropout_rate_Layer_2': 0.3557967403409582, 'dropout_rate_Layer_3': 0.1719981615493582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010858153473260984, 'l1_Layer_2': 0.0023232598874508336, 'l1_Layer_3': 3.434865007653255e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 95, 'n_units_Layer_3': 150}. Best is trial 8 with value: 3.707153043422841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 16.09% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 17.68 | sMAPE for Test Set is: 43.45% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:19:18,241]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:19:54,844]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:19:57,564]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:20:00,198]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:20:07,696]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:20:11,785]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:20:16,022]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:20:18,604]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:20:27,456]\u001b[0m Trial 156 finished with value: 4.910015368843433 and parameters: {'n_hidden': 4, 'learning_rate': 0.030714764529036005, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06126918478686215, 'dropout_rate_Layer_2': 0.10270647535073991, 'dropout_rate_Layer_3': 0.07250929911396678, 'dropout_rate_Layer_4': 0.06185254519099437, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.244204090218733e-05, 'l1_Layer_2': 7.505957437424207e-05, 'l1_Layer_3': 2.6738614836412116e-05, 'l1_Layer_4': 0.013424227210574194, 'n_units_Layer_1': 275, 'n_units_Layer_2': 240, 'n_units_Layer_3': 110, 'n_units_Layer_4': 115}. Best is trial 8 with value: 3.707153043422841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 14.91% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 12.03 | sMAPE for Test Set is: 27.58% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:20:29,989]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:20:39,679]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:20:42,788]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:20:46,024]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:20:49,411]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:20:53,049]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:20:56,627]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:21:00,454]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:21:06,351]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:21:10,373]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:21:15,157]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:21:24,810]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:21:44,434]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:21:59,042]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:23:15,053]\u001b[0m Trial 171 finished with value: 3.627741387867173 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005709611376171672, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3982343353766046, 'dropout_rate_Layer_2': 0.06292977374203518, 'dropout_rate_Layer_3': 0.3260775736498244, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017538971110640249, 'l1_Layer_2': 0.00015730741890749566, 'l1_Layer_3': 7.888838179931259e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 295, 'n_units_Layer_3': 195}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 11.02% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 14.12% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:23:19,211]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:24:42,499]\u001b[0m Trial 173 finished with value: 3.8821279827043327 and parameters: {'n_hidden': 3, 'learning_rate': 0.008396911305225466, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1716512874983269, 'dropout_rate_Layer_2': 0.36248073015669047, 'dropout_rate_Layer_3': 0.16127763566060263, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.2926324195818745e-05, 'l1_Layer_2': 0.0004703409596971634, 'l1_Layer_3': 0.011489197589248715, 'n_units_Layer_1': 190, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 11.88% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.99 | sMAPE for Test Set is: 20.40% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:24:52,723]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:25:42,262]\u001b[0m Trial 175 finished with value: 3.809243056778579 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009413824162820514, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19908044027755856, 'dropout_rate_Layer_2': 0.310877215646713, 'dropout_rate_Layer_3': 0.1642498953969923, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03743090205405752, 'l1_Layer_2': 1.060862831785753e-05, 'l1_Layer_3': 5.883305509194587e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 150, 'n_units_Layer_3': 80}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 11.60% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.26 | sMAPE for Test Set is: 14.37% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:25:48,240]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:25:55,395]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:25:58,108]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:26:01,927]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:26:06,555]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:26:48,361]\u001b[0m Trial 181 finished with value: 3.6817966367279347 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010725561787715747, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19661742867136944, 'dropout_rate_Layer_2': 0.3380478665791523, 'dropout_rate_Layer_3': 0.1800521563494095, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0062097791629887825, 'l1_Layer_2': 1.1270333284050444e-05, 'l1_Layer_3': 9.892785303021952e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 145, 'n_units_Layer_3': 75}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 11.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.73 | sMAPE for Test Set is: 17.37% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:27:29,690]\u001b[0m Trial 182 finished with value: 4.044899274863344 and parameters: {'n_hidden': 3, 'learning_rate': 0.011179875332975249, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14122922071675306, 'dropout_rate_Layer_2': 0.33040238198473015, 'dropout_rate_Layer_3': 0.1478891102678785, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00020984417274901794, 'l1_Layer_2': 0.008995760331758165, 'l1_Layer_3': 0.014976150456723344, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 185}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 12.44% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.29 | sMAPE for Test Set is: 23.63% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:27:33,230]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:27:36,754]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:27:42,238]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:27:47,360]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:28:03,607]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:28:07,536]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:28:11,617]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:28:16,864]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:28:28,157]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:28:31,310]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:28:36,785]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:28:40,594]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:28:43,423]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:28:47,244]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:28:51,376]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:29:03,147]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:29:07,170]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:29:11,342]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:29:14,298]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:29:37,833]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:29:44,834]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:29:49,396]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:29:52,392]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:29:55,469]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:30:02,984]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:30:07,414]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:30:11,057]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:30:20,167]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:30:24,402]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:30:29,380]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:30:31,861]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:34:44,004]\u001b[0m Trial 214 finished with value: 3.994187716998202 and parameters: {'n_hidden': 4, 'learning_rate': 0.003220294238082862, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1577644489447838, 'dropout_rate_Layer_2': 0.06691758843130266, 'dropout_rate_Layer_3': 0.17664623312769254, 'dropout_rate_Layer_4': 0.16878139584174162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014141221382730864, 'l1_Layer_2': 0.008375068663876719, 'l1_Layer_3': 0.0031927917082547677, 'l1_Layer_4': 0.003071608490599001, 'n_units_Layer_1': 285, 'n_units_Layer_2': 130, 'n_units_Layer_3': 115, 'n_units_Layer_4': 95}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 12.16% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.13 | sMAPE for Test Set is: 16.54% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:34:47,260]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:36:14,220]\u001b[0m Trial 216 finished with value: 3.92405225124217 and parameters: {'n_hidden': 4, 'learning_rate': 0.00251299650989115, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1700042234798988, 'dropout_rate_Layer_2': 0.06626790275181545, 'dropout_rate_Layer_3': 0.13603548761804304, 'dropout_rate_Layer_4': 0.1774000888276676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.490836814170447e-05, 'l1_Layer_2': 0.00027287202040062055, 'l1_Layer_3': 0.0034642489995160087, 'l1_Layer_4': 0.0024092770921163424, 'n_units_Layer_1': 285, 'n_units_Layer_2': 105, 'n_units_Layer_3': 60, 'n_units_Layer_4': 75}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.65 | sMAPE for Test Set is: 24.72% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:36:22,151]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:36:25,833]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:36:29,404]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:36:34,247]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:36:39,036]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:36:43,681]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:36:49,152]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:36:52,320]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:36:55,648]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:37:00,161]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:37:04,467]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:37:13,468]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:38:00,920]\u001b[0m Trial 229 finished with value: 4.055393984881638 and parameters: {'n_hidden': 3, 'learning_rate': 0.008599250743105198, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17555902384557717, 'dropout_rate_Layer_2': 0.23973939135481026, 'dropout_rate_Layer_3': 0.17520937700671593, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 6.028506187246405e-05, 'l1_Layer_2': 0.00037020428906757257, 'l1_Layer_3': 0.008380443428530934, 'n_units_Layer_1': 190, 'n_units_Layer_2': 90, 'n_units_Layer_3': 205}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 12.44% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 24.13% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:38:08,053]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:38:20,707]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:38:25,774]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:38:30,462]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:38:35,203]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:38:45,437]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:39:07,126]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:39:20,316]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:39:26,962]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:39:31,339]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:39:41,497]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:39:45,266]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:39:48,320]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:40:19,454]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:40:24,258]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:41:04,189]\u001b[0m Trial 245 finished with value: 3.6902498611613583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016035994397807785, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17130534719474969, 'dropout_rate_Layer_2': 0.3639651869181874, 'dropout_rate_Layer_3': 0.07977203612026978, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005123890178680053, 'l1_Layer_2': 1.0174704570110003e-05, 'l1_Layer_3': 3.1295908963083286e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 95, 'n_units_Layer_3': 60}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 11.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.23 | sMAPE for Test Set is: 18.30% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:41:25,754]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:41:31,349]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:41:36,091]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:41:45,700]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:43:03,433]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:43:10,865]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:43:14,893]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:43:20,289]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:43:32,363]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:43:41,564]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:43:54,237]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:44:04,544]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:44:30,725]\u001b[0m Trial 258 finished with value: 4.084809949939699 and parameters: {'n_hidden': 3, 'learning_rate': 0.009717354425367902, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19958075722190144, 'dropout_rate_Layer_2': 0.19432146053077298, 'dropout_rate_Layer_3': 0.18203226999308444, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.1408420256224414e-05, 'l1_Layer_2': 0.009114876463143027, 'l1_Layer_3': 0.005453861391383539, 'n_units_Layer_1': 200, 'n_units_Layer_2': 100, 'n_units_Layer_3': 205}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.49 | sMAPE for Test Set is: 21.58% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:44:35,501]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:44:42,664]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:44:46,023]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:44:52,328]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:44:57,016]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:45:01,111]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:45:03,971]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:45:08,739]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:45:13,343]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:46:25,133]\u001b[0m Trial 268 finished with value: 4.043861747476199 and parameters: {'n_hidden': 3, 'learning_rate': 0.002300411381495186, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18833450253050982, 'dropout_rate_Layer_2': 0.22252553134038378, 'dropout_rate_Layer_3': 0.31474796741942773, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.9641082409065136e-05, 'l1_Layer_2': 0.006095512704362377, 'l1_Layer_3': 0.01013351962062926, 'n_units_Layer_1': 240, 'n_units_Layer_2': 75, 'n_units_Layer_3': 215}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 12.28% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.82 | sMAPE for Test Set is: 22.33% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:46:27,530]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:46:31,916]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:46:42,262]\u001b[0m Trial 271 finished with value: 4.786695119229109 and parameters: {'n_hidden': 4, 'learning_rate': 0.014846750439690594, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2029818511146471, 'dropout_rate_Layer_2': 0.017475296903224937, 'dropout_rate_Layer_3': 0.18905385104071393, 'dropout_rate_Layer_4': 0.016164119965782178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.8272270688624998e-05, 'l1_Layer_2': 0.005697014815584584, 'l1_Layer_3': 0.0029086064511315594, 'l1_Layer_4': 0.02563474141343203, 'n_units_Layer_1': 290, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130, 'n_units_Layer_4': 65}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 15.54 | sMAPE for Test Set is: 37.43% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:46:50,929]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:47:01,524]\u001b[0m Trial 273 finished with value: 5.084915619784449 and parameters: {'n_hidden': 4, 'learning_rate': 0.015546412042325278, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2016030818992128, 'dropout_rate_Layer_2': 0.018017664726354223, 'dropout_rate_Layer_3': 0.1912543540327666, 'dropout_rate_Layer_4': 0.00791784017399487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.9465695846388858e-05, 'l1_Layer_2': 0.011105906041091053, 'l1_Layer_3': 0.002298947860329664, 'l1_Layer_4': 0.0262458632095039, 'n_units_Layer_1': 300, 'n_units_Layer_2': 215, 'n_units_Layer_3': 130, 'n_units_Layer_4': 80}. Best is trial 171 with value: 3.627741387867173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 15.51% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 16.89 | sMAPE for Test Set is: 41.45% | rMAE for Test Set is: 2.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:47:04,909]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:47:15,890]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:47:22,185]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:48:05,571]\u001b[0m Trial 277 finished with value: 3.5359858178604022 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013948633498142226, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34036660567060606, 'dropout_rate_Layer_2': 0.11409966545166614, 'dropout_rate_Layer_3': 0.35246895620065466, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00031745003399249533, 'l1_Layer_2': 2.702345320266324e-05, 'l1_Layer_3': 0.0005833263920304011, 'n_units_Layer_1': 195, 'n_units_Layer_2': 290, 'n_units_Layer_3': 235}. Best is trial 277 with value: 3.5359858178604022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 10.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.07 | sMAPE for Test Set is: 13.63% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:48:20,245]\u001b[0m Trial 278 finished with value: 4.86772460229792 and parameters: {'n_hidden': 4, 'learning_rate': 0.011664232633004267, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17799419278125694, 'dropout_rate_Layer_2': 0.03248362970805997, 'dropout_rate_Layer_3': 0.15815950886920105, 'dropout_rate_Layer_4': 0.01610995444989699, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.45069478222462e-05, 'l1_Layer_2': 0.00571183913301935, 'l1_Layer_3': 0.001193359381232536, 'l1_Layer_4': 0.03309782083224543, 'n_units_Layer_1': 275, 'n_units_Layer_2': 135, 'n_units_Layer_3': 95, 'n_units_Layer_4': 50}. Best is trial 277 with value: 3.5359858178604022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 16.23 | sMAPE for Test Set is: 39.31% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:48:23,636]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:48:27,792]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:48:32,338]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:48:36,182]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:48:41,075]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:48:48,342]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:48:54,795]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:48:57,852]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:49:06,106]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:49:09,732]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:49:13,752]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:49:18,862]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:49:22,441]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:49:25,158]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:49:34,322]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:49:37,978]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:49:42,675]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:49:47,739]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:49:50,670]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:49:56,040]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:50:35,462]\u001b[0m Trial 299 finished with value: 3.53451740051781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013537402713532003, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39632888157210794, 'dropout_rate_Layer_2': 0.11777450058059341, 'dropout_rate_Layer_3': 0.3581645644209763, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00032080667046283367, 'l1_Layer_2': 7.778042355441488e-05, 'l1_Layer_3': 0.00014606986613544575, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 245}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.53 | sMAPE for Validation Set is: 10.81% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 14.07% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:50:40,626]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:50:51,406]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:50:55,735]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:50:59,593]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:51:05,330]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:51:12,670]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:51:28,846]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:51:32,276]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:51:35,494]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:51:49,139]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:51:54,439]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:51:57,645]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:52:01,256]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:52:04,141]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:52:49,649]\u001b[0m Trial 314 finished with value: 3.5352559124468868 and parameters: {'n_hidden': 3, 'learning_rate': 0.001179098628808977, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3989798335751845, 'dropout_rate_Layer_2': 0.11085374799625583, 'dropout_rate_Layer_3': 0.3480731613696518, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003956873126544655, 'l1_Layer_2': 8.65706530622765e-05, 'l1_Layer_3': 0.00013816118257154434, 'n_units_Layer_1': 210, 'n_units_Layer_2': 300, 'n_units_Layer_3': 275}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 10.81% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 12.94% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:53:36,816]\u001b[0m Trial 315 finished with value: 3.5402729463133285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012583446902686849, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35967622944704825, 'dropout_rate_Layer_2': 0.12300014007868264, 'dropout_rate_Layer_3': 0.35761265423799066, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00039528633664116526, 'l1_Layer_2': 6.291097640742069e-05, 'l1_Layer_3': 0.00018546503400695432, 'n_units_Layer_1': 205, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 13.11% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:54:08,828]\u001b[0m Trial 316 finished with value: 3.5498249336727503 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009608740413199861, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3168107819106076, 'dropout_rate_Layer_2': 0.10093491536694231, 'dropout_rate_Layer_3': 0.35822714803484523, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016092968571539224, 'l1_Layer_2': 2.9989958709822386e-05, 'l1_Layer_3': 0.0003748522510578231, 'n_units_Layer_1': 215, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 10.84% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 15.68% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:54:19,818]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:54:23,701]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:54:26,703]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:54:33,111]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:54:37,216]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:55:19,852]\u001b[0m Trial 322 finished with value: 3.559208487500913 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022522814447119917, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17646271323464816, 'dropout_rate_Layer_2': 0.3383561190418416, 'dropout_rate_Layer_3': 0.08649515505836164, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004097962864943499, 'l1_Layer_2': 3.518641212275308e-05, 'l1_Layer_3': 1.6204160333950773e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 170, 'n_units_Layer_3': 90}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.88 | sMAPE for Test Set is: 20.18% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:55:26,562]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:55:29,963]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:55:33,554]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:55:37,393]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:55:40,961]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:55:46,627]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:55:49,550]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:55:52,452]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:56:15,750]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:56:21,593]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:56:24,476]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:56:28,047]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:56:33,978]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:56:37,336]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:56:42,255]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:56:45,269]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:56:49,054]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:56:55,405]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:56:59,359]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:57:02,353]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:57:05,979]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:57:10,868]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:57:31,429]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:57:34,124]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:57:39,302]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:57:48,111]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:57:51,830]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:58:32,181]\u001b[0m Trial 350 finished with value: 3.557824256371297 and parameters: {'n_hidden': 3, 'learning_rate': 0.001452847209583878, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3644603932006697, 'dropout_rate_Layer_2': 0.13464158916615168, 'dropout_rate_Layer_3': 0.29645145775671655, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005086904875374179, 'l1_Layer_2': 7.722545404751804e-05, 'l1_Layer_3': 9.591487719228934e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 230, 'n_units_Layer_3': 245}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 10.89% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 12.56% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 12:58:40,687]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:58:45,083]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:58:53,842]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:58:57,147]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:59:00,950]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:59:12,635]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:59:15,325]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:59:19,641]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:59:24,703]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 12:59:45,602]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:00:56,676]\u001b[0m Trial 361 finished with value: 3.614958072885233 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014412549158673172, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1667902144923253, 'dropout_rate_Layer_2': 0.22721436800074604, 'dropout_rate_Layer_3': 0.3068961861340776, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8718807217106244e-05, 'l1_Layer_2': 0.0004869041485167906, 'l1_Layer_3': 1.1494521562522819e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 65, 'n_units_Layer_3': 235}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 13.74% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:01:00,939]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:01:05,697]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:01:09,671]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:02:04,206]\u001b[0m Trial 365 finished with value: 3.659543063534039 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018610240345792147, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1582463822414503, 'dropout_rate_Layer_2': 0.22783331563186776, 'dropout_rate_Layer_3': 0.3168929976511222, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2293871304788734e-05, 'l1_Layer_2': 0.0005583835225496871, 'l1_Layer_3': 1.1288181548400754e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 15.06% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:02:59,937]\u001b[0m Trial 366 finished with value: 3.6369441937068316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013031043338665223, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16275143131888298, 'dropout_rate_Layer_2': 0.22536188426798925, 'dropout_rate_Layer_3': 0.3131192457772074, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.483938988641164e-05, 'l1_Layer_2': 0.0004990362526790874, 'l1_Layer_3': 1.3803125487276296e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 11.14% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 14.35% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:04:04,991]\u001b[0m Trial 367 finished with value: 3.7188622203175137 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013368380201813565, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1603563093404501, 'dropout_rate_Layer_2': 0.19148270507552492, 'dropout_rate_Layer_3': 0.3083124691060953, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6627001979132023e-05, 'l1_Layer_2': 0.0005597428318817877, 'l1_Layer_3': 1.330105046635233e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 11.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.13 | sMAPE for Test Set is: 16.16% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:04:13,767]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:04:19,822]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:05:05,545]\u001b[0m Trial 370 finished with value: 3.7515687403510185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012357636580102456, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15492772608209657, 'dropout_rate_Layer_2': 0.19928480932362538, 'dropout_rate_Layer_3': 0.2954578629993822, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4725129979209095e-05, 'l1_Layer_2': 0.0004013579943410761, 'l1_Layer_3': 1.2786021995510283e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 50, 'n_units_Layer_3': 230}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 11.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 15.53% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:05:27,397]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:06:55,707]\u001b[0m Trial 372 finished with value: 3.649431557242431 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012558906813702636, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15385540765651604, 'dropout_rate_Layer_2': 0.18966712370170194, 'dropout_rate_Layer_3': 0.29309106218701647, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6270698677152322e-05, 'l1_Layer_2': 0.0004401341010557339, 'l1_Layer_3': 1.0479695242971572e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 11.12% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.36 | sMAPE for Test Set is: 14.36% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:07:16,182]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:07:36,346]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:08:04,928]\u001b[0m Trial 375 finished with value: 3.5452596198691104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015675421821099607, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15850111044063112, 'dropout_rate_Layer_2': 0.3741980812587135, 'dropout_rate_Layer_3': 0.1076700844891218, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002506641835238218, 'l1_Layer_2': 1.7532884251538877e-05, 'l1_Layer_3': 3.4100561303561325e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 145, 'n_units_Layer_3': 85}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 10.81% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 19.36% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:08:25,260]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:09:16,642]\u001b[0m Trial 377 finished with value: 3.6639938879767833 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016180106540219243, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15634259013802654, 'dropout_rate_Layer_2': 0.19610635964425005, 'dropout_rate_Layer_3': 0.2994708763351851, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5284454717054498e-05, 'l1_Layer_2': 0.0004929816785854371, 'l1_Layer_3': 1.0003064673079203e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 11.12% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 16.27% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:09:42,120]\u001b[0m Trial 378 finished with value: 3.5906185568422355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022881408039826727, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1566584613883439, 'dropout_rate_Layer_2': 0.37594356012818403, 'dropout_rate_Layer_3': 0.099419519932834, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002598306312579644, 'l1_Layer_2': 1.7891671608956588e-05, 'l1_Layer_3': 1.989090713951905e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 190, 'n_units_Layer_3': 65}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 10.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.11 | sMAPE for Test Set is: 20.84% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:10:13,846]\u001b[0m Trial 379 finished with value: 3.577610110628316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015777752864588877, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15248194116622235, 'dropout_rate_Layer_2': 0.37510178008397493, 'dropout_rate_Layer_3': 0.10065147864648867, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023550666525331953, 'l1_Layer_2': 1.755584865217095e-05, 'l1_Layer_3': 1.9936342167525098e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 195, 'n_units_Layer_3': 70}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 10.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 20.35% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:10:17,574]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:10:27,529]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:10:36,620]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:10:42,611]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:10:48,168]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:10:54,869]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:11:24,650]\u001b[0m Trial 386 finished with value: 3.546211503462196 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015289016110902895, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1512391774691081, 'dropout_rate_Layer_2': 0.37607819818843863, 'dropout_rate_Layer_3': 0.12570671200579336, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002474956166798611, 'l1_Layer_2': 1.8383827461828915e-05, 'l1_Layer_3': 1.020343815339395e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 190, 'n_units_Layer_3': 70}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.71 | sMAPE for Test Set is: 22.10% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:11:45,733]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:12:16,614]\u001b[0m Trial 388 finished with value: 3.816313120537408 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011847415446976136, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15763942820338905, 'dropout_rate_Layer_2': 0.19115573305028838, 'dropout_rate_Layer_3': 0.29906467234360584, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4051144201064162e-05, 'l1_Layer_2': 0.0004502705364447222, 'l1_Layer_3': 1.3151108410807393e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 11.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.52 | sMAPE for Test Set is: 16.93% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:12:24,941]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:12:33,419]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:12:41,262]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:13:38,762]\u001b[0m Trial 392 finished with value: 3.841510325956611 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010079154299224892, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05654292936312853, 'dropout_rate_Layer_2': 0.18991997282403061, 'dropout_rate_Layer_3': 0.2851155940857101, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4027836077065343e-05, 'l1_Layer_2': 0.000490030608284693, 'l1_Layer_3': 1.827671739789144e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 11.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.61 | sMAPE for Test Set is: 17.23% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:14:12,473]\u001b[0m Trial 393 finished with value: 3.8597393623854646 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010873991081177415, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029771866320600276, 'dropout_rate_Layer_2': 0.1749436477323721, 'dropout_rate_Layer_3': 0.2745269175181236, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8359913842053263e-05, 'l1_Layer_2': 0.0007062696122298887, 'l1_Layer_3': 1.638973616349522e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 55, 'n_units_Layer_3': 235}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 11.73% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.96 | sMAPE for Test Set is: 15.74% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:14:17,184]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:14:47,558]\u001b[0m Trial 395 finished with value: 3.8763192110399074 and parameters: {'n_hidden': 4, 'learning_rate': 0.008523085504054064, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18802854099497807, 'dropout_rate_Layer_2': 0.046169839372766044, 'dropout_rate_Layer_3': 0.16036554315791562, 'dropout_rate_Layer_4': 0.10733297167993011, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.869925560704107e-05, 'l1_Layer_2': 0.02189931175312501, 'l1_Layer_3': 0.0009303330261233162, 'l1_Layer_4': 0.0024334959800537855, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 90, 'n_units_Layer_4': 90}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.16 | sMAPE for Test Set is: 20.92% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:15:41,823]\u001b[0m Trial 396 finished with value: 3.7859375197083813 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010680398470426587, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04012241728762915, 'dropout_rate_Layer_2': 0.18989357877759844, 'dropout_rate_Layer_3': 0.27487421821790736, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3823202504232875e-05, 'l1_Layer_2': 0.0007078027909079934, 'l1_Layer_3': 1.673029913838603e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 11.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.49 | sMAPE for Test Set is: 16.93% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:15:45,553]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:15:49,089]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:16:29,929]\u001b[0m Trial 399 finished with value: 3.895227760744717 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010915888152722637, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04784748131830527, 'dropout_rate_Layer_2': 0.17417798444970192, 'dropout_rate_Layer_3': 0.2772621283389055, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2839794041557395e-05, 'l1_Layer_2': 0.0007232618650622332, 'l1_Layer_3': 1.5138691442866753e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.78 | sMAPE for Test Set is: 17.55% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:16:35,091]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:17:30,185]\u001b[0m Trial 401 finished with value: 3.8823322271545955 and parameters: {'n_hidden': 3, 'learning_rate': 0.001037454663384895, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03807399844680495, 'dropout_rate_Layer_2': 0.17306099803079003, 'dropout_rate_Layer_3': 0.27600451516493, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8051709349706233e-05, 'l1_Layer_2': 0.0008533810198508951, 'l1_Layer_3': 1.570796527879458e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.27 | sMAPE for Test Set is: 16.46% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:17:33,701]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:18:15,130]\u001b[0m Trial 403 finished with value: 3.8946180087672038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010737735939578574, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03843671241138227, 'dropout_rate_Layer_2': 0.17798832953666618, 'dropout_rate_Layer_3': 0.28088730447012167, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2885353326450906e-05, 'l1_Layer_2': 0.0008435413304872594, 'l1_Layer_3': 1.8564503916576707e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.89% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.04 | sMAPE for Test Set is: 18.13% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:18:21,053]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:18:38,356]\u001b[0m Trial 405 finished with value: 4.51284539636065 and parameters: {'n_hidden': 4, 'learning_rate': 0.011466234600612753, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19812362927989263, 'dropout_rate_Layer_2': 0.06977840934677668, 'dropout_rate_Layer_3': 0.1675423290147343, 'dropout_rate_Layer_4': 0.04168738350083567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.9170773173692128e-05, 'l1_Layer_2': 0.007465369959933603, 'l1_Layer_3': 2.2193729557810003e-05, 'l1_Layer_4': 0.03320384828068435, 'n_units_Layer_1': 75, 'n_units_Layer_2': 165, 'n_units_Layer_3': 75, 'n_units_Layer_4': 105}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 13.69% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 12.70 | sMAPE for Test Set is: 29.42% | rMAE for Test Set is: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:19:35,163]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:20:31,605]\u001b[0m Trial 407 finished with value: 3.8259207749677553 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009255439759866906, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04045923162770461, 'dropout_rate_Layer_2': 0.16980048425402547, 'dropout_rate_Layer_3': 0.2816377216185065, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.793979535422853e-05, 'l1_Layer_2': 0.0009401949867644488, 'l1_Layer_3': 1.541375105487984e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 11.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.93 | sMAPE for Test Set is: 17.90% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:20:50,169]\u001b[0m Trial 408 finished with value: 4.785826366982203 and parameters: {'n_hidden': 4, 'learning_rate': 0.013404201717549769, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21536246749559942, 'dropout_rate_Layer_2': 0.06943020893727278, 'dropout_rate_Layer_3': 0.1706915317840025, 'dropout_rate_Layer_4': 0.022476884302923328, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.055159524615393e-05, 'l1_Layer_2': 0.014484926113301388, 'l1_Layer_3': 2.7993626337945062e-05, 'l1_Layer_4': 0.03342984404577473, 'n_units_Layer_1': 60, 'n_units_Layer_2': 155, 'n_units_Layer_3': 55, 'n_units_Layer_4': 105}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 14.53% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 14.93 | sMAPE for Test Set is: 35.51% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:20:59,986]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:21:44,401]\u001b[0m Trial 410 finished with value: 3.879205692489276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010836449731313556, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03746431340062645, 'dropout_rate_Layer_2': 0.16481571544906343, 'dropout_rate_Layer_3': 0.28239288012964003, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.801191807579504e-05, 'l1_Layer_2': 0.0010119546567342068, 'l1_Layer_3': 1.6139435354790855e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.20 | sMAPE for Test Set is: 16.19% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:22:37,253]\u001b[0m Trial 411 finished with value: 3.8525667559146 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009313103441349612, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04030942006182313, 'dropout_rate_Layer_2': 0.16908646452826065, 'dropout_rate_Layer_3': 0.2838427405674452, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8762667112634093e-05, 'l1_Layer_2': 0.0008061583273931898, 'l1_Layer_3': 1.5713526776199176e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.60 | sMAPE for Test Set is: 17.14% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:23:34,334]\u001b[0m Trial 412 finished with value: 4.167554765298157 and parameters: {'n_hidden': 4, 'learning_rate': 0.01094563933067377, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21506792759889937, 'dropout_rate_Layer_2': 0.06832560402115351, 'dropout_rate_Layer_3': 0.16856247916048617, 'dropout_rate_Layer_4': 0.061102778717617746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.791004986252964e-05, 'l1_Layer_2': 0.014340850099226391, 'l1_Layer_3': 2.4018951547493085e-05, 'l1_Layer_4': 0.03258029994120543, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 60, 'n_units_Layer_4': 130}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 26.86% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:23:43,611]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:23:48,981]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:24:44,008]\u001b[0m Trial 415 finished with value: 3.8539575074371686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009425917410359575, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03747111271428577, 'dropout_rate_Layer_2': 0.17623369902565073, 'dropout_rate_Layer_3': 0.28385781862611004, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7401657184362375e-05, 'l1_Layer_2': 0.0009755312665839232, 'l1_Layer_3': 1.6671093531616056e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 11.74% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.93 | sMAPE for Test Set is: 17.99% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:25:36,888]\u001b[0m Trial 416 finished with value: 3.832292197758481 and parameters: {'n_hidden': 3, 'learning_rate': 0.000918646198119778, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03784532006325081, 'dropout_rate_Layer_2': 0.16426363087693782, 'dropout_rate_Layer_3': 0.2823689920987959, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.707986395458515e-05, 'l1_Layer_2': 0.001076920947077234, 'l1_Layer_3': 1.6169161362722416e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 11.66% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.85 | sMAPE for Test Set is: 17.73% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:26:32,082]\u001b[0m Trial 417 finished with value: 3.8664268800799406 and parameters: {'n_hidden': 3, 'learning_rate': 0.000950327243632476, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036842030449024635, 'dropout_rate_Layer_2': 0.16667303711011755, 'dropout_rate_Layer_3': 0.2835358771564568, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.777771587672963e-05, 'l1_Layer_2': 0.0009034630028294922, 'l1_Layer_3': 1.6341166109064883e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.68 | sMAPE for Test Set is: 17.39% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:27:26,259]\u001b[0m Trial 418 finished with value: 3.8556802181469436 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009503796512257279, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03943393944199646, 'dropout_rate_Layer_2': 0.16651579309874323, 'dropout_rate_Layer_3': 0.28328038066025246, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7741711384037122e-05, 'l1_Layer_2': 0.0009817255812116182, 'l1_Layer_3': 1.7012400613645836e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 11.75% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.24 | sMAPE for Test Set is: 18.64% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:28:21,982]\u001b[0m Trial 419 finished with value: 3.853818625555802 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009242479778726065, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0319742787285948, 'dropout_rate_Layer_2': 0.1679314275495013, 'dropout_rate_Layer_3': 0.2835329577609184, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8191579190507023e-05, 'l1_Layer_2': 0.000980823349724031, 'l1_Layer_3': 1.6577667629316134e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 11.74% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.80 | sMAPE for Test Set is: 17.61% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:28:31,703]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:28:39,122]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:29:37,079]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:30:31,827]\u001b[0m Trial 423 finished with value: 3.8556615748973755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011117439666039296, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05010811431458911, 'dropout_rate_Layer_2': 0.16070399732326326, 'dropout_rate_Layer_3': 0.27102051927952103, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.439885457652868e-05, 'l1_Layer_2': 0.0008407867933268622, 'l1_Layer_3': 1.5584790110520052e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.41 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:31:26,455]\u001b[0m Trial 424 finished with value: 3.7827168183042574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009701756914803802, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050444107368869104, 'dropout_rate_Layer_2': 0.16118347181030834, 'dropout_rate_Layer_3': 0.2707910735396625, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1787845203463071e-05, 'l1_Layer_2': 0.0008699194522288809, 'l1_Layer_3': 1.5758066326286024e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 11.52% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.00 | sMAPE for Test Set is: 15.85% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:31:37,140]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:31:54,353]\u001b[0m Trial 426 finished with value: 3.5734806554721494 and parameters: {'n_hidden': 3, 'learning_rate': 0.003917591697677502, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33344584141283595, 'dropout_rate_Layer_2': 0.11904134656070609, 'dropout_rate_Layer_3': 0.34339589683236427, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018884457953461092, 'l1_Layer_2': 5.3531309772828793e-05, 'l1_Layer_3': 0.0005379777568357696, 'n_units_Layer_1': 245, 'n_units_Layer_2': 280, 'n_units_Layer_3': 210}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 10.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 17.80% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:32:03,019]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:32:12,737]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:32:22,555]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:32:27,713]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:32:49,362]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:32:59,048]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:33:54,157]\u001b[0m Trial 433 finished with value: 3.7968993177715844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010389552810322511, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04753591559909377, 'dropout_rate_Layer_2': 0.18179303304613864, 'dropout_rate_Layer_3': 0.27853046784918933, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2661993593744864e-05, 'l1_Layer_2': 0.0007746934703569843, 'l1_Layer_3': 1.582593729947032e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 11.54% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.60 | sMAPE for Test Set is: 17.16% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:34:33,025]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:35:26,493]\u001b[0m Trial 435 finished with value: 3.817711329122717 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009915129347176838, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02171073864613645, 'dropout_rate_Layer_2': 0.1838455670864775, 'dropout_rate_Layer_3': 0.27212935603762106, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9003706656449347e-05, 'l1_Layer_2': 0.0008770279370444892, 'l1_Layer_3': 1.635330988210696e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 11.57% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 17.83% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:35:34,845]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:35:39,385]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:36:21,620]\u001b[0m Trial 438 finished with value: 3.7940770875808254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008251541975568433, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05613316394032401, 'dropout_rate_Layer_2': 0.15767650768871921, 'dropout_rate_Layer_3': 0.2728000341287436, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8558907495397497e-05, 'l1_Layer_2': 0.0010234051594861472, 'l1_Layer_3': 1.5988831500392472e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 11.52% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 15.42% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:36:43,940]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:36:53,735]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:37:15,061]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:37:20,820]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:37:29,310]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:37:35,109]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:38:37,759]\u001b[0m Trial 445 finished with value: 3.8004006619338 and parameters: {'n_hidden': 3, 'learning_rate': 0.000843564838781653, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04403192013818306, 'dropout_rate_Layer_2': 0.16977975160569822, 'dropout_rate_Layer_3': 0.28199482633669337, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2021924464153531e-05, 'l1_Layer_2': 0.0009431168779335059, 'l1_Layer_3': 2.4295478623448943e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 240}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 11.53% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 15.32% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:38:53,197]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:39:00,927]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:39:08,792]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:39:14,513]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:39:20,165]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:39:35,625]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:39:41,353]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:40:38,749]\u001b[0m Trial 453 finished with value: 3.775605268607149 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006828321720798411, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050265742217553804, 'dropout_rate_Layer_2': 0.16358771960849347, 'dropout_rate_Layer_3': 0.28856737181349573, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3243924089521284e-05, 'l1_Layer_2': 0.001219381959621518, 'l1_Layer_3': 1.3852853262321845e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 55, 'n_units_Layer_3': 235}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 11.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.10 | sMAPE for Test Set is: 16.06% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:40:48,764]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:40:58,682]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:41:08,984]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:41:16,901]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:41:26,687]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:41:35,204]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:41:41,049]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:41:49,333]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:41:55,117]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:42:05,030]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:42:30,336]\u001b[0m Trial 464 finished with value: 3.614848621388832 and parameters: {'n_hidden': 3, 'learning_rate': 0.001293426608786231, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17799286597461889, 'dropout_rate_Layer_2': 0.3487986762669919, 'dropout_rate_Layer_3': 0.1515205160154637, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0030013383981342457, 'l1_Layer_2': 1.8240730598514885e-05, 'l1_Layer_3': 2.0327456876731028e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 170, 'n_units_Layer_3': 85}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 11.00% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.66 | sMAPE for Test Set is: 19.54% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:42:39,074]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:42:47,785]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:43:08,802]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:43:18,118]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:43:27,859]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:43:36,370]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:43:40,989]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:44:02,833]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:44:08,502]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:44:30,552]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:44:38,422]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:44:44,242]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:45:05,900]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:45:14,414]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:45:35,243]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:45:51,070]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:45:56,238]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:46:00,671]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:46:10,130]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:46:19,312]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:46:34,084]\u001b[0m Trial 485 finished with value: 5.181742123380943 and parameters: {'n_hidden': 4, 'learning_rate': 0.023005269370047633, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12437505192788954, 'dropout_rate_Layer_2': 0.030537188675822148, 'dropout_rate_Layer_3': 0.1873961237287448, 'dropout_rate_Layer_4': 0.029366438663973662, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.640025579785035e-05, 'l1_Layer_2': 0.00010988668518128363, 'l1_Layer_3': 4.323233850319628e-05, 'l1_Layer_4': 0.0031829708745866165, 'n_units_Layer_1': 65, 'n_units_Layer_2': 185, 'n_units_Layer_3': 85, 'n_units_Layer_4': 110}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 16.07% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 16.44 | sMAPE for Test Set is: 40.23% | rMAE for Test Set is: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:46:38,571]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:46:44,396]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:47:06,471]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:47:14,473]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:47:24,091]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:47:46,067]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:47:52,164]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:47:57,922]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:48:04,378]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:48:11,606]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:48:37,986]\u001b[0m Trial 496 finished with value: 3.623564001839032 and parameters: {'n_hidden': 3, 'learning_rate': 0.002307225752794993, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34750856101709954, 'dropout_rate_Layer_2': 0.07945121381726554, 'dropout_rate_Layer_3': 0.31335947529856206, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025465805814204625, 'l1_Layer_2': 4.123284806337543e-05, 'l1_Layer_3': 0.000544922341924477, 'n_units_Layer_1': 210, 'n_units_Layer_2': 300, 'n_units_Layer_3': 235}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 11.06% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 15.69% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:48:47,568]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:48:56,562]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:49:04,070]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:49:14,564]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:49:29,521]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:49:39,514]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:49:49,667]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:49:59,277]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:50:08,852]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:50:18,489]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:50:33,912]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:50:55,447]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:51:01,217]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:51:11,014]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:51:17,198]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:51:26,982]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:51:33,013]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:52:10,819]\u001b[0m Trial 514 finished with value: 3.7118507874922155 and parameters: {'n_hidden': 3, 'learning_rate': 0.002691152445003758, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37652210386025853, 'dropout_rate_Layer_2': 0.12238619023202837, 'dropout_rate_Layer_3': 0.3781329807285654, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010796939477116043, 'l1_Layer_2': 0.00012597552358672052, 'l1_Layer_3': 0.0003352080579599369, 'n_units_Layer_1': 195, 'n_units_Layer_2': 245, 'n_units_Layer_3': 245}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 11.37% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 12.78% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:52:26,131]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:52:32,055]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:52:42,251]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:52:51,865]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:53:01,731]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:53:21,560]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:53:26,266]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:53:42,369]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:54:11,943]\u001b[0m Trial 523 finished with value: 3.592105992950319 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011234657477777984, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3713010200807872, 'dropout_rate_Layer_2': 0.08417809390960289, 'dropout_rate_Layer_3': 0.27870108833700113, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034935481435810766, 'l1_Layer_2': 1.6680597275433728e-05, 'l1_Layer_3': 0.00011863228830458897, 'n_units_Layer_1': 225, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 11.06% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.19 | sMAPE for Test Set is: 20.88% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:54:17,236]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:54:23,356]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:54:33,707]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:54:42,273]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:54:48,334]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:54:53,611]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:54:59,677]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:55:05,283]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:55:09,996]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:55:26,806]\u001b[0m Trial 533 finished with value: 4.51373083368138 and parameters: {'n_hidden': 4, 'learning_rate': 0.01622255028587103, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2046282022142341, 'dropout_rate_Layer_2': 0.01098348961475004, 'dropout_rate_Layer_3': 0.17859485529787586, 'dropout_rate_Layer_4': 0.009254116897931345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.6538108496386845e-05, 'l1_Layer_2': 0.010899725928259281, 'l1_Layer_3': 1.4794101255258336e-05, 'l1_Layer_4': 0.023656602440520376, 'n_units_Layer_1': 75, 'n_units_Layer_2': 225, 'n_units_Layer_3': 250, 'n_units_Layer_4': 90}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 14.14% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 11.76 | sMAPE for Test Set is: 27.56% | rMAE for Test Set is: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:55:34,664]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:55:57,094]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:56:01,396]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:56:06,157]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:56:31,476]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:56:36,799]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:56:47,228]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:56:56,338]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:57:18,135]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:57:22,957]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:57:33,064]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:57:39,295]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:57:49,002]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:58:06,138]\u001b[0m Trial 547 finished with value: 4.167440094827939 and parameters: {'n_hidden': 4, 'learning_rate': 0.011676782937834033, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17901647998398154, 'dropout_rate_Layer_2': 0.025649896276703058, 'dropout_rate_Layer_3': 0.1781480528645919, 'dropout_rate_Layer_4': 0.025540646210756617, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.973238803253655e-05, 'l1_Layer_2': 0.00014930939529122974, 'l1_Layer_3': 1.5818772103596183e-05, 'l1_Layer_4': 0.023895010025798448, 'n_units_Layer_1': 80, 'n_units_Layer_2': 180, 'n_units_Layer_3': 225, 'n_units_Layer_4': 100}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 25.75% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:58:35,818]\u001b[0m Trial 548 finished with value: 4.043270695422614 and parameters: {'n_hidden': 4, 'learning_rate': 0.011608550579717332, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19344495907966164, 'dropout_rate_Layer_2': 0.023411797465594644, 'dropout_rate_Layer_3': 0.19756659946949703, 'dropout_rate_Layer_4': 0.028023793169237792, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.8958321812399107e-05, 'l1_Layer_2': 0.021835656039996834, 'l1_Layer_3': 1.5273505970183155e-05, 'l1_Layer_4': 0.035260153107939646, 'n_units_Layer_1': 80, 'n_units_Layer_2': 185, 'n_units_Layer_3': 240, 'n_units_Layer_4': 235}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.97 | sMAPE for Test Set is: 25.31% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 13:58:44,418]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:59:05,875]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:59:28,710]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:59:34,076]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:59:38,612]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:59:44,664]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:59:52,049]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 13:59:57,772]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:00:49,612]\u001b[0m Trial 557 finished with value: 3.5415607892734378 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007381068787329313, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38019205899338077, 'dropout_rate_Layer_2': 0.09768641608193653, 'dropout_rate_Layer_3': 0.3629936907592075, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011173855073301906, 'l1_Layer_2': 6.304472576068055e-05, 'l1_Layer_3': 0.000288391192694258, 'n_units_Layer_1': 220, 'n_units_Layer_2': 255, 'n_units_Layer_3': 260}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 10.88% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 14.06% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:01:12,387]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:01:22,965]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:01:32,295]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:01:38,446]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:01:42,950]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:02:04,232]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:02:08,910]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:02:14,667]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:02:40,459]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:02:46,629]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:02:53,546]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:02:59,747]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:03:04,280]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:03:10,258]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:03:19,998]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:03:25,918]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:03:33,210]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:03:39,506]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:03:49,469]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:03:54,056]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:04:01,594]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:04:22,432]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:04:43,298]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:04:49,178]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:04:56,727]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:05:01,475]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:05:06,185]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:05:11,694]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:05:35,123]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:05:40,792]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:05:50,289]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:05:55,420]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:06:00,865]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:06:57,353]\u001b[0m Trial 591 finished with value: 3.544296245290802 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006539758432984752, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.397431940232084, 'dropout_rate_Layer_2': 0.04969833535789481, 'dropout_rate_Layer_3': 0.3282170829726132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006320677653560699, 'l1_Layer_2': 0.00010200787282883071, 'l1_Layer_3': 0.0001224179844584516, 'n_units_Layer_1': 200, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 10.87% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 20.15% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:07:10,875]\u001b[0m Trial 592 finished with value: 4.352626719403755 and parameters: {'n_hidden': 4, 'learning_rate': 0.017402074253368555, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16014768113934869, 'dropout_rate_Layer_2': 0.04267062191435084, 'dropout_rate_Layer_3': 0.2009195139234671, 'dropout_rate_Layer_4': 0.05207595799003666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.4875871396491394e-05, 'l1_Layer_2': 0.00041383326128612854, 'l1_Layer_3': 1.2638523482826697e-05, 'l1_Layer_4': 0.001086057437327235, 'n_units_Layer_1': 50, 'n_units_Layer_2': 170, 'n_units_Layer_3': 55, 'n_units_Layer_4': 95}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 13.22% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 11.59 | sMAPE for Test Set is: 26.87% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:07:19,158]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:07:23,112]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:07:33,773]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:07:38,605]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:07:42,942]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:07:48,855]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:07:53,676]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:08:02,038]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:08:14,989]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:08:21,079]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:08:27,406]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:08:31,863]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:08:36,517]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:08:42,811]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:08:47,185]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:08:52,841]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:08:57,605]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:09:02,035]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:09:07,832]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:09:12,417]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:09:16,974]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:09:22,957]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:09:29,007]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:10:20,932]\u001b[0m Trial 616 finished with value: 3.7400011818812993 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005704728449040901, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12258790684569268, 'dropout_rate_Layer_2': 0.15337253374774618, 'dropout_rate_Layer_3': 0.25052811786949786, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2019770956843163e-05, 'l1_Layer_2': 0.00047284488901950606, 'l1_Layer_3': 1.7107647402102065e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 50, 'n_units_Layer_3': 255}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 11.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 15.86% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:10:25,332]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:10:31,212]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:11:55,255]\u001b[0m Trial 619 finished with value: 3.8888341295452764 and parameters: {'n_hidden': 4, 'learning_rate': 0.002259580695971379, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1675508844701728, 'dropout_rate_Layer_2': 0.06296826451060536, 'dropout_rate_Layer_3': 0.13883933936269918, 'dropout_rate_Layer_4': 0.014871106032306973, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0015583910804123403, 'l1_Layer_2': 0.0008244381823271499, 'l1_Layer_3': 2.847497391380227e-05, 'l1_Layer_4': 0.002277029422937663, 'n_units_Layer_1': 105, 'n_units_Layer_2': 210, 'n_units_Layer_3': 80, 'n_units_Layer_4': 265}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.33 | sMAPE for Test Set is: 23.90% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:11:59,940]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:12:20,686]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:12:26,259]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:12:36,686]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:12:42,417]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:12:47,029]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:12:54,493]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:13:05,418]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:13:10,155]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:13:20,321]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:13:40,996]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:13:45,442]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:15:36,404]\u001b[0m Trial 632 finished with value: 3.6747256236680172 and parameters: {'n_hidden': 4, 'learning_rate': 0.002324606789499931, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13147584800657414, 'dropout_rate_Layer_2': 0.06608535402116925, 'dropout_rate_Layer_3': 0.12117137764778814, 'dropout_rate_Layer_4': 0.06221733988933069, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00027102162806736817, 'l1_Layer_2': 0.0007948943785922793, 'l1_Layer_3': 1.5569248784303196e-05, 'l1_Layer_4': 0.0020702415124081914, 'n_units_Layer_1': 85, 'n_units_Layer_2': 215, 'n_units_Layer_3': 60, 'n_units_Layer_4': 260}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 11.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.62 | sMAPE for Test Set is: 22.11% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:15:44,287]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:15:54,415]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:16:00,263]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:16:15,850]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:16:21,783]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:16:31,566]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:18:06,918]\u001b[0m Trial 639 finished with value: 3.8919034873973053 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032252471118575854, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13190673780060186, 'dropout_rate_Layer_2': 0.06639385805281868, 'dropout_rate_Layer_3': 0.12504323835072664, 'dropout_rate_Layer_4': 0.05462352873676381, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0015663080096645265, 'l1_Layer_2': 0.0009385740826317934, 'l1_Layer_3': 3.4971501747472185e-05, 'l1_Layer_4': 0.0025110940361798835, 'n_units_Layer_1': 100, 'n_units_Layer_2': 210, 'n_units_Layer_3': 50, 'n_units_Layer_4': 260}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.89% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.95 | sMAPE for Test Set is: 25.45% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:18:11,581]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:18:17,721]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:18:22,525]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:20:02,641]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:20:08,256]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:21:34,080]\u001b[0m Trial 645 finished with value: 3.8859556160692397 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021402355195993153, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12064106060717723, 'dropout_rate_Layer_2': 0.07643316248391542, 'dropout_rate_Layer_3': 0.1417246905144177, 'dropout_rate_Layer_4': 0.05541153259598311, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003399421120121642, 'l1_Layer_2': 0.0009103954031320586, 'l1_Layer_3': 2.303534624168708e-05, 'l1_Layer_4': 0.003169621625233375, 'n_units_Layer_1': 100, 'n_units_Layer_2': 220, 'n_units_Layer_3': 60, 'n_units_Layer_4': 270}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.02 | sMAPE for Test Set is: 23.07% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:21:39,980]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:21:44,814]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:21:49,277]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:21:54,841]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:22:00,761]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:22:06,913]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:23:53,606]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:23:59,496]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:25:42,272]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:25:46,591]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:25:52,392]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:25:56,658]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:26:02,385]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:26:08,604]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:26:24,271]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:26:29,639]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:26:33,846]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:27:54,153]\u001b[0m Trial 663 finished with value: 4.0015338528089694 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016919686513161727, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13137630130519146, 'dropout_rate_Layer_2': 0.05246439572254774, 'dropout_rate_Layer_3': 0.12331571636343068, 'dropout_rate_Layer_4': 0.04556053016727745, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0002579083638135949, 'l1_Layer_2': 0.0015021149132108196, 'l1_Layer_3': 1.1671698725815265e-05, 'l1_Layer_4': 0.004073324719028376, 'n_units_Layer_1': 105, 'n_units_Layer_2': 210, 'n_units_Layer_3': 50, 'n_units_Layer_4': 255}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.05 | sMAPE for Test Set is: 22.93% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:27:58,984]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:28:10,020]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:28:15,727]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:28:21,708]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:28:31,993]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:28:36,371]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:28:51,631]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:29:30,806]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:31:07,033]\u001b[0m Trial 672 finished with value: 4.009313058795432 and parameters: {'n_hidden': 4, 'learning_rate': 0.002872314326135144, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11698085208404495, 'dropout_rate_Layer_2': 0.07535058643636294, 'dropout_rate_Layer_3': 0.12494563653370058, 'dropout_rate_Layer_4': 0.060175536197729314, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0002777425002373272, 'l1_Layer_2': 0.0010538544038774767, 'l1_Layer_3': 6.22643840979615e-05, 'l1_Layer_4': 0.002818416905181313, 'n_units_Layer_1': 95, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55, 'n_units_Layer_4': 285}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 12.20% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.68 | sMAPE for Test Set is: 22.24% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:31:11,781]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:32:32,676]\u001b[0m Trial 674 finished with value: 4.0003704550190795 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028750594930996042, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.121695553246984, 'dropout_rate_Layer_2': 0.07919195249958798, 'dropout_rate_Layer_3': 0.11151133767551517, 'dropout_rate_Layer_4': 0.08436455948611615, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003168038322193198, 'l1_Layer_2': 0.0009913070010114998, 'l1_Layer_3': 5.928686193494492e-05, 'l1_Layer_4': 0.0026599724439523202, 'n_units_Layer_1': 115, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55, 'n_units_Layer_4': 290}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 12.16% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.22 | sMAPE for Test Set is: 23.45% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:32:37,381]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:32:59,148]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:33:39,195]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:33:44,539]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:34:25,260]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:34:29,934]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:34:54,814]\u001b[0m Trial 681 finished with value: 3.801811335641801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011796413771016884, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09726066005829877, 'dropout_rate_Layer_2': 0.203694017918725, 'dropout_rate_Layer_3': 0.024198765080735013, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.360688899636206e-05, 'l1_Layer_2': 0.0004901845760625014, 'l1_Layer_3': 7.665006291137669e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.63 | sMAPE for Test Set is: 17.09% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:35:00,035]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:35:05,463]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:35:29,109]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:35:34,863]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:35:38,957]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:35:44,301]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:36:23,575]\u001b[0m Trial 688 finished with value: 3.724227544648688 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007146171130138545, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11045883045864187, 'dropout_rate_Layer_2': 0.006785452489705024, 'dropout_rate_Layer_3': 0.2168016598995596, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2844709367304781e-05, 'l1_Layer_2': 0.00030709338864524043, 'l1_Layer_3': 1.302166812159581e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 11.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.29 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:37:02,137]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:37:06,683]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:37:20,406]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:37:34,568]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:39:22,502]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:39:26,452]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:39:30,880]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:40:22,937]\u001b[0m Trial 696 finished with value: 3.70336850541486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006735872162293168, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10512753848122319, 'dropout_rate_Layer_2': 0.10895552204571497, 'dropout_rate_Layer_3': 0.2136573021000903, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3325794205011498e-05, 'l1_Layer_2': 0.00021997109037978337, 'l1_Layer_3': 3.301434739881018e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 11.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.53 | sMAPE for Test Set is: 16.95% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:40:27,316]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:40:42,601]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:40:46,910]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:40:52,461]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:40:56,963]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:41:01,538]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:41:05,848]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:41:10,485]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:41:17,881]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:41:22,153]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:41:43,570]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:41:51,770]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:42:01,390]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:42:05,521]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:42:10,827]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:42:52,526]\u001b[0m Trial 712 finished with value: 3.5698401343134307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006669380253246758, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39743997929826347, 'dropout_rate_Layer_2': 0.03857600555911153, 'dropout_rate_Layer_3': 0.3323410111787543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006911186704575711, 'l1_Layer_2': 9.920821408361319e-05, 'l1_Layer_3': 0.00012054336995785613, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 210}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 10.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.65 | sMAPE for Test Set is: 19.56% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:42:56,245]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:43:06,270]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:43:29,820]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:45:14,110]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:45:19,368]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:45:27,504]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:45:37,194]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:45:42,867]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:46:40,889]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:46:52,169]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:47:14,607]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:47:19,067]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:47:23,561]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:48:00,484]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:48:11,173]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:48:25,218]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:48:29,733]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:48:39,781]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:48:45,347]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:48:50,714]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:49:12,193]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:50:57,072]\u001b[0m Trial 734 finished with value: 3.978888497288223 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028728056569971806, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12600023375783867, 'dropout_rate_Layer_2': 0.21598264737232065, 'dropout_rate_Layer_3': 0.09939541892126831, 'dropout_rate_Layer_4': 0.1673904534594603, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003295424718691774, 'l1_Layer_2': 0.0005489112070709188, 'l1_Layer_3': 0.000406162762762926, 'l1_Layer_4': 0.001687683752029173, 'n_units_Layer_1': 100, 'n_units_Layer_2': 205, 'n_units_Layer_3': 60, 'n_units_Layer_4': 255}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 12.19% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.59 | sMAPE for Test Set is: 21.94% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:51:02,037]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:51:10,407]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:51:14,776]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:51:20,851]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:52:09,229]\u001b[0m Trial 739 finished with value: 3.542209456011348 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013270799334209763, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06748794670098388, 'dropout_rate_Layer_2': 0.11478373374798623, 'dropout_rate_Layer_3': 0.11510867299002701, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.076149344835908e-05, 'l1_Layer_2': 0.00169330880220215, 'l1_Layer_3': 1.7812919929692662e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 50, 'n_units_Layer_3': 230}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 10.81% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.48 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:52:13,241]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:52:25,140]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:52:32,714]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:52:36,588]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:52:40,473]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:52:44,751]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:53:23,596]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:53:38,168]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:53:45,390]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:53:55,383]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:54:17,697]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:55:44,065]\u001b[0m Trial 751 finished with value: 4.009031412028734 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024317938260947926, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12685307389359066, 'dropout_rate_Layer_2': 0.24606093381863564, 'dropout_rate_Layer_3': 0.10116145405971363, 'dropout_rate_Layer_4': 0.09342718000058678, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0004818470533142133, 'l1_Layer_2': 0.0004980754076179331, 'l1_Layer_3': 1.22720701416173e-05, 'l1_Layer_4': 0.002755140236688765, 'n_units_Layer_1': 115, 'n_units_Layer_2': 205, 'n_units_Layer_3': 50, 'n_units_Layer_4': 280}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 12.24% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.57 | sMAPE for Test Set is: 19.39% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:55:48,156]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:55:52,031]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:56:31,039]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:56:41,966]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:56:47,755]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:56:55,187]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:57:10,625]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:57:25,647]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:57:29,486]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:58:27,460]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:59:35,940]\u001b[0m Trial 762 finished with value: 3.549930113760453 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005895588295707227, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21917798462792432, 'dropout_rate_Layer_2': 0.10774293126153488, 'dropout_rate_Layer_3': 0.08508441658924402, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.583755208396814e-05, 'l1_Layer_2': 1.040538978689229e-05, 'l1_Layer_3': 2.374451546370415e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 55, 'n_units_Layer_3': 245}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 10.78% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 13.25% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 14:59:45,440]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 14:59:58,037]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:00:08,151]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:00:12,932]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:00:18,019]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:00:27,773]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:00:32,321]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:01:35,667]\u001b[0m Trial 770 finished with value: 4.129837922903413 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032488545004830506, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10771477498001225, 'dropout_rate_Layer_2': 0.24625972881299182, 'dropout_rate_Layer_3': 0.08214002768632561, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006447249886213128, 'l1_Layer_2': 0.0005434477398001198, 'l1_Layer_3': 0.000783306873896636, 'n_units_Layer_1': 110, 'n_units_Layer_2': 205, 'n_units_Layer_3': 85}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 12.54% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.09 | sMAPE for Test Set is: 20.39% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:01:50,983]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:02:44,222]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:02:48,673]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:03:39,838]\u001b[0m Trial 774 finished with value: 3.6163303032889265 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015651734002193884, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05412016567456817, 'dropout_rate_Layer_2': 0.07561509131090688, 'dropout_rate_Layer_3': 0.09454149642484934, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7419391261046633e-05, 'l1_Layer_2': 0.0001454273460466189, 'l1_Layer_3': 0.0019431888793367963, 'n_units_Layer_1': 245, 'n_units_Layer_2': 50, 'n_units_Layer_3': 250}. Best is trial 299 with value: 3.53451740051781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 11.03% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.54 | sMAPE for Test Set is: 16.90% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:03:43,639]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:03:52,267]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:03:57,077]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:04:01,526]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:05:38,519]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:05:45,910]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:05:51,312]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:05:58,155]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:06:02,602]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:06:07,115]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:06:29,466]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:06:38,484]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:06:44,312]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:06:49,542]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:06:53,524]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:06:59,572]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:07:03,621]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:07:38,868]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:07:42,627]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:07:48,141]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:08:27,081]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:08:32,289]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:08:36,528]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:08:40,723]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:10:13,598]\u001b[0m Trial 799 finished with value: 3.521332759732863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005457038753419073, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14288812610000617, 'dropout_rate_Layer_2': 0.03879567402809223, 'dropout_rate_Layer_3': 0.08998170792609382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1386560526607674e-05, 'l1_Layer_2': 0.0001034841894700117, 'l1_Layer_3': 0.0018545228453753886, 'n_units_Layer_1': 215, 'n_units_Layer_2': 65, 'n_units_Layer_3': 235}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 10.70% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 11.03% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:10:25,854]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:11:00,065]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:11:21,375]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:11:26,558]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:11:30,833]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:11:35,497]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:11:41,028]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:11:47,105]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:11:52,889]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:13:39,349]\u001b[0m Trial 809 finished with value: 3.5687953800640067 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007153977526205087, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15401522679930887, 'dropout_rate_Layer_2': 0.023512510975766582, 'dropout_rate_Layer_3': 0.08832787326773148, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013168457830827398, 'l1_Layer_2': 0.00017513914845152475, 'l1_Layer_3': 0.0018976250353290361, 'n_units_Layer_1': 210, 'n_units_Layer_2': 60, 'n_units_Layer_3': 235}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.75 | sMAPE for Test Set is: 10.95% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:13:45,003]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:14:04,217]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:14:07,703]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:14:17,648]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:14:32,502]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:14:36,177]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:16:07,829]\u001b[0m Trial 816 finished with value: 3.56376069845212 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006749833792920188, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13231312679588794, 'dropout_rate_Layer_2': 0.08997986687062468, 'dropout_rate_Layer_3': 0.026465060461521066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.9764132559122886e-05, 'l1_Layer_2': 2.590572361523878e-05, 'l1_Layer_3': 0.0014169807886890283, 'n_units_Layer_1': 215, 'n_units_Layer_2': 60, 'n_units_Layer_3': 245}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 10.91% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:16:41,366]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:16:50,495]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:16:57,375]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:17:16,963]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:18:30,498]\u001b[0m Trial 821 finished with value: 3.6419654040518643 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005789300925859303, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1461565754730231, 'dropout_rate_Layer_2': 0.08330360921518223, 'dropout_rate_Layer_3': 0.0464078158012142, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014662931802442546, 'l1_Layer_2': 3.018076741306209e-05, 'l1_Layer_3': 0.0014339558020820134, 'n_units_Layer_1': 215, 'n_units_Layer_2': 60, 'n_units_Layer_3': 245}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 11.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 11.11% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:19:09,314]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:21:09,904]\u001b[0m Trial 823 finished with value: 3.5767828488882696 and parameters: {'n_hidden': 3, 'learning_rate': 0.000591279819809763, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1407802031181813, 'dropout_rate_Layer_2': 0.020867813351146063, 'dropout_rate_Layer_3': 0.021855809209665303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001291180413684441, 'l1_Layer_2': 2.1743892874090668e-05, 'l1_Layer_3': 0.0010740133926563306, 'n_units_Layer_1': 215, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 10.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 10.70% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:21:15,352]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:22:27,901]\u001b[0m Trial 825 finished with value: 3.599281412853653 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005640256528195153, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13334712380910724, 'dropout_rate_Layer_2': 0.02347162064680927, 'dropout_rate_Layer_3': 0.031056559716198223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013036336809426125, 'l1_Layer_2': 3.26939356926468e-05, 'l1_Layer_3': 0.0010794456437165504, 'n_units_Layer_1': 210, 'n_units_Layer_2': 75, 'n_units_Layer_3': 255}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 10.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.73 | sMAPE for Test Set is: 10.93% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:22:31,494]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:22:39,448]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:22:54,852]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:23:49,634]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:23:56,866]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:24:11,818]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:26:07,222]\u001b[0m Trial 832 finished with value: 3.555089344523251 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005579654350108462, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13958211147532334, 'dropout_rate_Layer_2': 0.016275400789300364, 'dropout_rate_Layer_3': 0.04334960253050522, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010049886821389773, 'l1_Layer_2': 2.8756431297553458e-05, 'l1_Layer_3': 0.0012804252471295828, 'n_units_Layer_1': 210, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 10.87% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 10.88% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:28:01,957]\u001b[0m Trial 833 finished with value: 3.5490694064134996 and parameters: {'n_hidden': 3, 'learning_rate': 0.000556705079638501, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13557997496482804, 'dropout_rate_Layer_2': 0.022895539423490475, 'dropout_rate_Layer_3': 0.036773269568356214, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011988450698883788, 'l1_Layer_2': 2.6385853367691292e-05, 'l1_Layer_3': 0.0010472246112941178, 'n_units_Layer_1': 210, 'n_units_Layer_2': 80, 'n_units_Layer_3': 265}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 10.85% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:30:04,679]\u001b[0m Trial 834 finished with value: 3.5661030447949247 and parameters: {'n_hidden': 3, 'learning_rate': 0.000557225886758338, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13624975789570679, 'dropout_rate_Layer_2': 0.015197705186637421, 'dropout_rate_Layer_3': 0.045453387151017835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011105757264198367, 'l1_Layer_2': 2.6436525754977507e-05, 'l1_Layer_3': 0.0009870532409476415, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 265}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 10.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 10.80% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:30:08,490]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:31:21,522]\u001b[0m Trial 836 finished with value: 4.020401414004563 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018964822164929255, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15631205791219388, 'dropout_rate_Layer_2': 0.24421986760560258, 'dropout_rate_Layer_3': 0.0876757285792338, 'dropout_rate_Layer_4': 0.07049027199942398, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00026806633242106893, 'l1_Layer_2': 0.0005260133645876347, 'l1_Layer_3': 1.1439819258767436e-05, 'l1_Layer_4': 0.0033090277384492427, 'n_units_Layer_1': 105, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55, 'n_units_Layer_4': 270}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.02 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.18 | sMAPE for Test Set is: 23.23% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:31:26,406]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:32:20,561]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:32:25,534]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:32:39,851]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:32:43,502]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:32:59,291]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:33:03,249]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:33:58,121]\u001b[0m Trial 844 finished with value: 3.606652709709643 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005525023093404282, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14616114216341267, 'dropout_rate_Layer_2': 0.035671980489031925, 'dropout_rate_Layer_3': 0.04646263538446692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010373668925336407, 'l1_Layer_2': 3.962204471292035e-05, 'l1_Layer_3': 0.0011987566630938167, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 265}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 11.00% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 11.29% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:34:07,042]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:34:15,062]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:34:24,986]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:35:21,210]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:37:44,250]\u001b[0m Trial 849 finished with value: 3.5667455889637023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005549266681273403, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14592453256367294, 'dropout_rate_Layer_2': 0.01471727797877917, 'dropout_rate_Layer_3': 0.028887537681883207, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001038185919403067, 'l1_Layer_2': 2.681268018654404e-05, 'l1_Layer_3': 0.0012792754054861883, 'n_units_Layer_1': 205, 'n_units_Layer_2': 75, 'n_units_Layer_3': 265}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 10.89% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 10.75% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:38:04,401]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:39:41,209]\u001b[0m Trial 851 finished with value: 3.967997139936498 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022267503516394736, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15458660734036442, 'dropout_rate_Layer_2': 0.20618089707148107, 'dropout_rate_Layer_3': 0.057977179726586926, 'dropout_rate_Layer_4': 0.070708853735362, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0002474105451514032, 'l1_Layer_2': 0.0005281699110500696, 'l1_Layer_3': 0.005783929953933417, 'l1_Layer_4': 0.002764688208124835, 'n_units_Layer_1': 95, 'n_units_Layer_2': 215, 'n_units_Layer_3': 55, 'n_units_Layer_4': 255}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 12.02% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.66 | sMAPE for Test Set is: 24.42% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:39:50,838]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:40:01,117]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:41:25,996]\u001b[0m Trial 854 finished with value: 4.00691958383253 and parameters: {'n_hidden': 4, 'learning_rate': 0.00216264567109936, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1475820405545568, 'dropout_rate_Layer_2': 0.23369936291818047, 'dropout_rate_Layer_3': 0.05907135528336422, 'dropout_rate_Layer_4': 0.07050531869461894, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00018109062826990015, 'l1_Layer_2': 0.0005409487650045771, 'l1_Layer_3': 0.005439668471013681, 'l1_Layer_4': 0.0027730347504842444, 'n_units_Layer_1': 90, 'n_units_Layer_2': 215, 'n_units_Layer_3': 55, 'n_units_Layer_4': 260}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.27 | sMAPE for Test Set is: 23.55% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:42:02,903]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:42:09,788]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:42:13,688]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:43:08,119]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:44:03,834]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:45:59,351]\u001b[0m Trial 860 finished with value: 3.5399154040222953 and parameters: {'n_hidden': 3, 'learning_rate': 0.000504606759563233, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14803769751616408, 'dropout_rate_Layer_2': 0.0021094568370623023, 'dropout_rate_Layer_3': 0.021481460944348732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.262567645817431e-05, 'l1_Layer_2': 2.533452125253974e-05, 'l1_Layer_3': 0.0009003815474449792, 'n_units_Layer_1': 200, 'n_units_Layer_2': 80, 'n_units_Layer_3': 270}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 10.80% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.64 | sMAPE for Test Set is: 10.72% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:48:03,166]\u001b[0m Trial 861 finished with value: 3.9661874756799733 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026219670309668036, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15454048615604124, 'dropout_rate_Layer_2': 0.2040575113836788, 'dropout_rate_Layer_3': 0.05805795682381859, 'dropout_rate_Layer_4': 0.06300322707686046, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00019111233826718302, 'l1_Layer_2': 0.0004002388863281091, 'l1_Layer_3': 0.007051278560295836, 'l1_Layer_4': 0.002754871148306865, 'n_units_Layer_1': 90, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55, 'n_units_Layer_4': 240}. Best is trial 799 with value: 3.521332759732863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.79 | sMAPE for Test Set is: 22.50% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:49:42,667]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:51:02,152]\u001b[0m Trial 863 finished with value: 3.435864818002925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005078825413277586, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14724502370996442, 'dropout_rate_Layer_2': 0.002153722134529655, 'dropout_rate_Layer_3': 0.01877700609710637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011046300476931025, 'l1_Layer_2': 2.132820063941529e-05, 'l1_Layer_3': 0.0009894916855472283, 'n_units_Layer_1': 200, 'n_units_Layer_2': 80, 'n_units_Layer_3': 265}. Best is trial 863 with value: 3.435864818002925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 10.63% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:52:54,744]\u001b[0m Trial 864 finished with value: 3.453026798526224 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005227467285243751, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14561386157059664, 'dropout_rate_Layer_2': 0.0033132609577392613, 'dropout_rate_Layer_3': 0.020613803984691356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001172396578040653, 'l1_Layer_2': 2.195439038890592e-05, 'l1_Layer_3': 0.0007769615258298078, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 270}. Best is trial 863 with value: 3.435864818002925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 10.49% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.64 | sMAPE for Test Set is: 10.58% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:54:20,905]\u001b[0m Trial 865 finished with value: 3.976284034895942 and parameters: {'n_hidden': 4, 'learning_rate': 0.002031525195208792, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14696355858966892, 'dropout_rate_Layer_2': 0.2338451141815941, 'dropout_rate_Layer_3': 0.04247396366666042, 'dropout_rate_Layer_4': 0.0740897981478148, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00020239933528919314, 'l1_Layer_2': 0.00036206755272363237, 'l1_Layer_3': 0.006021506207445736, 'l1_Layer_4': 0.002446142741133474, 'n_units_Layer_1': 100, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55, 'n_units_Layer_4': 260}. Best is trial 863 with value: 3.435864818002925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.90 | sMAPE for Test Set is: 22.63% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:56:11,003]\u001b[0m Trial 866 finished with value: 3.4282958860215302 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005026744283267769, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1490242352579428, 'dropout_rate_Layer_2': 0.00424564193913159, 'dropout_rate_Layer_3': 0.019016622452106315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011871011918862416, 'l1_Layer_2': 2.3527335395303846e-05, 'l1_Layer_3': 0.0007958862102166019, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 285}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 10.43% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 10.47% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:57:17,766]\u001b[0m Trial 867 finished with value: 3.4808130404092306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005300713564130873, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14640058534186234, 'dropout_rate_Layer_2': 0.0041169626678124495, 'dropout_rate_Layer_3': 0.016814883060126067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011863137106100634, 'l1_Layer_2': 2.2175997027653597e-05, 'l1_Layer_3': 0.0007929601859123422, 'n_units_Layer_1': 200, 'n_units_Layer_2': 85, 'n_units_Layer_3': 265}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 10.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 10.86% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:58:37,067]\u001b[0m Trial 868 finished with value: 3.47305244922194 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005537628971268826, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1486086727550545, 'dropout_rate_Layer_2': 0.004900553925615959, 'dropout_rate_Layer_3': 0.018422272488763658, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011969579654596065, 'l1_Layer_2': 2.2969026509283114e-05, 'l1_Layer_3': 0.0009230420002993569, 'n_units_Layer_1': 195, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 10.58% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 10.67% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 15:58:40,204]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:58:48,815]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 15:58:52,521]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:00:17,612]\u001b[0m Trial 872 finished with value: 3.45003017782499 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005091679547158177, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14132949932626093, 'dropout_rate_Layer_2': 0.012704602013178537, 'dropout_rate_Layer_3': 0.01944040670589419, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001358039027401401, 'l1_Layer_2': 1.8074706774621623e-05, 'l1_Layer_3': 0.001003815850403652, 'n_units_Layer_1': 200, 'n_units_Layer_2': 85, 'n_units_Layer_3': 265}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 10.54% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.64 | sMAPE for Test Set is: 10.64% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:01:35,161]\u001b[0m Trial 873 finished with value: 4.001723576437828 and parameters: {'n_hidden': 4, 'learning_rate': 0.001937274028625613, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14683408144487298, 'dropout_rate_Layer_2': 0.2366059234099176, 'dropout_rate_Layer_3': 0.056539390755735774, 'dropout_rate_Layer_4': 0.07328972888770803, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00021111825893055435, 'l1_Layer_2': 0.000358607356863399, 'l1_Layer_3': 0.005111165038730998, 'l1_Layer_4': 0.0025977423627642922, 'n_units_Layer_1': 100, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55, 'n_units_Layer_4': 260}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 12.19% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.11 | sMAPE for Test Set is: 23.15% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:01:41,114]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:03:40,156]\u001b[0m Trial 875 finished with value: 3.4790467619296557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005072027293618477, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1404587045511588, 'dropout_rate_Layer_2': 0.008761422651739958, 'dropout_rate_Layer_3': 0.0206802951325356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001366843192709723, 'l1_Layer_2': 1.634509760553827e-05, 'l1_Layer_3': 0.0010160151494238159, 'n_units_Layer_1': 200, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 10.64% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 11.29% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:05:29,300]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:05:39,129]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:06:16,469]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:06:21,603]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:07:00,113]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:08:19,790]\u001b[0m Trial 881 finished with value: 3.468029263292611 and parameters: {'n_hidden': 3, 'learning_rate': 0.000500741912072444, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13839859903963003, 'dropout_rate_Layer_2': 0.010092017520079636, 'dropout_rate_Layer_3': 0.021969757244292187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014038350365792198, 'l1_Layer_2': 1.7088494138735883e-05, 'l1_Layer_3': 0.000772692575310965, 'n_units_Layer_1': 200, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 10.60% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 10.59% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:08:58,380]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:09:09,921]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:09:15,771]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:10:42,743]\u001b[0m Trial 885 finished with value: 3.4310088945101094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005055427218127994, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13609262157703428, 'dropout_rate_Layer_2': 0.012393488735089532, 'dropout_rate_Layer_3': 0.019182311540039312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001342884204378388, 'l1_Layer_2': 1.7444184361268755e-05, 'l1_Layer_3': 0.0010168513045980387, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 285}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 10.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 10.69% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:12:18,257]\u001b[0m Trial 886 finished with value: 3.43984489768577 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005032113616572186, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1381203192807738, 'dropout_rate_Layer_2': 0.010817408836224698, 'dropout_rate_Layer_3': 0.019855578898409526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013393211373096835, 'l1_Layer_2': 1.7447829247832352e-05, 'l1_Layer_3': 0.0009869143963370868, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 290}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 10.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 10.64% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:12:33,652]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:13:25,700]\u001b[0m Trial 888 finished with value: 4.078781727345962 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021714356737457543, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1416201232841926, 'dropout_rate_Layer_2': 0.24529709272780637, 'dropout_rate_Layer_3': 0.04875095663621288, 'dropout_rate_Layer_4': 0.16400903420435659, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00013259472039052041, 'l1_Layer_2': 0.0006810594190423748, 'l1_Layer_3': 0.008006815039943712, 'l1_Layer_4': 0.0035273279031778843, 'n_units_Layer_1': 100, 'n_units_Layer_2': 210, 'n_units_Layer_3': 50, 'n_units_Layer_4': 255}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 12.35% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.34 | sMAPE for Test Set is: 26.11% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:13:29,215]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:13:34,345]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:13:39,174]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:13:46,599]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:13:54,284]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:14:24,728]\u001b[0m Trial 894 finished with value: 3.85275719342507 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012066506182395135, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1028620658737126, 'dropout_rate_Layer_2': 0.36097053008535784, 'dropout_rate_Layer_3': 0.13491420992161568, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.009109825740256778, 'l1_Layer_2': 2.5808752797411268e-05, 'l1_Layer_3': 2.7295814326439497e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 160, 'n_units_Layer_3': 255}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.82 | sMAPE for Test Set is: 22.72% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:14:29,669]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:15:45,420]\u001b[0m Trial 896 finished with value: 3.482351095782978 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005008289393879465, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13154439984361818, 'dropout_rate_Layer_2': 0.0006491034966393462, 'dropout_rate_Layer_3': 0.019958787489908772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017808773851814134, 'l1_Layer_2': 2.0213799512438233e-05, 'l1_Layer_3': 0.0008561151597560928, 'n_units_Layer_1': 200, 'n_units_Layer_2': 85, 'n_units_Layer_3': 290}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 10.57% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:15:56,306]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:16:00,329]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:17:23,518]\u001b[0m Trial 899 finished with value: 3.4354348354765825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005006428735425322, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13853266996987815, 'dropout_rate_Layer_2': 0.016958529180166604, 'dropout_rate_Layer_3': 0.029707018243355816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018624995468126905, 'l1_Layer_2': 1.5505950548643826e-05, 'l1_Layer_3': 0.0009719831677963281, 'n_units_Layer_1': 190, 'n_units_Layer_2': 90, 'n_units_Layer_3': 290}. Best is trial 866 with value: 3.4282958860215302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 10.66% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:18:49,785]\u001b[0m Trial 900 finished with value: 3.4249326714279484 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005617869922502085, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12909021019256037, 'dropout_rate_Layer_2': 0.016525712965892586, 'dropout_rate_Layer_3': 0.02864724270630284, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018767944709029402, 'l1_Layer_2': 1.8864738188694478e-05, 'l1_Layer_3': 0.001007020982737311, 'n_units_Layer_1': 190, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290}. Best is trial 900 with value: 3.4249326714279484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 10.48% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 10.61% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:18:53,616]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:20:23,132]\u001b[0m Trial 902 finished with value: 3.404476385422925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005890705201516906, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1369219571254199, 'dropout_rate_Layer_2': 0.020042174677039767, 'dropout_rate_Layer_3': 0.008428485264107204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017137103440032113, 'l1_Layer_2': 1.8378937038636733e-05, 'l1_Layer_3': 0.000709634050911779, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 300}. Best is trial 902 with value: 3.404476385422925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.40 | sMAPE for Validation Set is: 10.40% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 10.54% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:20:26,564]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:21:22,732]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:21:26,648]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:22:04,873]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:23:09,615]\u001b[0m Trial 907 finished with value: 4.060864725587977 and parameters: {'n_hidden': 4, 'learning_rate': 0.00222169527228701, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1640820474173279, 'dropout_rate_Layer_2': 0.2441949193104718, 'dropout_rate_Layer_3': 0.044644779453903535, 'dropout_rate_Layer_4': 0.1784151046623081, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00019451453177508131, 'l1_Layer_2': 0.0009191764936082918, 'l1_Layer_3': 0.01042844902904792, 'l1_Layer_4': 0.0033914875305587006, 'n_units_Layer_1': 85, 'n_units_Layer_2': 205, 'n_units_Layer_3': 50, 'n_units_Layer_4': 265}. Best is trial 902 with value: 3.404476385422925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.98 | sMAPE for Test Set is: 25.20% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:23:15,208]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:24:52,397]\u001b[0m Trial 909 finished with value: 3.439225332506098 and parameters: {'n_hidden': 3, 'learning_rate': 0.000500531319712043, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12990279136038338, 'dropout_rate_Layer_2': 0.018190118361524475, 'dropout_rate_Layer_3': 0.020584820366947604, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015050106042591654, 'l1_Layer_2': 1.471969250790517e-05, 'l1_Layer_3': 0.0006117755719493109, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295}. Best is trial 902 with value: 3.404476385422925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 10.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 10.75% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:24:55,778]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:26:46,020]\u001b[0m Trial 911 finished with value: 3.4690172356333817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005021691829931355, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11875678499676716, 'dropout_rate_Layer_2': 0.017308776164684438, 'dropout_rate_Layer_3': 0.016574835978337654, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020482716300559118, 'l1_Layer_2': 1.4983036401287478e-05, 'l1_Layer_3': 0.0006030296272876997, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295}. Best is trial 902 with value: 3.404476385422925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 10.60% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.60 | sMAPE for Test Set is: 10.54% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:28:09,967]\u001b[0m Trial 912 finished with value: 3.448533518920397 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005110558125666687, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12064114073054548, 'dropout_rate_Layer_2': 0.007953974113622298, 'dropout_rate_Layer_3': 0.01602624394848401, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001906272692999834, 'l1_Layer_2': 1.4728729705656007e-05, 'l1_Layer_3': 0.0005650601299155047, 'n_units_Layer_1': 190, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290}. Best is trial 902 with value: 3.404476385422925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 10.57% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.60 | sMAPE for Test Set is: 10.56% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:29:04,196]\u001b[0m Trial 913 finished with value: 3.453845238592372 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005107710137978844, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12018306109057765, 'dropout_rate_Layer_2': 0.0005420843295746776, 'dropout_rate_Layer_3': 0.015449228599746767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002070911051442176, 'l1_Layer_2': 1.4619709353618562e-05, 'l1_Layer_3': 0.000560131815807185, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 285}. Best is trial 902 with value: 3.404476385422925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 10.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.75 | sMAPE for Test Set is: 10.98% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:29:09,712]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:30:06,427]\u001b[0m Trial 915 finished with value: 3.4337334648102136 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005018894313237275, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11809310041014813, 'dropout_rate_Layer_2': 0.00574655578842417, 'dropout_rate_Layer_3': 0.00013494883889446016, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002127591781031774, 'l1_Layer_2': 1.396014052874996e-05, 'l1_Layer_3': 0.0005722039087531893, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 295}. Best is trial 902 with value: 3.404476385422925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 10.52% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 10.79% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:30:12,346]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:31:39,032]\u001b[0m Trial 917 finished with value: 3.410474081934053 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005050554348424981, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1252128069055396, 'dropout_rate_Layer_2': 0.005534284775528647, 'dropout_rate_Layer_3': 0.0002547205476988892, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001960082783905583, 'l1_Layer_2': 1.4041734167646314e-05, 'l1_Layer_3': 0.0005970035692648675, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 295}. Best is trial 902 with value: 3.404476385422925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.41 | sMAPE for Validation Set is: 10.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 10.61% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:31:53,211]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:31:56,718]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:32:20,636]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:34:06,548]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:34:44,131]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:34:58,541]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:35:03,584]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:35:57,706]\u001b[0m Trial 925 finished with value: 3.394309903807258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005100692072691195, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1189403090794374, 'dropout_rate_Layer_2': 0.008183177619692191, 'dropout_rate_Layer_3': 0.001749892226309938, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019031206205277903, 'l1_Layer_2': 1.0154780472143351e-05, 'l1_Layer_3': 0.0005201336324675908, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 295}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.39 | sMAPE for Validation Set is: 10.39% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 10.62% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:37:22,652]\u001b[0m Trial 926 finished with value: 3.4477957817695657 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005219032928771171, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11731916927372205, 'dropout_rate_Layer_2': 0.0079001033801837, 'dropout_rate_Layer_3': 0.00028466296141734307, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021341992047855458, 'l1_Layer_2': 1.6716459028983444e-05, 'l1_Layer_3': 0.0004917032871851, 'n_units_Layer_1': 180, 'n_units_Layer_2': 105, 'n_units_Layer_3': 300}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 10.55% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 10.98% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:37:26,312]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:37:31,058]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:38:25,888]\u001b[0m Trial 929 finished with value: 3.431452726465363 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005069487448970556, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1189277473782274, 'dropout_rate_Layer_2': 0.008366989009016237, 'dropout_rate_Layer_3': 0.015195945374918607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025143268351566724, 'l1_Layer_2': 1.3395537766009926e-05, 'l1_Layer_3': 0.0005242895298498459, 'n_units_Layer_1': 185, 'n_units_Layer_2': 100, 'n_units_Layer_3': 295}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 10.48% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 10.91% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:39:15,293]\u001b[0m Trial 930 finished with value: 3.4267867473561453 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005039779906606429, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1189615969135262, 'dropout_rate_Layer_2': 0.007938475697924422, 'dropout_rate_Layer_3': 0.0006402121775114268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017847772421950033, 'l1_Layer_2': 1.3255024283161859e-05, 'l1_Layer_3': 0.0005422049342736506, 'n_units_Layer_1': 185, 'n_units_Layer_2': 100, 'n_units_Layer_3': 295}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 10.74% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:40:03,688]\u001b[0m Trial 931 finished with value: 3.4280146727615226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005010263222286803, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11744007610667874, 'dropout_rate_Layer_2': 0.00806044746872214, 'dropout_rate_Layer_3': 0.0005576583297601644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025377635239157864, 'l1_Layer_2': 1.2899644491186215e-05, 'l1_Layer_3': 0.0005028645654849679, 'n_units_Layer_1': 185, 'n_units_Layer_2': 100, 'n_units_Layer_3': 295}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 10.51% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.75 | sMAPE for Test Set is: 10.98% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:40:13,258]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:40:49,869]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:42:29,223]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:42:34,465]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:42:39,309]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:44:04,224]\u001b[0m Trial 937 finished with value: 3.471233231151126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005047040335671403, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1162581885674161, 'dropout_rate_Layer_2': 0.007846676560257615, 'dropout_rate_Layer_3': 0.0012462144380151509, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027622181000483187, 'l1_Layer_2': 1.3160107286486835e-05, 'l1_Layer_3': 0.00049992679431331, 'n_units_Layer_1': 185, 'n_units_Layer_2': 105, 'n_units_Layer_3': 295}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 10.60% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.70 | sMAPE for Test Set is: 10.77% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:44:08,275]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:44:24,320]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:45:22,025]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:45:27,859]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:46:25,403]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:48:19,515]\u001b[0m Trial 943 finished with value: 3.442321070992081 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005593321309405797, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12299934218097107, 'dropout_rate_Layer_2': 0.011811235180622721, 'dropout_rate_Layer_3': 0.011975275227568099, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027701899225784693, 'l1_Layer_2': 1.6693974713268104e-05, 'l1_Layer_3': 0.000574954087855468, 'n_units_Layer_1': 185, 'n_units_Layer_2': 100, 'n_units_Layer_3': 290}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 10.53% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 10.95% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:48:27,340]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:49:03,963]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:50:31,380]\u001b[0m Trial 946 finished with value: 3.433503689464022 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005010084408119773, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1228167026598085, 'dropout_rate_Layer_2': 0.010683216296731444, 'dropout_rate_Layer_3': 0.010357110414794545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002719533479851121, 'l1_Layer_2': 1.277136802356698e-05, 'l1_Layer_3': 0.0005879457818315126, 'n_units_Layer_1': 185, 'n_units_Layer_2': 105, 'n_units_Layer_3': 290}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 10.48% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 10.73% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:51:51,269]\u001b[0m Trial 947 finished with value: 3.433835890634988 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005840006998150658, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12288570702850485, 'dropout_rate_Layer_2': 0.019295160804353055, 'dropout_rate_Layer_3': 0.008332464406045476, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002683610769085628, 'l1_Layer_2': 1.0008044661157493e-05, 'l1_Layer_3': 0.00040006423398504266, 'n_units_Layer_1': 185, 'n_units_Layer_2': 105, 'n_units_Layer_3': 290}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 10.58% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:51:54,998]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:51:58,229]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:52:46,020]\u001b[0m Trial 950 finished with value: 3.4326527125386996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005002361087565586, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1164488995499105, 'dropout_rate_Layer_2': 0.016262428950484572, 'dropout_rate_Layer_3': 0.01056837979544687, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024076243800539557, 'l1_Layer_2': 1.366944763122994e-05, 'l1_Layer_3': 0.0004988330812245482, 'n_units_Layer_1': 170, 'n_units_Layer_2': 110, 'n_units_Layer_3': 300}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 10.57% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 10.78% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:52:53,432]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:54:09,923]\u001b[0m Trial 952 finished with value: 3.48244767084468 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005830056038940778, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12176254402409106, 'dropout_rate_Layer_2': 0.016437580499010736, 'dropout_rate_Layer_3': 0.009849712760622166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021766863225616267, 'l1_Layer_2': 1.0159883983169135e-05, 'l1_Layer_3': 0.000375705613983581, 'n_units_Layer_1': 170, 'n_units_Layer_2': 115, 'n_units_Layer_3': 300}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 10.63% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 10.63% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 16:54:26,748]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:54:31,206]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:54:35,723]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:55:26,400]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:55:41,099]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:55:46,270]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:56:42,454]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:57:04,361]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:57:20,031]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:57:27,688]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:58:07,120]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 16:59:05,036]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:00:34,703]\u001b[0m Trial 965 finished with value: 3.419211037343219 and parameters: {'n_hidden': 3, 'learning_rate': 0.000559693054775548, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11602775248591113, 'dropout_rate_Layer_2': 8.430643011970562e-05, 'dropout_rate_Layer_3': 0.015581126043389237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019371840883744838, 'l1_Layer_2': 1.2315745932899645e-05, 'l1_Layer_3': 0.0003643917242066845, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 290}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 10.44% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 10.79% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:00:45,047]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:00:52,416]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:02:22,938]\u001b[0m Trial 968 finished with value: 3.442900568610907 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005618129685792777, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11107135046059366, 'dropout_rate_Layer_2': 0.009656050095609929, 'dropout_rate_Layer_3': 0.025880101841591882, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002882716023456683, 'l1_Layer_2': 1.7437750788247425e-05, 'l1_Layer_3': 0.00042241886002673085, 'n_units_Layer_1': 180, 'n_units_Layer_2': 115, 'n_units_Layer_3': 290}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 10.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 10.74% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:03:18,492]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:04:11,785]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:04:14,696]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:04:53,993]\u001b[0m Trial 972 finished with value: 3.568417775244686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007573665535905097, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3722514895852368, 'dropout_rate_Layer_2': 0.10344340738857953, 'dropout_rate_Layer_3': 0.30801153465943654, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006959102661336903, 'l1_Layer_2': 1.9959455879648802e-05, 'l1_Layer_3': 9.46122943846664e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 250}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 10.87% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 11.90% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:06:24,571]\u001b[0m Trial 973 finished with value: 3.419001601130825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005561815637645555, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12342984973993781, 'dropout_rate_Layer_2': 0.0007922898660336743, 'dropout_rate_Layer_3': 0.0012036865608525172, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019721854363375735, 'l1_Layer_2': 1.5142583207645045e-05, 'l1_Layer_3': 0.00031443585880604956, 'n_units_Layer_1': 180, 'n_units_Layer_2': 105, 'n_units_Layer_3': 295}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 10.43% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 10.76% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:06:30,707]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:07:41,681]\u001b[0m Trial 975 finished with value: 3.9943774500594684 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027849786471233575, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15653053323927163, 'dropout_rate_Layer_2': 0.17197070632150882, 'dropout_rate_Layer_3': 0.060076912467794, 'dropout_rate_Layer_4': 0.07206565942818961, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00018045433909803403, 'l1_Layer_2': 0.0005535389910984167, 'l1_Layer_3': 0.0008763258131582019, 'l1_Layer_4': 0.002422905023142654, 'n_units_Layer_1': 90, 'n_units_Layer_2': 210, 'n_units_Layer_3': 50, 'n_units_Layer_4': 260}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 12.10% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.21 | sMAPE for Test Set is: 23.30% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:08:36,952]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:08:41,957]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:08:53,562]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:08:57,191]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:09:00,106]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:09:04,146]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:09:08,192]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:09:17,743]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:09:20,888]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:09:28,345]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:09:35,743]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:10:09,025]\u001b[0m Trial 987 finished with value: 3.7350761621535598 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012552794371880748, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10816988652993076, 'dropout_rate_Layer_2': 0.33406917234497513, 'dropout_rate_Layer_3': 0.15670557487017917, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0039434473203654894, 'l1_Layer_2': 2.1926771119701187e-05, 'l1_Layer_3': 2.9437217046155587e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 160, 'n_units_Layer_3': 240}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 11.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.11 | sMAPE for Test Set is: 23.55% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:10:13,747]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:10:17,337]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:11:09,612]\u001b[0m Trial 990 finished with value: 3.43834467064735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005946120515135129, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12870510648140562, 'dropout_rate_Layer_2': 0.02233735092568537, 'dropout_rate_Layer_3': 0.012793913177320577, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002258746280758561, 'l1_Layer_2': 1.1795549931744854e-05, 'l1_Layer_3': 0.0003690865336641447, 'n_units_Layer_1': 190, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 10.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 10.50% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:12:03,193]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:13:44,049]\u001b[0m Trial 992 finished with value: 4.0001199948920885 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032271620990021606, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13532614289198017, 'dropout_rate_Layer_2': 0.23669509653423934, 'dropout_rate_Layer_3': 0.07503292269783579, 'dropout_rate_Layer_4': 0.0665248344968972, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00028643906751772, 'l1_Layer_2': 0.0005467408689820276, 'l1_Layer_3': 0.0008786157541637253, 'l1_Layer_4': 0.004080098857759615, 'n_units_Layer_1': 185, 'n_units_Layer_2': 210, 'n_units_Layer_3': 65, 'n_units_Layer_4': 275}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.96 | sMAPE for Test Set is: 25.17% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:13:50,405]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:13:53,837]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:14:31,737]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:14:41,118]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:16:07,189]\u001b[0m Trial 997 finished with value: 3.959100430637765 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022615297263926704, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13699523938914915, 'dropout_rate_Layer_2': 0.12687576648786653, 'dropout_rate_Layer_3': 0.07566326307864435, 'dropout_rate_Layer_4': 0.07532745467220572, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00022998722979478657, 'l1_Layer_2': 0.0006051681150435818, 'l1_Layer_3': 0.0011624883619513018, 'l1_Layer_4': 0.0033554286614451544, 'n_units_Layer_1': 150, 'n_units_Layer_2': 215, 'n_units_Layer_3': 60, 'n_units_Layer_4': 285}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 12.04% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.36 | sMAPE for Test Set is: 23.70% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:17:02,466]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:17:36,986]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:17:40,408]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:18:36,024]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:19:37,865]\u001b[0m Trial 1002 finished with value: 3.472397076244461 and parameters: {'n_hidden': 3, 'learning_rate': 0.000500274948203862, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11604763761330779, 'dropout_rate_Layer_2': 0.011041908718092089, 'dropout_rate_Layer_3': 0.029807220582510886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00035630405743200376, 'l1_Layer_2': 1.2435234844503816e-05, 'l1_Layer_3': 0.0003410067038329715, 'n_units_Layer_1': 185, 'n_units_Layer_2': 95, 'n_units_Layer_3': 285}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 10.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 10.82% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:20:34,133]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:21:29,571]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:23:06,516]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:24:02,745]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:24:08,863]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:25:03,747]\u001b[0m Trial 1008 finished with value: 3.438204838936555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006012105779261963, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10720849907288964, 'dropout_rate_Layer_2': 0.009186486420584665, 'dropout_rate_Layer_3': 0.016830925953065286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001589210891253885, 'l1_Layer_2': 1.6577147521074282e-05, 'l1_Layer_3': 0.000569358086495476, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 295}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 10.59% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 11.04% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:25:20,561]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:26:50,253]\u001b[0m Trial 1010 finished with value: 3.630496002517821 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012979723202946778, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1452108494558892, 'dropout_rate_Layer_2': 0.3449354086236179, 'dropout_rate_Layer_3': 0.16781119814492815, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00317760391278769, 'l1_Layer_2': 3.9906792235967415e-05, 'l1_Layer_3': 1.262019107169466e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 165, 'n_units_Layer_3': 185}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 11.09% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.20 | sMAPE for Test Set is: 21.24% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:28:23,466]\u001b[0m Trial 1011 finished with value: 3.986536067859643 and parameters: {'n_hidden': 4, 'learning_rate': 0.002963350534030972, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1551448999695024, 'dropout_rate_Layer_2': 0.11539990040282178, 'dropout_rate_Layer_3': 0.06467728888436226, 'dropout_rate_Layer_4': 0.07667688818296242, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003217326339042666, 'l1_Layer_2': 0.0034307149800909655, 'l1_Layer_3': 0.0010770667200443865, 'l1_Layer_4': 0.006153141758212306, 'n_units_Layer_1': 80, 'n_units_Layer_2': 215, 'n_units_Layer_3': 60, 'n_units_Layer_4': 290}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 12.13% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.72 | sMAPE for Test Set is: 24.75% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:28:27,036]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:28:30,948]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:28:40,162]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:29:37,857]\u001b[0m Trial 1015 finished with value: 3.4482015448575574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006678303633349508, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10646648022933096, 'dropout_rate_Layer_2': 4.5050444355917985e-05, 'dropout_rate_Layer_3': 0.015341924261815975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021014565523622754, 'l1_Layer_2': 2.0270243204565703e-05, 'l1_Layer_3': 0.00043298113663085846, 'n_units_Layer_1': 175, 'n_units_Layer_2': 90, 'n_units_Layer_3': 285}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 10.58% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 11.57% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:30:00,365]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:30:04,267]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:31:10,081]\u001b[0m Trial 1018 finished with value: 3.751306271575238 and parameters: {'n_hidden': 3, 'learning_rate': 0.002041559183586727, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14811351248068128, 'dropout_rate_Layer_2': 0.3471060291349302, 'dropout_rate_Layer_3': 0.12026141694415002, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003392545441963008, 'l1_Layer_2': 4.166188508329587e-05, 'l1_Layer_3': 1.1239018085703744e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.36 | sMAPE for Test Set is: 24.35% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:32:03,947]\u001b[0m Trial 1019 finished with value: 3.421736584053803 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006847248296729225, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10913595709377526, 'dropout_rate_Layer_2': 0.0003670297694459944, 'dropout_rate_Layer_3': 0.0075732463329681535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001572864872365253, 'l1_Layer_2': 1.6811770048961305e-05, 'l1_Layer_3': 0.00033843952571718463, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 10.49% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 11.12% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:33:48,571]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:33:53,321]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:34:53,574]\u001b[0m Trial 1022 finished with value: 4.025807967807549 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029076056857397906, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14611414301483203, 'dropout_rate_Layer_2': 0.07653884397340274, 'dropout_rate_Layer_3': 0.08011393371107198, 'dropout_rate_Layer_4': 0.07423359803275403, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003306775996292932, 'l1_Layer_2': 0.00041013738109503566, 'l1_Layer_3': 0.0009190378316880514, 'l1_Layer_4': 0.005812535082387132, 'n_units_Layer_1': 150, 'n_units_Layer_2': 215, 'n_units_Layer_3': 60, 'n_units_Layer_4': 285}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 24.88% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:35:00,807]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:35:04,353]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:35:08,157]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:35:47,054]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:35:51,045]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:37:20,472]\u001b[0m Trial 1028 finished with value: 3.440142857722064 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006734606787187074, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1259062732419874, 'dropout_rate_Layer_2': 0.01827616698465867, 'dropout_rate_Layer_3': 0.035243231495056496, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046443544495991865, 'l1_Layer_2': 1.9561596022010986e-05, 'l1_Layer_3': 0.0007207559225036058, 'n_units_Layer_1': 190, 'n_units_Layer_2': 100, 'n_units_Layer_3': 275}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 10.52% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.75 | sMAPE for Test Set is: 10.84% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:37:28,417]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:37:35,846]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:37:39,893]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:37:47,533]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:39:27,531]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:39:32,061]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:40:28,173]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:42:36,205]\u001b[0m Trial 1036 finished with value: 3.513212596937265 and parameters: {'n_hidden': 3, 'learning_rate': 0.000650491627848756, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12235097367471139, 'dropout_rate_Layer_2': 0.007910308495504514, 'dropout_rate_Layer_3': 0.03457471078328979, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026933795085927025, 'l1_Layer_2': 1.9373276159198617e-05, 'l1_Layer_3': 0.0007683805332331453, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 290}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.51 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 11.27% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:42:39,898]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:42:53,896]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:43:31,058]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:44:11,509]\u001b[0m Trial 1040 finished with value: 3.601893838237783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012880867818073503, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36245026948434805, 'dropout_rate_Layer_2': 0.10570518499881955, 'dropout_rate_Layer_3': 0.3701635577514693, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00048394514325170846, 'l1_Layer_2': 8.48739247901076e-05, 'l1_Layer_3': 0.00016542816237106686, 'n_units_Layer_1': 285, 'n_units_Layer_2': 295, 'n_units_Layer_3': 260}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 10.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.29 | sMAPE for Test Set is: 21.19% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:44:49,986]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:44:57,917]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:45:51,152]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:46:38,541]\u001b[0m Trial 1044 finished with value: 3.678280790016416 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016719111540840783, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1284755848866145, 'dropout_rate_Layer_2': 0.3707395930065658, 'dropout_rate_Layer_3': 0.09996326423952927, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004023915977900257, 'l1_Layer_2': 2.9064416283894144e-05, 'l1_Layer_3': 1.79712705770184e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 190, 'n_units_Layer_3': 170}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 11.16% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.21 | sMAPE for Test Set is: 23.69% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:46:42,387]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:47:03,728]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:47:07,344]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:47:17,450]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:47:26,568]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:47:33,807]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:47:37,717]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:48:45,850]\u001b[0m Trial 1052 finished with value: 3.471374835481857 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007038249500891981, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11327401728708827, 'dropout_rate_Layer_2': 0.024879016155169187, 'dropout_rate_Layer_3': 0.01650885938692451, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002249572785841476, 'l1_Layer_2': 1.00252089175294e-05, 'l1_Layer_3': 0.0008135599790383822, 'n_units_Layer_1': 195, 'n_units_Layer_2': 115, 'n_units_Layer_3': 295}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 10.67% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 10.66% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:48:50,923]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:48:58,915]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:49:06,320]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:49:11,381]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:50:36,667]\u001b[0m Trial 1057 finished with value: 3.703477040833379 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016640153415598143, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1299101882424399, 'dropout_rate_Layer_2': 0.3552223521697339, 'dropout_rate_Layer_3': 0.08076398744449212, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004174255305964443, 'l1_Layer_2': 2.1348642921747087e-05, 'l1_Layer_3': 2.025363395855942e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 190, 'n_units_Layer_3': 195}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 11.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.29 | sMAPE for Test Set is: 23.48% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:50:40,226]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:51:07,292]\u001b[0m Trial 1059 finished with value: 3.558515273259338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017131524535912953, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13150535088223972, 'dropout_rate_Layer_2': 0.35745796874699454, 'dropout_rate_Layer_3': 0.08348008258664665, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003237582315353775, 'l1_Layer_2': 3.177094141012023e-05, 'l1_Layer_3': 1.991806139264921e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 190, 'n_units_Layer_3': 175}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 10.87% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.21 | sMAPE for Test Set is: 21.31% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:51:43,069]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:53:23,231]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:55:00,932]\u001b[0m Trial 1062 finished with value: 3.9771347044699685 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028641897327327417, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12728775166282005, 'dropout_rate_Layer_2': 0.06473182529051509, 'dropout_rate_Layer_3': 0.13032722232427138, 'dropout_rate_Layer_4': 0.08954243805646078, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0012730808145464485, 'l1_Layer_2': 0.0006183846853567206, 'l1_Layer_3': 0.002707901215780745, 'l1_Layer_4': 0.0022473457161094144, 'n_units_Layer_1': 180, 'n_units_Layer_2': 235, 'n_units_Layer_3': 60, 'n_units_Layer_4': 270}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 24.35% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:55:10,726]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:56:02,141]\u001b[0m Trial 1064 finished with value: 3.442477626110145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006286591427701823, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11851750125825576, 'dropout_rate_Layer_2': 0.02264418712752124, 'dropout_rate_Layer_3': 0.01058525482359798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020366987869695148, 'l1_Layer_2': 1.204078506129037e-05, 'l1_Layer_3': 0.00038952350534778566, 'n_units_Layer_1': 190, 'n_units_Layer_2': 90, 'n_units_Layer_3': 280}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 10.55% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 10.71% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 17:56:16,910]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:56:21,683]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:58:08,886]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:58:45,953]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 17:59:41,942]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:00:21,656]\u001b[0m Trial 1070 finished with value: 3.7325139553853255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020029710934437455, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16095467237696362, 'dropout_rate_Layer_2': 0.36870442190937314, 'dropout_rate_Layer_3': 0.07222961222960152, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0035701270708951727, 'l1_Layer_2': 2.2895378064524555e-05, 'l1_Layer_3': 1.1455186619432658e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 200, 'n_units_Layer_3': 155}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 11.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.12 | sMAPE for Test Set is: 21.34% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:00:27,324]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:00:31,849]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:00:39,843]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:01:33,511]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:02:13,845]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:02:19,625]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:03:14,071]\u001b[0m Trial 1077 finished with value: 3.4861765512097036 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006151914008077305, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1311750528977211, 'dropout_rate_Layer_2': 0.015575226017056548, 'dropout_rate_Layer_3': 9.099498239562714e-06, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001617141304419819, 'l1_Layer_2': 1.0144371590721861e-05, 'l1_Layer_3': 0.0006726863126217771, 'n_units_Layer_1': 185, 'n_units_Layer_2': 105, 'n_units_Layer_3': 275}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.49 | sMAPE for Validation Set is: 10.71% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 11.07% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:03:17,210]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:03:22,364]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:04:58,896]\u001b[0m Trial 1080 finished with value: 4.045820736068144 and parameters: {'n_hidden': 4, 'learning_rate': 0.004910589160061808, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12741605754420707, 'dropout_rate_Layer_2': 0.17202575959091462, 'dropout_rate_Layer_3': 0.08787814626195967, 'dropout_rate_Layer_4': 0.09404551152901423, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00022506198724604805, 'l1_Layer_2': 0.0007312453188068024, 'l1_Layer_3': 0.0005732241947163183, 'l1_Layer_4': 0.0017055963685023684, 'n_units_Layer_1': 180, 'n_units_Layer_2': 200, 'n_units_Layer_3': 60, 'n_units_Layer_4': 180}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.93 | sMAPE for Test Set is: 22.60% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:05:02,899]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:05:54,510]\u001b[0m Trial 1082 finished with value: 3.4254003817631102 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005568489181632755, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12661157528515177, 'dropout_rate_Layer_2': 0.021003576601275963, 'dropout_rate_Layer_3': 0.03619806644851027, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00033598805726326407, 'l1_Layer_2': 5.619556365615937e-05, 'l1_Layer_3': 0.0003996199103613622, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 280}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 10.55% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:05:58,124]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:06:01,838]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:06:47,461]\u001b[0m Trial 1085 finished with value: 3.560104226266871 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007045209107725482, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3751332821339967, 'dropout_rate_Layer_2': 0.07443256569361983, 'dropout_rate_Layer_3': 0.3047822319962997, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007149333400156962, 'l1_Layer_2': 2.053999807989699e-05, 'l1_Layer_3': 9.014296245641721e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 230, 'n_units_Layer_3': 250}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 10.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 12.16% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:07:06,475]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:08:01,424]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:08:18,014]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:08:28,726]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:08:32,614]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:08:39,134]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:08:42,536]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:09:38,974]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:09:44,324]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:09:48,455]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:10:11,455]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:10:16,922]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:10:20,819]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:10:25,007]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:10:28,889]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:10:32,773]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:10:35,695]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:10:49,617]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:10:53,103]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:10:56,862]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:11:16,021]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:11:19,783]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:11:23,497]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:11:27,446]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:11:34,625]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:11:49,117]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:12:27,520]\u001b[0m Trial 1112 finished with value: 3.499421933061362 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011457076725648197, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15309082229459148, 'dropout_rate_Layer_2': 0.3401248740502052, 'dropout_rate_Layer_3': 0.10422205579115439, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013979256511986026, 'l1_Layer_2': 9.332284687695924e-05, 'l1_Layer_3': 1.9097591338830452e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 190, 'n_units_Layer_3': 190}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 10.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.43 | sMAPE for Test Set is: 21.60% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:12:36,037]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:12:43,151]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:12:52,549]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:12:59,617]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:13:04,461]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:13:25,396]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:13:35,999]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:13:39,176]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:13:44,056]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:13:49,174]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:14:31,974]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:14:35,903]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:14:39,854]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:15:29,019]\u001b[0m Trial 1126 finished with value: 3.4245411131235475 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005033837767501642, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11463515128806832, 'dropout_rate_Layer_2': 0.022104692828233345, 'dropout_rate_Layer_3': 0.0080458138050726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014958560653274356, 'l1_Layer_2': 1.231461327743107e-05, 'l1_Layer_3': 0.00017580031320922336, 'n_units_Layer_1': 185, 'n_units_Layer_2': 95, 'n_units_Layer_3': 295}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 10.49% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.64 | sMAPE for Test Set is: 10.69% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:15:33,126]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:15:56,475]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:17:07,469]\u001b[0m Trial 1129 finished with value: 3.553427449280545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005050264090508073, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3788065119701517, 'dropout_rate_Layer_2': 0.12390092714716298, 'dropout_rate_Layer_3': 0.34238813376508226, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005411721320811027, 'l1_Layer_2': 2.622119640186661e-05, 'l1_Layer_3': 0.0004030752924783196, 'n_units_Layer_1': 210, 'n_units_Layer_2': 245, 'n_units_Layer_3': 285}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 10.85% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 11.76% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:17:15,200]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:17:18,817]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:17:22,728]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:17:28,553]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:17:35,744]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:17:46,022]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:18:42,010]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:18:56,135]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:18:59,851]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:20:20,622]\u001b[0m Trial 1139 finished with value: 3.7147325136230864 and parameters: {'n_hidden': 3, 'learning_rate': 0.001049913363591306, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12941661528032058, 'dropout_rate_Layer_2': 0.35788351870491014, 'dropout_rate_Layer_3': 0.08168179397140546, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002027227323803857, 'l1_Layer_2': 8.164066891015841e-05, 'l1_Layer_3': 3.335976323812889e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 185, 'n_units_Layer_3': 175}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 11.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.12 | sMAPE for Test Set is: 23.31% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:20:26,139]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:20:52,899]\u001b[0m Trial 1141 finished with value: 3.514832573505309 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014459080762746752, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17576821843175663, 'dropout_rate_Layer_2': 0.31681198159889135, 'dropout_rate_Layer_3': 0.11296935410767193, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013763071403855285, 'l1_Layer_2': 1.2953614443144511e-05, 'l1_Layer_3': 1.3197288756102328e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 190, 'n_units_Layer_3': 190}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.51 | sMAPE for Validation Set is: 10.76% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.94 | sMAPE for Test Set is: 20.68% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:20:56,609]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:21:08,854]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:21:17,963]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:21:21,686]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:23:02,806]\u001b[0m Trial 1146 finished with value: 3.927988078261221 and parameters: {'n_hidden': 4, 'learning_rate': 0.003529415289117422, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15978477802951516, 'dropout_rate_Layer_2': 0.2075863714362958, 'dropout_rate_Layer_3': 0.06540565996602507, 'dropout_rate_Layer_4': 0.06847154579149048, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0002828167144693698, 'l1_Layer_2': 0.00045057403440623646, 'l1_Layer_3': 0.0006870771983550532, 'l1_Layer_4': 0.003594265532347033, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 60, 'n_units_Layer_4': 280}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.90 | sMAPE for Test Set is: 22.73% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:23:19,527]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:23:24,637]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:23:27,933]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:23:31,609]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:23:47,217]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:23:50,966]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:23:54,004]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:24:04,202]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:24:26,671]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:24:30,859]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:24:35,616]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:24:39,174]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:24:44,750]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:24:54,222]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:25:03,005]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:25:22,285]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:25:27,805]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:25:31,420]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:25:36,129]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:25:41,823]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:26:35,903]\u001b[0m Trial 1167 finished with value: 3.564065983757182 and parameters: {'n_hidden': 3, 'learning_rate': 0.000612704815424486, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005537439459692428, 'dropout_rate_Layer_2': 0.2847513355968488, 'dropout_rate_Layer_3': 0.008436274255912589, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014180109300496687, 'l1_Layer_2': 5.143023828963461e-05, 'l1_Layer_3': 0.0007758685859401212, 'n_units_Layer_1': 185, 'n_units_Layer_2': 100, 'n_units_Layer_3': 275}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 10.94% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 11.57% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:26:39,717]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:27:16,224]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:27:20,462]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:27:29,778]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:27:35,833]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:28:09,920]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:28:25,346]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:28:36,268]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:29:16,949]\u001b[0m Trial 1176 finished with value: 3.4839514425169376 and parameters: {'n_hidden': 3, 'learning_rate': 0.000993004102827901, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1928624222567787, 'dropout_rate_Layer_2': 0.3654443931922153, 'dropout_rate_Layer_3': 0.05567476409149376, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018419093704228281, 'l1_Layer_2': 4.462171149734637e-05, 'l1_Layer_3': 2.6034147318091616e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 210, 'n_units_Layer_3': 200}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 10.64% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.81 | sMAPE for Test Set is: 20.29% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:29:56,054]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:30:35,108]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:30:38,809]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:31:17,005]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:31:33,350]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:31:37,388]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:31:43,013]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:31:50,226]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:31:53,175]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:32:43,820]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:32:54,959]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:32:58,688]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:33:02,155]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:33:06,256]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:33:10,041]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:33:29,067]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:34:05,559]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:34:10,482]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:34:15,147]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:34:18,868]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:34:28,291]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:36:26,945]\u001b[0m Trial 1198 finished with value: 3.4539847671031065 and parameters: {'n_hidden': 3, 'learning_rate': 0.000549352260357623, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11345198331841472, 'dropout_rate_Layer_2': 0.029563493437808695, 'dropout_rate_Layer_3': 0.014973954586861765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002238868595918821, 'l1_Layer_2': 0.0045841338747096404, 'l1_Layer_3': 0.0006711715355548089, 'n_units_Layer_1': 190, 'n_units_Layer_2': 85, 'n_units_Layer_3': 300}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 10.56% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 10.74% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:37:06,953]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:37:15,834]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:37:19,231]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:37:23,303]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:37:33,820]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:39:26,228]\u001b[0m Trial 1204 finished with value: 3.464571948164668 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005008694069681242, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1276770705313496, 'dropout_rate_Layer_2': 0.008073872194306211, 'dropout_rate_Layer_3': 0.022982507235068755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014566016058834442, 'l1_Layer_2': 1.8407667240254e-05, 'l1_Layer_3': 0.0005856362409737507, 'n_units_Layer_1': 165, 'n_units_Layer_2': 120, 'n_units_Layer_3': 290}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.46 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 11.23% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:40:08,376]\u001b[0m Trial 1205 finished with value: 3.472649264570942 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009677393187866195, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19889562237635106, 'dropout_rate_Layer_2': 0.36403903849394076, 'dropout_rate_Layer_3': 0.0668992737052505, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009420893544010403, 'l1_Layer_2': 4.479815170436958e-05, 'l1_Layer_3': 2.646566664189824e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 225, 'n_units_Layer_3': 200}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.89 | sMAPE for Test Set is: 17.69% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:40:13,354]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:40:52,851]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:40:57,780]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:41:01,310]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:41:05,497]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:41:08,787]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:41:12,458]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:41:20,012]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:41:23,898]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:41:28,346]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:41:48,627]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:43:34,309]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:43:42,380]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:43:52,288]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:44:51,596]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:44:59,405]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:03,453]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:07,324]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:14,916]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:17,790]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:22,699]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:26,357]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:34,408]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:38,063]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:43,230]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:46,978]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:50,731]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:54,013]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:45:57,868]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:46:01,461]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:46:05,219]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:48:30,292]\u001b[0m Trial 1237 finished with value: 3.431880975100359 and parameters: {'n_hidden': 3, 'learning_rate': 0.000552324383354031, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11890320077658692, 'dropout_rate_Layer_2': 0.012887447186534551, 'dropout_rate_Layer_3': 0.006613666239194479, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020446775660059856, 'l1_Layer_2': 1.8464037959235396e-05, 'l1_Layer_3': 0.0014090648508127371, 'n_units_Layer_1': 170, 'n_units_Layer_2': 100, 'n_units_Layer_3': 290}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 10.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.64 | sMAPE for Test Set is: 10.61% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:48:45,805]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:49:08,012]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:49:11,707]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:49:48,573]\u001b[0m Trial 1241 finished with value: 3.554527724175479 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010505463144053824, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37134392715800413, 'dropout_rate_Layer_2': 0.11113751253705298, 'dropout_rate_Layer_3': 0.3528336776505659, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008347425652701087, 'l1_Layer_2': 3.599966621147779e-05, 'l1_Layer_3': 0.0001378993341886288, 'n_units_Layer_1': 210, 'n_units_Layer_2': 235, 'n_units_Layer_3': 215}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 10.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.83 | sMAPE for Test Set is: 20.09% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:49:55,561]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:50:30,740]\u001b[0m Trial 1243 finished with value: 3.539656820785622 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010880623524507364, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39875030743197626, 'dropout_rate_Layer_2': 0.11561770621557935, 'dropout_rate_Layer_3': 0.3504066974535229, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004727661499732691, 'l1_Layer_2': 3.5316907671183784e-05, 'l1_Layer_3': 0.00023007169841824418, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 210}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 10.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.97 | sMAPE for Test Set is: 20.35% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:51:14,829]\u001b[0m Trial 1244 finished with value: 3.573174827538389 and parameters: {'n_hidden': 3, 'learning_rate': 0.001087196174871064, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3921074590365758, 'dropout_rate_Layer_2': 0.10323950057133863, 'dropout_rate_Layer_3': 0.3848778580446803, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00039993554450177296, 'l1_Layer_2': 3.8166496152180836e-05, 'l1_Layer_3': 0.00025506568108390424, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 190}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.53 | sMAPE for Test Set is: 19.45% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:51:22,087]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:51:26,196]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:51:31,845]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:51:35,624]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:51:39,623]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:51:43,630]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:51:47,110]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:52:10,178]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:52:26,363]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:52:30,993]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:52:38,874]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:52:46,845]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:53:24,227]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:53:28,473]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:53:58,600]\u001b[0m Trial 1259 finished with value: 3.5343091185132884 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011887708289675463, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20379599482233754, 'dropout_rate_Layer_2': 0.36609599275305177, 'dropout_rate_Layer_3': 0.05820259281332759, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014748140414751973, 'l1_Layer_2': 8.301937680816975e-05, 'l1_Layer_3': 3.163076813498153e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 210, 'n_units_Layer_3': 205}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.53 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 17.82% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:54:02,561]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:54:06,608]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:54:10,607]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:54:14,334]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:54:52,107]\u001b[0m Trial 1264 finished with value: 3.4788348622872625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011610389580519746, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2089342356735382, 'dropout_rate_Layer_2': 0.3773394058568437, 'dropout_rate_Layer_3': 0.04893225650487958, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013907232215365543, 'l1_Layer_2': 7.579933970937514e-05, 'l1_Layer_3': 3.0468289257958766e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 210, 'n_units_Layer_3': 210}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 10.59% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.25 | sMAPE for Test Set is: 18.50% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:54:56,393]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:55:00,465]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:55:05,772]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:55:18,085]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:55:22,580]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:55:27,559]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:55:31,707]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:55:42,705]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:55:46,750]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:55:50,201]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:55:53,908]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:55:57,614]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:56:02,899]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:57:35,662]\u001b[0m Trial 1278 finished with value: 3.4594240861676036 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005456030928711088, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12497003494319806, 'dropout_rate_Layer_2': 0.014783139103410229, 'dropout_rate_Layer_3': 0.028917886986028096, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014559077335632052, 'l1_Layer_2': 0.003184704673016097, 'l1_Layer_3': 8.914178371001154e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 100, 'n_units_Layer_3': 290}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.46 | sMAPE for Validation Set is: 10.55% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 10.84% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:57:56,930]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:58:02,292]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:58:06,661]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:58:45,266]\u001b[0m Trial 1282 finished with value: 3.495026181982882 and parameters: {'n_hidden': 3, 'learning_rate': 0.001162157745618424, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20890024181918326, 'dropout_rate_Layer_2': 0.3788655860321687, 'dropout_rate_Layer_3': 0.04582672971000312, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001316453502860085, 'l1_Layer_2': 7.468802481591464e-05, 'l1_Layer_3': 2.731487153332691e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 210}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 10.71% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.73 | sMAPE for Test Set is: 17.35% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:58:52,495]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:59:30,698]\u001b[0m Trial 1284 finished with value: 3.5032979799382513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011476678305101821, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20194387726038848, 'dropout_rate_Layer_2': 0.3807877178913578, 'dropout_rate_Layer_3': 0.04644709749629048, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013460198996877778, 'l1_Layer_2': 8.171792598630752e-05, 'l1_Layer_3': 3.476444988968978e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 220}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 10.69% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.02 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 18:59:34,046]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 18:59:57,007]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:00:45,525]\u001b[0m Trial 1287 finished with value: 3.480548114496903 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009010921277398579, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20858184318719894, 'dropout_rate_Layer_2': 0.38142706450909153, 'dropout_rate_Layer_3': 0.04014394356538178, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001270511880254894, 'l1_Layer_2': 7.918253593991848e-05, 'l1_Layer_3': 3.291461207546736e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 235, 'n_units_Layer_3': 220}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 10.64% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.70 | sMAPE for Test Set is: 17.31% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:01:00,521]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:01:16,986]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:01:22,466]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:01:44,157]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:02:04,436]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:02:08,347]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:02:12,096]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:02:15,540]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:02:28,009]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:02:36,043]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:02:51,645]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:02:56,949]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:03:01,675]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:03:05,462]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:03:13,410]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:04:10,222]\u001b[0m Trial 1303 finished with value: 3.4741942718308727 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009391288785537448, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2024484640501494, 'dropout_rate_Layer_2': 0.3813085626426302, 'dropout_rate_Layer_3': 0.037395340768332716, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009036131780505811, 'l1_Layer_2': 9.116911420878144e-05, 'l1_Layer_3': 4.386494472745289e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 220, 'n_units_Layer_3': 210}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.80 | sMAPE for Test Set is: 17.64% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:04:48,738]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:04:52,547]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:04:56,117]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:04:59,479]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:05:39,332]\u001b[0m Trial 1308 finished with value: 3.4117962971390736 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007875211631451341, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0948503091420277, 'dropout_rate_Layer_2': 0.0005306991932171644, 'dropout_rate_Layer_3': 0.025321186221906163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002107214335485504, 'l1_Layer_2': 2.3511570529204168e-05, 'l1_Layer_3': 0.00015699336388961095, 'n_units_Layer_1': 185, 'n_units_Layer_2': 105, 'n_units_Layer_3': 285}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.41 | sMAPE for Validation Set is: 10.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 10.56% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:05:42,433]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:05:47,183]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:05:50,404]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:05:54,577]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:06:02,306]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:06:23,652]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:06:31,927]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:06:39,876]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:06:44,885]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:07:00,035]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:07:45,439]\u001b[0m Trial 1319 finished with value: 3.4766123503768465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011679486371609813, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21163733541967164, 'dropout_rate_Layer_2': 0.3763463306933946, 'dropout_rate_Layer_3': 0.030339112615916902, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001443972025374872, 'l1_Layer_2': 7.355954239747106e-05, 'l1_Layer_3': 2.7709051936444818e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 230, 'n_units_Layer_3': 220}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 10.60% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.79 | sMAPE for Test Set is: 17.63% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:07:53,447]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:08:52,715]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:08:57,396]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:09:33,291]\u001b[0m Trial 1323 finished with value: 3.534425845061822 and parameters: {'n_hidden': 3, 'learning_rate': 0.001275967408820357, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36628882039969, 'dropout_rate_Layer_2': 0.13011829969318578, 'dropout_rate_Layer_3': 0.3341310515528545, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00033781611535421485, 'l1_Layer_2': 6.0953777616498785e-05, 'l1_Layer_3': 0.00019316854899090847, 'n_units_Layer_1': 230, 'n_units_Layer_2': 240, 'n_units_Layer_3': 240}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.53 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.72 | sMAPE for Test Set is: 19.76% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:10:01,840]\u001b[0m Trial 1324 finished with value: 3.519477968242581 and parameters: {'n_hidden': 3, 'learning_rate': 0.001171938590986478, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.210455697561162, 'dropout_rate_Layer_2': 0.3796897121672504, 'dropout_rate_Layer_3': 0.019875969146751025, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013772564406381916, 'l1_Layer_2': 7.735298210207455e-05, 'l1_Layer_3': 2.887984625379162e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 230}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 10.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.75 | sMAPE for Test Set is: 17.34% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:10:05,607]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:10:09,155]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:10:52,744]\u001b[0m Trial 1327 finished with value: 3.5153627722267777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011727622192472301, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20782796059505831, 'dropout_rate_Layer_2': 0.38170782803110787, 'dropout_rate_Layer_3': 0.021916126601151033, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001266863539745254, 'l1_Layer_2': 8.055494053944825e-05, 'l1_Layer_3': 2.9878602332564394e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 230, 'n_units_Layer_3': 235}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 10.73% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.15 | sMAPE for Test Set is: 18.39% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:10:59,818]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:11:03,580]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:11:19,438]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:11:22,937]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:12:05,905]\u001b[0m Trial 1332 finished with value: 3.5250462455056897 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008851346132253993, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.210802805400573, 'dropout_rate_Layer_2': 0.38235652578854523, 'dropout_rate_Layer_3': 0.019403812899694537, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013046162313212477, 'l1_Layer_2': 8.312205315088996e-05, 'l1_Layer_3': 2.8891737192156862e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 245, 'n_units_Layer_3': 235}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.53 | sMAPE for Validation Set is: 10.74% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 17.04% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:12:14,541]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:12:54,019]\u001b[0m Trial 1334 finished with value: 3.5205167090648595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009139480195535039, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21169417608527358, 'dropout_rate_Layer_2': 0.3994368277453802, 'dropout_rate_Layer_3': 0.018708829472062156, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009665222569769995, 'l1_Layer_2': 0.00010956678188049485, 'l1_Layer_3': 2.9892352887160324e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 230, 'n_units_Layer_3': 235}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 10.75% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.98 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:12:58,310]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:13:02,107]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:13:23,840]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:13:27,824]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:13:31,381]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:13:59,026]\u001b[0m Trial 1340 finished with value: 3.5934073737657712 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014115373575180605, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3785420382149591, 'dropout_rate_Layer_2': 0.11745579945954228, 'dropout_rate_Layer_3': 0.3443927534414307, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003056234729183289, 'l1_Layer_2': 6.002157665621058e-05, 'l1_Layer_3': 0.0002169519162358986, 'n_units_Layer_1': 220, 'n_units_Layer_2': 240, 'n_units_Layer_3': 235}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.19 | sMAPE for Test Set is: 20.84% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:14:14,814]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:14:19,660]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:14:23,553]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:15:04,676]\u001b[0m Trial 1344 finished with value: 3.5647445684482704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012158477510766051, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3893411098813367, 'dropout_rate_Layer_2': 0.12573174960418218, 'dropout_rate_Layer_3': 0.3336974177460406, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00038671080562592016, 'l1_Layer_2': 6.766153562890989e-05, 'l1_Layer_3': 0.0002703029567940511, 'n_units_Layer_1': 225, 'n_units_Layer_2': 255, 'n_units_Layer_3': 205}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 10.90% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.97 | sMAPE for Test Set is: 20.37% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:15:12,286]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:15:16,018]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:16:06,879]\u001b[0m Trial 1347 finished with value: 3.5422683349268396 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008122181255623383, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3661857398877816, 'dropout_rate_Layer_2': 0.14871072216443013, 'dropout_rate_Layer_3': 0.3253410889014746, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008445158732013345, 'l1_Layer_2': 9.418973090311535e-05, 'l1_Layer_3': 0.00014583053437101378, 'n_units_Layer_1': 230, 'n_units_Layer_2': 270, 'n_units_Layer_3': 220}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 10.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 18.82% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:16:10,996]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:16:16,672]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:16:36,828]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:16:40,115]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:16:51,090]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:17:38,314]\u001b[0m Trial 1353 finished with value: 3.463986095107911 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009025786416046114, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21826832418667033, 'dropout_rate_Layer_2': 0.39941724042924376, 'dropout_rate_Layer_3': 0.02336949635314054, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009649430135188202, 'l1_Layer_2': 7.94569342792391e-05, 'l1_Layer_3': 5.4472612055278634e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 245, 'n_units_Layer_3': 230}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.46 | sMAPE for Validation Set is: 10.54% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.84 | sMAPE for Test Set is: 17.67% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:17:42,279]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:17:46,334]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:18:43,857]\u001b[0m Trial 1356 finished with value: 3.5355910758865607 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006218998795027878, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33900523158149454, 'dropout_rate_Layer_2': 0.14693070569244354, 'dropout_rate_Layer_3': 0.31296356224935146, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014128342506036302, 'l1_Layer_2': 0.00010183267373346885, 'l1_Layer_3': 0.0004649588379221632, 'n_units_Layer_1': 235, 'n_units_Layer_2': 265, 'n_units_Layer_3': 240}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.49 | sMAPE for Test Set is: 19.17% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:18:50,990]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:18:56,075]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:18:59,998]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:19:20,802]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:19:24,529]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:19:39,039]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:19:44,781]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:20:08,397]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:20:12,152]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:20:20,033]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:20:23,325]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:20:31,810]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:20:35,425]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:20:40,691]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:21:42,828]\u001b[0m Trial 1371 finished with value: 3.4733359472312073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006504984084024656, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34224253179478653, 'dropout_rate_Layer_2': 0.1402232514451166, 'dropout_rate_Layer_3': 0.3332812846930719, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020893990489370933, 'l1_Layer_2': 0.00016473473223847863, 'l1_Layer_3': 0.0002976751988674302, 'n_units_Layer_1': 235, 'n_units_Layer_2': 295, 'n_units_Layer_3': 220}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 10.59% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.37 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:21:46,589]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:21:56,226]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:22:17,945]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:22:26,696]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:22:34,798]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:23:11,211]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:23:16,063]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:23:19,757]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:24:04,808]\u001b[0m Trial 1380 finished with value: 3.500372492920753 and parameters: {'n_hidden': 3, 'learning_rate': 0.000960669556561197, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20093792238162694, 'dropout_rate_Layer_2': 0.38325509382630446, 'dropout_rate_Layer_3': 0.010896287982227639, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009105409250373867, 'l1_Layer_2': 9.000463950640256e-05, 'l1_Layer_3': 3.2358147054886955e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 235, 'n_units_Layer_3': 220}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 10.67% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.65 | sMAPE for Test Set is: 17.26% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:24:08,812]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:25:00,632]\u001b[0m Trial 1382 finished with value: 3.4690618119914656 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013113565067299296, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3476411215060165, 'dropout_rate_Layer_2': 0.12991930439199395, 'dropout_rate_Layer_3': 0.3494580687112737, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011857462522715635, 'l1_Layer_2': 8.020275782167107e-05, 'l1_Layer_3': 0.000161746339884854, 'n_units_Layer_1': 200, 'n_units_Layer_2': 280, 'n_units_Layer_3': 240}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 10.59% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.34 | sMAPE for Test Set is: 18.80% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:25:04,310]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:25:08,636]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:25:12,416]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:25:16,096]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:25:20,604]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:25:23,790]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:25:27,726]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:25:54,137]\u001b[0m Trial 1390 finished with value: 3.5727692543816523 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013213355078309586, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3367564786186725, 'dropout_rate_Layer_2': 0.12949363958370153, 'dropout_rate_Layer_3': 0.31444476057381143, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.485470532328307e-05, 'l1_Layer_2': 0.00011967141468109594, 'l1_Layer_3': 0.00015596922555035598, 'n_units_Layer_1': 195, 'n_units_Layer_2': 290, 'n_units_Layer_3': 240}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 10.92% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.93 | sMAPE for Test Set is: 20.33% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:25:57,978]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:26:02,139]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:26:10,048]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:26:14,167]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:26:18,170]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:26:23,836]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:26:37,435]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:26:53,256]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:27:09,453]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:27:13,147]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:27:16,924]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:27:38,072]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:27:49,112]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:27:54,303]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:27:58,159]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:28:01,602]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:28:05,278]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:28:10,467]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:28:29,596]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:28:38,157]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:29:15,258]\u001b[0m Trial 1411 finished with value: 3.484962193024669 and parameters: {'n_hidden': 3, 'learning_rate': 0.001131642318136457, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21445888151394235, 'dropout_rate_Layer_2': 0.3854750120438071, 'dropout_rate_Layer_3': 0.0035344105530713647, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007058278550901294, 'l1_Layer_2': 5.9725242890674216e-05, 'l1_Layer_3': 3.4529126725895586e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 245, 'n_units_Layer_3': 235}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 10.60% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 17.07% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:29:18,777]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:29:27,900]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:29:35,436]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:29:39,516]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:29:47,397]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:29:52,738]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:30:02,437]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:30:06,406]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:30:09,822]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:30:14,022]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:30:19,135]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:30:23,919]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:30:43,863]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:30:52,009]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:30:57,450]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:31:06,662]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:31:51,706]\u001b[0m Trial 1428 finished with value: 3.494680731256581 and parameters: {'n_hidden': 3, 'learning_rate': 0.001044434318549238, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2341626148142206, 'dropout_rate_Layer_2': 0.3859396309867949, 'dropout_rate_Layer_3': 0.011088166462210891, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007661510225985517, 'l1_Layer_2': 0.00010982367754987011, 'l1_Layer_3': 2.662368163746103e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 220}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.49 | sMAPE for Validation Set is: 10.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.57 | sMAPE for Test Set is: 17.08% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:31:56,628]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:32:18,790]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:32:23,977]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:32:31,612]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:33:08,660]\u001b[0m Trial 1433 finished with value: 3.4847314824116737 and parameters: {'n_hidden': 3, 'learning_rate': 0.001112812883833278, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2225769291996065, 'dropout_rate_Layer_2': 0.37386465654774775, 'dropout_rate_Layer_3': 0.03470500785270433, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004957839448663164, 'l1_Layer_2': 5.9220160311888986e-05, 'l1_Layer_3': 2.5104133939404136e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 10.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.66 | sMAPE for Test Set is: 19.62% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:33:53,292]\u001b[0m Trial 1434 finished with value: 3.531062230091521 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009886967015173245, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38453774150738435, 'dropout_rate_Layer_2': 0.15495149570539868, 'dropout_rate_Layer_3': 0.30914002370710614, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001101409056858922, 'l1_Layer_2': 0.00015274356673388568, 'l1_Layer_3': 0.00015729502772976074, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 200}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.53 | sMAPE for Validation Set is: 10.78% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 19.34% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:33:58,294]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:34:02,065]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:34:05,456]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:34:10,977]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:34:18,888]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:34:26,371]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:34:31,472]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:35:13,370]\u001b[0m Trial 1442 finished with value: 3.524279227154659 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011456869178166037, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22306939706990803, 'dropout_rate_Layer_2': 0.3752334701396924, 'dropout_rate_Layer_3': 0.03142302840419086, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000435741620143268, 'l1_Layer_2': 5.2466022106011414e-05, 'l1_Layer_3': 2.4950130777164146e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 10.74% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 18.82% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:35:17,182]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:35:37,649]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:35:41,656]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:35:44,660]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:36:06,389]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:36:22,835]\u001b[0m Trial 1448 finished with value: 3.5958488610336894 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019122139792540711, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35339748701452506, 'dropout_rate_Layer_2': 0.13120899714269946, 'dropout_rate_Layer_3': 0.2952380160514596, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001177943452142728, 'l1_Layer_2': 0.0001856948766978207, 'l1_Layer_3': 0.00016017960436000284, 'n_units_Layer_1': 255, 'n_units_Layer_2': 295, 'n_units_Layer_3': 150}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.16 | sMAPE for Test Set is: 21.24% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:36:26,857]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:36:30,302]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:36:41,699]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:36:45,707]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:36:50,677]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:36:55,547]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:37:05,427]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:37:21,322]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:37:26,446]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:37:30,001]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:37:34,306]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:37:39,345]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:37:43,215]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:37:48,163]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:38:25,940]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:38:29,305]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:38:37,456]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:38:45,739]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:38:53,948]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:39:38,957]\u001b[0m Trial 1468 finished with value: 3.4814668660900883 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009486060040148542, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2157788832994039, 'dropout_rate_Layer_2': 0.3983886633998829, 'dropout_rate_Layer_3': 0.01047338094147989, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009922276518159938, 'l1_Layer_2': 9.878873266891506e-05, 'l1_Layer_3': 2.5614485339016696e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 240, 'n_units_Layer_3': 240}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 10.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.76 | sMAPE for Test Set is: 17.54% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:39:46,694]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:39:50,557]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:39:58,781]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:40:02,522]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:40:06,321]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:40:09,468]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:40:13,410]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:40:58,396]\u001b[0m Trial 1476 finished with value: 3.4917701895232525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009588458684707515, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22762036648832093, 'dropout_rate_Layer_2': 0.3853586914026456, 'dropout_rate_Layer_3': 0.008981158054379781, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011030758365485939, 'l1_Layer_2': 5.437078253222377e-05, 'l1_Layer_3': 2.546475805819862e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 220, 'n_units_Layer_3': 245}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.49 | sMAPE for Validation Set is: 10.63% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.49 | sMAPE for Test Set is: 19.23% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:41:02,266]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:41:06,074]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:41:15,826]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:41:40,822]\u001b[0m Trial 1480 finished with value: 3.5537617571926643 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010102794973532757, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3849076299357714, 'dropout_rate_Layer_2': 0.14168420053063097, 'dropout_rate_Layer_3': 0.33883515199080755, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020162795757194327, 'l1_Layer_2': 9.725421042410021e-05, 'l1_Layer_3': 0.00011246723672817266, 'n_units_Layer_1': 235, 'n_units_Layer_2': 280, 'n_units_Layer_3': 195}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 10.85% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.93 | sMAPE for Test Set is: 20.25% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:42:06,801]\u001b[0m Trial 1481 finished with value: 3.5500868042088083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008438064977475847, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3735741365452323, 'dropout_rate_Layer_2': 0.17337834613119668, 'dropout_rate_Layer_3': 0.3521481551619699, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016236770728415874, 'l1_Layer_2': 6.771033184742146e-05, 'l1_Layer_3': 0.00019215166500603336, 'n_units_Layer_1': 200, 'n_units_Layer_2': 290, 'n_units_Layer_3': 210}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 10.84% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.62 | sMAPE for Test Set is: 19.55% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:42:14,738]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:42:19,978]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:43:11,873]\u001b[0m Trial 1484 finished with value: 3.495095223217259 and parameters: {'n_hidden': 3, 'learning_rate': 0.000730896582803771, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39403251840680364, 'dropout_rate_Layer_2': 0.15082278395977317, 'dropout_rate_Layer_3': 0.33253387679930213, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00043730618945372586, 'l1_Layer_2': 0.00013289131474280002, 'l1_Layer_3': 0.00014926555775263717, 'n_units_Layer_1': 220, 'n_units_Layer_2': 265, 'n_units_Layer_3': 225}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 10.68% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.20 | sMAPE for Test Set is: 18.52% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:43:19,273]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:44:34,763]\u001b[0m Trial 1486 finished with value: 3.984620934691509 and parameters: {'n_hidden': 4, 'learning_rate': 0.004384248512409613, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14958431457382934, 'dropout_rate_Layer_2': 0.16579473033161962, 'dropout_rate_Layer_3': 0.11902308386017497, 'dropout_rate_Layer_4': 0.0731940887025916, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0012861573567661965, 'l1_Layer_2': 0.000711309891437156, 'l1_Layer_3': 0.00014341821542416993, 'l1_Layer_4': 0.0038102121901432357, 'n_units_Layer_1': 105, 'n_units_Layer_2': 210, 'n_units_Layer_3': 50, 'n_units_Layer_4': 265}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 12.20% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.29 | sMAPE for Test Set is: 23.70% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:45:13,801]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:46:00,722]\u001b[0m Trial 1488 finished with value: 3.4668641037781143 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009704175823210517, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22815661397804662, 'dropout_rate_Layer_2': 0.38984603639436777, 'dropout_rate_Layer_3': 0.026938999350909952, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007357904337994923, 'l1_Layer_2': 5.6810042170042747e-05, 'l1_Layer_3': 2.5235079565159746e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 240, 'n_units_Layer_3': 255}. Best is trial 925 with value: 3.394309903807258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 10.56% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.06 | sMAPE for Test Set is: 18.13% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 19:46:04,608]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:46:08,384]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:46:11,998]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:46:33,085]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:46:38,208]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:46:42,896]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:46:49,311]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:47:08,487]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:47:12,664]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:47:16,598]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 19:47:22,169]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-01-01, MAE is:1.86 & sMAPE is:8.12% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :1.86 & 8.12% & 0.99\n",
      "for 2018-01-02, MAE is:6.18 & sMAPE is:20.68% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 14.40% & 0.99\n",
      "for 2018-01-03, MAE is:1.72 & sMAPE is:5.62% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 11.47% & 0.78\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DFE7798700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:5.09 & sMAPE is:16.41% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 12.71% & 1.14\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DFE78383A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:3.64 & sMAPE is:11.32% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 12.43% & 1.11\n",
      "for 2018-01-06, MAE is:2.09 & sMAPE is:6.67% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 11.47% & 1.00\n",
      "for 2018-01-07, MAE is:1.92 & sMAPE is:6.42% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 10.75% & 1.02\n",
      "for 2018-01-08, MAE is:4.23 & sMAPE is:11.77% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 10.88% & 0.94\n",
      "for 2018-01-09, MAE is:0.78 & sMAPE is:2.65% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 9.96% & 0.87\n",
      "for 2018-01-10, MAE is:11.28 & sMAPE is:30.30% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 12.00% & 0.88\n",
      "for 2018-01-11, MAE is:10.83 & sMAPE is:25.82% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 13.25% & 0.89\n",
      "for 2018-01-12, MAE is:4.78 & sMAPE is:12.71% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 13.21% & 0.91\n",
      "for 2018-01-13, MAE is:2.94 & sMAPE is:9.73% & rMAE is:3.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 12.94% & 1.07\n",
      "for 2018-01-14, MAE is:2.03 & sMAPE is:6.81% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 12.50% & 1.08\n",
      "for 2018-01-15, MAE is:5.12 & sMAPE is:16.87% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 12.79% & 1.06\n",
      "for 2018-01-16, MAE is:8.31 & sMAPE is:29.34% & rMAE is:3.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 13.83% & 1.20\n",
      "for 2018-01-17, MAE is:4.32 & sMAPE is:12.86% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 13.77% & 1.17\n",
      "for 2018-01-18, MAE is:6.87 & sMAPE is:20.30% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 14.13% & 1.16\n",
      "for 2018-01-19, MAE is:8.62 & sMAPE is:22.39% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 14.57% & 1.21\n",
      "for 2018-01-20, MAE is:3.41 & sMAPE is:9.51% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 14.31% & 1.20\n",
      "for 2018-01-21, MAE is:3.56 & sMAPE is:9.99% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 14.11% & 1.18\n",
      "for 2018-01-22, MAE is:3.30 & sMAPE is:8.13% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.84% & 1.14\n",
      "for 2018-01-23, MAE is:3.31 & sMAPE is:8.78% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 13.62% & 1.11\n",
      "for 2018-01-24, MAE is:1.60 & sMAPE is:6.17% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 13.31% & 1.08\n",
      "for 2018-01-25, MAE is:7.48 & sMAPE is:27.54% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 13.88% & 1.07\n",
      "for 2018-01-26, MAE is:12.13 & sMAPE is:32.08% & rMAE is:4.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 14.58% & 1.19\n",
      "for 2018-01-27, MAE is:3.28 & sMAPE is:10.52% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 14.43% & 1.18\n",
      "for 2018-01-28, MAE is:1.46 & sMAPE is:5.45% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 14.11% & 1.15\n",
      "for 2018-01-29, MAE is:1.46 & sMAPE is:5.15% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 13.80% & 1.11\n",
      "for 2018-01-30, MAE is:2.34 & sMAPE is:6.98% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 13.57% & 1.09\n",
      "for 2018-01-31, MAE is:1.34 & sMAPE is:4.35% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 13.27% & 1.08\n",
      "for 2018-02-01, MAE is:3.04 & sMAPE is:10.29% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 13.18% & 1.07\n",
      "for 2018-02-02, MAE is:8.79 & sMAPE is:24.56% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 13.52% & 1.11\n",
      "for 2018-02-03, MAE is:2.77 & sMAPE is:7.75% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 13.35% & 1.10\n",
      "for 2018-02-04, MAE is:2.44 & sMAPE is:7.28% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 13.18% & 1.08\n",
      "for 2018-02-05, MAE is:11.53 & sMAPE is:20.41% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 13.38% & 1.06\n",
      "for 2018-02-06, MAE is:10.32 & sMAPE is:22.12% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 13.62% & 1.05\n",
      "for 2018-02-07, MAE is:10.17 & sMAPE is:22.53% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 13.85% & 1.04\n",
      "for 2018-02-08, MAE is:11.71 & sMAPE is:25.27% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 14.15% & 1.03\n",
      "for 2018-02-09, MAE is:5.24 & sMAPE is:13.53% & rMAE is:3.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 14.13% & 1.09\n",
      "for 2018-02-10, MAE is:3.90 & sMAPE is:11.24% & rMAE is:2.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 14.06% & 1.12\n",
      "for 2018-02-11, MAE is:0.72 & sMAPE is:2.48% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 13.78% & 1.10\n",
      "for 2018-02-12, MAE is:1.58 & sMAPE is:4.92% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 13.58% & 1.08\n",
      "for 2018-02-13, MAE is:5.79 & sMAPE is:15.24% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 13.62% & 1.07\n",
      "for 2018-02-14, MAE is:5.23 & sMAPE is:13.27% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 13.61% & 1.06\n",
      "for 2018-02-15, MAE is:1.83 & sMAPE is:5.69% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 13.44% & 1.04\n",
      "for 2018-02-16, MAE is:5.79 & sMAPE is:16.00% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 13.49% & 1.07\n",
      "for 2018-02-17, MAE is:6.59 & sMAPE is:18.23% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 13.59% & 1.08\n",
      "for 2018-02-18, MAE is:1.69 & sMAPE is:4.44% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 13.40% & 1.07\n",
      "for 2018-02-19, MAE is:9.85 & sMAPE is:20.79% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 13.55% & 1.06\n",
      "for 2018-02-20, MAE is:10.37 & sMAPE is:22.42% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 13.72% & 1.06\n",
      "for 2018-02-21, MAE is:7.84 & sMAPE is:17.04% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 13.79% & 1.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-22, MAE is:7.66 & sMAPE is:16.03% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 13.83% & 1.04\n",
      "for 2018-02-23, MAE is:4.30 & sMAPE is:9.00% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 13.74% & 1.03\n",
      "for 2018-02-24, MAE is:2.46 & sMAPE is:6.55% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 13.61% & 1.03\n",
      "for 2018-02-25, MAE is:1.82 & sMAPE is:4.80% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 13.45% & 1.03\n",
      "for 2018-02-26, MAE is:5.61 & sMAPE is:11.45% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.42% & 1.03\n",
      "for 2018-02-27, MAE is:6.21 & sMAPE is:12.08% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 13.39% & 1.03\n",
      "for 2018-02-28, MAE is:6.89 & sMAPE is:13.66% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 13.40% & 1.04\n",
      "for 2018-03-01, MAE is:53.43 & sMAPE is:59.20% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 14.16% & 1.05\n",
      "for 2018-03-02, MAE is:21.19 & sMAPE is:39.44% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 14.58% & 1.06\n",
      "for 2018-03-03, MAE is:15.56 & sMAPE is:43.24% & rMAE is:3.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 15.04% & 1.09\n",
      "for 2018-03-04, MAE is:4.99 & sMAPE is:12.88% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 15.00% & 1.11\n",
      "for 2018-03-05, MAE is:11.87 & sMAPE is:23.09% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 15.13% & 1.11\n",
      "for 2018-03-06, MAE is:3.74 & sMAPE is:7.33% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 15.01% & 1.11\n",
      "for 2018-03-07, MAE is:7.57 & sMAPE is:16.21% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 15.03% & 1.12\n",
      "for 2018-03-08, MAE is:5.56 & sMAPE is:14.81% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 15.03% & 1.10\n",
      "for 2018-03-09, MAE is:4.66 & sMAPE is:11.85% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 14.98% & 1.09\n",
      "for 2018-03-10, MAE is:1.98 & sMAPE is:5.13% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 14.84% & 1.08\n",
      "for 2018-03-11, MAE is:0.88 & sMAPE is:2.46% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 14.66% & 1.07\n",
      "for 2018-03-12, MAE is:4.32 & sMAPE is:10.24% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 14.60% & 1.06\n",
      "for 2018-03-13, MAE is:3.53 & sMAPE is:8.42% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 14.51% & 1.05\n",
      "for 2018-03-14, MAE is:7.29 & sMAPE is:14.94% & rMAE is:4.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 14.52% & 1.10\n",
      "for 2018-03-15, MAE is:6.03 & sMAPE is:12.73% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 14.49% & 1.10\n",
      "for 2018-03-16, MAE is:2.34 & sMAPE is:5.70% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 14.38% & 1.10\n",
      "for 2018-03-17, MAE is:1.23 & sMAPE is:3.21% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 14.23% & 1.10\n",
      "for 2018-03-18, MAE is:1.32 & sMAPE is:3.54% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 14.09% & 1.10\n",
      "for 2018-03-19, MAE is:2.80 & sMAPE is:6.44% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 13.99% & 1.10\n",
      "for 2018-03-20, MAE is:5.38 & sMAPE is:12.39% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 13.97% & 1.11\n",
      "for 2018-03-21, MAE is:3.11 & sMAPE is:6.77% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 13.88% & 1.11\n",
      "for 2018-03-22, MAE is:4.89 & sMAPE is:11.03% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 13.85% & 1.10\n",
      "for 2018-03-23, MAE is:6.36 & sMAPE is:12.87% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 13.84% & 1.10\n",
      "for 2018-03-24, MAE is:1.12 & sMAPE is:2.73% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 13.70% & 1.09\n",
      "for 2018-03-25, MAE is:1.69 & sMAPE is:4.32% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 13.59% & 1.09\n",
      "for 2018-03-26, MAE is:5.93 & sMAPE is:12.53% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 13.58% & 1.09\n",
      "for 2018-03-27, MAE is:2.50 & sMAPE is:5.02% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 13.48% & 1.08\n",
      "for 2018-03-28, MAE is:5.68 & sMAPE is:12.55% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 13.47% & 1.09\n",
      "for 2018-03-29, MAE is:2.19 & sMAPE is:5.44% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 13.38% & 1.09\n",
      "for 2018-03-30, MAE is:0.93 & sMAPE is:2.33% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 13.25% & 1.08\n",
      "for 2018-03-31, MAE is:1.55 & sMAPE is:4.00% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 13.15% & 1.08\n",
      "for 2018-04-01, MAE is:1.15 & sMAPE is:3.00% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 13.04% & 1.08\n",
      "for 2018-04-02, MAE is:0.88 & sMAPE is:2.21% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 12.92% & 1.07\n",
      "for 2018-04-03, MAE is:3.38 & sMAPE is:8.02% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 12.87% & 1.07\n",
      "for 2018-04-04, MAE is:2.34 & sMAPE is:5.55% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.79% & 1.06\n",
      "for 2018-04-05, MAE is:3.72 & sMAPE is:8.97% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 12.75% & 1.06\n",
      "for 2018-04-06, MAE is:1.43 & sMAPE is:3.57% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 12.65% & 1.06\n",
      "for 2018-04-07, MAE is:3.11 & sMAPE is:8.25% & rMAE is:3.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 12.61% & 1.09\n",
      "for 2018-04-08, MAE is:2.78 & sMAPE is:7.30% & rMAE is:4.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 12.55% & 1.12\n",
      "for 2018-04-09, MAE is:3.10 & sMAPE is:7.03% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 12.50% & 1.12\n",
      "for 2018-04-10, MAE is:1.49 & sMAPE is:3.63% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 12.41% & 1.11\n",
      "for 2018-04-11, MAE is:3.24 & sMAPE is:8.38% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 12.37% & 1.12\n",
      "for 2018-04-12, MAE is:1.94 & sMAPE is:4.70% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 12.29% & 1.12\n",
      "for 2018-04-13, MAE is:1.74 & sMAPE is:4.35% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 12.22% & 1.12\n",
      "for 2018-04-14, MAE is:4.08 & sMAPE is:11.25% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 12.21% & 1.12\n",
      "for 2018-04-15, MAE is:3.55 & sMAPE is:9.38% & rMAE is:9.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 12.18% & 1.20\n",
      "for 2018-04-16, MAE is:8.93 & sMAPE is:19.84% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 12.25% & 1.21\n",
      "for 2018-04-17, MAE is:2.86 & sMAPE is:6.40% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 12.20% & 1.21\n",
      "for 2018-04-18, MAE is:4.31 & sMAPE is:10.47% & rMAE is:2.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 12.18% & 1.22\n",
      "for 2018-04-19, MAE is:4.23 & sMAPE is:10.74% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 12.17% & 1.23\n",
      "for 2018-04-20, MAE is:4.81 & sMAPE is:12.95% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 12.18% & 1.23\n",
      "for 2018-04-21, MAE is:2.67 & sMAPE is:8.63% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 12.14% & 1.22\n",
      "for 2018-04-22, MAE is:3.94 & sMAPE is:11.85% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 12.14% & 1.22\n",
      "for 2018-04-23, MAE is:4.03 & sMAPE is:12.17% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 12.14% & 1.21\n",
      "for 2018-04-24, MAE is:3.88 & sMAPE is:11.84% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.14% & 1.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-25, MAE is:4.24 & sMAPE is:12.53% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.14% & 1.20\n",
      "for 2018-04-26, MAE is:1.61 & sMAPE is:4.33% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 12.08% & 1.19\n",
      "for 2018-04-27, MAE is:1.61 & sMAPE is:4.36% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 12.01% & 1.19\n",
      "for 2018-04-28, MAE is:2.87 & sMAPE is:8.22% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 11.98% & 1.19\n",
      "for 2018-04-29, MAE is:1.18 & sMAPE is:3.45% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 11.91% & 1.18\n",
      "for 2018-04-30, MAE is:3.00 & sMAPE is:9.50% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 11.89% & 1.18\n",
      "for 2018-05-01, MAE is:9.19 & sMAPE is:45.71% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 12.17% & 1.18\n",
      "for 2018-05-02, MAE is:6.83 & sMAPE is:21.96% & rMAE is:3.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 12.25% & 1.20\n",
      "for 2018-05-03, MAE is:2.03 & sMAPE is:5.38% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 12.19% & 1.21\n",
      "for 2018-05-04, MAE is:5.64 & sMAPE is:14.24% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 12.21% & 1.21\n",
      "for 2018-05-05, MAE is:2.00 & sMAPE is:6.66% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.16% & 1.20\n",
      "for 2018-05-06, MAE is:7.45 & sMAPE is:41.35% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 12.39% & 1.20\n",
      "for 2018-05-07, MAE is:8.55 & sMAPE is:48.50% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 12.68% & 1.20\n",
      "for 2018-05-08, MAE is:13.13 & sMAPE is:66.79% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 13.10% & 1.20\n",
      "for 2018-05-09, MAE is:9.59 & sMAPE is:73.83% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 13.57% & 1.20\n",
      "for 2018-05-10, MAE is:6.64 & sMAPE is:59.33% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 13.92% & 1.19\n",
      "for 2018-05-11, MAE is:21.39 & sMAPE is:106.65% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 14.63% & 1.20\n",
      "for 2018-05-12, MAE is:5.91 & sMAPE is:22.11% & rMAE is:3.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 14.69% & 1.21\n",
      "for 2018-05-13, MAE is:4.25 & sMAPE is:23.52% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 14.75% & 1.21\n",
      "for 2018-05-14, MAE is:16.82 & sMAPE is:53.84% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 15.05% & 1.21\n",
      "for 2018-05-15, MAE is:16.80 & sMAPE is:34.20% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 15.19% & 1.20\n",
      "for 2018-05-16, MAE is:41.32 & sMAPE is:61.46% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 15.53% & 1.20\n",
      "for 2018-05-17, MAE is:16.13 & sMAPE is:53.94% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 15.81% & 1.20\n",
      "for 2018-05-18, MAE is:8.32 & sMAPE is:33.98% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 15.94% & 1.20\n",
      "for 2018-05-19, MAE is:5.91 & sMAPE is:18.81% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 15.96% & 1.20\n",
      "for 2018-05-20, MAE is:4.51 & sMAPE is:17.99% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 15.98% & 1.20\n",
      "for 2018-05-21, MAE is:12.14 & sMAPE is:61.58% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 16.30% & 1.20\n",
      "for 2018-05-22, MAE is:21.42 & sMAPE is:48.58% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 16.53% & 1.21\n",
      "for 2018-05-23, MAE is:21.21 & sMAPE is:41.04% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 16.70% & 1.21\n",
      "for 2018-05-24, MAE is:15.81 & sMAPE is:36.52% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 16.84% & 1.21\n",
      "for 2018-05-25, MAE is:7.79 & sMAPE is:21.06% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.86% & 1.20\n",
      "for 2018-05-26, MAE is:4.12 & sMAPE is:11.09% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 16.82% & 1.20\n",
      "for 2018-05-27, MAE is:2.28 & sMAPE is:6.11% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 16.75% & 1.20\n",
      "for 2018-05-28, MAE is:5.97 & sMAPE is:14.17% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 16.73% & 1.19\n",
      "for 2018-05-29, MAE is:4.07 & sMAPE is:9.64% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 16.69% & 1.19\n",
      "for 2018-05-30, MAE is:10.04 & sMAPE is:23.92% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 16.73% & 1.18\n",
      "for 2018-05-31, MAE is:3.79 & sMAPE is:8.84% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 16.68% & 1.18\n",
      "for 2018-06-01, MAE is:13.27 & sMAPE is:25.03% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.74% & 1.17\n",
      "for 2018-06-02, MAE is:2.86 & sMAPE is:6.66% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 16.67% & 1.17\n",
      "for 2018-06-03, MAE is:3.25 & sMAPE is:8.06% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 16.62% & 1.17\n",
      "for 2018-06-04, MAE is:2.52 & sMAPE is:5.98% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 16.55% & 1.17\n",
      "for 2018-06-05, MAE is:4.86 & sMAPE is:10.31% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 16.51% & 1.16\n",
      "for 2018-06-06, MAE is:4.68 & sMAPE is:9.59% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 16.46% & 1.16\n",
      "for 2018-06-07, MAE is:6.07 & sMAPE is:12.67% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 16.44% & 1.16\n",
      "for 2018-06-08, MAE is:4.27 & sMAPE is:8.89% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 16.39% & 1.16\n",
      "for 2018-06-09, MAE is:2.44 & sMAPE is:5.43% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 16.32% & 1.16\n",
      "for 2018-06-10, MAE is:2.61 & sMAPE is:5.88% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 16.26% & 1.15\n",
      "for 2018-06-11, MAE is:5.49 & sMAPE is:10.34% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 16.22% & 1.15\n",
      "for 2018-06-12, MAE is:10.13 & sMAPE is:17.22% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 16.23% & 1.15\n",
      "for 2018-06-13, MAE is:6.39 & sMAPE is:12.54% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 16.21% & 1.15\n",
      "for 2018-06-14, MAE is:3.73 & sMAPE is:7.63% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 16.15% & 1.15\n",
      "for 2018-06-15, MAE is:6.42 & sMAPE is:13.19% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 16.14% & 1.15\n",
      "for 2018-06-16, MAE is:1.42 & sMAPE is:3.30% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 16.06% & 1.15\n",
      "for 2018-06-17, MAE is:1.62 & sMAPE is:3.86% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 15.99% & 1.15\n",
      "for 2018-06-18, MAE is:2.80 & sMAPE is:6.04% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 15.93% & 1.14\n",
      "for 2018-06-19, MAE is:2.39 & sMAPE is:6.04% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 15.87% & 1.14\n",
      "for 2018-06-20, MAE is:3.38 & sMAPE is:7.80% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 15.82% & 1.13\n",
      "for 2018-06-21, MAE is:3.20 & sMAPE is:8.09% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 15.78% & 1.13\n",
      "for 2018-06-22, MAE is:9.37 & sMAPE is:38.34% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 15.91% & 1.12\n",
      "for 2018-06-23, MAE is:9.05 & sMAPE is:30.52% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 15.99% & 1.12\n",
      "for 2018-06-24, MAE is:5.68 & sMAPE is:14.97% & rMAE is:3.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 15.99% & 1.14\n",
      "for 2018-06-25, MAE is:10.93 & sMAPE is:21.34% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 16.02% & 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-26, MAE is:7.75 & sMAPE is:15.23% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 16.01% & 1.14\n",
      "for 2018-06-27, MAE is:13.58 & sMAPE is:25.40% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 16.06% & 1.14\n",
      "for 2018-06-28, MAE is:3.88 & sMAPE is:8.33% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 16.02% & 1.13\n",
      "for 2018-06-29, MAE is:5.21 & sMAPE is:11.94% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 16.00% & 1.13\n",
      "for 2018-06-30, MAE is:5.88 & sMAPE is:13.88% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 15.99% & 1.13\n",
      "for 2018-07-01, MAE is:3.49 & sMAPE is:8.13% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 15.94% & 1.12\n",
      "for 2018-07-02, MAE is:5.02 & sMAPE is:10.54% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 15.91% & 1.12\n",
      "for 2018-07-03, MAE is:3.90 & sMAPE is:7.47% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 15.87% & 1.12\n",
      "for 2018-07-04, MAE is:2.52 & sMAPE is:4.75% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 15.81% & 1.11\n",
      "for 2018-07-05, MAE is:3.68 & sMAPE is:6.84% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 15.76% & 1.11\n",
      "for 2018-07-06, MAE is:2.48 & sMAPE is:5.03% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 15.70% & 1.11\n",
      "for 2018-07-07, MAE is:1.97 & sMAPE is:4.30% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 15.64% & 1.11\n",
      "for 2018-07-08, MAE is:3.10 & sMAPE is:6.68% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 15.59% & 1.11\n",
      "for 2018-07-09, MAE is:2.34 & sMAPE is:4.65% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 15.54% & 1.11\n",
      "for 2018-07-10, MAE is:3.37 & sMAPE is:6.62% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 15.49% & 1.11\n",
      "for 2018-07-11, MAE is:2.04 & sMAPE is:3.94% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 15.43% & 1.11\n",
      "for 2018-07-12, MAE is:2.24 & sMAPE is:4.33% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 15.37% & 1.11\n",
      "for 2018-07-13, MAE is:2.20 & sMAPE is:4.25% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 15.31% & 1.11\n",
      "for 2018-07-14, MAE is:1.18 & sMAPE is:2.33% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 15.25% & 1.10\n",
      "for 2018-07-15, MAE is:1.07 & sMAPE is:2.13% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 15.18% & 1.10\n",
      "for 2018-07-16, MAE is:2.00 & sMAPE is:3.74% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 15.12% & 1.10\n",
      "for 2018-07-17, MAE is:1.25 & sMAPE is:2.36% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 15.06% & 1.10\n",
      "for 2018-07-18, MAE is:1.57 & sMAPE is:3.04% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 15.00% & 1.10\n",
      "for 2018-07-19, MAE is:2.29 & sMAPE is:4.45% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 14.95% & 1.10\n",
      "for 2018-07-20, MAE is:2.46 & sMAPE is:4.76% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 14.90% & 1.10\n",
      "for 2018-07-21, MAE is:2.55 & sMAPE is:5.07% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 14.85% & 1.11\n",
      "for 2018-07-22, MAE is:1.24 & sMAPE is:2.43% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 14.79% & 1.11\n",
      "for 2018-07-23, MAE is:1.55 & sMAPE is:2.83% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 14.73% & 1.11\n",
      "for 2018-07-24, MAE is:3.53 & sMAPE is:6.34% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 14.69% & 1.11\n",
      "for 2018-07-25, MAE is:6.20 & sMAPE is:10.42% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 14.67% & 1.10\n",
      "for 2018-07-26, MAE is:2.32 & sMAPE is:4.04% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 14.61% & 1.10\n",
      "for 2018-07-27, MAE is:4.77 & sMAPE is:8.76% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 14.59% & 1.11\n",
      "for 2018-07-28, MAE is:1.74 & sMAPE is:3.52% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 14.53% & 1.10\n",
      "for 2018-07-29, MAE is:2.32 & sMAPE is:4.55% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 14.49% & 1.10\n",
      "for 2018-07-30, MAE is:4.79 & sMAPE is:7.78% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 14.45% & 1.10\n",
      "for 2018-07-31, MAE is:3.89 & sMAPE is:6.72% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 14.42% & 1.11\n",
      "for 2018-08-01, MAE is:3.09 & sMAPE is:5.28% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 14.37% & 1.11\n",
      "for 2018-08-02, MAE is:5.59 & sMAPE is:9.31% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 14.35% & 1.11\n",
      "for 2018-08-03, MAE is:6.00 & sMAPE is:9.62% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 14.33% & 1.11\n",
      "for 2018-08-04, MAE is:3.99 & sMAPE is:7.19% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 14.30% & 1.11\n",
      "for 2018-08-05, MAE is:1.49 & sMAPE is:3.06% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 14.24% & 1.11\n",
      "for 2018-08-06, MAE is:7.18 & sMAPE is:11.35% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 14.23% & 1.11\n",
      "for 2018-08-07, MAE is:3.99 & sMAPE is:6.12% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 14.19% & 1.11\n",
      "for 2018-08-08, MAE is:3.50 & sMAPE is:6.14% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 14.16% & 1.11\n",
      "for 2018-08-09, MAE is:5.24 & sMAPE is:9.33% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 14.13% & 1.11\n",
      "for 2018-08-10, MAE is:1.83 & sMAPE is:3.91% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 14.09% & 1.10\n",
      "for 2018-08-11, MAE is:0.95 & sMAPE is:1.97% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 14.03% & 1.10\n",
      "for 2018-08-12, MAE is:2.48 & sMAPE is:5.31% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 14.00% & 1.09\n",
      "for 2018-08-13, MAE is:5.22 & sMAPE is:9.48% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 13.98% & 1.09\n",
      "for 2018-08-14, MAE is:2.88 & sMAPE is:5.11% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 13.94% & 1.09\n",
      "for 2018-08-15, MAE is:1.82 & sMAPE is:3.22% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 13.89% & 1.09\n",
      "for 2018-08-16, MAE is:4.24 & sMAPE is:7.87% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 13.86% & 1.09\n",
      "for 2018-08-17, MAE is:6.71 & sMAPE is:12.24% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 13.86% & 1.09\n",
      "for 2018-08-18, MAE is:2.54 & sMAPE is:5.47% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 13.82% & 1.09\n",
      "for 2018-08-19, MAE is:2.92 & sMAPE is:6.61% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 13.79% & 1.09\n",
      "for 2018-08-20, MAE is:2.85 & sMAPE is:5.54% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 13.75% & 1.09\n",
      "for 2018-08-21, MAE is:11.06 & sMAPE is:18.99% & rMAE is:3.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 13.77% & 1.09\n",
      "for 2018-08-22, MAE is:4.20 & sMAPE is:7.33% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 13.75% & 1.09\n",
      "for 2018-08-23, MAE is:10.61 & sMAPE is:18.43% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 13.77% & 1.10\n",
      "for 2018-08-24, MAE is:4.42 & sMAPE is:8.03% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 13.74% & 1.09\n",
      "for 2018-08-25, MAE is:5.22 & sMAPE is:10.64% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 13.73% & 1.10\n",
      "for 2018-08-26, MAE is:2.77 & sMAPE is:5.39% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 13.69% & 1.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-27, MAE is:1.67 & sMAPE is:3.12% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 13.65% & 1.09\n",
      "for 2018-08-28, MAE is:11.75 & sMAPE is:19.46% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 13.67% & 1.10\n",
      "for 2018-08-29, MAE is:4.40 & sMAPE is:6.70% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 13.65% & 1.09\n",
      "for 2018-08-30, MAE is:6.72 & sMAPE is:10.53% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 13.63% & 1.09\n",
      "for 2018-08-31, MAE is:6.80 & sMAPE is:11.29% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 13.62% & 1.09\n",
      "for 2018-09-01, MAE is:4.94 & sMAPE is:8.72% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 13.60% & 1.09\n",
      "for 2018-09-02, MAE is:3.07 & sMAPE is:5.66% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 13.57% & 1.09\n",
      "for 2018-09-03, MAE is:6.08 & sMAPE is:9.93% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 13.56% & 1.09\n",
      "for 2018-09-04, MAE is:7.25 & sMAPE is:11.37% & rMAE is:2.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 13.55% & 1.09\n",
      "for 2018-09-05, MAE is:4.25 & sMAPE is:6.70% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 13.52% & 1.10\n",
      "for 2018-09-06, MAE is:3.86 & sMAPE is:5.99% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 13.49% & 1.10\n",
      "for 2018-09-07, MAE is:3.54 & sMAPE is:5.82% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 13.46% & 1.10\n",
      "for 2018-09-08, MAE is:1.98 & sMAPE is:3.74% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 13.42% & 1.09\n",
      "for 2018-09-09, MAE is:1.15 & sMAPE is:2.18% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 13.38% & 1.09\n",
      "for 2018-09-10, MAE is:3.60 & sMAPE is:6.07% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 13.35% & 1.09\n",
      "for 2018-09-11, MAE is:2.43 & sMAPE is:4.10% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 13.31% & 1.09\n",
      "for 2018-09-12, MAE is:1.98 & sMAPE is:3.65% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 13.27% & 1.08\n",
      "for 2018-09-13, MAE is:14.68 & sMAPE is:23.14% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 13.31% & 1.09\n",
      "for 2018-09-14, MAE is:5.37 & sMAPE is:8.61% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 13.29% & 1.09\n",
      "for 2018-09-15, MAE is:2.52 & sMAPE is:4.67% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 13.26% & 1.09\n",
      "for 2018-09-16, MAE is:2.28 & sMAPE is:4.53% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 13.23% & 1.09\n",
      "for 2018-09-17, MAE is:8.50 & sMAPE is:13.66% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 13.23% & 1.09\n",
      "for 2018-09-18, MAE is:3.99 & sMAPE is:6.90% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 13.20% & 1.09\n",
      "for 2018-09-19, MAE is:6.82 & sMAPE is:13.26% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 13.20% & 1.09\n",
      "for 2018-09-20, MAE is:5.83 & sMAPE is:12.17% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 13.20% & 1.09\n",
      "for 2018-09-21, MAE is:8.83 & sMAPE is:25.93% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 13.25% & 1.08\n",
      "for 2018-09-22, MAE is:8.50 & sMAPE is:52.08% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 13.39% & 1.08\n",
      "for 2018-09-23, MAE is:14.88 & sMAPE is:47.29% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 13.52% & 1.08\n",
      "for 2018-09-24, MAE is:6.18 & sMAPE is:23.74% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 13.56% & 1.08\n",
      "for 2018-09-25, MAE is:6.73 & sMAPE is:14.41% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 13.56% & 1.08\n",
      "for 2018-09-26, MAE is:8.11 & sMAPE is:31.95% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 13.63% & 1.07\n",
      "for 2018-09-27, MAE is:5.16 & sMAPE is:16.82% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 13.64% & 1.07\n",
      "for 2018-09-28, MAE is:4.51 & sMAPE is:11.97% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 13.64% & 1.07\n",
      "for 2018-09-29, MAE is:5.21 & sMAPE is:14.60% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 13.64% & 1.07\n",
      "for 2018-09-30, MAE is:8.47 & sMAPE is:26.31% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 13.69% & 1.07\n",
      "for 2018-10-01, MAE is:12.85 & sMAPE is:23.03% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 13.72% & 1.07\n",
      "for 2018-10-02, MAE is:5.09 & sMAPE is:10.30% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 13.71% & 1.07\n",
      "for 2018-10-03, MAE is:3.32 & sMAPE is:6.93% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 13.68% & 1.06\n",
      "for 2018-10-04, MAE is:14.87 & sMAPE is:24.38% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 13.72% & 1.06\n",
      "for 2018-10-05, MAE is:10.11 & sMAPE is:17.12% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 13.73% & 1.06\n",
      "for 2018-10-06, MAE is:8.67 & sMAPE is:15.87% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 13.74% & 1.06\n",
      "for 2018-10-07, MAE is:8.40 & sMAPE is:15.87% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 13.75% & 1.06\n",
      "for 2018-10-08, MAE is:9.69 & sMAPE is:15.82% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 13.76% & 1.06\n",
      "for 2018-10-09, MAE is:14.43 & sMAPE is:22.82% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 13.79% & 1.06\n",
      "for 2018-10-10, MAE is:10.47 & sMAPE is:16.61% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 13.80% & 1.06\n",
      "for 2018-10-11, MAE is:10.83 & sMAPE is:20.87% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 13.82% & 1.06\n",
      "for 2018-10-12, MAE is:9.88 & sMAPE is:17.67% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 13.84% & 1.06\n",
      "for 2018-10-13, MAE is:9.03 & sMAPE is:25.28% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 13.88% & 1.06\n",
      "for 2018-10-14, MAE is:10.15 & sMAPE is:64.16% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 14.05% & 1.05\n",
      "for 2018-10-15, MAE is:28.24 & sMAPE is:76.25% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 14.27% & 1.06\n",
      "for 2018-10-16, MAE is:19.72 & sMAPE is:32.54% & rMAE is:3.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 14.33% & 1.07\n",
      "for 2018-10-17, MAE is:15.53 & sMAPE is:23.64% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 14.36% & 1.07\n",
      "for 2018-10-18, MAE is:7.85 & sMAPE is:13.29% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 14.36% & 1.07\n",
      "for 2018-10-19, MAE is:16.79 & sMAPE is:27.11% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 14.40% & 1.07\n",
      "for 2018-10-20, MAE is:5.57 & sMAPE is:10.65% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 14.39% & 1.07\n",
      "for 2018-10-21, MAE is:5.67 & sMAPE is:12.12% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 14.38% & 1.06\n",
      "for 2018-10-22, MAE is:7.72 & sMAPE is:19.70% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 14.40% & 1.06\n",
      "for 2018-10-23, MAE is:4.18 & sMAPE is:15.39% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 14.40% & 1.06\n",
      "for 2018-10-24, MAE is:9.19 & sMAPE is:20.31% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 14.42% & 1.06\n",
      "for 2018-10-25, MAE is:3.75 & sMAPE is:7.76% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 14.40% & 1.05\n",
      "for 2018-10-26, MAE is:10.06 & sMAPE is:17.74% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 14.41% & 1.05\n",
      "for 2018-10-27, MAE is:4.34 & sMAPE is:8.70% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 14.39% & 1.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-28, MAE is:2.52 & sMAPE is:5.37% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 14.36% & 1.05\n",
      "for 2018-10-29, MAE is:5.30 & sMAPE is:10.79% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 14.35% & 1.05\n",
      "for 2018-10-30, MAE is:1.79 & sMAPE is:4.27% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 14.32% & 1.05\n",
      "for 2018-10-31, MAE is:7.62 & sMAPE is:14.29% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 14.32% & 1.05\n",
      "for 2018-11-01, MAE is:2.38 & sMAPE is:5.16% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 14.29% & 1.05\n",
      "for 2018-11-02, MAE is:1.86 & sMAPE is:4.05% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 14.26% & 1.04\n",
      "for 2018-11-03, MAE is:6.05 & sMAPE is:12.83% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 14.25% & 1.05\n",
      "for 2018-11-04, MAE is:4.63 & sMAPE is:10.71% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 14.24% & 1.05\n",
      "for 2018-11-05, MAE is:9.53 & sMAPE is:17.08% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 14.25% & 1.05\n",
      "for 2018-11-06, MAE is:11.72 & sMAPE is:21.14% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 14.27% & 1.05\n",
      "for 2018-11-07, MAE is:10.28 & sMAPE is:19.12% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 14.29% & 1.05\n",
      "for 2018-11-08, MAE is:15.32 & sMAPE is:26.24% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 14.32% & 1.05\n",
      "for 2018-11-09, MAE is:8.36 & sMAPE is:14.82% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 14.33% & 1.05\n",
      "for 2018-11-10, MAE is:1.33 & sMAPE is:3.13% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 14.29% & 1.05\n",
      "for 2018-11-11, MAE is:1.41 & sMAPE is:3.50% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 14.26% & 1.04\n",
      "for 2018-11-12, MAE is:4.36 & sMAPE is:9.46% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 14.24% & 1.04\n",
      "for 2018-11-13, MAE is:3.37 & sMAPE is:6.59% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 14.22% & 1.04\n",
      "for 2018-11-14, MAE is:12.28 & sMAPE is:21.49% & rMAE is:3.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 14.24% & 1.05\n",
      "for 2018-11-15, MAE is:11.47 & sMAPE is:19.35% & rMAE is:2.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 14.26% & 1.05\n",
      "for 2018-11-16, MAE is:7.62 & sMAPE is:13.43% & rMAE is:2.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 14.25% & 1.06\n",
      "for 2018-11-17, MAE is:4.62 & sMAPE is:9.62% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 14.24% & 1.06\n",
      "for 2018-11-18, MAE is:1.98 & sMAPE is:4.36% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 14.21% & 1.06\n",
      "for 2018-11-19, MAE is:1.71 & sMAPE is:3.50% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 14.18% & 1.06\n",
      "for 2018-11-20, MAE is:2.50 & sMAPE is:5.40% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 14.15% & 1.05\n",
      "for 2018-11-21, MAE is:6.07 & sMAPE is:11.15% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 14.14% & 1.06\n",
      "for 2018-11-22, MAE is:21.10 & sMAPE is:28.81% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 14.18% & 1.06\n",
      "for 2018-11-23, MAE is:16.87 & sMAPE is:21.27% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 14.21% & 1.06\n",
      "for 2018-11-24, MAE is:9.80 & sMAPE is:16.73% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 14.21% & 1.05\n",
      "for 2018-11-25, MAE is:2.87 & sMAPE is:5.44% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 14.19% & 1.05\n",
      "for 2018-11-26, MAE is:14.20 & sMAPE is:19.30% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 14.20% & 1.05\n",
      "for 2018-11-27, MAE is:15.69 & sMAPE is:21.02% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 14.22% & 1.05\n",
      "for 2018-11-28, MAE is:6.81 & sMAPE is:12.42% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 14.22% & 1.05\n",
      "for 2018-11-29, MAE is:2.82 & sMAPE is:6.38% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 14.19% & 1.05\n",
      "for 2018-11-30, MAE is:2.70 & sMAPE is:5.75% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 14.17% & 1.04\n",
      "for 2018-12-01, MAE is:2.60 & sMAPE is:5.76% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 14.14% & 1.04\n",
      "for 2018-12-02, MAE is:4.70 & sMAPE is:11.19% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 14.13% & 1.04\n",
      "for 2018-12-03, MAE is:3.60 & sMAPE is:7.96% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 14.12% & 1.04\n",
      "for 2018-12-04, MAE is:5.64 & sMAPE is:11.88% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 14.11% & 1.04\n",
      "for 2018-12-05, MAE is:3.08 & sMAPE is:6.21% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 14.09% & 1.04\n",
      "for 2018-12-06, MAE is:2.90 & sMAPE is:5.56% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 14.06% & 1.03\n",
      "for 2018-12-07, MAE is:2.55 & sMAPE is:5.18% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 14.04% & 1.03\n",
      "for 2018-12-08, MAE is:2.24 & sMAPE is:5.13% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 14.01% & 1.03\n",
      "for 2018-12-09, MAE is:3.97 & sMAPE is:10.37% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 14.00% & 1.03\n",
      "for 2018-12-10, MAE is:3.70 & sMAPE is:8.52% & rMAE is:3.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 13.98% & 1.04\n",
      "for 2018-12-11, MAE is:3.42 & sMAPE is:7.18% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 13.96% & 1.04\n",
      "for 2018-12-12, MAE is:9.72 & sMAPE is:16.46% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 13.97% & 1.04\n",
      "for 2018-12-13, MAE is:7.18 & sMAPE is:11.44% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 13.96% & 1.04\n",
      "for 2018-12-14, MAE is:17.78 & sMAPE is:26.73% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 14.00% & 1.04\n",
      "for 2018-12-15, MAE is:3.82 & sMAPE is:6.80% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 13.98% & 1.04\n",
      "for 2018-12-16, MAE is:5.34 & sMAPE is:11.13% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 13.97% & 1.04\n",
      "for 2018-12-17, MAE is:9.39 & sMAPE is:13.83% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 13.97% & 1.03\n",
      "for 2018-12-18, MAE is:4.88 & sMAPE is:8.01% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 13.95% & 1.03\n",
      "for 2018-12-19, MAE is:1.23 & sMAPE is:2.29% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 13.92% & 1.03\n",
      "for 2018-12-20, MAE is:5.19 & sMAPE is:8.92% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 13.91% & 1.03\n",
      "for 2018-12-21, MAE is:2.27 & sMAPE is:4.10% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 13.88% & 1.03\n",
      "for 2018-12-22, MAE is:2.44 & sMAPE is:4.83% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 13.85% & 1.03\n",
      "for 2018-12-23, MAE is:4.33 & sMAPE is:8.48% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 13.84% & 1.03\n",
      "for 2018-12-24, MAE is:2.01 & sMAPE is:3.85% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 13.81% & 1.03\n",
      "for 2018-12-25, MAE is:6.76 & sMAPE is:15.29% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 13.81% & 1.02\n",
      "for 2018-12-26, MAE is:12.43 & sMAPE is:31.41% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 13.86% & 1.02\n",
      "for 2018-12-27, MAE is:3.68 & sMAPE is:7.63% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 13.85% & 1.02\n",
      "for 2018-12-28, MAE is:4.22 & sMAPE is:8.18% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 13.83% & 1.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-12-29, MAE is:1.80 & sMAPE is:3.62% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 13.80% & 1.02\n",
      "for 2018-12-30, MAE is:5.15 & sMAPE is:10.69% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 13.79% & 1.03\n",
      "for 2018-12-31, MAE is:3.74 & sMAPE is:8.26% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 13.78% & 1.03\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:01:35,000]\u001b[0m A new study created in RDB with name: SE_4_2019\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:01:49,587]\u001b[0m Trial 0 finished with value: 9.054665551727267 and parameters: {'n_hidden': 4, 'learning_rate': 0.01964219392381131, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2631298459593683, 'dropout_rate_Layer_2': 0.37217768275567337, 'dropout_rate_Layer_3': 0.23356429238410611, 'dropout_rate_Layer_4': 0.2895177235751562, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012792200211888852, 'l1_Layer_2': 0.012110013329057133, 'l1_Layer_3': 0.0032357461094841447, 'l1_Layer_4': 2.5278958822460455e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 235, 'n_units_Layer_3': 195, 'n_units_Layer_4': 195}. Best is trial 0 with value: 9.054665551727267.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.05 | sMAPE for Validation Set is: 20.38% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 17.98% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:02:13,811]\u001b[0m Trial 1 finished with value: 8.296120235293936 and parameters: {'n_hidden': 4, 'learning_rate': 0.06565668274609418, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04935183554893055, 'dropout_rate_Layer_2': 0.3489223544960258, 'dropout_rate_Layer_3': 0.3973398508480647, 'dropout_rate_Layer_4': 0.35895232416739825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.721154410662058e-05, 'l1_Layer_2': 0.011397007896641838, 'l1_Layer_3': 1.1482993363518403e-05, 'l1_Layer_4': 0.034348763313160335, 'n_units_Layer_1': 75, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270, 'n_units_Layer_4': 55}. Best is trial 1 with value: 8.296120235293936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 19.17% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 6.59 | sMAPE for Test Set is: 18.43% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:02:40,641]\u001b[0m Trial 2 finished with value: 9.007107797681284 and parameters: {'n_hidden': 3, 'learning_rate': 0.02043439289550321, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1669226097601424, 'dropout_rate_Layer_2': 0.2883681312389442, 'dropout_rate_Layer_3': 0.019627450864788412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019638194370642372, 'l1_Layer_2': 0.0009449992203604101, 'l1_Layer_3': 1.7508089836152578e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 150, 'n_units_Layer_3': 230}. Best is trial 1 with value: 8.296120235293936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.01 | sMAPE for Validation Set is: 20.20% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 6.07 | sMAPE for Test Set is: 16.94% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:02:44,753]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:03:48,631]\u001b[0m Trial 4 finished with value: 6.1162238144341785 and parameters: {'n_hidden': 4, 'learning_rate': 0.0044768196495760726, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01813082704135005, 'dropout_rate_Layer_2': 0.3956950463695265, 'dropout_rate_Layer_3': 0.2827276319967715, 'dropout_rate_Layer_4': 0.36034107667384696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017941955197833077, 'l1_Layer_2': 7.691587829351679e-05, 'l1_Layer_3': 0.0005540614709872965, 'l1_Layer_4': 5.644504058283056e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 280, 'n_units_Layer_3': 100, 'n_units_Layer_4': 230}. Best is trial 4 with value: 6.1162238144341785.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 13.98% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 15.07% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:04:00,237]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:04:30,106]\u001b[0m Trial 6 finished with value: 7.033191015831362 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018587276846634376, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13438212346518613, 'dropout_rate_Layer_2': 0.34303608373935657, 'dropout_rate_Layer_3': 0.2869303017026118, 'dropout_rate_Layer_4': 0.07404787993368181, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032985313997028823, 'l1_Layer_2': 0.0006837745913772087, 'l1_Layer_3': 0.019025392329337712, 'l1_Layer_4': 3.733517467726048e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145, 'n_units_Layer_4': 60}. Best is trial 4 with value: 6.1162238144341785.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.03 | sMAPE for Validation Set is: 15.60% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 17.36% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:04:35,007]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:04:40,210]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:04:43,859]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:05:07,671]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:05:19,527]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:05:23,527]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:05:27,989]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:05:32,252]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:05:37,019]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:05:45,872]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:05:49,748]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:05:52,510]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:05:59,200]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:06:27,360]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:06:41,716]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:06:48,065]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:06:53,126]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:07:00,563]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:07:05,604]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:07:12,839]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:07:32,095]\u001b[0m Trial 27 finished with value: 5.737225102889916 and parameters: {'n_hidden': 4, 'learning_rate': 0.0074273722483823145, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11779252108909413, 'dropout_rate_Layer_2': 0.04017260546293327, 'dropout_rate_Layer_3': 0.23358613957734256, 'dropout_rate_Layer_4': 0.07096542962104198, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0047358105669837135, 'l1_Layer_2': 0.00032114525864295363, 'l1_Layer_3': 0.024745105946765298, 'l1_Layer_4': 0.0006681638321674815, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295, 'n_units_Layer_4': 180}. Best is trial 27 with value: 5.737225102889916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 14.82% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:07:37,061]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:07:41,476]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:07:46,643]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:07:51,082]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:07:54,409]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:07:59,482]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:08:05,807]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:08:15,587]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:08:19,032]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:08:24,088]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:08:42,861]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:08:52,863]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:08:57,003]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:09:04,732]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:09:16,973]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:09:22,393]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:09:26,660]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:09:34,543]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:09:43,901]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:09:48,580]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:09:52,534]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:09:56,110]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:10:01,942]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:10:07,455]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:10:10,899]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:10:17,053]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:10:38,191]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:11:17,669]\u001b[0m Trial 55 finished with value: 7.39753845990925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024696186431054316, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21759803689656892, 'dropout_rate_Layer_2': 0.08214503892600132, 'dropout_rate_Layer_3': 0.27474004070377034, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0038378875937989053, 'l1_Layer_2': 0.00019278134234993903, 'l1_Layer_3': 0.024090718190112655, 'n_units_Layer_1': 195, 'n_units_Layer_2': 265, 'n_units_Layer_3': 250}. Best is trial 27 with value: 5.737225102889916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.40 | sMAPE for Validation Set is: 16.46% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 15.36% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:11:21,079]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:11:31,258]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:11:35,887]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:11:40,382]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:11:58,632]\u001b[0m Trial 60 finished with value: 5.206170378894557 and parameters: {'n_hidden': 3, 'learning_rate': 0.016720262339709347, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06735160432939487, 'dropout_rate_Layer_2': 0.35973087806761794, 'dropout_rate_Layer_3': 0.05550928300792149, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.6040470855025704e-05, 'l1_Layer_2': 0.0003883868775881826, 'l1_Layer_3': 4.862215226403552e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 185, 'n_units_Layer_3': 165}. Best is trial 60 with value: 5.206170378894557.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 13.98% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:12:15,941]\u001b[0m Trial 61 finished with value: 5.494037635854724 and parameters: {'n_hidden': 3, 'learning_rate': 0.021107435206553195, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06335025840362679, 'dropout_rate_Layer_2': 0.36242609548125265, 'dropout_rate_Layer_3': 0.06773291531400111, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.276427873163395e-05, 'l1_Layer_2': 0.0005126003738656985, 'l1_Layer_3': 4.3191451561023356e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 185, 'n_units_Layer_3': 120}. Best is trial 60 with value: 5.206170378894557.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 12.32% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 14.38% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:12:38,944]\u001b[0m Trial 62 finished with value: 4.995996768931881 and parameters: {'n_hidden': 3, 'learning_rate': 0.01880905782687749, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.058178238744530555, 'dropout_rate_Layer_2': 0.36199374617980057, 'dropout_rate_Layer_3': 0.02402602493496494, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012152962187823854, 'l1_Layer_2': 0.00039015596129207415, 'l1_Layer_3': 1.627305132312945e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 185, 'n_units_Layer_3': 115}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 11.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 13.35% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:12:43,152]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:13:04,325]\u001b[0m Trial 64 finished with value: 5.3192108221427015 and parameters: {'n_hidden': 3, 'learning_rate': 0.010239508960598238, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0631623259151505, 'dropout_rate_Layer_2': 0.36406054281241423, 'dropout_rate_Layer_3': 0.0019332799444590695, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5945108737041177e-05, 'l1_Layer_2': 0.00011957315642259141, 'l1_Layer_3': 4.8017967123867066e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 13.90% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:13:14,314]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:13:30,302]\u001b[0m Trial 66 finished with value: 5.287207332221267 and parameters: {'n_hidden': 3, 'learning_rate': 0.012044523828526893, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010605112809747207, 'dropout_rate_Layer_2': 0.37836955120681115, 'dropout_rate_Layer_3': 0.029353621647549177, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.664792386637885e-05, 'l1_Layer_2': 0.0003359207576749398, 'l1_Layer_3': 8.272882638381153e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 180, 'n_units_Layer_3': 85}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 12.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 13.76% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:13:38,432]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:13:42,490]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:13:49,104]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:13:54,201]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:14:32,410]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:14:36,051]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:14:48,895]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:14:55,337]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:15:00,229]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:15:04,254]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:15:08,030]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:15:13,695]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:15:31,447]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:15:42,643]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:15:47,383]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:16:10,510]\u001b[0m Trial 82 finished with value: 5.474921644857254 and parameters: {'n_hidden': 4, 'learning_rate': 0.00913168812397981, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17517526533514607, 'dropout_rate_Layer_2': 0.3795998481792236, 'dropout_rate_Layer_3': 0.21008376051316147, 'dropout_rate_Layer_4': 0.2570782401836001, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0035752470700434534, 'l1_Layer_2': 0.0010200479448797019, 'l1_Layer_3': 0.004552826482505576, 'l1_Layer_4': 4.436948639755187e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 190, 'n_units_Layer_3': 240, 'n_units_Layer_4': 50}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.77 | sMAPE for Test Set is: 13.93% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:16:17,218]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:16:20,215]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:16:25,311]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:16:58,965]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:17:09,294]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:17:12,850]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:17:15,816]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:17:21,909]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:17:26,350]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:17:53,909]\u001b[0m Trial 92 finished with value: 5.661508916663057 and parameters: {'n_hidden': 4, 'learning_rate': 0.00270246228979152, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2430896449857799, 'dropout_rate_Layer_2': 0.3710983629723173, 'dropout_rate_Layer_3': 0.25993940925610437, 'dropout_rate_Layer_4': 0.17688640304562953, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009807717651647585, 'l1_Layer_2': 0.005972146524525479, 'l1_Layer_3': 0.003062082849480293, 'l1_Layer_4': 2.9667345237709452e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 175, 'n_units_Layer_4': 155}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 12.74% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 14.16% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:17:58,869]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:19:04,090]\u001b[0m Trial 94 finished with value: 5.398760603357736 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005427667527239858, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008953370576319564, 'dropout_rate_Layer_2': 0.0012790635916434812, 'dropout_rate_Layer_3': 0.22156925744362563, 'dropout_rate_Layer_4': 0.19324380394604823, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000876851319706907, 'l1_Layer_2': 1.0316089453910588e-05, 'l1_Layer_3': 0.09968381333848904, 'l1_Layer_4': 1.7453139640742675e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50, 'n_units_Layer_4': 300}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 13.84% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:19:26,639]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:19:32,382]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:19:35,570]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:19:38,386]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:19:47,362]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:19:50,061]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:19:59,406]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:20:22,716]\u001b[0m Trial 102 finished with value: 5.176005111451034 and parameters: {'n_hidden': 4, 'learning_rate': 0.011884824730144563, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08403981688732012, 'dropout_rate_Layer_2': 0.0056015660560094485, 'dropout_rate_Layer_3': 0.21309975337733003, 'dropout_rate_Layer_4': 0.17361493266298672, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011228069281947605, 'l1_Layer_2': 1.0463553519389091e-05, 'l1_Layer_3': 0.031346512122933615, 'l1_Layer_4': 1.7603734396117646e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 60, 'n_units_Layer_4': 300}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 13.49% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:20:28,456]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:20:31,585]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:20:34,640]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:20:42,171]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:20:58,425]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:21:07,319]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:21:11,303]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:21:14,467]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:21:18,016]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:21:27,275]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:21:31,572]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:21:51,083]\u001b[0m Trial 114 finished with value: 5.486252199164981 and parameters: {'n_hidden': 4, 'learning_rate': 0.020757638021507298, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007443214545927927, 'dropout_rate_Layer_2': 0.010001316063582788, 'dropout_rate_Layer_3': 0.19263628782098516, 'dropout_rate_Layer_4': 0.1996764307378075, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005976365341582455, 'l1_Layer_2': 1.019075741546594e-05, 'l1_Layer_3': 0.09254085338010332, 'l1_Layer_4': 1.49265712668117e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 105, 'n_units_Layer_3': 50, 'n_units_Layer_4': 300}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 12.49% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.73 | sMAPE for Test Set is: 13.97% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:22:00,072]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:22:03,856]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:22:08,505]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:22:23,947]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:22:29,252]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:22:34,166]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:22:37,926]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:22:41,392]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:22:53,421]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:22:57,119]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:23:00,209]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:23:03,973]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:23:13,771]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:23:17,581]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:23:22,190]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:23:26,634]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:23:30,183]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:23:38,109]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:23:47,772]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:24:11,960]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:24:15,575]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:24:19,487]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:24:23,046]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:24:30,351]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:24:33,590]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:24:43,989]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:24:50,311]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:24:57,226]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:25:03,143]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:25:18,854]\u001b[0m Trial 144 finished with value: 5.390228057174045 and parameters: {'n_hidden': 3, 'learning_rate': 0.038761256914439685, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12416709963668175, 'dropout_rate_Layer_2': 0.3171253089770342, 'dropout_rate_Layer_3': 0.010099233903150892, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001508598033891155, 'l1_Layer_2': 0.0005787826425677266, 'l1_Layer_3': 6.765717010564426e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 90}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 14.09% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:25:28,080]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:25:31,159]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:25:34,025]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:25:38,233]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:25:44,973]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:25:49,220]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:26:10,263]\u001b[0m Trial 151 finished with value: 9.204018462134917 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031322779014930757, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0038618835524291822, 'dropout_rate_Layer_2': 0.2116891325447791, 'dropout_rate_Layer_3': 0.06297010321575044, 'dropout_rate_Layer_4': 0.30853774941943984, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0008981749142578165, 'l1_Layer_2': 0.0002456913465764564, 'l1_Layer_3': 0.0007712485141955969, 'l1_Layer_4': 9.102185072139591e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 130, 'n_units_Layer_3': 240, 'n_units_Layer_4': 230}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.20 | sMAPE for Validation Set is: 21.02% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 17.44% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:26:17,765]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:26:21,906]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:26:36,665]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:26:43,844]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:26:51,173]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:27:06,256]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:27:11,128]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:27:28,595]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:27:35,976]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:27:43,794]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:28:06,419]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:28:12,616]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:28:32,684]\u001b[0m Trial 164 finished with value: 7.636147226088539 and parameters: {'n_hidden': 4, 'learning_rate': 0.004122652910785169, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05730589994799451, 'dropout_rate_Layer_2': 0.35862362535360226, 'dropout_rate_Layer_3': 0.13285913161717822, 'dropout_rate_Layer_4': 0.23363809110275913, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005776099272005163, 'l1_Layer_2': 0.00011482327186353957, 'l1_Layer_3': 0.0009459856967669688, 'l1_Layer_4': 5.0309328077030565e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280, 'n_units_Layer_4': 175}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.64 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 5.60 | sMAPE for Test Set is: 15.62% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:28:36,118]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:28:39,506]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:28:47,477]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:28:51,062]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:29:01,060]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:29:06,085]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:29:18,029]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:29:20,849]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:29:27,769]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:29:33,527]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:29:38,739]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:29:43,627]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:29:46,603]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:29:54,415]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:30:00,837]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:30:14,242]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:30:17,136]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:30:21,419]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:30:28,425]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:30:51,324]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:30:55,012]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:31:35,777]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:31:38,741]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:31:41,728]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:31:44,988]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:31:47,627]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:31:51,017]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:31:54,257]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:32:16,941]\u001b[0m Trial 193 finished with value: 5.696953527279184 and parameters: {'n_hidden': 4, 'learning_rate': 0.006828381309112812, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0720056714803181, 'dropout_rate_Layer_2': 0.3515613764042038, 'dropout_rate_Layer_3': 0.12002479189310875, 'dropout_rate_Layer_4': 0.34347279494366756, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00022355238043761944, 'l1_Layer_2': 1.108328445869245e-05, 'l1_Layer_3': 0.001005094920895869, 'l1_Layer_4': 0.0002989405609276456, 'n_units_Layer_1': 110, 'n_units_Layer_2': 285, 'n_units_Layer_3': 165, 'n_units_Layer_4': 165}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 13.30% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.94 | sMAPE for Test Set is: 14.77% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:32:20,902]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:32:24,128]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:32:27,558]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:32:40,223]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:33:05,624]\u001b[0m Trial 198 finished with value: 5.010889826815444 and parameters: {'n_hidden': 3, 'learning_rate': 0.011758068654107383, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06522264809212902, 'dropout_rate_Layer_2': 0.3178449222658563, 'dropout_rate_Layer_3': 0.006490020471757851, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023208864625960454, 'l1_Layer_2': 0.0004591092880318485, 'l1_Layer_3': 1.1470293094941951e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 290}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 11.48% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 13.31% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:33:39,618]\u001b[0m Trial 199 finished with value: 5.045828895275819 and parameters: {'n_hidden': 3, 'learning_rate': 0.00984424013471423, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07306840589788677, 'dropout_rate_Layer_2': 0.3230000424626018, 'dropout_rate_Layer_3': 0.006317439036761202, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001193685953283979, 'l1_Layer_2': 0.0008815027568081056, 'l1_Layer_3': 1.1894948190485372e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 155, 'n_units_Layer_3': 255}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 11.49% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 13.43% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:33:46,992]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:33:54,446]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:33:59,550]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:34:07,134]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:34:14,443]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:34:19,147]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:34:23,269]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:34:27,932]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:34:37,377]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:34:57,939]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:35:58,557]\u001b[0m Trial 210 finished with value: 5.386582219205532 and parameters: {'n_hidden': 4, 'learning_rate': 0.000714229964023512, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2109872154349272, 'dropout_rate_Layer_2': 0.35813447374166235, 'dropout_rate_Layer_3': 0.3143342558349493, 'dropout_rate_Layer_4': 0.08304914776815688, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0028072071215951367, 'l1_Layer_2': 0.0018131086849764602, 'l1_Layer_3': 0.005814032021896899, 'l1_Layer_4': 2.755468133494574e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235, 'n_units_Layer_4': 190}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 13.80% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:37:17,149]\u001b[0m Trial 211 finished with value: 6.2166745797393475 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012824405635268469, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0026153530435493455, 'dropout_rate_Layer_2': 0.05301346964307642, 'dropout_rate_Layer_3': 0.20396054267093014, 'dropout_rate_Layer_4': 0.28617100126928946, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07197739253543642, 'l1_Layer_2': 3.774670171188823e-05, 'l1_Layer_3': 0.04029330949583104, 'l1_Layer_4': 1.3156166195074219e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 100, 'n_units_Layer_3': 150, 'n_units_Layer_4': 245}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 5.36 | sMAPE for Test Set is: 15.55% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:37:21,835]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:37:25,504]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:37:30,636]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:37:35,058]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:37:40,222]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:37:43,940]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:37:47,132]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:37:55,286]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:37:58,719]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:38:01,986]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:38:09,348]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:38:12,850]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:38:16,949]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:38:45,032]\u001b[0m Trial 225 finished with value: 5.059330404563989 and parameters: {'n_hidden': 3, 'learning_rate': 0.020650440021132133, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05669803750375751, 'dropout_rate_Layer_2': 0.3211230506895765, 'dropout_rate_Layer_3': 0.00935297364649689, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020494643420339577, 'l1_Layer_2': 0.00044773329522181554, 'l1_Layer_3': 1.0053147689816413e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 140, 'n_units_Layer_3': 290}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.54 | sMAPE for Test Set is: 13.31% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:38:48,856]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:38:53,788]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:39:00,789]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:39:14,281]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:39:17,283]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:39:20,869]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:39:24,387]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:39:29,691]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:39:33,204]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:39:37,729]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:39:42,329]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:39:52,572]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:39:55,637]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:40:19,083]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:40:30,398]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:40:34,663]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:40:37,592]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:40:40,421]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:41:08,416]\u001b[0m Trial 244 finished with value: 6.5669585991971315 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005111175372549973, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03447334931754581, 'dropout_rate_Layer_2': 0.3046539617532169, 'dropout_rate_Layer_3': 0.12944967809849664, 'dropout_rate_Layer_4': 0.3525756197285446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.640954580708236e-05, 'l1_Layer_2': 2.5268153999593537e-05, 'l1_Layer_3': 0.0809293583191541, 'l1_Layer_4': 0.001458667710187322, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 155, 'n_units_Layer_4': 105}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 14.79% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:41:11,619]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:41:17,169]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:41:20,216]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:41:23,433]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:41:33,658]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:41:37,402]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:41:40,441]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:41:43,405]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:41:55,440]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:42:12,510]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:42:22,496]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:42:43,664]\u001b[0m Trial 256 finished with value: 5.350692173409062 and parameters: {'n_hidden': 3, 'learning_rate': 0.012243997584037896, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10729193707433149, 'dropout_rate_Layer_2': 0.31489342012108545, 'dropout_rate_Layer_3': 0.04194570350849784, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003077298026817628, 'l1_Layer_2': 0.000711419984629437, 'l1_Layer_3': 2.114737388480324e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 120, 'n_units_Layer_3': 270}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 14.03% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:43:00,004]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:43:05,480]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:43:10,543]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:43:38,926]\u001b[0m Trial 260 finished with value: 6.457759630462533 and parameters: {'n_hidden': 4, 'learning_rate': 0.00059499991784554, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038643652082934965, 'dropout_rate_Layer_2': 0.30399151695178134, 'dropout_rate_Layer_3': 0.27180902125100537, 'dropout_rate_Layer_4': 0.359446902163998, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.173429836273201e-05, 'l1_Layer_2': 1.0329842237135238e-05, 'l1_Layer_3': 0.0636877730655446, 'l1_Layer_4': 0.0016836237553077894, 'n_units_Layer_1': 90, 'n_units_Layer_2': 295, 'n_units_Layer_3': 150, 'n_units_Layer_4': 105}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 14.95% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:43:42,242]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:43:45,143]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:43:50,645]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:43:54,964]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:44:27,442]\u001b[0m Trial 265 finished with value: 6.300106327493762 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005045723566727678, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031349908453492406, 'dropout_rate_Layer_2': 0.31318338590481154, 'dropout_rate_Layer_3': 0.29538364299933817, 'dropout_rate_Layer_4': 0.3600925755468353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.793621533750605e-05, 'l1_Layer_2': 2.4041041353605774e-05, 'l1_Layer_3': 0.09002207479912189, 'l1_Layer_4': 0.0016568613368570602, 'n_units_Layer_1': 80, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155, 'n_units_Layer_4': 100}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 14.22% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 14.84% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:44:38,177]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:44:41,453]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:44:44,517]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:44:47,685]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:44:53,648]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:44:59,759]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:45:13,421]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:45:35,830]\u001b[0m Trial 273 finished with value: 5.3197938424914915 and parameters: {'n_hidden': 4, 'learning_rate': 0.0042129327887410715, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08520893534875365, 'dropout_rate_Layer_2': 0.14266556371216893, 'dropout_rate_Layer_3': 0.17258708580744503, 'dropout_rate_Layer_4': 0.2821993403025914, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0181938822401123e-05, 'l1_Layer_2': 2.1586986054281395e-05, 'l1_Layer_3': 0.0008153989392939051, 'l1_Layer_4': 0.0032738980148722366, 'n_units_Layer_1': 150, 'n_units_Layer_2': 135, 'n_units_Layer_3': 150, 'n_units_Layer_4': 210}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 12.28% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 14.05% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:45:42,200]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:45:46,366]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:45:49,302]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:45:53,025]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:45:59,513]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:46:03,699]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:46:07,032]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:46:15,237]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:46:18,848]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:46:50,773]\u001b[0m Trial 283 finished with value: 5.642771083100992 and parameters: {'n_hidden': 4, 'learning_rate': 0.002208800621109881, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17335262381346334, 'dropout_rate_Layer_2': 0.3618051135939097, 'dropout_rate_Layer_3': 0.23234929503608268, 'dropout_rate_Layer_4': 0.08657919346809173, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008166007062706345, 'l1_Layer_2': 0.01330882817371155, 'l1_Layer_3': 0.00737115249695771, 'l1_Layer_4': 2.2993447178551416e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 255, 'n_units_Layer_4': 100}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 12.93% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 14.36% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:47:07,563]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:47:11,100]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:47:14,101]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:47:23,595]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:47:33,955]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:47:54,295]\u001b[0m Trial 289 finished with value: 5.241151264330972 and parameters: {'n_hidden': 3, 'learning_rate': 0.018324332913413864, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07585826377630561, 'dropout_rate_Layer_2': 0.3068398358225884, 'dropout_rate_Layer_3': 0.022065505957186857, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000311277695707214, 'l1_Layer_2': 0.00044305664721223345, 'l1_Layer_3': 1.7232853937934182e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 130, 'n_units_Layer_3': 75}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 12.02% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.70 | sMAPE for Test Set is: 13.80% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:47:58,115]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:48:01,414]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:48:18,982]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:48:24,444]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:48:30,670]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:48:35,599]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:48:41,030]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:48:46,589]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:48:51,255]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:48:54,428]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:48:57,530]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:49:04,971]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:49:22,155]\u001b[0m Trial 302 finished with value: 6.004849281621823 and parameters: {'n_hidden': 4, 'learning_rate': 0.03278423951188375, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03597950736221478, 'dropout_rate_Layer_2': 0.20416753909753443, 'dropout_rate_Layer_3': 0.22202746198781725, 'dropout_rate_Layer_4': 0.2999968639587277, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0017355905563643996, 'l1_Layer_2': 7.455651857497834e-05, 'l1_Layer_3': 0.033978777755005664, 'l1_Layer_4': 0.002492391410002393, 'n_units_Layer_1': 105, 'n_units_Layer_2': 135, 'n_units_Layer_3': 75, 'n_units_Layer_4': 140}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 15.29% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:49:25,890]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:49:29,620]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:49:48,835]\u001b[0m Trial 305 finished with value: 6.176559561582029 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007283773998828032, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10752926595308068, 'dropout_rate_Layer_2': 0.2585838479763826, 'dropout_rate_Layer_3': 0.29018763437454964, 'dropout_rate_Layer_4': 0.3180320366680593, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.095348039452644e-05, 'l1_Layer_2': 2.4202693596720707e-05, 'l1_Layer_3': 0.08266023230275199, 'l1_Layer_4': 0.001120008043482007, 'n_units_Layer_1': 140, 'n_units_Layer_2': 285, 'n_units_Layer_3': 105, 'n_units_Layer_4': 110}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 13.96% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 14.78% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:49:53,093]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:49:56,308]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:49:59,162]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:50:02,550]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:50:06,132]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:50:09,410]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:50:16,083]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:50:19,228]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:50:22,690]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:50:38,066]\u001b[0m Trial 315 finished with value: 5.532472249702368 and parameters: {'n_hidden': 4, 'learning_rate': 0.009860973621010969, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08819596164347107, 'dropout_rate_Layer_2': 0.0745778785715641, 'dropout_rate_Layer_3': 0.1569967627157399, 'dropout_rate_Layer_4': 0.3773582111511695, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011370792869952905, 'l1_Layer_2': 2.5433931509218907e-05, 'l1_Layer_3': 0.042563826240872425, 'l1_Layer_4': 4.3289890419637774e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 185, 'n_units_Layer_3': 70, 'n_units_Layer_4': 275}. Best is trial 62 with value: 4.995996768931881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 12.62% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 14.14% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:50:53,943]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:50:57,102]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:51:00,902]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:51:05,032]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:51:11,207]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:51:17,927]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:51:23,287]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:51:26,602]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:51:36,023]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:51:40,319]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:51:49,108]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:51:51,903]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:51:54,874]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:51:58,503]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:52:01,767]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:52:04,996]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:52:08,143]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:52:13,348]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:52:18,210]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:52:21,685]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:52:26,816]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:52:37,150]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:52:41,996]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:52:46,151]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:52:52,293]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:53:01,886]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:53:19,312]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:53:29,590]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:53:33,035]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:53:39,611]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:53:45,710]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:55:36,393]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:55:57,256]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:56:00,749]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:56:22,899]\u001b[0m Trial 350 finished with value: 4.828288364872141 and parameters: {'n_hidden': 3, 'learning_rate': 0.011999538686957367, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1706553212032139, 'dropout_rate_Layer_2': 0.3538172373606823, 'dropout_rate_Layer_3': 0.04542821413494408, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001893796564368668, 'l1_Layer_2': 0.00013558000092302535, 'l1_Layer_3': 5.672323793018425e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 11.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 13.37% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:56:25,700]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:56:42,206]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:56:45,523]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:56:48,707]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:56:58,439]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:57:10,123]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:57:14,997]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:57:25,099]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:57:28,786]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:57:38,412]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:59:17,283]\u001b[0m Trial 361 finished with value: 5.368336226633805 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006820417404727857, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25615048212325375, 'dropout_rate_Layer_2': 0.3999396245670699, 'dropout_rate_Layer_3': 0.2706833097648609, 'dropout_rate_Layer_4': 0.13945331394899738, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004807104401806617, 'l1_Layer_2': 0.003295240207861209, 'l1_Layer_3': 0.0043892583701956095, 'l1_Layer_4': 1.8650969416222795e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 230, 'n_units_Layer_3': 240, 'n_units_Layer_4': 70}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 12.25% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 13.89% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 02:59:28,176]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:59:31,358]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:59:36,191]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 02:59:43,188]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:00:19,821]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:00:23,976]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:00:37,328]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:00:40,762]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:00:49,031]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:00:53,140]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:01:01,303]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:01:04,128]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:01:07,418]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:01:10,803]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:01:19,831]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:01:26,121]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:01:31,192]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:01:42,540]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:02:05,954]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:02:16,995]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:02:31,399]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:02:34,807]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:02:45,084]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:03:20,799]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:03:27,305]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:03:47,091]\u001b[0m Trial 387 finished with value: 6.314520174848744 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009331114900637448, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02617452191818096, 'dropout_rate_Layer_2': 0.3104252086507543, 'dropout_rate_Layer_3': 0.23139396328935577, 'dropout_rate_Layer_4': 0.34207409142161943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.157789370173282e-05, 'l1_Layer_2': 1.0236612732944412e-05, 'l1_Layer_3': 0.0531977573893213, 'l1_Layer_4': 0.0014861336109475898, 'n_units_Layer_1': 65, 'n_units_Layer_2': 285, 'n_units_Layer_3': 205, 'n_units_Layer_4': 80}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 14.29% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 5.25 | sMAPE for Test Set is: 15.20% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:03:50,374]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:03:53,914]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:03:57,150]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:03:59,790]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:04:45,023]\u001b[0m Trial 392 finished with value: 6.139920893345909 and parameters: {'n_hidden': 4, 'learning_rate': 0.000942388247662397, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021287790117400698, 'dropout_rate_Layer_2': 0.3142482306466292, 'dropout_rate_Layer_3': 0.2395428920664139, 'dropout_rate_Layer_4': 0.30503047148164786, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00018728800974503928, 'l1_Layer_2': 1.789968481287496e-05, 'l1_Layer_3': 0.017727689050113463, 'l1_Layer_4': 0.0006730467568944399, 'n_units_Layer_1': 65, 'n_units_Layer_2': 245, 'n_units_Layer_3': 205, 'n_units_Layer_4': 70}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 16.05% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:04:49,141]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:04:53,448]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:05:01,743]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:05:05,266]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:05:48,116]\u001b[0m Trial 397 finished with value: 6.358549164775585 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015043992506984108, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006016233528194186, 'dropout_rate_Layer_2': 0.2717488953089842, 'dropout_rate_Layer_3': 0.2277208430036178, 'dropout_rate_Layer_4': 0.3081238183260371, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00015883550455390584, 'l1_Layer_2': 1.9677597672055762e-05, 'l1_Layer_3': 0.01666262513805492, 'l1_Layer_4': 0.0005966220268151405, 'n_units_Layer_1': 125, 'n_units_Layer_2': 245, 'n_units_Layer_3': 165, 'n_units_Layer_4': 70}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 14.25% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 15.04% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:05:51,405]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:05:54,223]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:05:59,646]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:06:02,792]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:06:10,030]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:06:13,385]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:06:31,753]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:06:35,067]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:06:43,532]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:06:49,831]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:06:54,598]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:07:02,417]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:07:07,058]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:07:10,906]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:07:14,415]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:07:53,184]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:08:37,908]\u001b[0m Trial 414 finished with value: 5.371000824036766 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011910486399412052, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05648768366943184, 'dropout_rate_Layer_2': 0.33629616593933664, 'dropout_rate_Layer_3': 0.25092381440129646, 'dropout_rate_Layer_4': 0.3086275056188083, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002805837537052853, 'l1_Layer_2': 3.698272569133044e-05, 'l1_Layer_3': 0.02750867294346242, 'l1_Layer_4': 0.0003978642691183207, 'n_units_Layer_1': 120, 'n_units_Layer_2': 215, 'n_units_Layer_3': 85, 'n_units_Layer_4': 50}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 12.33% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.84 | sMAPE for Test Set is: 14.32% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:08:48,189]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:08:52,236]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:08:57,494]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:09:01,227]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:09:38,342]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:09:42,222]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:09:57,407]\u001b[0m Trial 421 finished with value: 5.474912232446937 and parameters: {'n_hidden': 4, 'learning_rate': 0.018253250635071962, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002526734125254987, 'dropout_rate_Layer_2': 0.018177211961143955, 'dropout_rate_Layer_3': 0.19419265115984755, 'dropout_rate_Layer_4': 0.2027163552860078, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004843082617194434, 'l1_Layer_2': 1.0424822048340215e-05, 'l1_Layer_3': 0.06573739626163738, 'l1_Layer_4': 2.6963566774317074e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 115, 'n_units_Layer_3': 50, 'n_units_Layer_4': 295}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 13.70% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:10:13,281]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:10:22,744]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:10:25,530]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:11:02,291]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:11:47,957]\u001b[0m Trial 426 finished with value: 5.199215757194178 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024108117018133107, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.051799271994618076, 'dropout_rate_Layer_2': 0.38028349491815966, 'dropout_rate_Layer_3': 0.22559252828548682, 'dropout_rate_Layer_4': 0.1642167193642547, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000464917081139692, 'l1_Layer_2': 7.131960629878232e-05, 'l1_Layer_3': 0.024858914731400446, 'l1_Layer_4': 0.00038409167224837104, 'n_units_Layer_1': 125, 'n_units_Layer_2': 245, 'n_units_Layer_3': 90, 'n_units_Layer_4': 300}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 11.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 13.05% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:13:27,894]\u001b[0m Trial 427 finished with value: 5.495533003114455 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007164174008119199, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25739678738828864, 'dropout_rate_Layer_2': 0.3767100386363796, 'dropout_rate_Layer_3': 0.2666126528164438, 'dropout_rate_Layer_4': 0.15589238919125642, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00035073821883659524, 'l1_Layer_2': 0.0018320413742336358, 'l1_Layer_3': 0.004973653320358818, 'l1_Layer_4': 2.6960015454855236e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270, 'n_units_Layer_4': 80}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 13.92% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:13:31,398]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:13:36,874]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:13:42,003]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:13:52,579]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:13:56,007]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:13:59,623]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:15:38,426]\u001b[0m Trial 434 finished with value: 5.306875594900973 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008943052861419233, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25046018004793197, 'dropout_rate_Layer_2': 0.3812109508184918, 'dropout_rate_Layer_3': 0.27904969472195834, 'dropout_rate_Layer_4': 0.19682535278497126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017207908017941915, 'l1_Layer_2': 0.0012308490453287473, 'l1_Layer_3': 0.007827444727755388, 'l1_Layer_4': 3.105964133197698e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295, 'n_units_Layer_4': 85}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 12.24% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 13.52% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:15:47,631]\u001b[0m Trial 435 finished with value: 5.846870672298763 and parameters: {'n_hidden': 3, 'learning_rate': 0.014738704225730497, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04798695806239976, 'dropout_rate_Layer_2': 0.34676733102608526, 'dropout_rate_Layer_3': 0.11145577928625744, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.798606295944798e-05, 'l1_Layer_2': 0.00017166490843447896, 'l1_Layer_3': 5.551397896746336e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 155, 'n_units_Layer_3': 80}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 13.33% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 15.14% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:15:51,475]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:15:54,917]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:15:59,078]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:16:26,875]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:16:30,164]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:16:38,558]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:16:59,082]\u001b[0m Trial 442 finished with value: 5.4046160411479525 and parameters: {'n_hidden': 4, 'learning_rate': 0.01584618826157228, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0026338209631305703, 'dropout_rate_Layer_2': 0.03143257131673837, 'dropout_rate_Layer_3': 0.21594492275195493, 'dropout_rate_Layer_4': 0.1891628008097121, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001020034387208785, 'l1_Layer_2': 1.8264916206228845e-05, 'l1_Layer_3': 0.04597121488828755, 'l1_Layer_4': 2.2552569138943033e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 125, 'n_units_Layer_3': 55, 'n_units_Layer_4': 265}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 12.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 13.79% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:17:02,524]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:17:05,651]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:17:08,564]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:17:18,366]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:17:21,260]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:17:24,798]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:17:33,134]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:17:38,512]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:18:23,785]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:18:31,884]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:18:35,443]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:18:38,724]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:18:46,490]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:19:46,360]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:19:52,021]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:19:55,761]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:20:12,115]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:20:15,576]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:20:19,411]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:20:22,773]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:20:27,188]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:20:33,181]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:20:37,102]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:20:40,435]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:21:03,726]\u001b[0m Trial 467 finished with value: 5.791353912801938 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016671734195471083, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05672819031791301, 'dropout_rate_Layer_2': 0.32993798866003504, 'dropout_rate_Layer_3': 0.2262732450932333, 'dropout_rate_Layer_4': 0.16869012098581432, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00015046279940314275, 'l1_Layer_2': 1.500061984691452e-05, 'l1_Layer_3': 0.029012557365535173, 'l1_Layer_4': 0.0001927235547659832, 'n_units_Layer_1': 165, 'n_units_Layer_2': 265, 'n_units_Layer_3': 50, 'n_units_Layer_4': 50}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 13.21% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 14.84% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:21:16,399]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:21:54,697]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:21:58,999]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:22:06,284]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:22:22,917]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:22:38,789]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:22:41,712]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:22:45,143]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:23:43,611]\u001b[0m Trial 476 finished with value: 5.3170422902009555 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015789864774898995, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012675042497835727, 'dropout_rate_Layer_2': 0.3438538005390949, 'dropout_rate_Layer_3': 0.21165469830623718, 'dropout_rate_Layer_4': 0.19637410765181817, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002112300913274802, 'l1_Layer_2': 4.218717158548106e-05, 'l1_Layer_3': 0.015793288182803074, 'l1_Layer_4': 0.00012464802427529335, 'n_units_Layer_1': 180, 'n_units_Layer_2': 160, 'n_units_Layer_3': 60, 'n_units_Layer_4': 295}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 12.01% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 13.36% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:23:46,294]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:23:52,720]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:24:04,895]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:24:09,862]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:25:05,164]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:25:08,530]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:25:12,214]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:25:16,454]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:25:32,094]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:25:35,221]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:26:14,127]\u001b[0m Trial 487 finished with value: 5.501706065137069 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011444692982278402, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25796816067303313, 'dropout_rate_Layer_2': 0.3816544268593287, 'dropout_rate_Layer_3': 0.2609072926168987, 'dropout_rate_Layer_4': 0.2546083048501284, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003798228153497784, 'l1_Layer_2': 0.0005802789200232366, 'l1_Layer_3': 0.004205439781230044, 'l1_Layer_4': 4.7011565306717223e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235, 'n_units_Layer_4': 55}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 12.58% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 14.29% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:26:18,187]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:26:29,145]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:26:32,002]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:28:21,060]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:28:31,429]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:28:36,076]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:28:45,805]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:29:19,420]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:29:22,400]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:29:25,155]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:29:28,230]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:29:31,739]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:29:36,977]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:29:40,708]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:29:44,778]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:29:53,672]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:30:10,242]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:30:17,282]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:30:22,694]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:30:25,871]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:30:28,667]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:30:31,664]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:30:34,664]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:31:24,214]\u001b[0m Trial 511 finished with value: 5.7552412301512845 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015350574833630844, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04991246263779694, 'dropout_rate_Layer_2': 0.33172667717091225, 'dropout_rate_Layer_3': 0.212568930418136, 'dropout_rate_Layer_4': 0.09952817930512842, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013125952454350523, 'l1_Layer_2': 0.0001481068626144662, 'l1_Layer_3': 0.002202052694373986, 'l1_Layer_4': 3.2096105019642355e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 165, 'n_units_Layer_3': 115, 'n_units_Layer_4': 200}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 13.30% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.84 | sMAPE for Test Set is: 14.21% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:31:27,176]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:31:30,704]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:31:36,006]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:31:41,204]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:31:49,082]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:31:52,502]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:31:58,934]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:32:04,547]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:32:10,147]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:32:33,367]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:32:36,790]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:32:40,460]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:35:16,182]\u001b[0m Trial 524 finished with value: 5.088384027827384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007932829876931819, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22446414810397253, 'dropout_rate_Layer_2': 0.21264150506152396, 'dropout_rate_Layer_3': 0.23806085563749685, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006215155543406962, 'l1_Layer_2': 0.0007832864401403488, 'l1_Layer_3': 0.0017658076496872965, 'n_units_Layer_1': 55, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 11.52% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 13.47% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:35:23,590]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:35:27,321]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:35:30,718]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:35:34,218]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:35:51,746]\u001b[0m Trial 529 finished with value: 4.95172712496539 and parameters: {'n_hidden': 3, 'learning_rate': 0.009337961722692044, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09354371659325472, 'dropout_rate_Layer_2': 0.3834976738349935, 'dropout_rate_Layer_3': 0.09733429403841734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002092966297538641, 'l1_Layer_2': 0.00014413606412685455, 'l1_Layer_3': 5.092024002781374e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 180, 'n_units_Layer_3': 95}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 11.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 13.31% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:36:24,632]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:36:29,132]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:36:36,525]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:37:40,859]\u001b[0m Trial 533 finished with value: 5.993601891417299 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021799475825477173, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010840435936648414, 'dropout_rate_Layer_2': 0.38268008720608465, 'dropout_rate_Layer_3': 0.21945597420552587, 'dropout_rate_Layer_4': 0.19404139534778453, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002812479663818668, 'l1_Layer_2': 4.5133064418314395e-05, 'l1_Layer_3': 0.002189838826432829, 'l1_Layer_4': 3.0215750828149235e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 145, 'n_units_Layer_3': 95, 'n_units_Layer_4': 195}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.99 | sMAPE for Validation Set is: 13.74% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 15.08% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:37:43,925]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:37:47,055]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:39:23,665]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:39:29,140]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:39:43,161]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:41:22,911]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:41:26,755]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:41:40,233]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:41:44,212]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:42:38,271]\u001b[0m Trial 543 finished with value: 6.052418932100025 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013908615792740985, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009557936942995775, 'dropout_rate_Layer_2': 0.3666966515809822, 'dropout_rate_Layer_3': 0.22025338372420936, 'dropout_rate_Layer_4': 0.19564135988528977, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00023171397716312197, 'l1_Layer_2': 4.440958578545102e-05, 'l1_Layer_3': 0.002271919929480621, 'l1_Layer_4': 2.3722278348590214e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 145, 'n_units_Layer_3': 95, 'n_units_Layer_4': 195}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.05 | sMAPE for Validation Set is: 13.92% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 15.16% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:42:42,347]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:44:49,318]\u001b[0m Trial 545 finished with value: 5.182159720239691 and parameters: {'n_hidden': 3, 'learning_rate': 0.000532419620269826, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11559734415007479, 'dropout_rate_Layer_2': 0.3680604575049272, 'dropout_rate_Layer_3': 0.2445921621385655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006640494165910611, 'l1_Layer_2': 0.0014925709261875116, 'l1_Layer_3': 0.001757233566446001, 'n_units_Layer_1': 70, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 13.60% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:48:06,304]\u001b[0m Trial 546 finished with value: 5.15818612242544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005602772786319822, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1097282833966786, 'dropout_rate_Layer_2': 0.30686997320141174, 'dropout_rate_Layer_3': 0.24719900388397548, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008446327895570482, 'l1_Layer_2': 0.0014322022449382021, 'l1_Layer_3': 0.0015456065395106388, 'n_units_Layer_1': 160, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 11.69% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 13.25% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:48:20,449]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:48:23,798]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:48:27,285]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:48:30,654]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:48:33,871]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:48:45,920]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:48:49,652]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:48:53,700]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:48:56,809]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:49:22,650]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:49:37,849]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:49:41,295]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:49:44,699]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:49:49,447]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:49:52,335]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:50:02,743]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:50:13,145]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:50:17,015]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:50:19,930]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:50:44,875]\u001b[0m Trial 566 finished with value: 6.081248861966408 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018644147756491395, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10488611250219365, 'dropout_rate_Layer_2': 0.05574405443858266, 'dropout_rate_Layer_3': 0.26799386736379666, 'dropout_rate_Layer_4': 0.015241997146233865, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.012425277017648638, 'l1_Layer_2': 0.00022144431871918242, 'l1_Layer_3': 0.0038413710065599463, 'l1_Layer_4': 8.025617257854999e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 65, 'n_units_Layer_3': 130, 'n_units_Layer_4': 260}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 14.62% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:50:59,469]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:51:23,441]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:51:27,510]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:51:36,906]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:51:52,142]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:52:24,381]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:53:49,588]\u001b[0m Trial 573 finished with value: 5.221947982866226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005755675364489606, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12413685306118571, 'dropout_rate_Layer_2': 0.3646470367724116, 'dropout_rate_Layer_3': 0.2673698584000128, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017174110551772984, 'l1_Layer_2': 0.0009946973752888101, 'l1_Layer_3': 0.001347974058340242, 'n_units_Layer_1': 150, 'n_units_Layer_2': 200, 'n_units_Layer_3': 155}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 13.78% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:53:52,662]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:53:57,460]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:54:01,019]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:54:04,946]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:54:08,576]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:54:11,960]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:54:19,640]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:54:29,934]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:54:35,740]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:54:52,148]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:54:56,214]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:55:09,767]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:55:17,616]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:55:20,527]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:55:23,641]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:55:27,475]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:55:30,422]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:55:37,516]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:56:01,259]\u001b[0m Trial 592 finished with value: 5.400696721059205 and parameters: {'n_hidden': 4, 'learning_rate': 0.016488104488294478, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004111486560883925, 'dropout_rate_Layer_2': 0.029108259032114007, 'dropout_rate_Layer_3': 0.18851259906744383, 'dropout_rate_Layer_4': 0.20652619613919304, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00046972038847097736, 'l1_Layer_2': 1.5380715544768984e-05, 'l1_Layer_3': 0.027480551341224797, 'l1_Layer_4': 3.325154452773299e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 115, 'n_units_Layer_3': 55, 'n_units_Layer_4': 290}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 12.18% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 13.39% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:56:04,898]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:56:08,207]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:56:15,842]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:56:22,937]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:56:29,867]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:56:33,694]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:56:41,945]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:56:47,019]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:56:50,736]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:56:53,895]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:56:57,350]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:57:00,972]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:57:04,186]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:57:31,266]\u001b[0m Trial 606 finished with value: 5.223762440659258 and parameters: {'n_hidden': 4, 'learning_rate': 0.005776715491508654, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026854348726043663, 'dropout_rate_Layer_2': 0.026282284591734848, 'dropout_rate_Layer_3': 0.18752935349135108, 'dropout_rate_Layer_4': 0.21124133847777746, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000999287872414544, 'l1_Layer_2': 3.400504739629364e-05, 'l1_Layer_3': 0.0258908640548383, 'l1_Layer_4': 3.860365038984077e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 90, 'n_units_Layer_3': 60, 'n_units_Layer_4': 285}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 13.77% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 03:57:34,553]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 03:57:49,098]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:00:17,830]\u001b[0m Trial 609 finished with value: 5.1249591906776635 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006334189729998768, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12794131543760412, 'dropout_rate_Layer_2': 0.387246053112807, 'dropout_rate_Layer_3': 0.22700791838458415, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007063841365180396, 'l1_Layer_2': 0.0018860458249210967, 'l1_Layer_3': 0.0018985860633511883, 'n_units_Layer_1': 160, 'n_units_Layer_2': 210, 'n_units_Layer_3': 140}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 11.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 14.36% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:00:21,599]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:00:25,567]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:00:28,470]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:00:36,672]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:00:40,127]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:01:14,138]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:01:17,458]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:02:04,389]\u001b[0m Trial 617 finished with value: 4.834607726282248 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027927941356486346, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05662242712870015, 'dropout_rate_Layer_2': 0.1212592476579184, 'dropout_rate_Layer_3': 0.14369337936383392, 'dropout_rate_Layer_4': 0.23830262544398104, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007380511312813113, 'l1_Layer_2': 5.1989884853400614e-05, 'l1_Layer_3': 0.009601661225691133, 'l1_Layer_4': 0.0008412220475111897, 'n_units_Layer_1': 180, 'n_units_Layer_2': 50, 'n_units_Layer_3': 80, 'n_units_Layer_4': 160}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 11.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 12.85% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:02:07,489]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:02:20,600]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:02:27,742]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:03:30,311]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:03:43,770]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:03:54,956]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:04:00,104]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:04:31,763]\u001b[0m Trial 625 finished with value: 5.006773407477017 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025155154200973535, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12769458359214508, 'dropout_rate_Layer_2': 0.11639116283770833, 'dropout_rate_Layer_3': 0.1219509525921933, 'dropout_rate_Layer_4': 0.2363333025396139, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003539789091320869, 'l1_Layer_2': 7.249289155088903e-05, 'l1_Layer_3': 0.023405355487374768, 'l1_Layer_4': 0.0007349127203925724, 'n_units_Layer_1': 225, 'n_units_Layer_2': 50, 'n_units_Layer_3': 285, 'n_units_Layer_4': 110}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 11.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 13.46% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:04:34,861]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:05:07,159]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:05:14,892]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:05:34,716]\u001b[0m Trial 629 finished with value: 5.035047559631603 and parameters: {'n_hidden': 3, 'learning_rate': 0.009993688948532958, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11020942354376029, 'dropout_rate_Layer_2': 0.30170649865410576, 'dropout_rate_Layer_3': 0.0727886727172231, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011432795074099165, 'l1_Layer_2': 0.0002824638805763112, 'l1_Layer_3': 1.8424108763944186e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 11.55% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 13.44% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:05:37,904]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:05:42,501]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:05:45,451]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:05:48,100]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:05:51,698]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:06:03,628]\u001b[0m Trial 635 finished with value: 5.158285683755325 and parameters: {'n_hidden': 3, 'learning_rate': 0.015772496573258462, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1303043091536311, 'dropout_rate_Layer_2': 0.20198854039322597, 'dropout_rate_Layer_3': 0.06709982011755727, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.027842144134227e-05, 'l1_Layer_2': 0.00011133456723941591, 'l1_Layer_3': 1.2041555943355071e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 165, 'n_units_Layer_3': 220}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 14.16% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:06:08,519]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:06:15,770]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:06:18,684]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:07:16,289]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:07:18,951]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:08:57,464]\u001b[0m Trial 641 finished with value: 5.540687137209503 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005987993654315393, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11655797459311289, 'dropout_rate_Layer_2': 0.3901720258995498, 'dropout_rate_Layer_3': 0.24534544959627946, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004285767103910497, 'l1_Layer_2': 0.0024519824952968965, 'l1_Layer_3': 0.04377222280766466, 'n_units_Layer_1': 160, 'n_units_Layer_2': 220, 'n_units_Layer_3': 140}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 12.68% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.82 | sMAPE for Test Set is: 14.13% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:09:00,843]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:09:34,242]\u001b[0m Trial 643 finished with value: 4.88029578038434 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023466928457871574, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1272340916226174, 'dropout_rate_Layer_2': 0.10665694427390912, 'dropout_rate_Layer_3': 0.13710107169387237, 'dropout_rate_Layer_4': 0.2683910228590789, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001947169417670132, 'l1_Layer_2': 7.602548610215219e-05, 'l1_Layer_3': 0.006190876948033801, 'l1_Layer_4': 0.0009402484116412952, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 280, 'n_units_Layer_4': 90}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 11.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 13.16% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:09:37,350]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:10:12,482]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:10:15,322]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:10:30,112]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:10:33,359]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:10:36,338]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:10:39,825]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:11:17,125]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:11:57,960]\u001b[0m Trial 652 finished with value: 5.529493341548037 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011462489098692658, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03146989077975636, 'dropout_rate_Layer_2': 0.3657750557694494, 'dropout_rate_Layer_3': 0.19328182768368088, 'dropout_rate_Layer_4': 0.2222523245596894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001904339404554421, 'l1_Layer_2': 2.86099626781696e-05, 'l1_Layer_3': 0.0006628686655635655, 'l1_Layer_4': 1.282932831235887e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 130, 'n_units_Layer_4': 210}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 12.72% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 14.01% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:12:00,891]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:12:04,711]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:12:08,017]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:12:17,361]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:12:24,053]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:12:37,069]\u001b[0m Trial 658 finished with value: 5.112030758147355 and parameters: {'n_hidden': 3, 'learning_rate': 0.00858489503696653, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0470613250555738, 'dropout_rate_Layer_2': 0.24085220041057026, 'dropout_rate_Layer_3': 0.07358274077652172, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.94876576215586e-05, 'l1_Layer_2': 0.00016635471907912034, 'l1_Layer_3': 1.0584266157247538e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 145, 'n_units_Layer_3': 120}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.54 | sMAPE for Test Set is: 13.52% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:12:41,217]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:12:47,710]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:13:19,687]\u001b[0m Trial 661 finished with value: 5.331719412111037 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011386774246957424, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030342312523818065, 'dropout_rate_Layer_2': 0.3979698351924638, 'dropout_rate_Layer_3': 0.1918322392607872, 'dropout_rate_Layer_4': 0.2596963828001621, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002946432065700609, 'l1_Layer_2': 2.880235065931711e-05, 'l1_Layer_3': 0.00047675343306159375, 'l1_Layer_4': 1.328666636382308e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 175, 'n_units_Layer_3': 135, 'n_units_Layer_4': 210}. Best is trial 350 with value: 4.828288364872141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 12.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 13.85% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:13:23,094]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:13:32,381]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:13:39,518]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:13:43,217]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:13:48,150]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:13:51,199]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:13:54,623]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:14:39,459]\u001b[0m Trial 669 finished with value: 4.783177221696025 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024289111322722784, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13070210404594793, 'dropout_rate_Layer_2': 0.11665372743370135, 'dropout_rate_Layer_3': 0.10987967483280807, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028766667940454516, 'l1_Layer_2': 0.00016197513467481489, 'l1_Layer_3': 0.009744776950346602, 'n_units_Layer_1': 260, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275}. Best is trial 669 with value: 4.783177221696025.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 10.89% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 12.88% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:14:42,264]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:14:56,863]\u001b[0m Trial 671 finished with value: 5.2796393105482045 and parameters: {'n_hidden': 3, 'learning_rate': 0.006529498178131869, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18991331417329155, 'dropout_rate_Layer_2': 0.29090126516896225, 'dropout_rate_Layer_3': 0.06748891410625878, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010796368474603217, 'l1_Layer_2': 0.00018800609424077288, 'l1_Layer_3': 6.375551365090556e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 165, 'n_units_Layer_3': 120}. Best is trial 669 with value: 4.783177221696025.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 12.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 14.02% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:15:00,873]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:16:05,604]\u001b[0m Trial 673 finished with value: 5.150589928662533 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006996257699985049, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12391624607809722, 'dropout_rate_Layer_2': 0.3931781706889964, 'dropout_rate_Layer_3': 0.22253064108444387, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022019899575817883, 'l1_Layer_2': 0.0007374704872016728, 'l1_Layer_3': 0.014423414896811504, 'n_units_Layer_1': 150, 'n_units_Layer_2': 230, 'n_units_Layer_3': 170}. Best is trial 669 with value: 4.783177221696025.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 13.62% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:16:11,029]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:16:15,220]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:16:19,050]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:16:30,694]\u001b[0m Trial 677 finished with value: 5.3070278614193365 and parameters: {'n_hidden': 3, 'learning_rate': 0.004954851340723541, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19825979757410245, 'dropout_rate_Layer_2': 0.18806148995825223, 'dropout_rate_Layer_3': 0.3395037094654516, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.672036428821276e-05, 'l1_Layer_2': 0.00013820044111631684, 'l1_Layer_3': 9.969771886689444e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 170, 'n_units_Layer_3': 100}. Best is trial 669 with value: 4.783177221696025.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.82 | sMAPE for Test Set is: 14.13% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:16:38,045]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:16:42,247]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:16:46,576]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:16:50,773]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:16:57,352]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:17:01,006]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:17:05,100]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:17:09,450]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:17:17,136]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:17:21,178]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:17:24,460]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:17:28,612]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:17:33,098]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:17:55,384]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:18:00,928]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:18:04,707]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:18:12,434]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:19:01,381]\u001b[0m Trial 695 finished with value: 4.72595540272235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018036355305152746, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1806732139349091, 'dropout_rate_Layer_2': 0.11531390662460142, 'dropout_rate_Layer_3': 0.06145517293963039, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020718963074070954, 'l1_Layer_2': 0.0002820470520515864, 'l1_Layer_3': 0.005374765537902006, 'n_units_Layer_1': 265, 'n_units_Layer_2': 50, 'n_units_Layer_3': 255}. Best is trial 695 with value: 4.72595540272235.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 10.87% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 12.66% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:19:08,595]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:19:12,772]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:19:16,047]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:19:22,245]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:20:03,710]\u001b[0m Trial 700 finished with value: 4.803580714293255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023374604150642815, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18980739293660429, 'dropout_rate_Layer_2': 0.08668351576305855, 'dropout_rate_Layer_3': 0.061867532343300856, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015625312734335092, 'l1_Layer_2': 0.0003142301318271158, 'l1_Layer_3': 0.005192751536529235, 'n_units_Layer_1': 270, 'n_units_Layer_2': 50, 'n_units_Layer_3': 260}. Best is trial 695 with value: 4.72595540272235.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 11.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 12.67% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:20:39,197]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:20:42,565]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:20:45,308]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:20:48,559]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:21:05,597]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:21:09,163]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:21:12,336]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:21:25,314]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:21:28,170]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:21:40,537]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:21:58,548]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:22:01,414]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:22:11,654]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:22:14,584]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:22:22,274]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:22:27,979]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:23:05,176]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:23:13,513]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:23:17,914]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:00,181]\u001b[0m Trial 720 finished with value: 5.712601168692889 and parameters: {'n_hidden': 4, 'learning_rate': 0.0037232492832534373, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06317191198371144, 'dropout_rate_Layer_2': 0.3730664400282518, 'dropout_rate_Layer_3': 0.17245007733520876, 'dropout_rate_Layer_4': 0.21878090069830092, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00014736348992229752, 'l1_Layer_2': 0.00010267606940368555, 'l1_Layer_3': 0.0004613638029531905, 'l1_Layer_4': 1.5960607577586024e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 155, 'n_units_Layer_3': 135, 'n_units_Layer_4': 200}. Best is trial 695 with value: 4.72595540272235.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 13.12% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 14.43% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:24:03,917]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:11,012]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:13,812]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:21,254]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:26,709]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:30,341]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:33,622]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:37,074]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:39,975]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:44,854]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:48,461]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:51,838]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:24:55,167]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:25:10,001]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:25:18,178]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:25:21,041]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:25:25,153]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:25:29,050]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:25:33,129]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:25:36,533]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:25:40,082]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:25:43,379]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:25:46,295]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:25:49,578]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:26:03,121]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:26:37,304]\u001b[0m Trial 746 finished with value: 4.828892623507998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019908941257861003, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19388592658116008, 'dropout_rate_Layer_2': 0.11826659595772668, 'dropout_rate_Layer_3': 0.035137822391835306, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021937054421459988, 'l1_Layer_2': 0.00028558399649838723, 'l1_Layer_3': 0.004636317546535936, 'n_units_Layer_1': 265, 'n_units_Layer_2': 50, 'n_units_Layer_3': 260}. Best is trial 695 with value: 4.72595540272235.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 11.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.37 | sMAPE for Test Set is: 13.09% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:26:40,863]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:26:54,608]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:27:00,034]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:27:03,233]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:27:06,119]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:27:09,626]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:27:12,882]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:27:17,282]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:27:55,198]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:29:08,756]\u001b[0m Trial 756 finished with value: 4.673593468008983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015631520931190168, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21282536724655893, 'dropout_rate_Layer_2': 0.12751739412713228, 'dropout_rate_Layer_3': 0.058151465193665264, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019697678070922518, 'l1_Layer_2': 0.00023335669676438468, 'l1_Layer_3': 0.003235960122938306, 'n_units_Layer_1': 270, 'n_units_Layer_2': 60, 'n_units_Layer_3': 235}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 10.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 12.73% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:29:11,488]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:29:20,874]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:30:22,385]\u001b[0m Trial 759 finished with value: 4.769747359508465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014535290771201992, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22520568162104843, 'dropout_rate_Layer_2': 0.1296156118466918, 'dropout_rate_Layer_3': 0.05223189670640712, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.620257384064056e-05, 'l1_Layer_2': 0.0002551143038914408, 'l1_Layer_3': 0.0033271837439115457, 'n_units_Layer_1': 275, 'n_units_Layer_2': 75, 'n_units_Layer_3': 235}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 10.92% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 12.74% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:30:29,434]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:31:04,433]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:31:12,436]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:31:15,893]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:31:27,246]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:31:42,212]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:31:46,124]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:31:50,129]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:31:57,834]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:32:38,845]\u001b[0m Trial 769 finished with value: 5.160460292973331 and parameters: {'n_hidden': 4, 'learning_rate': 0.000829989822764695, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04501625847408905, 'dropout_rate_Layer_2': 0.3333341570363716, 'dropout_rate_Layer_3': 0.1424552011758906, 'dropout_rate_Layer_4': 0.23760907458005975, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00014603981351647002, 'l1_Layer_2': 5.881417796604664e-05, 'l1_Layer_3': 0.000913440001243443, 'l1_Layer_4': 1.2706657100926776e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 270, 'n_units_Layer_3': 165, 'n_units_Layer_4': 90}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 11.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 13.91% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:32:42,837]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:32:58,578]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:33:03,474]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:33:09,413]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:33:31,159]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:33:36,787]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:34:28,827]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:34:32,833]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:34:40,733]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:34:50,138]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:34:53,314]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:35:27,755]\u001b[0m Trial 781 finished with value: 4.735184858822067 and parameters: {'n_hidden': 3, 'learning_rate': 0.001302865483771875, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2469724361543339, 'dropout_rate_Layer_2': 0.16236915530352733, 'dropout_rate_Layer_3': 0.06784872728916788, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002015105806165362, 'l1_Layer_2': 0.00020568891027431682, 'l1_Layer_3': 0.001677206104796651, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 240}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 13.05% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:35:32,847]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:35:36,184]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:35:40,402]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:36:15,285]\u001b[0m Trial 785 finished with value: 5.293680235709114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012616925258245224, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25529531520332893, 'dropout_rate_Layer_2': 0.15172673023718822, 'dropout_rate_Layer_3': 0.06683139261954439, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015701845942794234, 'l1_Layer_2': 0.00018220899149579462, 'l1_Layer_3': 0.0017096778116701048, 'n_units_Layer_1': 300, 'n_units_Layer_2': 80, 'n_units_Layer_3': 235}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 13.95% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:37:56,455]\u001b[0m Trial 786 finished with value: 4.728430792828068 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008503213851883752, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2636178778651658, 'dropout_rate_Layer_2': 0.16061677609953978, 'dropout_rate_Layer_3': 0.06691633266177828, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.265642934996764e-05, 'l1_Layer_2': 0.0006304029290484868, 'l1_Layer_3': 0.003333667428706089, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 245}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 10.88% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 12.57% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:37:59,924]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:38:58,630]\u001b[0m Trial 788 finished with value: 4.745668068296195 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009145719449033316, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2532536666353977, 'dropout_rate_Layer_2': 0.16612097509529322, 'dropout_rate_Layer_3': 0.05591487580792251, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.589519161077846e-05, 'l1_Layer_2': 0.0005712592822181205, 'l1_Layer_3': 0.0032004487613985803, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 245}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 10.94% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 12.65% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:39:01,825]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:39:05,027]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:40:04,453]\u001b[0m Trial 791 finished with value: 5.329855312155611 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010038158114188992, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06089075147542616, 'dropout_rate_Layer_2': 0.34027585163064944, 'dropout_rate_Layer_3': 0.12057152119813297, 'dropout_rate_Layer_4': 0.2560460094375457, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00015079232104170758, 'l1_Layer_2': 1.8255635156868012e-05, 'l1_Layer_3': 0.0007263225636276794, 'l1_Layer_4': 2.0069665808141443e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150, 'n_units_Layer_4': 65}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 12.04% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.77 | sMAPE for Test Set is: 13.69% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:40:42,826]\u001b[0m Trial 792 finished with value: 5.272779812382142 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007376953426053866, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06259872861935165, 'dropout_rate_Layer_2': 0.33965200643200394, 'dropout_rate_Layer_3': 0.1258753884896583, 'dropout_rate_Layer_4': 0.25877438209591713, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00022726856358660626, 'l1_Layer_2': 0.00014048979598217803, 'l1_Layer_3': 0.0006218938063874981, 'l1_Layer_4': 2.0170371331663418e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160, 'n_units_Layer_4': 60}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 13.60% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:40:57,741]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:41:08,386]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:41:11,333]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:41:43,706]\u001b[0m Trial 796 finished with value: 5.266426499995439 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007554566657434473, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06759435850976327, 'dropout_rate_Layer_2': 0.38905960423225794, 'dropout_rate_Layer_3': 0.1052216151887931, 'dropout_rate_Layer_4': 0.2642538530622591, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00024907626654749283, 'l1_Layer_2': 3.486973846159543e-05, 'l1_Layer_3': 0.0006420613850146705, 'l1_Layer_4': 1.1181992299121363e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150, 'n_units_Layer_4': 80}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 12.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.64 | sMAPE for Test Set is: 13.63% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:41:47,076]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:43:09,674]\u001b[0m Trial 798 finished with value: 4.75224171074631 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008262423312120427, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2607508913739417, 'dropout_rate_Layer_2': 0.16873064218546482, 'dropout_rate_Layer_3': 0.08010830693462535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.65060209110949e-05, 'l1_Layer_2': 0.0006308973218334107, 'l1_Layer_3': 0.003175568493286948, 'n_units_Layer_1': 285, 'n_units_Layer_2': 65, 'n_units_Layer_3': 245}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 10.92% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.16 | sMAPE for Test Set is: 12.53% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:43:15,059]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:43:18,055]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:43:21,960]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:43:27,469]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:43:30,427]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:43:52,408]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:44:27,684]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:44:36,162]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:44:44,269]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:44:52,220]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:44:57,119]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:45:17,120]\u001b[0m Trial 810 finished with value: 5.157637191649033 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007721450270914236, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02391970691425586, 'dropout_rate_Layer_2': 0.3799207289503034, 'dropout_rate_Layer_3': 0.10875911787259429, 'dropout_rate_Layer_4': 0.25993528478608785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002433929816823516, 'l1_Layer_2': 3.6122517559878165e-05, 'l1_Layer_3': 0.0006693064140464687, 'l1_Layer_4': 1.07855338996522e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 290, 'n_units_Layer_3': 150, 'n_units_Layer_4': 90}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 13.94% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:45:25,826]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:45:29,276]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:45:32,263]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:45:35,605]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:45:42,435]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:47:22,938]\u001b[0m Trial 816 finished with value: 4.6827442266066415 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006704215872911947, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2774259290897095, 'dropout_rate_Layer_2': 0.1899235837832179, 'dropout_rate_Layer_3': 0.08020670211341956, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.913320892528857e-05, 'l1_Layer_2': 0.001072646112520131, 'l1_Layer_3': 0.00135280972290404, 'n_units_Layer_1': 285, 'n_units_Layer_2': 85, 'n_units_Layer_3': 220}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 10.74% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.15 | sMAPE for Test Set is: 12.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:47:26,627]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:47:30,239]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:47:39,874]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:48:19,185]\u001b[0m Trial 820 finished with value: 4.9874783057385095 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010173638542059827, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04014292007681762, 'dropout_rate_Layer_2': 0.3902722992070924, 'dropout_rate_Layer_3': 0.14066369186461364, 'dropout_rate_Layer_4': 0.2801772054520057, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00019541815741311636, 'l1_Layer_2': 5.312610471054158e-05, 'l1_Layer_3': 0.0006508078835328154, 'l1_Layer_4': 1.3323685056662001e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 290, 'n_units_Layer_3': 150, 'n_units_Layer_4': 85}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 14.11% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:48:28,946]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:48:34,607]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:48:39,355]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:48:42,969]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:48:45,872]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:48:49,321]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:48:57,223]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:49:05,548]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:49:19,549]\u001b[0m Trial 829 finished with value: 5.12161009564302 and parameters: {'n_hidden': 3, 'learning_rate': 0.004927638210806767, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04011757779456605, 'dropout_rate_Layer_2': 0.28790474094276935, 'dropout_rate_Layer_3': 0.2763874524463762, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014579941994089941, 'l1_Layer_2': 0.0006828683056994114, 'l1_Layer_3': 1.7464732461257094e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 160, 'n_units_Layer_3': 100}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 11.67% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 14.30% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:49:22,620]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:49:55,228]\u001b[0m Trial 831 finished with value: 4.932312407440313 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009763885847796045, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.039004129396771794, 'dropout_rate_Layer_2': 0.3913819292316502, 'dropout_rate_Layer_3': 0.11989939636783845, 'dropout_rate_Layer_4': 0.2759520950978076, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00042863822006232216, 'l1_Layer_2': 5.420695193156519e-05, 'l1_Layer_3': 0.0005660768407795126, 'l1_Layer_4': 2.2498334528114557e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180, 'n_units_Layer_4': 85}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 11.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 13.27% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:50:01,837]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:50:05,874]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:50:09,310]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:50:12,446]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:50:16,456]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:51:31,146]\u001b[0m Trial 837 finished with value: 4.987707808421754 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005772493063662755, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017928962027649584, 'dropout_rate_Layer_2': 0.3787662845898836, 'dropout_rate_Layer_3': 0.09555156011363901, 'dropout_rate_Layer_4': 0.27786131555285465, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006463649246211723, 'l1_Layer_2': 4.980322812019777e-05, 'l1_Layer_3': 0.000860446273956186, 'l1_Layer_4': 1.0461499482817904e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 300, 'n_units_Layer_3': 150, 'n_units_Layer_4': 75}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 11.35% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 13.25% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 04:51:36,718]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:52:11,360]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:52:15,365]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:52:18,957]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:52:22,057]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:52:26,949]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:52:30,322]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:53:12,999]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:53:16,253]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:53:19,865]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:53:24,125]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:53:36,630]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:53:49,139]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:53:53,565]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:53:59,764]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:54:15,242]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:54:25,545]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:54:39,203]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:54:43,382]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:54:46,826]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:54:49,715]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:54:53,490]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:54:56,557]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:55:06,941]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:55:10,933]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:55:39,727]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:56:01,083]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:56:04,439]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:56:11,449]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:56:15,639]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:56:49,354]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:57:17,368]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:57:51,923]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:57:58,247]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:58:01,000]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:58:10,545]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:58:47,711]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:59:08,577]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:59:23,232]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:59:38,528]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:59:43,696]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 04:59:47,155]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:00:34,709]\u001b[0m Trial 880 finished with value: 5.106418694641781 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009074790114063274, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06280009552040834, 'dropout_rate_Layer_2': 0.3999665810782911, 'dropout_rate_Layer_3': 0.13895823282445602, 'dropout_rate_Layer_4': 0.27328439220897954, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017136264846558336, 'l1_Layer_2': 1.9319126140598217e-05, 'l1_Layer_3': 0.0002810022832662824, 'l1_Layer_4': 1.4325001114318443e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170, 'n_units_Layer_4': 100}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.54 | sMAPE for Test Set is: 13.61% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:01:09,334]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:01:16,491]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:01:19,547]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:02:14,161]\u001b[0m Trial 884 finished with value: 4.737519646823073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005398706697667204, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2464582436454202, 'dropout_rate_Layer_2': 0.16496525223524655, 'dropout_rate_Layer_3': 0.09006080917763046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001052353794853312, 'l1_Layer_2': 0.00046180166594069654, 'l1_Layer_3': 0.0024625806539309435, 'n_units_Layer_1': 225, 'n_units_Layer_2': 230, 'n_units_Layer_3': 250}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 10.93% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.27 | sMAPE for Test Set is: 12.85% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:02:18,950]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:02:25,969]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:02:29,652]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:02:32,548]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:02:35,336]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:02:49,999]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:02:53,428]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:03:00,729]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:03:30,369]\u001b[0m Trial 893 finished with value: 5.008461896778263 and parameters: {'n_hidden': 4, 'learning_rate': 0.000869701566740747, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07155724847898765, 'dropout_rate_Layer_2': 0.3959503843775346, 'dropout_rate_Layer_3': 0.1375126517709524, 'dropout_rate_Layer_4': 0.2714131509143501, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001647849633154762, 'l1_Layer_2': 2.6239867139005915e-05, 'l1_Layer_3': 0.00028242183524263193, 'l1_Layer_4': 1.4622131384879228e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170, 'n_units_Layer_4': 75}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 11.54% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.73 | sMAPE for Test Set is: 13.77% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:03:43,277]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:03:47,725]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:04:15,162]\u001b[0m Trial 896 finished with value: 5.208459035004982 and parameters: {'n_hidden': 3, 'learning_rate': 0.005378154682742538, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08021663954507333, 'dropout_rate_Layer_2': 0.38739807245967484, 'dropout_rate_Layer_3': 0.25335092349572497, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026924455963152696, 'l1_Layer_2': 0.0029877299975096146, 'l1_Layer_3': 0.006891618619115112, 'n_units_Layer_1': 165, 'n_units_Layer_2': 225, 'n_units_Layer_3': 135}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.73 | sMAPE for Test Set is: 13.70% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:04:18,542]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:04:21,725]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:04:25,102]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:04:29,472]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:04:32,819]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:04:37,795]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:04:41,581]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:04:46,042]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:04:49,806]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:04:56,293]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:05:00,172]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:05:03,898]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:05:07,160]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:05:20,487]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:05:34,084]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:05:37,104]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:05:44,729]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:05:57,331]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:06:00,524]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:06:04,855]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:06:08,029]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:06:16,473]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:06:21,191]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:06:24,245]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:06:44,512]\u001b[0m Trial 921 finished with value: 5.332882353908745 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008326581802770861, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06358156432580436, 'dropout_rate_Layer_2': 0.3705883710906141, 'dropout_rate_Layer_3': 0.13263937302204304, 'dropout_rate_Layer_4': 0.2922865050575003, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.513403917747949e-05, 'l1_Layer_2': 2.3707725425889957e-05, 'l1_Layer_3': 0.0003825570310294949, 'l1_Layer_4': 1.490055493827518e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 275, 'n_units_Layer_3': 170, 'n_units_Layer_4': 100}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 12.42% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.84 | sMAPE for Test Set is: 14.20% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:06:47,917]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:06:53,175]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:07:37,114]\u001b[0m Trial 924 finished with value: 4.982820474555372 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006627160203455883, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07728746434837713, 'dropout_rate_Layer_2': 0.3925248042558056, 'dropout_rate_Layer_3': 0.12146000084500203, 'dropout_rate_Layer_4': 0.28145535333409216, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00023175849299123853, 'l1_Layer_2': 3.96583576913048e-05, 'l1_Layer_3': 0.0006878736986284102, 'l1_Layer_4': 2.0183931628766943e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180, 'n_units_Layer_4': 85}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 11.48% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.70 | sMAPE for Test Set is: 13.64% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:08:04,786]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:08:52,820]\u001b[0m Trial 926 finished with value: 5.01932065812791 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005534040052134198, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05326069346259624, 'dropout_rate_Layer_2': 0.392291372974415, 'dropout_rate_Layer_3': 0.1461191923535387, 'dropout_rate_Layer_4': 0.29893587068140637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008174987487937317, 'l1_Layer_2': 6.425850202913028e-05, 'l1_Layer_3': 0.00020801449496958064, 'l1_Layer_4': 3.1467275770565524e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 290, 'n_units_Layer_3': 180, 'n_units_Layer_4': 85}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.60 | sMAPE for Test Set is: 13.51% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:08:55,759]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:08:59,780]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:09:56,059]\u001b[0m Trial 929 finished with value: 4.794740456549148 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005453087340492552, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07039695402604287, 'dropout_rate_Layer_2': 0.3872922353234704, 'dropout_rate_Layer_3': 0.15141506854235942, 'dropout_rate_Layer_4': 0.30292661242397895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007258550944947296, 'l1_Layer_2': 6.522142222325793e-05, 'l1_Layer_3': 0.00018845059986123016, 'l1_Layer_4': 3.341806365125107e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 290, 'n_units_Layer_3': 180, 'n_units_Layer_4': 115}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 10.98% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 12.96% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:10:04,777]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:10:08,495]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:11:07,486]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:11:10,811]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:11:15,264]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:11:18,362]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:11:25,278]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:11:32,038]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:11:37,346]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:12:21,067]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:12:44,206]\u001b[0m Trial 940 finished with value: 5.130638032847499 and parameters: {'n_hidden': 3, 'learning_rate': 0.009026609954753812, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09223441260189916, 'dropout_rate_Layer_2': 0.1891760876594847, 'dropout_rate_Layer_3': 0.07628696773067735, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0030241649567099606, 'l1_Layer_2': 0.0008842125085290317, 'l1_Layer_3': 2.5359981425496023e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 11.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 13.24% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:12:55,618]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:12:59,595]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:13:42,440]\u001b[0m Trial 943 finished with value: 4.708597975372157 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008371025514505966, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26835841033838054, 'dropout_rate_Layer_2': 0.18613999377635548, 'dropout_rate_Layer_3': 0.059049041368699894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7975270932260665e-05, 'l1_Layer_2': 0.0006542524743863495, 'l1_Layer_3': 0.0022746356432289208, 'n_units_Layer_1': 235, 'n_units_Layer_2': 220, 'n_units_Layer_3': 250}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 10.81% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 12.74% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:13:45,324]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:13:49,757]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:14:11,234]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:14:37,710]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:14:43,758]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:15:07,516]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:15:11,589]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:15:42,862]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:16:33,949]\u001b[0m Trial 952 finished with value: 4.8966620946374455 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005073383381871962, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07950836178302606, 'dropout_rate_Layer_2': 0.3806822919201383, 'dropout_rate_Layer_3': 0.14028873650707582, 'dropout_rate_Layer_4': 0.2739402406171186, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012021712287252613, 'l1_Layer_2': 5.352653733321023e-05, 'l1_Layer_3': 0.00013209486984276447, 'l1_Layer_4': 3.347569919753089e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180, 'n_units_Layer_4': 100}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 11.32% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.47 | sMAPE for Test Set is: 13.41% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:17:29,945]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:17:40,646]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:18:47,809]\u001b[0m Trial 955 finished with value: 4.880222383833019 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009209721051696316, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29843727441928486, 'dropout_rate_Layer_2': 0.19186554306239054, 'dropout_rate_Layer_3': 0.020918299869125023, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.442063846295985e-05, 'l1_Layer_2': 0.000980198336931753, 'l1_Layer_3': 0.0011482392104213914, 'n_units_Layer_1': 215, 'n_units_Layer_2': 225, 'n_units_Layer_3': 225}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 11.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 13.03% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:18:51,239]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:19:31,694]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:19:37,730]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:19:46,119]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:19:49,816]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:19:53,978]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:20:09,399]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:20:12,903]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:20:18,288]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:20:22,767]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:20:32,773]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:20:44,486]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:20:48,612]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:20:56,770]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:21:00,512]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:21:08,386]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:22:04,155]\u001b[0m Trial 972 finished with value: 4.760737240394399 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006077336598358697, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.050974559295577024, 'dropout_rate_Layer_2': 0.374541010953688, 'dropout_rate_Layer_3': 0.14715420817739616, 'dropout_rate_Layer_4': 0.2714645330543132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008523884312525218, 'l1_Layer_2': 3.463016385818038e-05, 'l1_Layer_3': 0.000226914470487029, 'l1_Layer_4': 2.579514474595467e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 295, 'n_units_Layer_3': 190, 'n_units_Layer_4': 115}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 10.93% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 13.07% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:22:07,843]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:22:12,507]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:22:34,266]\u001b[0m Trial 975 finished with value: 4.750981405362959 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034287286092898515, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.165319936199776, 'dropout_rate_Layer_2': 0.18974882856701072, 'dropout_rate_Layer_3': 0.3141407727468571, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018066372267592564, 'l1_Layer_2': 0.0008222717952330002, 'l1_Layer_3': 1.938763162396718e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 10.88% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 13.11% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:22:39,685]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:22:43,188]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:22:46,185]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:23:52,759]\u001b[0m Trial 979 finished with value: 4.954110261266235 and parameters: {'n_hidden': 4, 'learning_rate': 0.00059828759110084, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.051004731089075196, 'dropout_rate_Layer_2': 0.3737871737230873, 'dropout_rate_Layer_3': 0.1466493294774269, 'dropout_rate_Layer_4': 0.27589979653372865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008451477693308013, 'l1_Layer_2': 5.5814855958331244e-05, 'l1_Layer_3': 0.00013971398444910746, 'l1_Layer_4': 2.6559551281783394e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 295, 'n_units_Layer_3': 190, 'n_units_Layer_4': 115}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 11.30% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 13.60% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:23:56,996]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:24:10,296]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:24:30,914]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:24:38,867]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:24:42,602]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:24:45,681]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:25:01,604]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:25:04,739]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:25:12,407]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:25:15,355]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:25:46,195]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:25:52,835]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:26:51,567]\u001b[0m Trial 992 finished with value: 4.808997659465676 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006329151426594004, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07752278449419997, 'dropout_rate_Layer_2': 0.36156321649574413, 'dropout_rate_Layer_3': 0.1627058776242452, 'dropout_rate_Layer_4': 0.31595668945162564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008748455032267443, 'l1_Layer_2': 5.445285943937947e-05, 'l1_Layer_3': 0.00012985133792489794, 'l1_Layer_4': 2.373664146999817e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 295, 'n_units_Layer_3': 200, 'n_units_Layer_4': 110}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 11.04% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 13.32% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:27:01,494]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:27:05,813]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:27:08,783]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:27:13,749]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:27:21,868]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:27:25,900]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:27:29,194]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:27:36,314]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:27:42,501]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:27:52,073]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:27:54,966]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:28:08,375]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:28:14,916]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:28:19,860]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:28:24,685]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:28:28,170]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:28:31,899]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:28:36,018]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:28:39,920]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:28:42,938]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:28:46,962]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:28:50,350]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:28:56,808]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:29:00,845]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:29:22,048]\u001b[0m Trial 1017 finished with value: 5.247883532229303 and parameters: {'n_hidden': 3, 'learning_rate': 0.007944010047360365, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02877417334214813, 'dropout_rate_Layer_2': 0.1480019362040152, 'dropout_rate_Layer_3': 0.2773556340046786, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006205335227032559, 'l1_Layer_2': 0.0011422037785854692, 'l1_Layer_3': 0.0014325731070833092, 'n_units_Layer_1': 140, 'n_units_Layer_2': 175, 'n_units_Layer_3': 220}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 12.10% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 13.82% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:29:28,081]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:29:41,715]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:29:44,783]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:29:48,353]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:29:56,270]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:30:00,002]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:30:03,642]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:30:08,570]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:30:16,173]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:30:19,325]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:30:31,025]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:30:34,422]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:30:37,535]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:30:41,725]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:30:45,177]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:30:48,347]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:30:57,767]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:31:14,373]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:31:19,951]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:31:23,901]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:31:29,483]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:31:33,159]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:33:14,403]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:33:17,321]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:33:24,446]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:33:28,730]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:34:05,213]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:34:20,534]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:34:32,380]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:34:35,757]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:34:39,754]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:34:54,120]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:34:58,856]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:35:02,659]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:35:05,835]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:35:56,711]\u001b[0m Trial 1053 finished with value: 4.910363263808592 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006566436794497098, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.044351738621822026, 'dropout_rate_Layer_2': 0.3848062821990874, 'dropout_rate_Layer_3': 0.14739302838607954, 'dropout_rate_Layer_4': 0.2707952337717113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010471440659198304, 'l1_Layer_2': 6.807595260399425e-05, 'l1_Layer_3': 0.00031015334798691833, 'l1_Layer_4': 2.198651884331321e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 285, 'n_units_Layer_3': 180, 'n_units_Layer_4': 130}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 11.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 13.44% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:35:59,889]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:36:15,007]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:36:18,388]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:36:24,293]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:36:31,669]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:36:39,120]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:36:43,008]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:36:46,302]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:36:53,449]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:37:37,415]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:37:40,865]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:37:44,775]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:37:48,114]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:37:51,101]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:38:06,519]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:38:09,522]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:39:04,163]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:39:10,084]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:39:45,986]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:39:59,709]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:40:02,987]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:40:10,879]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:40:14,414]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:40:19,817]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:41:16,624]\u001b[0m Trial 1078 finished with value: 4.884337832847787 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006809914398976822, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05576591470771056, 'dropout_rate_Layer_2': 0.3845739338616278, 'dropout_rate_Layer_3': 0.14861760777181993, 'dropout_rate_Layer_4': 0.2718837974919103, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010248001146244805, 'l1_Layer_2': 6.43224991042871e-05, 'l1_Layer_3': 0.0002928497288281276, 'l1_Layer_4': 2.1630100989569227e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 290, 'n_units_Layer_3': 175, 'n_units_Layer_4': 125}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 11.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 13.85% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:41:20,063]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:41:23,981]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:41:27,943]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:41:31,335]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:41:52,981]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:41:58,457]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:42:03,238]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:42:08,961]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:42:25,033]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:43:29,826]\u001b[0m Trial 1088 finished with value: 4.903536880526906 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006810333093402253, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05581043456608374, 'dropout_rate_Layer_2': 0.3866651055090683, 'dropout_rate_Layer_3': 0.16206017476342693, 'dropout_rate_Layer_4': 0.3218660686490355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010273479145919474, 'l1_Layer_2': 6.388245737669451e-05, 'l1_Layer_3': 0.0003164157024980977, 'l1_Layer_4': 2.1752816872648674e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180, 'n_units_Layer_4': 135}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 11.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 12.83% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:43:34,422]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:44:34,245]\u001b[0m Trial 1090 finished with value: 4.837066369398568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007763606815993377, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23064877634442082, 'dropout_rate_Layer_2': 0.16523819837661016, 'dropout_rate_Layer_3': 0.06169612851429019, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000236419966390188, 'l1_Layer_2': 0.0007220200502397836, 'l1_Layer_3': 0.006593925974842216, 'n_units_Layer_1': 275, 'n_units_Layer_2': 270, 'n_units_Layer_3': 250}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 11.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 12.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:44:37,273]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:44:46,216]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:45:17,472]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:45:20,585]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:45:23,963]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:45:27,719]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:46:02,428]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:46:12,307]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:46:17,730]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:46:20,700]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:46:23,904]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:46:39,009]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:46:42,618]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:47:19,207]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:47:25,303]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:47:28,385]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:47:38,881]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:47:46,726]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:48:00,417]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:48:04,173]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:48:07,626]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:49:45,794]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:49:50,916]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:50:55,055]\u001b[0m Trial 1114 finished with value: 4.6770944307147895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005676062551219408, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24288536050939943, 'dropout_rate_Layer_2': 0.21547963581767132, 'dropout_rate_Layer_3': 0.026795491645941867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.813377706077191e-05, 'l1_Layer_2': 0.0012191105351052175, 'l1_Layer_3': 0.0007237743369308792, 'n_units_Layer_1': 285, 'n_units_Layer_2': 95, 'n_units_Layer_3': 215}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 10.75% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.17 | sMAPE for Test Set is: 12.56% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:50:58,486]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:51:06,325]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:51:10,465]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:51:23,678]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:51:31,533]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:51:36,989]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:51:40,326]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:51:49,994]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:51:58,783]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:52:01,921]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:52:05,988]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:52:18,684]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:54:02,485]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:54:05,696]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:54:10,922]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:54:16,368]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:54:19,376]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:54:22,674]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:54:59,530]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:55:04,780]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:55:09,071]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:55:53,122]\u001b[0m Trial 1136 finished with value: 4.813951506530327 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005649353053115047, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04015359609281982, 'dropout_rate_Layer_2': 0.3541156074064814, 'dropout_rate_Layer_3': 0.162151232634082, 'dropout_rate_Layer_4': 0.29365604144623725, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010651141717302423, 'l1_Layer_2': 5.21660078355205e-05, 'l1_Layer_3': 0.00031792740335053957, 'l1_Layer_4': 1.7513908370421447e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 290, 'n_units_Layer_3': 190, 'n_units_Layer_4': 115}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 11.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 13.29% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:56:00,662]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:56:06,970]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:56:10,152]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:57:05,611]\u001b[0m Trial 1140 finished with value: 4.701740812220831 and parameters: {'n_hidden': 3, 'learning_rate': 0.000505901581510789, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26386002016351406, 'dropout_rate_Layer_2': 0.17376392408141497, 'dropout_rate_Layer_3': 0.017915281077639227, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.086631487741772e-05, 'l1_Layer_2': 0.0003605092888521449, 'l1_Layer_3': 0.0007120726565927133, 'n_units_Layer_1': 300, 'n_units_Layer_2': 90, 'n_units_Layer_3': 230}. Best is trial 756 with value: 4.673593468008983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 10.78% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 12.85% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 05:57:08,552]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:57:12,609]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:57:20,249]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:57:48,088]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:57:51,628]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:00,185]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:07,046]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:14,527]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:19,737]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:25,242]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:28,974]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:32,321]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:35,338]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:39,525]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:43,906]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:47,614]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:53,890]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:58:56,901]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:59:01,175]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:59:04,220]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:59:07,545]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:59:11,964]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:59:15,228]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:59:18,984]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:59:41,735]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:59:44,920]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 05:59:50,577]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:00:13,684]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:00:17,496]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:00:33,341]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:00:37,165]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:00:43,747]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:00:46,672]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:00:51,302]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:00:59,792]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:01:03,445]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:01:13,390]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:01:16,850]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:01:19,620]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:01:29,512]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:01:33,243]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:01:35,965]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:01:40,955]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:01:44,515]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:01:47,962]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:01:51,748]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:01:56,084]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:02:05,271]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:02:08,851]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:02:11,842]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:02:15,886]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:02:22,005]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:02:43,390]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:02:48,558]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:03:32,957]\u001b[0m Trial 1195 finished with value: 4.6688110589892275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005668971446523498, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21000784582976895, 'dropout_rate_Layer_2': 0.1841010707004758, 'dropout_rate_Layer_3': 0.03912464975674149, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.51560121550995e-05, 'l1_Layer_2': 0.00017818868750088036, 'l1_Layer_3': 0.001035089488951285, 'n_units_Layer_1': 275, 'n_units_Layer_2': 85, 'n_units_Layer_3': 225}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 10.73% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 12.82% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:03:45,480]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:03:48,696]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:04:01,192]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:04:32,498]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:04:36,404]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:05:06,226]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:05:09,859]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:05:14,111]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:05:21,848]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:05:39,677]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:05:44,959]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:05:48,471]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:05:52,775]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:05:55,486]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:06:10,425]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:06:19,167]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:06:24,685]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:06:30,595]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:06:33,361]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:07:11,275]\u001b[0m Trial 1215 finished with value: 5.063436148206615 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028425703770481423, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20119981488355201, 'dropout_rate_Layer_2': 0.3750397816933153, 'dropout_rate_Layer_3': 0.007683504350169355, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.2328699669853446e-05, 'l1_Layer_2': 3.76451678805771e-05, 'l1_Layer_3': 0.01591268898910393, 'n_units_Layer_1': 155, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.54 | sMAPE for Test Set is: 13.46% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:07:25,854]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:07:38,706]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:07:51,358]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:07:56,424]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:07:59,876]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:08:03,835]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:08:16,299]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:08:20,473]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:08:23,896]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:08:27,709]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:08:34,302]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:08:37,616]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:08:42,717]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:08:49,561]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:08:53,011]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:08:56,791]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:09:03,734]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:09:12,109]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:09:18,365]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:09:22,776]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:09:26,741]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:09:37,667]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:09:40,999]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:09:45,078]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:09:51,815]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:09:55,456]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:10:01,601]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:10:04,784]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:11:03,382]\u001b[0m Trial 1244 finished with value: 4.774861833623001 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005459807026915679, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21708483388077893, 'dropout_rate_Layer_2': 0.19528868129332083, 'dropout_rate_Layer_3': 0.04566147644103539, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002569661201917283, 'l1_Layer_2': 0.0003888004309742633, 'l1_Layer_3': 0.001184263029618543, 'n_units_Layer_1': 240, 'n_units_Layer_2': 240, 'n_units_Layer_3': 235}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 11.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 12.70% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:11:09,490]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:11:13,893]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:11:22,140]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:11:26,245]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:11:30,475]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:11:35,126]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:11:41,580]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:11:45,758]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:11:53,991]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:11:59,798]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:12:05,821]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:12:40,921]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:12:43,674]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:12:57,241]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:13:02,894]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:13:09,833]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:13:46,397]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:13:50,481]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:13:54,227]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:14:35,737]\u001b[0m Trial 1264 finished with value: 4.6952946174477725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005000655974463893, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26757115646925234, 'dropout_rate_Layer_2': 0.17517961432173523, 'dropout_rate_Layer_3': 0.0014572989588505086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.465841536579715e-05, 'l1_Layer_2': 0.0001587567048544062, 'l1_Layer_3': 0.000954573874121993, 'n_units_Layer_1': 215, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 12.65% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:14:38,599]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:15:35,501]\u001b[0m Trial 1266 finished with value: 4.954277864359388 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007791441721465902, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.059662015509573785, 'dropout_rate_Layer_2': 0.3837707743412054, 'dropout_rate_Layer_3': 0.1476171153346634, 'dropout_rate_Layer_4': 0.3201500260068652, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013051569674984856, 'l1_Layer_2': 4.940681172307548e-05, 'l1_Layer_3': 0.00031531780235608616, 'l1_Layer_4': 5.133364076929136e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 180, 'n_units_Layer_4': 110}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 11.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 13.62% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:15:39,309]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:15:48,917]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:15:52,143]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:16:00,506]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:16:03,225]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:16:09,256]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:16:17,419]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:16:21,008]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:16:52,583]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:16:55,384]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:17:35,853]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:17:46,253]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:17:49,928]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:18:20,685]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:19:14,323]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:19:17,972]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:19:20,805]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:19:26,312]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:19:29,458]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:19:33,170]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:19:36,390]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:19:48,755]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:20:33,008]\u001b[0m Trial 1289 finished with value: 4.681653922913905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005771657525616471, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23910498660473212, 'dropout_rate_Layer_2': 0.14976456564313984, 'dropout_rate_Layer_3': 0.001035633042063451, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.500460025295786e-05, 'l1_Layer_2': 0.0002484910916315712, 'l1_Layer_3': 0.0007685992861072076, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 225}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 12.74% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:20:36,100]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:21:35,321]\u001b[0m Trial 1291 finished with value: 4.675412339982151 and parameters: {'n_hidden': 3, 'learning_rate': 0.000739573442711694, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2355788325001613, 'dropout_rate_Layer_2': 0.14769534192983985, 'dropout_rate_Layer_3': 0.0003164056888414757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7586028636137972e-05, 'l1_Layer_2': 0.00013450400853345484, 'l1_Layer_3': 0.0007973968128950716, 'n_units_Layer_1': 195, 'n_units_Layer_2': 75, 'n_units_Layer_3': 220}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 10.72% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 12.64% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:21:38,720]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:22:11,313]\u001b[0m Trial 1293 finished with value: 4.7093575053508046 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005911701559031746, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20773176610864152, 'dropout_rate_Layer_2': 0.1338894920644172, 'dropout_rate_Layer_3': 0.01130887985434429, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.660999370235097e-05, 'l1_Layer_2': 0.0001652388880525414, 'l1_Layer_3': 0.000736722697344496, 'n_units_Layer_1': 175, 'n_units_Layer_2': 75, 'n_units_Layer_3': 220}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 10.85% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 12.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:22:15,169]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:22:18,201]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:22:26,998]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:23:04,177]\u001b[0m Trial 1297 finished with value: 4.726102271346406 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007381523838599396, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20893515926290268, 'dropout_rate_Layer_2': 0.13585827225744285, 'dropout_rate_Layer_3': 0.0008777704126561401, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.150228757057877e-05, 'l1_Layer_2': 0.00015853311450630893, 'l1_Layer_3': 0.0007883926653625875, 'n_units_Layer_1': 190, 'n_units_Layer_2': 95, 'n_units_Layer_3': 210}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 10.88% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 12.63% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:23:08,375]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:23:11,241]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:23:24,236]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:23:29,094]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:24:24,830]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:24:31,212]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:24:46,734]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:24:50,388]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:25:43,428]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:25:54,522]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:25:57,804]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:26:10,911]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:26:14,087]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:26:17,338]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:26:20,843]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:26:57,260]\u001b[0m Trial 1313 finished with value: 4.748477159603126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005828515608080197, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2334151201424925, 'dropout_rate_Layer_2': 0.14907011998071693, 'dropout_rate_Layer_3': 0.0055254275756567205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6733172124739003e-05, 'l1_Layer_2': 8.520466591638462e-05, 'l1_Layer_3': 0.00043798816712583573, 'n_units_Layer_1': 200, 'n_units_Layer_2': 105, 'n_units_Layer_3': 230}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 10.88% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 12.75% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:27:01,235]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:27:07,837]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:27:10,912]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:27:14,730]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:27:26,209]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:27:29,864]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:27:34,373]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:27:37,540]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:27:40,474]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:27:47,876]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:27:51,419]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:27:56,839]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:28:11,681]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:28:15,113]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:28:24,433]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:28:58,032]\u001b[0m Trial 1329 finished with value: 4.721520674317465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007703761800456263, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24034995186739716, 'dropout_rate_Layer_2': 0.1361790883249037, 'dropout_rate_Layer_3': 0.016407318160096385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7388440811318307e-05, 'l1_Layer_2': 0.00023607290452757007, 'l1_Layer_3': 0.0008383452023579177, 'n_units_Layer_1': 210, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 10.83% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 12.72% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:29:26,376]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:29:34,296]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:29:41,930]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:29:45,540]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:29:48,432]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:30:19,217]\u001b[0m Trial 1335 finished with value: 4.762669169245707 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006336435225343294, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21441352939509198, 'dropout_rate_Layer_2': 0.10702891763440314, 'dropout_rate_Layer_3': 0.0003148513321213143, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.284596820738453e-05, 'l1_Layer_2': 0.0001900006841386586, 'l1_Layer_3': 0.0008996445438460109, 'n_units_Layer_1': 205, 'n_units_Layer_2': 75, 'n_units_Layer_3': 220}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 12.74% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:30:26,694]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:30:31,049]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:31:22,257]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:31:30,040]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:06,522]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:11,286]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:14,629]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:17,434]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:24,908]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:30,136]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:34,048]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:37,824]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:41,119]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:44,760]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:48,218]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:51,035]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:32:54,733]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:33:01,880]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:33:08,435]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:33:13,082]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:33:20,354]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:33:23,156]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:33:27,429]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:33:34,541]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:33:38,156]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:33:44,731]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:33:48,342]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:33:54,748]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:34:45,208]\u001b[0m Trial 1364 finished with value: 4.702186607102441 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005513863510546438, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22540037456541004, 'dropout_rate_Layer_2': 0.12787897971857537, 'dropout_rate_Layer_3': 0.022646669334125784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.881873364287918e-05, 'l1_Layer_2': 0.00011030908761561988, 'l1_Layer_3': 0.0007353585752161388, 'n_units_Layer_1': 175, 'n_units_Layer_2': 70, 'n_units_Layer_3': 205}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 10.82% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.16 | sMAPE for Test Set is: 12.56% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:34:51,174]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:34:54,424]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:34:57,740]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:35:01,529]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:35:53,484]\u001b[0m Trial 1369 finished with value: 4.819754134378841 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010680845326031187, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04975817030135446, 'dropout_rate_Layer_2': 0.39924861813060414, 'dropout_rate_Layer_3': 0.17551093499548048, 'dropout_rate_Layer_4': 0.2662685977360925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007658849485004146, 'l1_Layer_2': 0.00016105931090614473, 'l1_Layer_3': 0.00017869852036496366, 'l1_Layer_4': 1.755988604911641e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 285, 'n_units_Layer_3': 205, 'n_units_Layer_4': 125}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 11.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 13.12% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:36:20,496]\u001b[0m Trial 1370 finished with value: 4.890419224969057 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010243393937799594, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05159713226832362, 'dropout_rate_Layer_2': 0.38902355915295017, 'dropout_rate_Layer_3': 0.17627229890836696, 'dropout_rate_Layer_4': 0.2645634730574154, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008195817783746886, 'l1_Layer_2': 0.0001470855545858542, 'l1_Layer_3': 0.00018164706347169915, 'l1_Layer_4': 1.7929614966128927e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 285, 'n_units_Layer_3': 210, 'n_units_Layer_4': 125}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 11.23% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 13.39% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:36:23,212]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:36:26,466]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:36:31,269]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:36:34,659]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:36:39,284]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:36:42,801]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:36:46,126]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:36:49,549]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:36:52,642]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:36:57,154]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:37:37,835]\u001b[0m Trial 1381 finished with value: 4.718846758499713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005555274809536927, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2284918885673776, 'dropout_rate_Layer_2': 0.12428900097566846, 'dropout_rate_Layer_3': 0.024054000131894623, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8586420080909777e-05, 'l1_Layer_2': 0.00011440864617546189, 'l1_Layer_3': 0.0007430976429120906, 'n_units_Layer_1': 170, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 10.88% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 12.63% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:37:41,412]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:37:44,697]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:37:47,832]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:37:54,987]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:37:58,498]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:38:04,891]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:38:08,636]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:38:11,818]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:38:14,699]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:38:18,768]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:38:22,792]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:38:30,301]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:38:33,771]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:38:38,362]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:38:44,322]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:39:49,986]\u001b[0m Trial 1397 finished with value: 4.862233672563812 and parameters: {'n_hidden': 4, 'learning_rate': 0.00107960531682413, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.047379678444762846, 'dropout_rate_Layer_2': 0.3783154619847354, 'dropout_rate_Layer_3': 0.17905317144458832, 'dropout_rate_Layer_4': 0.26616866814990914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006895747755499431, 'l1_Layer_2': 0.00037489421908540213, 'l1_Layer_3': 0.00016915736127032178, 'l1_Layer_4': 1.6864088686853437e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 285, 'n_units_Layer_3': 210, 'n_units_Layer_4': 125}. Best is trial 1195 with value: 4.6688110589892275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 11.00% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 13.08% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:39:52,585]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:39:57,173]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:40:04,983]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:40:07,952]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:40:16,586]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:40:19,632]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:40:23,652]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:40:26,482]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:40:33,550]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:40:37,386]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:40:41,322]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:40:44,527]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:40:58,324]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:41:01,803]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:41:08,953]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:41:12,066]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:41:19,791]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:41:23,377]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:41:26,633]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:41:30,156]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:41:34,089]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:41:37,654]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:41:42,055]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:42:45,992]\u001b[0m Trial 1421 finished with value: 4.636670161465692 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009190371796933252, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03521981654821997, 'dropout_rate_Layer_2': 0.3857476148543189, 'dropout_rate_Layer_3': 0.16227169434824612, 'dropout_rate_Layer_4': 0.2643580541724299, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005701714463237661, 'l1_Layer_2': 8.848375834306894e-05, 'l1_Layer_3': 0.00016281190231987378, 'l1_Layer_4': 1.2431272978308982e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 285, 'n_units_Layer_3': 205, 'n_units_Layer_4': 115}. Best is trial 1421 with value: 4.636670161465692.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 10.58% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 13.15% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:43:23,331]\u001b[0m Trial 1422 finished with value: 4.705832971860576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005425433172170225, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22475173848636676, 'dropout_rate_Layer_2': 0.12667299756855327, 'dropout_rate_Layer_3': 0.026582818596675488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8809186885525514e-05, 'l1_Layer_2': 0.00012068777562771119, 'l1_Layer_3': 0.0006220265862678592, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 170}. Best is trial 1421 with value: 4.636670161465692.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 10.84% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 12.65% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:44:18,110]\u001b[0m Trial 1423 finished with value: 4.695073861432031 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005376297766017729, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2229592660174684, 'dropout_rate_Layer_2': 0.1291108326369949, 'dropout_rate_Layer_3': 0.03165270987286782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4790978725063699e-05, 'l1_Layer_2': 0.00013656958424746458, 'l1_Layer_3': 0.0005722364750459425, 'n_units_Layer_1': 160, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200}. Best is trial 1421 with value: 4.636670161465692.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 10.75% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 12.59% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:44:23,039]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:44:26,589]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:44:38,390]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:44:41,424]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:44:46,382]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:44:54,516]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:44:57,994]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:45:01,588]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:45:15,195]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:45:18,416]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:45:23,963]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:45:30,650]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:45:44,544]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:45:49,745]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:45:53,642]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:45:57,158]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:46:00,124]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:46:03,360]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:46:06,489]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:46:13,119]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:46:21,268]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:46:31,436]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:46:35,401]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:46:40,840]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:46:47,893]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:47:01,512]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:47:09,315]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:47:12,097]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:47:16,149]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:47:23,731]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:47:27,599]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:47:30,472]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:47:39,721]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:47:42,970]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:47:51,093]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:49:21,670]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:50:47,724]\u001b[0m Trial 1460 finished with value: 5.462809396171925 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008736448390858717, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0929863200358687, 'dropout_rate_Layer_2': 0.3597869887448445, 'dropout_rate_Layer_3': 0.1861947113524341, 'dropout_rate_Layer_4': 0.17593523413081663, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0062154576190751355, 'l1_Layer_2': 0.01621980911267112, 'l1_Layer_3': 0.0013819491941227356, 'l1_Layer_4': 0.0008971213651471091, 'n_units_Layer_1': 60, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240, 'n_units_Layer_4': 100}. Best is trial 1421 with value: 4.636670161465692.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 12.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 14.12% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:50:55,773]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:50:58,602]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:51:02,064]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:51:05,895]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:51:09,364]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:52:04,693]\u001b[0m Trial 1466 finished with value: 4.8253853716575 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012311095680296257, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03991301220314331, 'dropout_rate_Layer_2': 0.36959774710313287, 'dropout_rate_Layer_3': 0.15404888363826882, 'dropout_rate_Layer_4': 0.27728513342608313, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000901464524850485, 'l1_Layer_2': 8.666804593823418e-05, 'l1_Layer_3': 0.00011163023039126744, 'l1_Layer_4': 1.7156860246599815e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 300, 'n_units_Layer_3': 190, 'n_units_Layer_4': 110}. Best is trial 1421 with value: 4.636670161465692.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 11.00% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 13.26% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:52:08,472]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:52:11,721]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:52:17,134]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:52:23,100]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:52:29,180]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:52:35,914]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:52:38,907]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:52:46,537]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:52:49,597]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:52:53,962]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:53:01,774]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:53:05,052]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:53:09,366]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:53:13,631]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:53:16,462]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:53:20,270]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:54:38,563]\u001b[0m Trial 1483 finished with value: 5.5671175629333405 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009478261479184026, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0003382658667501204, 'dropout_rate_Layer_2': 0.3592370918136885, 'dropout_rate_Layer_3': 0.10104087144613964, 'dropout_rate_Layer_4': 0.16128846446733494, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00921901134532843, 'l1_Layer_2': 0.01636884111477131, 'l1_Layer_3': 0.0018743219432876645, 'l1_Layer_4': 0.0004830940821815255, 'n_units_Layer_1': 70, 'n_units_Layer_2': 185, 'n_units_Layer_3': 245, 'n_units_Layer_4': 115}. Best is trial 1421 with value: 4.636670161465692.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 12.69% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 14.21% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 06:55:19,333]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:55:43,191]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:55:55,993]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:56:21,650]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:56:25,376]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:56:28,368]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:56:31,943]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:56:34,994]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:56:38,760]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:56:42,800]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:57:01,323]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:57:04,367]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:57:08,057]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:57:16,703]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:57:19,986]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 06:57:23,321]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-01-01, MAE is:15.01 & sMAPE is:59.38% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :15.01 & 59.38% & 0.75\n",
      "for 2019-01-02, MAE is:23.06 & sMAPE is:71.49% & rMAE is:4.40 ||| daily mean of MAE & sMAPE & rMAE till now are :19.03 & 65.44% & 2.58\n",
      "for 2019-01-03, MAE is:10.76 & sMAPE is:21.21% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :16.27 & 50.69% & 2.33\n",
      "for 2019-01-04, MAE is:2.40 & sMAPE is:4.48% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :12.81 & 39.14% & 1.99\n",
      "for 2019-01-05, MAE is:2.41 & sMAPE is:4.75% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :10.73 & 32.26% & 1.79\n",
      "for 2019-01-06, MAE is:2.19 & sMAPE is:4.27% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :9.30 & 27.60% & 1.70\n",
      "for 2019-01-07, MAE is:5.60 & sMAPE is:9.50% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.77 & 25.01% & 1.54\n",
      "for 2019-01-08, MAE is:3.78 & sMAPE is:8.12% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.15 & 22.90% & 1.37\n",
      "for 2019-01-09, MAE is:4.89 & sMAPE is:9.25% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 21.38% & 1.28\n",
      "for 2019-01-10, MAE is:9.24 & sMAPE is:14.16% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 20.66% & 1.26\n",
      "for 2019-01-11, MAE is:4.30 & sMAPE is:8.05% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 19.52% & 1.39\n",
      "for 2019-01-12, MAE is:2.33 & sMAPE is:4.88% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 18.30% & 1.34\n",
      "for 2019-01-13, MAE is:2.85 & sMAPE is:6.04% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 17.35% & 1.29\n",
      "for 2019-01-14, MAE is:6.96 & sMAPE is:17.75% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 17.38% & 1.24\n",
      "for 2019-01-15, MAE is:5.94 & sMAPE is:12.43% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 17.05% & 1.26\n",
      "for 2019-01-16, MAE is:2.97 & sMAPE is:5.86% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 16.35% & 1.23\n",
      "for 2019-01-17, MAE is:3.34 & sMAPE is:6.30% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 15.76% & 1.18\n",
      "for 2019-01-18, MAE is:9.12 & sMAPE is:15.30% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 15.73% & 1.15\n",
      "for 2019-01-19, MAE is:3.32 & sMAPE is:6.22% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 15.23% & 1.12\n",
      "for 2019-01-20, MAE is:2.95 & sMAPE is:5.27% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 14.73% & 1.08\n",
      "for 2019-01-21, MAE is:5.17 & sMAPE is:7.46% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 14.39% & 1.04\n",
      "for 2019-01-22, MAE is:5.13 & sMAPE is:7.88% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 14.09% & 1.01\n",
      "for 2019-01-23, MAE is:10.47 & sMAPE is:14.57% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 14.11% & 0.99\n",
      "for 2019-01-24, MAE is:18.13 & sMAPE is:22.96% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 14.48% & 0.98\n",
      "for 2019-01-25, MAE is:6.07 & sMAPE is:8.79% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 14.25% & 0.98\n",
      "for 2019-01-26, MAE is:1.72 & sMAPE is:3.14% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 13.83% & 0.98\n",
      "for 2019-01-27, MAE is:2.03 & sMAPE is:4.00% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 13.46% & 0.96\n",
      "for 2019-01-28, MAE is:4.17 & sMAPE is:6.97% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 13.23% & 0.94\n",
      "for 2019-01-29, MAE is:4.10 & sMAPE is:6.53% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 13.00% & 0.95\n",
      "for 2019-01-30, MAE is:3.16 & sMAPE is:5.45% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 12.75% & 0.93\n",
      "for 2019-01-31, MAE is:4.27 & sMAPE is:7.14% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 12.57% & 0.91\n",
      "for 2019-02-01, MAE is:5.37 & sMAPE is:9.09% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 12.46% & 0.89\n",
      "for 2019-02-02, MAE is:4.03 & sMAPE is:7.40% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 12.30% & 0.91\n",
      "for 2019-02-03, MAE is:2.98 & sMAPE is:5.60% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 12.11% & 0.92\n",
      "for 2019-02-04, MAE is:4.64 & sMAPE is:8.21% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 12.00% & 0.95\n",
      "for 2019-02-05, MAE is:2.15 & sMAPE is:3.96% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 11.77% & 0.93\n",
      "for 2019-02-06, MAE is:3.55 & sMAPE is:6.30% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 11.63% & 0.92\n",
      "for 2019-02-07, MAE is:4.40 & sMAPE is:8.21% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 11.54% & 0.91\n",
      "for 2019-02-08, MAE is:2.32 & sMAPE is:4.92% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 11.37% & 0.90\n",
      "for 2019-02-09, MAE is:1.75 & sMAPE is:3.81% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 11.18% & 0.88\n",
      "for 2019-02-10, MAE is:1.37 & sMAPE is:3.01% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 10.98% & 0.87\n",
      "for 2019-02-11, MAE is:4.43 & sMAPE is:8.80% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 10.93% & 0.86\n",
      "for 2019-02-12, MAE is:2.79 & sMAPE is:5.72% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 10.80% & 0.86\n",
      "for 2019-02-13, MAE is:2.93 & sMAPE is:6.09% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 10.70% & 0.85\n",
      "for 2019-02-14, MAE is:4.16 & sMAPE is:8.58% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 10.65% & 0.85\n",
      "for 2019-02-15, MAE is:3.97 & sMAPE is:8.39% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 10.60% & 0.85\n",
      "for 2019-02-16, MAE is:1.26 & sMAPE is:3.17% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 10.44% & 0.84\n",
      "for 2019-02-17, MAE is:3.48 & sMAPE is:8.63% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 10.41% & 0.84\n",
      "for 2019-02-18, MAE is:3.31 & sMAPE is:7.17% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 10.34% & 0.84\n",
      "for 2019-02-19, MAE is:2.35 & sMAPE is:5.71% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 10.25% & 0.83\n",
      "for 2019-02-20, MAE is:3.09 & sMAPE is:7.56% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 10.19% & 0.83\n",
      "for 2019-02-21, MAE is:2.14 & sMAPE is:4.72% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 10.09% & 0.83\n",
      "for 2019-02-22, MAE is:3.02 & sMAPE is:6.47% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 10.02% & 0.84\n",
      "for 2019-02-23, MAE is:0.95 & sMAPE is:2.36% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 9.88% & 0.85\n",
      "for 2019-02-24, MAE is:1.62 & sMAPE is:4.32% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 9.78% & 0.85\n",
      "for 2019-02-25, MAE is:2.34 & sMAPE is:5.56% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 9.70% & 0.84\n",
      "for 2019-02-26, MAE is:3.37 & sMAPE is:7.35% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 9.66% & 0.85\n",
      "for 2019-02-27, MAE is:2.38 & sMAPE is:5.61% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 9.59% & 0.85\n",
      "for 2019-02-28, MAE is:3.20 & sMAPE is:8.14% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 9.57% & 0.85\n",
      "for 2019-03-01, MAE is:2.26 & sMAPE is:5.17% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 9.49% & 0.85\n",
      "for 2019-03-02, MAE is:2.35 & sMAPE is:5.58% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 9.43% & 0.85\n",
      "for 2019-03-03, MAE is:3.66 & sMAPE is:9.58% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 9.43% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-04, MAE is:5.12 & sMAPE is:11.16% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 9.46% & 0.90\n",
      "for 2019-03-05, MAE is:2.65 & sMAPE is:6.11% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 9.41% & 0.90\n",
      "for 2019-03-06, MAE is:4.67 & sMAPE is:10.09% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 9.42% & 0.91\n",
      "for 2019-03-07, MAE is:2.04 & sMAPE is:4.87% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 9.35% & 0.90\n",
      "for 2019-03-08, MAE is:2.02 & sMAPE is:5.43% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 9.29% & 0.89\n",
      "for 2019-03-09, MAE is:3.24 & sMAPE is:8.92% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.28% & 0.89\n",
      "for 2019-03-10, MAE is:1.94 & sMAPE is:5.01% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 9.22% & 0.90\n",
      "for 2019-03-11, MAE is:2.40 & sMAPE is:5.59% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 9.17% & 0.90\n",
      "for 2019-03-12, MAE is:2.74 & sMAPE is:6.27% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 9.13% & 0.89\n",
      "for 2019-03-13, MAE is:1.83 & sMAPE is:4.56% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 9.07% & 0.89\n",
      "for 2019-03-14, MAE is:1.83 & sMAPE is:4.59% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 9.01% & 0.89\n",
      "for 2019-03-15, MAE is:2.87 & sMAPE is:7.08% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 8.98% & 0.88\n",
      "for 2019-03-16, MAE is:1.68 & sMAPE is:4.02% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 8.91% & 0.88\n",
      "for 2019-03-17, MAE is:3.02 & sMAPE is:8.68% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 8.91% & 0.88\n",
      "for 2019-03-18, MAE is:6.41 & sMAPE is:16.89% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 9.01% & 0.88\n",
      "for 2019-03-19, MAE is:6.58 & sMAPE is:15.35% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 9.09% & 0.90\n",
      "for 2019-03-20, MAE is:2.60 & sMAPE is:6.21% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 9.06% & 0.91\n",
      "for 2019-03-21, MAE is:2.52 & sMAPE is:6.40% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 9.03% & 0.91\n",
      "for 2019-03-22, MAE is:2.70 & sMAPE is:6.69% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 9.00% & 0.91\n",
      "for 2019-03-23, MAE is:3.18 & sMAPE is:9.46% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 9.00% & 0.90\n",
      "for 2019-03-24, MAE is:4.90 & sMAPE is:15.37% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 9.08% & 0.91\n",
      "for 2019-03-25, MAE is:2.94 & sMAPE is:8.28% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 9.07% & 0.91\n",
      "for 2019-03-26, MAE is:2.68 & sMAPE is:6.96% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 9.04% & 0.91\n",
      "for 2019-03-27, MAE is:1.66 & sMAPE is:4.10% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 8.99% & 0.91\n",
      "for 2019-03-28, MAE is:3.63 & sMAPE is:9.51% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 8.99% & 0.91\n",
      "for 2019-03-29, MAE is:7.23 & sMAPE is:35.41% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 9.29% & 0.90\n",
      "for 2019-03-30, MAE is:5.60 & sMAPE is:18.89% & rMAE is:3.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 9.40% & 0.93\n",
      "for 2019-03-31, MAE is:4.79 & sMAPE is:19.03% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 9.51% & 0.93\n",
      "for 2019-04-01, MAE is:3.83 & sMAPE is:9.77% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 9.51% & 0.93\n",
      "for 2019-04-02, MAE is:3.00 & sMAPE is:9.03% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 9.51% & 0.93\n",
      "for 2019-04-03, MAE is:7.97 & sMAPE is:21.80% & rMAE is:3.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 9.64% & 0.96\n",
      "for 2019-04-04, MAE is:3.09 & sMAPE is:7.94% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 9.62% & 0.96\n",
      "for 2019-04-05, MAE is:2.04 & sMAPE is:5.29% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 9.57% & 0.95\n",
      "for 2019-04-06, MAE is:1.57 & sMAPE is:4.19% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 9.52% & 0.95\n",
      "for 2019-04-07, MAE is:2.67 & sMAPE is:7.09% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 9.49% & 0.94\n",
      "for 2019-04-08, MAE is:3.33 & sMAPE is:7.60% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 9.47% & 0.94\n",
      "for 2019-04-09, MAE is:2.78 & sMAPE is:6.57% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 9.44% & 0.93\n",
      "for 2019-04-10, MAE is:2.44 & sMAPE is:5.55% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 9.41% & 0.93\n",
      "for 2019-04-11, MAE is:5.60 & sMAPE is:12.30% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 9.43% & 0.93\n",
      "for 2019-04-12, MAE is:3.37 & sMAPE is:7.04% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 9.41% & 0.92\n",
      "for 2019-04-13, MAE is:1.92 & sMAPE is:4.49% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 9.36% & 0.92\n",
      "for 2019-04-14, MAE is:2.58 & sMAPE is:6.33% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 9.33% & 0.92\n",
      "for 2019-04-15, MAE is:4.33 & sMAPE is:9.19% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 9.33% & 0.92\n",
      "for 2019-04-16, MAE is:3.22 & sMAPE is:7.15% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 9.31% & 0.92\n",
      "for 2019-04-17, MAE is:1.55 & sMAPE is:3.54% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 9.26% & 0.92\n",
      "for 2019-04-18, MAE is:2.22 & sMAPE is:5.23% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 9.22% & 0.91\n",
      "for 2019-04-19, MAE is:1.36 & sMAPE is:3.26% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 9.17% & 0.91\n",
      "for 2019-04-20, MAE is:3.04 & sMAPE is:7.67% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 9.15% & 0.91\n",
      "for 2019-04-21, MAE is:1.72 & sMAPE is:4.64% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 9.11% & 0.91\n",
      "for 2019-04-22, MAE is:3.66 & sMAPE is:12.13% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 9.14% & 0.90\n",
      "for 2019-04-23, MAE is:13.34 & sMAPE is:45.63% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 9.46% & 0.91\n",
      "for 2019-04-24, MAE is:10.21 & sMAPE is:47.00% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 9.79% & 0.90\n",
      "for 2019-04-25, MAE is:10.22 & sMAPE is:27.58% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 9.95% & 0.91\n",
      "for 2019-04-26, MAE is:6.35 & sMAPE is:15.55% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 9.99% & 0.92\n",
      "for 2019-04-27, MAE is:3.52 & sMAPE is:10.80% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 10.00% & 0.92\n",
      "for 2019-04-28, MAE is:9.14 & sMAPE is:51.18% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 10.35% & 0.92\n",
      "for 2019-04-29, MAE is:5.03 & sMAPE is:15.04% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 10.39% & 0.91\n",
      "for 2019-04-30, MAE is:3.90 & sMAPE is:13.86% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 10.42% & 0.92\n",
      "for 2019-05-01, MAE is:9.33 & sMAPE is:61.76% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 10.84% & 0.91\n",
      "for 2019-05-02, MAE is:8.31 & sMAPE is:58.98% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 11.24% & 0.91\n",
      "for 2019-05-03, MAE is:4.96 & sMAPE is:16.08% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 11.28% & 0.91\n",
      "for 2019-05-04, MAE is:6.20 & sMAPE is:16.80% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 11.32% & 0.91\n",
      "for 2019-05-05, MAE is:3.09 & sMAPE is:8.36% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 11.30% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-06, MAE is:5.46 & sMAPE is:13.92% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 11.32% & 0.91\n",
      "for 2019-05-07, MAE is:3.73 & sMAPE is:8.96% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 11.30% & 0.90\n",
      "for 2019-05-08, MAE is:6.11 & sMAPE is:15.73% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 11.33% & 0.90\n",
      "for 2019-05-09, MAE is:10.88 & sMAPE is:31.60% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 11.49% & 0.90\n",
      "for 2019-05-10, MAE is:8.52 & sMAPE is:28.99% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 11.63% & 0.90\n",
      "for 2019-05-11, MAE is:3.55 & sMAPE is:10.12% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 11.61% & 0.90\n",
      "for 2019-05-12, MAE is:18.29 & sMAPE is:102.78% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 12.30% & 0.90\n",
      "for 2019-05-13, MAE is:11.58 & sMAPE is:33.11% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 12.46% & 0.91\n",
      "for 2019-05-14, MAE is:6.68 & sMAPE is:15.17% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 12.48% & 0.92\n",
      "for 2019-05-15, MAE is:5.77 & sMAPE is:12.39% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 12.48% & 0.92\n",
      "for 2019-05-16, MAE is:2.66 & sMAPE is:7.03% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 12.44% & 0.92\n",
      "for 2019-05-17, MAE is:3.02 & sMAPE is:8.24% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 12.41% & 0.92\n",
      "for 2019-05-18, MAE is:2.39 & sMAPE is:7.93% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 12.38% & 0.92\n",
      "for 2019-05-19, MAE is:7.01 & sMAPE is:21.15% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 12.44% & 0.91\n",
      "for 2019-05-20, MAE is:3.57 & sMAPE is:7.51% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 12.41% & 0.91\n",
      "for 2019-05-21, MAE is:1.91 & sMAPE is:4.54% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 12.35% & 0.91\n",
      "for 2019-05-22, MAE is:3.06 & sMAPE is:7.70% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 12.32% & 0.90\n",
      "for 2019-05-23, MAE is:4.98 & sMAPE is:11.59% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 12.31% & 0.90\n",
      "for 2019-05-24, MAE is:5.58 & sMAPE is:13.13% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 12.32% & 0.91\n",
      "for 2019-05-25, MAE is:1.86 & sMAPE is:5.22% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 12.27% & 0.91\n",
      "for 2019-05-26, MAE is:4.81 & sMAPE is:17.43% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 12.30% & 0.90\n",
      "for 2019-05-27, MAE is:6.10 & sMAPE is:20.98% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 12.36% & 0.90\n",
      "for 2019-05-28, MAE is:5.49 & sMAPE is:14.50% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 12.38% & 0.90\n",
      "for 2019-05-29, MAE is:9.11 & sMAPE is:29.09% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 12.49% & 0.91\n",
      "for 2019-05-30, MAE is:21.08 & sMAPE is:116.06% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 13.18% & 0.91\n",
      "for 2019-05-31, MAE is:10.94 & sMAPE is:54.29% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.45% & 0.91\n",
      "for 2019-06-01, MAE is:11.08 & sMAPE is:49.67% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 13.69% & 0.90\n",
      "for 2019-06-02, MAE is:7.19 & sMAPE is:49.73% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 13.93% & 0.90\n",
      "for 2019-06-03, MAE is:5.76 & sMAPE is:14.39% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.93% & 0.91\n",
      "for 2019-06-04, MAE is:12.25 & sMAPE is:49.39% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 14.16% & 0.91\n",
      "for 2019-06-05, MAE is:7.73 & sMAPE is:27.22% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 14.24% & 0.91\n",
      "for 2019-06-06, MAE is:7.43 & sMAPE is:73.95% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 14.62% & 0.91\n",
      "for 2019-06-07, MAE is:8.28 & sMAPE is:35.82% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 14.76% & 0.91\n",
      "for 2019-06-08, MAE is:13.71 & sMAPE is:90.66% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 15.23% & 0.91\n",
      "for 2019-06-09, MAE is:10.91 & sMAPE is:83.16% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 15.66% & 0.92\n",
      "for 2019-06-10, MAE is:12.14 & sMAPE is:63.25% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 15.95% & 0.92\n",
      "for 2019-06-11, MAE is:9.96 & sMAPE is:43.52% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 16.12% & 0.92\n",
      "for 2019-06-12, MAE is:11.44 & sMAPE is:55.99% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 16.37% & 0.92\n",
      "for 2019-06-13, MAE is:12.29 & sMAPE is:40.10% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 16.51% & 0.91\n",
      "for 2019-06-14, MAE is:12.25 & sMAPE is:29.11% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 16.59% & 0.92\n",
      "for 2019-06-15, MAE is:2.78 & sMAPE is:11.67% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 16.56% & 0.91\n",
      "for 2019-06-16, MAE is:4.94 & sMAPE is:22.74% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 16.60% & 0.91\n",
      "for 2019-06-17, MAE is:3.11 & sMAPE is:12.37% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 16.57% & 0.91\n",
      "for 2019-06-18, MAE is:6.71 & sMAPE is:23.79% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 16.61% & 0.90\n",
      "for 2019-06-19, MAE is:13.83 & sMAPE is:44.00% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 16.78% & 0.91\n",
      "for 2019-06-20, MAE is:4.11 & sMAPE is:13.80% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 16.76% & 0.90\n",
      "for 2019-06-21, MAE is:7.82 & sMAPE is:28.68% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 16.83% & 0.91\n",
      "for 2019-06-22, MAE is:4.73 & sMAPE is:30.25% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 16.90% & 0.91\n",
      "for 2019-06-23, MAE is:4.41 & sMAPE is:21.50% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 16.93% & 0.91\n",
      "for 2019-06-24, MAE is:6.21 & sMAPE is:19.51% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 16.95% & 0.91\n",
      "for 2019-06-25, MAE is:7.55 & sMAPE is:17.66% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 16.95% & 0.91\n",
      "for 2019-06-26, MAE is:8.01 & sMAPE is:21.98% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 16.98% & 0.91\n",
      "for 2019-06-27, MAE is:9.51 & sMAPE is:30.78% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 17.06% & 0.91\n",
      "for 2019-06-28, MAE is:8.97 & sMAPE is:22.29% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 17.09% & 0.91\n",
      "for 2019-06-29, MAE is:2.95 & sMAPE is:12.25% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 17.06% & 0.91\n",
      "for 2019-06-30, MAE is:4.61 & sMAPE is:30.04% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 17.13% & 0.91\n",
      "for 2019-07-01, MAE is:4.67 & sMAPE is:24.15% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 17.17% & 0.91\n",
      "for 2019-07-02, MAE is:2.26 & sMAPE is:7.55% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 17.12% & 0.91\n",
      "for 2019-07-03, MAE is:2.32 & sMAPE is:7.72% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 17.07% & 0.90\n",
      "for 2019-07-04, MAE is:3.14 & sMAPE is:10.48% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 17.03% & 0.90\n",
      "for 2019-07-05, MAE is:1.44 & sMAPE is:5.26% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 16.97% & 0.90\n",
      "for 2019-07-06, MAE is:1.64 & sMAPE is:5.66% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 16.91% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-07, MAE is:4.15 & sMAPE is:16.18% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 16.90% & 0.89\n",
      "for 2019-07-08, MAE is:3.17 & sMAPE is:10.02% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 16.87% & 0.89\n",
      "for 2019-07-09, MAE is:6.76 & sMAPE is:20.27% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 16.88% & 0.89\n",
      "for 2019-07-10, MAE is:3.27 & sMAPE is:9.75% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 16.85% & 0.89\n",
      "for 2019-07-11, MAE is:5.73 & sMAPE is:14.07% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 16.83% & 0.88\n",
      "for 2019-07-12, MAE is:2.91 & sMAPE is:7.66% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 16.78% & 0.88\n",
      "for 2019-07-13, MAE is:2.45 & sMAPE is:6.97% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 16.73% & 0.88\n",
      "for 2019-07-14, MAE is:1.05 & sMAPE is:2.91% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 16.66% & 0.88\n",
      "for 2019-07-15, MAE is:3.29 & sMAPE is:8.60% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 16.62% & 0.87\n",
      "for 2019-07-16, MAE is:3.13 & sMAPE is:8.06% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 16.58% & 0.87\n",
      "for 2019-07-17, MAE is:7.34 & sMAPE is:17.48% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 16.58% & 0.87\n",
      "for 2019-07-18, MAE is:4.19 & sMAPE is:9.80% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 16.55% & 0.87\n",
      "for 2019-07-19, MAE is:3.99 & sMAPE is:9.35% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 16.51% & 0.87\n",
      "for 2019-07-20, MAE is:1.47 & sMAPE is:4.10% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 16.45% & 0.87\n",
      "for 2019-07-21, MAE is:1.21 & sMAPE is:3.47% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 16.39% & 0.87\n",
      "for 2019-07-22, MAE is:2.80 & sMAPE is:8.11% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 16.35% & 0.87\n",
      "for 2019-07-23, MAE is:6.43 & sMAPE is:14.56% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 16.34% & 0.87\n",
      "for 2019-07-24, MAE is:6.27 & sMAPE is:12.24% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 16.32% & 0.88\n",
      "for 2019-07-25, MAE is:4.19 & sMAPE is:8.11% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 16.28% & 0.88\n",
      "for 2019-07-26, MAE is:3.76 & sMAPE is:8.53% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 16.24% & 0.88\n",
      "for 2019-07-27, MAE is:1.70 & sMAPE is:4.75% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 16.18% & 0.88\n",
      "for 2019-07-28, MAE is:2.78 & sMAPE is:8.03% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 16.15% & 0.88\n",
      "for 2019-07-29, MAE is:9.99 & sMAPE is:23.88% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 16.18% & 0.88\n",
      "for 2019-07-30, MAE is:4.50 & sMAPE is:10.93% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 16.16% & 0.88\n",
      "for 2019-07-31, MAE is:10.67 & sMAPE is:24.74% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 16.20% & 0.89\n",
      "for 2019-08-01, MAE is:5.93 & sMAPE is:13.37% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 16.18% & 0.89\n",
      "for 2019-08-02, MAE is:4.14 & sMAPE is:10.49% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 16.16% & 0.89\n",
      "for 2019-08-03, MAE is:2.75 & sMAPE is:7.39% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 16.12% & 0.89\n",
      "for 2019-08-04, MAE is:2.25 & sMAPE is:5.98% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 16.07% & 0.89\n",
      "for 2019-08-05, MAE is:3.69 & sMAPE is:8.26% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 16.03% & 0.89\n",
      "for 2019-08-06, MAE is:2.38 & sMAPE is:5.64% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 15.99% & 0.89\n",
      "for 2019-08-07, MAE is:1.57 & sMAPE is:3.95% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 15.93% & 0.89\n",
      "for 2019-08-08, MAE is:1.40 & sMAPE is:3.71% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 15.88% & 0.88\n",
      "for 2019-08-09, MAE is:2.86 & sMAPE is:7.38% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 15.84% & 0.88\n",
      "for 2019-08-10, MAE is:1.31 & sMAPE is:3.85% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 15.78% & 0.88\n",
      "for 2019-08-11, MAE is:5.22 & sMAPE is:21.59% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 15.81% & 0.88\n",
      "for 2019-08-12, MAE is:4.41 & sMAPE is:10.29% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 15.79% & 0.88\n",
      "for 2019-08-13, MAE is:4.35 & sMAPE is:11.05% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 15.76% & 0.88\n",
      "for 2019-08-14, MAE is:5.49 & sMAPE is:12.79% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 15.75% & 0.88\n",
      "for 2019-08-15, MAE is:2.11 & sMAPE is:5.89% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 15.71% & 0.88\n",
      "for 2019-08-16, MAE is:2.92 & sMAPE is:7.56% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 15.67% & 0.87\n",
      "for 2019-08-17, MAE is:2.74 & sMAPE is:10.90% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 15.65% & 0.87\n",
      "for 2019-08-18, MAE is:3.81 & sMAPE is:12.52% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 15.64% & 0.87\n",
      "for 2019-08-19, MAE is:2.52 & sMAPE is:7.00% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 15.60% & 0.87\n",
      "for 2019-08-20, MAE is:3.54 & sMAPE is:9.01% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 15.57% & 0.87\n",
      "for 2019-08-21, MAE is:6.72 & sMAPE is:15.30% & rMAE is:2.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 15.57% & 0.88\n",
      "for 2019-08-22, MAE is:3.20 & sMAPE is:8.03% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 15.54% & 0.88\n",
      "for 2019-08-23, MAE is:4.08 & sMAPE is:10.08% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 15.51% & 0.88\n",
      "for 2019-08-24, MAE is:2.22 & sMAPE is:6.69% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 15.48% & 0.88\n",
      "for 2019-08-25, MAE is:4.23 & sMAPE is:13.39% & rMAE is:5.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 15.47% & 0.90\n",
      "for 2019-08-26, MAE is:10.03 & sMAPE is:22.77% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 15.50% & 0.90\n",
      "for 2019-08-27, MAE is:6.48 & sMAPE is:14.20% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 15.49% & 0.90\n",
      "for 2019-08-28, MAE is:10.22 & sMAPE is:21.09% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 15.52% & 0.90\n",
      "for 2019-08-29, MAE is:4.67 & sMAPE is:10.58% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 15.50% & 0.90\n",
      "for 2019-08-30, MAE is:5.61 & sMAPE is:13.92% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 15.49% & 0.90\n",
      "for 2019-08-31, MAE is:1.78 & sMAPE is:4.89% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 15.45% & 0.91\n",
      "for 2019-09-01, MAE is:2.49 & sMAPE is:7.58% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 15.41% & 0.91\n",
      "for 2019-09-02, MAE is:5.12 & sMAPE is:12.71% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 15.40% & 0.91\n",
      "for 2019-09-03, MAE is:4.11 & sMAPE is:9.83% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 15.38% & 0.91\n",
      "for 2019-09-04, MAE is:5.61 & sMAPE is:11.84% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 15.37% & 0.91\n",
      "for 2019-09-05, MAE is:1.88 & sMAPE is:5.50% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 15.33% & 0.90\n",
      "for 2019-09-06, MAE is:1.85 & sMAPE is:5.93% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 15.29% & 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-07, MAE is:4.00 & sMAPE is:11.30% & rMAE is:3.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 15.27% & 0.91\n",
      "for 2019-09-08, MAE is:3.89 & sMAPE is:10.53% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 15.25% & 0.91\n",
      "for 2019-09-09, MAE is:10.06 & sMAPE is:23.54% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 15.29% & 0.91\n",
      "for 2019-09-10, MAE is:3.58 & sMAPE is:9.21% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 15.26% & 0.91\n",
      "for 2019-09-11, MAE is:2.25 & sMAPE is:6.72% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 15.23% & 0.91\n",
      "for 2019-09-12, MAE is:3.60 & sMAPE is:9.70% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 15.21% & 0.91\n",
      "for 2019-09-13, MAE is:2.44 & sMAPE is:6.96% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 15.18% & 0.91\n",
      "for 2019-09-14, MAE is:2.37 & sMAPE is:7.75% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 15.15% & 0.91\n",
      "for 2019-09-15, MAE is:3.85 & sMAPE is:16.56% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 15.15% & 0.91\n",
      "for 2019-09-16, MAE is:13.05 & sMAPE is:45.06% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 15.27% & 0.91\n",
      "for 2019-09-17, MAE is:4.29 & sMAPE is:12.10% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 15.26% & 0.91\n",
      "for 2019-09-18, MAE is:5.82 & sMAPE is:15.11% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 15.25% & 0.91\n",
      "for 2019-09-19, MAE is:7.15 & sMAPE is:16.29% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 15.26% & 0.91\n",
      "for 2019-09-20, MAE is:6.14 & sMAPE is:14.70% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 15.26% & 0.91\n",
      "for 2019-09-21, MAE is:3.24 & sMAPE is:8.81% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 15.23% & 0.91\n",
      "for 2019-09-22, MAE is:3.58 & sMAPE is:11.17% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 15.22% & 0.91\n",
      "for 2019-09-23, MAE is:7.48 & sMAPE is:17.73% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 15.23% & 0.91\n",
      "for 2019-09-24, MAE is:9.96 & sMAPE is:22.11% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 15.25% & 0.91\n",
      "for 2019-09-25, MAE is:5.40 & sMAPE is:12.36% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 15.24% & 0.91\n",
      "for 2019-09-26, MAE is:3.45 & sMAPE is:9.38% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 15.22% & 0.91\n",
      "for 2019-09-27, MAE is:6.79 & sMAPE is:18.27% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 15.23% & 0.91\n",
      "for 2019-09-28, MAE is:1.77 & sMAPE is:5.83% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 15.20% & 0.91\n",
      "for 2019-09-29, MAE is:3.87 & sMAPE is:13.31% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 15.19% & 0.91\n",
      "for 2019-09-30, MAE is:3.59 & sMAPE is:10.03% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 15.17% & 0.91\n",
      "for 2019-10-01, MAE is:8.61 & sMAPE is:21.00% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 15.19% & 0.91\n",
      "for 2019-10-02, MAE is:4.42 & sMAPE is:10.54% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 15.17% & 0.91\n",
      "for 2019-10-03, MAE is:8.90 & sMAPE is:21.24% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 15.20% & 0.91\n",
      "for 2019-10-04, MAE is:6.95 & sMAPE is:14.39% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 15.19% & 0.91\n",
      "for 2019-10-05, MAE is:5.83 & sMAPE is:15.70% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 15.20% & 0.91\n",
      "for 2019-10-06, MAE is:1.61 & sMAPE is:4.11% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 15.16% & 0.91\n",
      "for 2019-10-07, MAE is:18.14 & sMAPE is:33.59% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 15.22% & 0.91\n",
      "for 2019-10-08, MAE is:6.27 & sMAPE is:13.11% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 15.21% & 0.91\n",
      "for 2019-10-09, MAE is:12.16 & sMAPE is:24.60% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 15.25% & 0.91\n",
      "for 2019-10-10, MAE is:7.64 & sMAPE is:16.46% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 15.25% & 0.91\n",
      "for 2019-10-11, MAE is:2.84 & sMAPE is:8.55% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 15.23% & 0.91\n",
      "for 2019-10-12, MAE is:5.20 & sMAPE is:16.00% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 15.23% & 0.91\n",
      "for 2019-10-13, MAE is:3.04 & sMAPE is:9.12% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 15.21% & 0.91\n",
      "for 2019-10-14, MAE is:7.92 & sMAPE is:17.16% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 15.22% & 0.91\n",
      "for 2019-10-15, MAE is:5.48 & sMAPE is:11.85% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 15.20% & 0.91\n",
      "for 2019-10-16, MAE is:7.65 & sMAPE is:16.45% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 15.21% & 0.91\n",
      "for 2019-10-17, MAE is:11.47 & sMAPE is:25.93% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 15.25% & 0.92\n",
      "for 2019-10-18, MAE is:5.90 & sMAPE is:13.77% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 15.24% & 0.92\n",
      "for 2019-10-19, MAE is:3.50 & sMAPE is:9.98% & rMAE is:3.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 15.22% & 0.92\n",
      "for 2019-10-20, MAE is:4.47 & sMAPE is:12.33% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 15.21% & 0.92\n",
      "for 2019-10-21, MAE is:6.99 & sMAPE is:15.62% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 15.21% & 0.93\n",
      "for 2019-10-22, MAE is:4.67 & sMAPE is:9.67% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 15.20% & 0.93\n",
      "for 2019-10-23, MAE is:3.75 & sMAPE is:8.59% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 15.17% & 0.93\n",
      "for 2019-10-24, MAE is:3.58 & sMAPE is:8.87% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 15.15% & 0.93\n",
      "for 2019-10-25, MAE is:2.50 & sMAPE is:7.76% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 15.13% & 0.93\n",
      "for 2019-10-26, MAE is:6.22 & sMAPE is:24.25% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 15.16% & 0.93\n",
      "for 2019-10-27, MAE is:5.40 & sMAPE is:16.97% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 15.16% & 0.93\n",
      "for 2019-10-28, MAE is:5.34 & sMAPE is:12.01% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 15.15% & 0.93\n",
      "for 2019-10-29, MAE is:3.91 & sMAPE is:7.88% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 15.13% & 0.93\n",
      "for 2019-10-30, MAE is:6.69 & sMAPE is:13.98% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 15.13% & 0.93\n",
      "for 2019-10-31, MAE is:4.05 & sMAPE is:9.22% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 15.11% & 0.93\n",
      "for 2019-11-01, MAE is:4.95 & sMAPE is:12.07% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 15.10% & 0.93\n",
      "for 2019-11-02, MAE is:2.52 & sMAPE is:7.38% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 15.07% & 0.93\n",
      "for 2019-11-03, MAE is:3.72 & sMAPE is:10.47% & rMAE is:2.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 15.06% & 0.94\n",
      "for 2019-11-04, MAE is:7.41 & sMAPE is:19.05% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 15.07% & 0.94\n",
      "for 2019-11-05, MAE is:4.60 & sMAPE is:10.09% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 15.05% & 0.94\n",
      "for 2019-11-06, MAE is:8.88 & sMAPE is:16.43% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 15.06% & 0.95\n",
      "for 2019-11-07, MAE is:3.78 & sMAPE is:7.82% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 15.03% & 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-08, MAE is:7.56 & sMAPE is:15.94% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 15.04% & 0.94\n",
      "for 2019-11-09, MAE is:1.96 & sMAPE is:4.83% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 15.00% & 0.94\n",
      "for 2019-11-10, MAE is:3.27 & sMAPE is:7.70% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 14.98% & 0.94\n",
      "for 2019-11-11, MAE is:2.48 & sMAPE is:5.90% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 14.95% & 0.94\n",
      "for 2019-11-12, MAE is:2.75 & sMAPE is:6.31% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 14.92% & 0.94\n",
      "for 2019-11-13, MAE is:6.69 & sMAPE is:13.87% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 14.92% & 0.94\n",
      "for 2019-11-14, MAE is:3.49 & sMAPE is:7.22% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 14.90% & 0.94\n",
      "for 2019-11-15, MAE is:2.32 & sMAPE is:5.73% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 14.87% & 0.94\n",
      "for 2019-11-16, MAE is:1.96 & sMAPE is:4.85% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 14.84% & 0.94\n",
      "for 2019-11-17, MAE is:3.37 & sMAPE is:8.94% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 14.82% & 0.94\n",
      "for 2019-11-18, MAE is:4.40 & sMAPE is:10.82% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 14.81% & 0.94\n",
      "for 2019-11-19, MAE is:2.79 & sMAPE is:6.47% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 14.78% & 0.95\n",
      "for 2019-11-20, MAE is:6.38 & sMAPE is:13.16% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 14.78% & 0.95\n",
      "for 2019-11-21, MAE is:4.25 & sMAPE is:9.37% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 14.76% & 0.95\n",
      "for 2019-11-22, MAE is:3.53 & sMAPE is:8.35% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 14.74% & 0.95\n",
      "for 2019-11-23, MAE is:1.13 & sMAPE is:3.04% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 14.70% & 0.95\n",
      "for 2019-11-24, MAE is:2.01 & sMAPE is:5.43% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 14.67% & 0.95\n",
      "for 2019-11-25, MAE is:2.29 & sMAPE is:5.23% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 14.65% & 0.95\n",
      "for 2019-11-26, MAE is:3.68 & sMAPE is:8.47% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 14.63% & 0.95\n",
      "for 2019-11-27, MAE is:2.01 & sMAPE is:4.81% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 14.60% & 0.95\n",
      "for 2019-11-28, MAE is:3.11 & sMAPE is:7.50% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 14.58% & 0.95\n",
      "for 2019-11-29, MAE is:2.94 & sMAPE is:7.07% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 14.55% & 0.95\n",
      "for 2019-11-30, MAE is:1.69 & sMAPE is:4.19% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 14.52% & 0.95\n",
      "for 2019-12-01, MAE is:1.33 & sMAPE is:3.28% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 14.49% & 0.95\n",
      "for 2019-12-02, MAE is:5.08 & sMAPE is:11.04% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 14.48% & 0.95\n",
      "for 2019-12-03, MAE is:10.52 & sMAPE is:21.22% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 14.50% & 0.95\n",
      "for 2019-12-04, MAE is:6.86 & sMAPE is:14.81% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 14.50% & 0.95\n",
      "for 2019-12-05, MAE is:4.04 & sMAPE is:10.36% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 14.49% & 0.95\n",
      "for 2019-12-06, MAE is:6.47 & sMAPE is:20.30% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 14.50% & 0.95\n",
      "for 2019-12-07, MAE is:3.86 & sMAPE is:11.61% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 14.50% & 0.95\n",
      "for 2019-12-08, MAE is:4.09 & sMAPE is:15.77% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 14.50% & 0.95\n",
      "for 2019-12-09, MAE is:11.64 & sMAPE is:52.70% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 14.61% & 0.95\n",
      "for 2019-12-10, MAE is:6.22 & sMAPE is:15.02% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 14.61% & 0.95\n",
      "for 2019-12-11, MAE is:11.30 & sMAPE is:37.25% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 14.68% & 0.95\n",
      "for 2019-12-12, MAE is:6.89 & sMAPE is:15.77% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 14.68% & 0.95\n",
      "for 2019-12-13, MAE is:2.78 & sMAPE is:7.25% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 14.66% & 0.95\n",
      "for 2019-12-14, MAE is:4.23 & sMAPE is:11.43% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 14.65% & 0.95\n",
      "for 2019-12-15, MAE is:2.50 & sMAPE is:7.91% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 14.63% & 0.95\n",
      "for 2019-12-16, MAE is:4.61 & sMAPE is:11.75% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 14.62% & 0.95\n",
      "for 2019-12-17, MAE is:3.51 & sMAPE is:8.45% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 14.61% & 0.95\n",
      "for 2019-12-18, MAE is:3.52 & sMAPE is:8.46% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 14.59% & 0.95\n",
      "for 2019-12-19, MAE is:3.72 & sMAPE is:9.32% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 14.57% & 0.95\n",
      "for 2019-12-20, MAE is:1.62 & sMAPE is:4.57% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 14.55% & 0.95\n",
      "for 2019-12-21, MAE is:3.20 & sMAPE is:9.55% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 14.53% & 0.95\n",
      "for 2019-12-22, MAE is:2.92 & sMAPE is:8.53% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 14.51% & 0.95\n",
      "for 2019-12-23, MAE is:1.65 & sMAPE is:4.67% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 14.49% & 0.95\n",
      "for 2019-12-24, MAE is:4.42 & sMAPE is:13.21% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 14.48% & 0.95\n",
      "for 2019-12-25, MAE is:1.64 & sMAPE is:4.74% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 14.46% & 0.95\n",
      "for 2019-12-26, MAE is:2.89 & sMAPE is:8.21% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 14.44% & 0.95\n",
      "for 2019-12-27, MAE is:3.06 & sMAPE is:7.82% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 14.42% & 0.95\n",
      "for 2019-12-28, MAE is:2.19 & sMAPE is:6.27% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 14.40% & 0.95\n",
      "for 2019-12-29, MAE is:2.96 & sMAPE is:10.77% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 14.39% & 0.95\n",
      "for 2019-12-30, MAE is:8.31 & sMAPE is:42.28% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 14.46% & 0.95\n",
      "for 2019-12-31, MAE is:3.49 & sMAPE is:16.85% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 14.47% & 0.95\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:03:54,009]\u001b[0m A new study created in RDB with name: SE_4_2020\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:04:03,573]\u001b[0m Trial 0 finished with value: 5.556128108461476 and parameters: {'n_hidden': 4, 'learning_rate': 0.01964219392381131, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2631298459593683, 'dropout_rate_Layer_2': 0.37217768275567337, 'dropout_rate_Layer_3': 0.23356429238410611, 'dropout_rate_Layer_4': 0.2895177235751562, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012792200211888852, 'l1_Layer_2': 0.012110013329057133, 'l1_Layer_3': 0.0032357461094841447, 'l1_Layer_4': 2.5278958822460455e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 235, 'n_units_Layer_3': 195, 'n_units_Layer_4': 195}. Best is trial 0 with value: 5.556128108461476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 15.86% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 15.13 | sMAPE for Test Set is: 63.75% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:04:26,862]\u001b[0m Trial 1 finished with value: 6.371495697067658 and parameters: {'n_hidden': 4, 'learning_rate': 0.06565668274609418, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04935183554893055, 'dropout_rate_Layer_2': 0.3489223544960258, 'dropout_rate_Layer_3': 0.3973398508480647, 'dropout_rate_Layer_4': 0.35895232416739825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.721154410662058e-05, 'l1_Layer_2': 0.011397007896641838, 'l1_Layer_3': 1.1482993363518403e-05, 'l1_Layer_4': 0.034348763313160335, 'n_units_Layer_1': 75, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270, 'n_units_Layer_4': 55}. Best is trial 0 with value: 5.556128108461476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 17.50% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 13.14 | sMAPE for Test Set is: 59.13% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:04:30,497]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:05:21,243]\u001b[0m Trial 3 finished with value: 4.823216853656804 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007149284812719697, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12608447112948556, 'dropout_rate_Layer_2': 0.3696527011867759, 'dropout_rate_Layer_3': 0.07280864135905066, 'dropout_rate_Layer_4': 0.11190531815242527, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 8.264392365524795e-05, 'l1_Layer_2': 1.9345671280203125e-05, 'l1_Layer_3': 0.0007290800848895018, 'l1_Layer_4': 0.0009435505099533775, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180, 'n_units_Layer_4': 125}. Best is trial 3 with value: 4.823216853656804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 14.12% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 12.33 | sMAPE for Test Set is: 56.93% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:05:29,616]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:05:32,828]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:06:26,358]\u001b[0m Trial 6 finished with value: 4.8381473195841425 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018587276846634376, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13438212346518613, 'dropout_rate_Layer_2': 0.34303608373935657, 'dropout_rate_Layer_3': 0.2869303017026118, 'dropout_rate_Layer_4': 0.07404787993368181, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032985313997028823, 'l1_Layer_2': 0.0006837745913772087, 'l1_Layer_3': 0.019025392329337712, 'l1_Layer_4': 3.733517467726048e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145, 'n_units_Layer_4': 60}. Best is trial 3 with value: 4.823216853656804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 14.05% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 14.16 | sMAPE for Test Set is: 61.59% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:06:33,887]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:07:55,659]\u001b[0m Trial 8 finished with value: 4.40130391365989 and parameters: {'n_hidden': 4, 'learning_rate': 0.004173660796937017, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12502254715619876, 'dropout_rate_Layer_2': 0.3507047191569168, 'dropout_rate_Layer_3': 0.0742395847728644, 'dropout_rate_Layer_4': 0.1555727965869839, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004149825295680265, 'l1_Layer_2': 5.7743772398847734e-05, 'l1_Layer_3': 0.000124010863661017, 'l1_Layer_4': 0.00027108563561846754, 'n_units_Layer_1': 135, 'n_units_Layer_2': 235, 'n_units_Layer_3': 170, 'n_units_Layer_4': 150}. Best is trial 8 with value: 4.40130391365989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 13.00% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 12.83 | sMAPE for Test Set is: 58.35% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:07:59,250]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:08:05,848]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:08:10,195]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:08:17,612]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:08:22,029]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:08:45,884]\u001b[0m Trial 14 finished with value: 4.867649191735621 and parameters: {'n_hidden': 4, 'learning_rate': 0.0045160304845142905, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21978585656326977, 'dropout_rate_Layer_2': 0.18720085118464547, 'dropout_rate_Layer_3': 0.14991305877817793, 'dropout_rate_Layer_4': 0.1400037093411188, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0018583526653770416, 'l1_Layer_2': 0.050996955949945105, 'l1_Layer_3': 0.0009004254467615035, 'l1_Layer_4': 0.00034791432347101853, 'n_units_Layer_1': 65, 'n_units_Layer_2': 235, 'n_units_Layer_3': 240, 'n_units_Layer_4': 295}. Best is trial 8 with value: 4.40130391365989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 14.13% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 13.51 | sMAPE for Test Set is: 59.98% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:08:50,754]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:08:56,096]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:09:05,940]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:09:08,732]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:09:13,171]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:09:18,504]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:09:25,547]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:09:29,996]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:09:37,184]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:09:40,305]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:10:06,292]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:10:13,313]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:10:17,250]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:10:23,827]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:11:14,917]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:11:19,110]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:11:22,577]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:11:26,999]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:11:30,780]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:11:33,551]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:12:01,681]\u001b[0m Trial 35 finished with value: 4.730139703857167 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025616761601481583, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27961934694066326, 'dropout_rate_Layer_2': 0.3988072958148754, 'dropout_rate_Layer_3': 0.25510880919672807, 'dropout_rate_Layer_4': 0.016886202135050737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014321282681020995, 'l1_Layer_2': 0.03451172627984669, 'l1_Layer_3': 0.03251124647770948, 'l1_Layer_4': 1.0306677677533082e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 95, 'n_units_Layer_3': 100, 'n_units_Layer_4': 110}. Best is trial 8 with value: 4.40130391365989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 13.10 | sMAPE for Test Set is: 59.12% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:12:06,839]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:12:20,518]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:12:30,474]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:12:34,807]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:12:39,176]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:12:43,194]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:12:48,771]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:12:55,052]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:13:09,503]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:13:20,493]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:13:29,200]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:13:34,448]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:14:07,888]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:14:11,802]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:14:15,380]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:14:21,761]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:14:26,727]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:14:34,553]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:14:39,889]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:14:46,660]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:14:50,510]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:15:46,797]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:16:12,308]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:16:17,330]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:16:23,085]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:16:27,982]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:16:34,890]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:16:40,209]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:16:48,232]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:18:22,097]\u001b[0m Trial 65 finished with value: 4.8895593719109485 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005087980600061833, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18697626900275588, 'dropout_rate_Layer_2': 0.3863841718785701, 'dropout_rate_Layer_3': 0.2241762180931914, 'dropout_rate_Layer_4': 0.25136819231161867, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007632147233096701, 'l1_Layer_2': 0.013613215049674759, 'l1_Layer_3': 0.00020367595572332638, 'l1_Layer_4': 0.007977012030215886, 'n_units_Layer_1': 95, 'n_units_Layer_2': 135, 'n_units_Layer_3': 105, 'n_units_Layer_4': 80}. Best is trial 8 with value: 4.40130391365989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 14.21% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 12.58 | sMAPE for Test Set is: 57.54% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:18:31,916]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:18:39,825]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:18:44,208]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:18:50,267]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:18:56,325]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:19:01,180]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:19:07,516]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:19:15,642]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:19:19,741]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:19:44,312]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:19:48,746]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:20:28,077]\u001b[0m Trial 77 finished with value: 4.126852273441421 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028613333674698447, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006757152560024279, 'dropout_rate_Layer_2': 0.22538766829730053, 'dropout_rate_Layer_3': 0.002127845143428322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001322479010633465, 'l1_Layer_2': 5.98963619718298e-05, 'l1_Layer_3': 0.00010005785487074496, 'n_units_Layer_1': 185, 'n_units_Layer_2': 135, 'n_units_Layer_3': 300}. Best is trial 77 with value: 4.126852273441421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 12.42% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.34 | sMAPE for Test Set is: 48.83% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:20:31,758]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:20:36,052]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:20:40,485]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:20:56,646]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:21:04,620]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:21:14,566]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:21:30,485]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:21:39,004]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:21:51,061]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:21:55,259]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:21:59,972]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:22:03,426]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:22:08,382]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:22:12,265]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:22:37,739]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:22:41,993]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:22:47,537]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:22:52,943]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:22:56,680]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:23:01,973]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:25:18,505]\u001b[0m Trial 98 finished with value: 4.727922118238453 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011675880691551456, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39036401034533375, 'dropout_rate_Layer_2': 0.30280106647882926, 'dropout_rate_Layer_3': 0.2959336034749915, 'dropout_rate_Layer_4': 0.05882728814499856, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002672602371682115, 'l1_Layer_2': 0.039510008796829026, 'l1_Layer_3': 0.03397421253023735, 'l1_Layer_4': 0.0008889880886470796, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 110, 'n_units_Layer_4': 90}. Best is trial 77 with value: 4.126852273441421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 13.18 | sMAPE for Test Set is: 59.34% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:25:56,789]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:26:36,206]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:26:41,138]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:26:46,671]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:26:52,020]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:27:00,486]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:27:06,537]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:27:14,918]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:27:18,959]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:27:36,954]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:28:37,679]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:28:44,243]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:28:58,199]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:29:04,551]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:30:05,594]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:30:28,465]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:30:33,087]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:30:37,836]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:30:43,470]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:31:19,011]\u001b[0m Trial 118 finished with value: 4.033488516825316 and parameters: {'n_hidden': 3, 'learning_rate': 0.001545901767563575, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026423397867914367, 'dropout_rate_Layer_2': 0.17427183986212974, 'dropout_rate_Layer_3': 0.0049387073745504155, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008124620019538263, 'l1_Layer_2': 0.00018120853863013797, 'l1_Layer_3': 0.002044486198293144, 'n_units_Layer_1': 185, 'n_units_Layer_2': 110, 'n_units_Layer_3': 260}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.77 | sMAPE for Test Set is: 48.11% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:31:22,130]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:31:25,395]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:31:32,600]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:31:43,611]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:31:47,182]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:31:53,345]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:31:57,042]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 14.21% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 13.87 | sMAPE for Test Set is: 60.87% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:32:47,044]\u001b[0m Trial 126 finished with value: 4.873645401533756 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007184562466871917, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14642640659198072, 'dropout_rate_Layer_2': 0.2832708863758936, 'dropout_rate_Layer_3': 0.22406593771326286, 'dropout_rate_Layer_4': 0.19187909590300295, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013744186802751252, 'l1_Layer_2': 0.09096717009101377, 'l1_Layer_3': 0.0007294315734583459, 'l1_Layer_4': 0.0005267217058773304, 'n_units_Layer_1': 165, 'n_units_Layer_2': 140, 'n_units_Layer_3': 100, 'n_units_Layer_4': 85}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:33:59,349]\u001b[0m Trial 127 finished with value: 4.691395632470343 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012943304807621694, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36857730736051236, 'dropout_rate_Layer_2': 0.363762046312984, 'dropout_rate_Layer_3': 0.31700028070290825, 'dropout_rate_Layer_4': 0.05340084266770026, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005849209429963708, 'l1_Layer_2': 0.015701491226708348, 'l1_Layer_3': 0.03726491942319905, 'l1_Layer_4': 0.0008438612743815833, 'n_units_Layer_1': 60, 'n_units_Layer_2': 85, 'n_units_Layer_3': 125, 'n_units_Layer_4': 125}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 13.69% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 12.96 | sMAPE for Test Set is: 58.83% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:34:59,726]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:35:07,597]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:35:17,703]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:35:21,245]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:35:29,156]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:35:36,744]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:35:49,049]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:35:52,571]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:35:57,643]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:36:02,405]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:36:06,781]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:36:13,896]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:36:18,854]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:36:25,097]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:36:38,762]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:36:42,218]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:36:57,862]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:37:02,937]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:37:25,548]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:37:35,723]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:37:41,650]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:37:45,353]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:37:53,146]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:38:18,084]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:38:23,074]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:38:27,916]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:38:35,787]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:38:39,839]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:38:44,893]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:38:49,237]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:40:34,319]\u001b[0m Trial 158 finished with value: 4.747563428576877 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009634322131223346, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30843268374566035, 'dropout_rate_Layer_2': 0.3864926155492644, 'dropout_rate_Layer_3': 0.3181719512160827, 'dropout_rate_Layer_4': 0.030242634256312056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0024653429587064017, 'l1_Layer_2': 0.015055342225293087, 'l1_Layer_3': 0.013031110907563974, 'l1_Layer_4': 0.0006722868962914329, 'n_units_Layer_1': 50, 'n_units_Layer_2': 85, 'n_units_Layer_3': 130, 'n_units_Layer_4': 120}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 12.46 | sMAPE for Test Set is: 57.36% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:40:50,599]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:40:56,306]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:40:59,611]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:41:16,247]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:41:22,209]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:41:26,516]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:41:32,490]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:41:36,225]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:41:47,190]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:42:01,819]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:42:08,636]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:42:15,621]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:42:19,312]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:42:24,879]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:42:31,057]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:42:36,047]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:42:40,953]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:42:56,855]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:43:04,865]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:43:08,943]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:43:34,510]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:43:40,562]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:44:01,844]\u001b[0m Trial 181 finished with value: 4.097881698716065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035470021490493255, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02058556718295826, 'dropout_rate_Layer_2': 0.1780251136931294, 'dropout_rate_Layer_3': 0.013442447705049067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019903679817829655, 'l1_Layer_2': 7.648977671242882e-05, 'l1_Layer_3': 0.00017832483530966055, 'n_units_Layer_1': 210, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 12.34% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.69 | sMAPE for Test Set is: 47.54% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:44:09,479]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:44:15,161]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:44:24,725]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:44:29,666]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:44:45,184]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:44:56,850]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:45:03,558]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:45:43,971]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:45:48,678]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:45:53,986]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:46:05,098]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:46:11,725]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:46:17,068]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:46:20,981]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:46:26,834]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:48:05,731]\u001b[0m Trial 197 finished with value: 4.8266503689852955 and parameters: {'n_hidden': 4, 'learning_rate': 0.001653656840082573, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1706583841793888, 'dropout_rate_Layer_2': 0.375755461705863, 'dropout_rate_Layer_3': 0.1230113737390376, 'dropout_rate_Layer_4': 0.12178805015477784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00030369033717271, 'l1_Layer_2': 0.0015687050170893621, 'l1_Layer_3': 0.0005976763656511807, 'l1_Layer_4': 0.0009798823881126315, 'n_units_Layer_1': 55, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275, 'n_units_Layer_4': 250}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 14.06% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 12.98 | sMAPE for Test Set is: 58.64% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:48:11,918]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:48:16,561]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:48:20,888]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:49:59,899]\u001b[0m Trial 201 finished with value: 4.783356326643093 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011991528040559325, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3776748126927265, 'dropout_rate_Layer_2': 0.38843114372284443, 'dropout_rate_Layer_3': 0.3176775240452952, 'dropout_rate_Layer_4': 0.04852001145805435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002697018131524019, 'l1_Layer_2': 0.027280560633716176, 'l1_Layer_3': 0.01367149190362307, 'l1_Layer_4': 0.00036136603510996963, 'n_units_Layer_1': 65, 'n_units_Layer_2': 170, 'n_units_Layer_3': 115, 'n_units_Layer_4': 225}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 12.50 | sMAPE for Test Set is: 57.49% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:50:34,113]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:52:08,240]\u001b[0m Trial 203 finished with value: 4.745242714269202 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006605424623826187, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.187169635474277, 'dropout_rate_Layer_2': 0.3680090169660954, 'dropout_rate_Layer_3': 0.12849697605925609, 'dropout_rate_Layer_4': 0.11922336635335283, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003168536242909209, 'l1_Layer_2': 0.0015023935976933534, 'l1_Layer_3': 0.0005763142205601989, 'l1_Layer_4': 0.0009388576331341978, 'n_units_Layer_1': 50, 'n_units_Layer_2': 285, 'n_units_Layer_3': 275, 'n_units_Layer_4': 275}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 13.89% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 13.40 | sMAPE for Test Set is: 59.72% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:52:47,346]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:52:55,505]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:52:59,281]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:54:06,177]\u001b[0m Trial 207 finished with value: 4.842253335547848 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008602776735376013, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.138972306552847, 'dropout_rate_Layer_2': 0.34021247243131103, 'dropout_rate_Layer_3': 0.11282484362986575, 'dropout_rate_Layer_4': 0.12261929454826367, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00011060697529385527, 'l1_Layer_2': 0.0019704468976090065, 'l1_Layer_3': 0.00056544390593502, 'l1_Layer_4': 0.0008658932435211548, 'n_units_Layer_1': 50, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280, 'n_units_Layer_4': 290}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 14.08% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 12.92 | sMAPE for Test Set is: 58.53% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:55:16,240]\u001b[0m Trial 208 finished with value: 4.7315469664923535 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012230240127535995, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13087552707738842, 'dropout_rate_Layer_2': 0.34838440874522064, 'dropout_rate_Layer_3': 0.10909102680734904, 'dropout_rate_Layer_4': 0.08494191865732226, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00010913088742032084, 'l1_Layer_2': 0.0016892813783658536, 'l1_Layer_3': 0.0004637490630761592, 'l1_Layer_4': 0.0008118308727125146, 'n_units_Layer_1': 50, 'n_units_Layer_2': 255, 'n_units_Layer_3': 285, 'n_units_Layer_4': 300}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 13.80% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 12.96 | sMAPE for Test Set is: 58.66% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:55:22,275]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:55:27,950]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:55:31,716]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:55:37,235]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:55:41,793]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:55:46,562]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:55:52,138]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:55:55,842]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:55:59,235]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:56:03,400]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:56:54,946]\u001b[0m Trial 219 finished with value: 4.1708213872653985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017021154020494728, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014264202218011907, 'dropout_rate_Layer_2': 0.2503855349825405, 'dropout_rate_Layer_3': 0.03473637416780191, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016806266340686018, 'l1_Layer_2': 8.072032606858282e-05, 'l1_Layer_3': 0.0002311740808895036, 'n_units_Layer_1': 135, 'n_units_Layer_2': 225, 'n_units_Layer_3': 260}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 12.45% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.14 | sMAPE for Test Set is: 47.85% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 12:56:59,336]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:57:04,694]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:57:09,276]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:57:13,499]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 12:57:51,849]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:00:10,467]\u001b[0m Trial 225 finished with value: 4.700856340770616 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008830820729145559, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3830213985353051, 'dropout_rate_Layer_2': 0.38360637794244223, 'dropout_rate_Layer_3': 0.35861240948051276, 'dropout_rate_Layer_4': 0.022409734454428745, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0024048155980991013, 'l1_Layer_2': 0.01070223674593857, 'l1_Layer_3': 0.012533277794249452, 'l1_Layer_4': 0.0006471074122549752, 'n_units_Layer_1': 65, 'n_units_Layer_2': 95, 'n_units_Layer_3': 115, 'n_units_Layer_4': 110}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 13.74% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 12.57 | sMAPE for Test Set is: 57.67% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:00:17,170]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:00:33,927]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:01:37,314]\u001b[0m Trial 228 finished with value: 4.820151939463128 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012831991396201356, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09212645463383815, 'dropout_rate_Layer_2': 0.3729585206489228, 'dropout_rate_Layer_3': 0.08914410481485309, 'dropout_rate_Layer_4': 0.11767048896738624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.1183387117533505e-05, 'l1_Layer_2': 0.0018866309738484704, 'l1_Layer_3': 0.0004832044048883747, 'l1_Layer_4': 0.0008790974911825245, 'n_units_Layer_1': 50, 'n_units_Layer_2': 280, 'n_units_Layer_3': 250, 'n_units_Layer_4': 265}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 13.98% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 13.24 | sMAPE for Test Set is: 59.36% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:01:48,000]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:01:56,272]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:02:03,310]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:02:09,704]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:02:16,108]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:02:19,852]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:02:25,816]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:02:40,086]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:02:46,078]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:02:52,070]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:02:56,352]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:03:00,485]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:03:06,602]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:03:10,891]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:03:14,261]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:04:14,936]\u001b[0m Trial 244 finished with value: 4.846042762521925 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017801323438618715, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09182036935577331, 'dropout_rate_Layer_2': 0.3758131254801015, 'dropout_rate_Layer_3': 0.03704052528144342, 'dropout_rate_Layer_4': 0.11473126954517333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00020038068876263832, 'l1_Layer_2': 0.002429691453279291, 'l1_Layer_3': 0.0022348089727317116, 'l1_Layer_4': 0.002678620090488904, 'n_units_Layer_1': 50, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300, 'n_units_Layer_4': 240}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 14.03% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 13.88 | sMAPE for Test Set is: 60.99% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:04:19,075]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:04:22,495]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:04:28,597]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:04:43,596]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:04:47,809]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:04:52,505]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:04:56,523]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:05:11,534]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:05:19,231]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:05:23,515]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:05:31,542]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:05:36,694]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:05:40,852]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:05:50,830]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:05:59,529]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:06:04,716]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:06:08,393]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:06:35,625]\u001b[0m Trial 262 finished with value: 4.183925617031989 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019929947123829526, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.035970224242545645, 'dropout_rate_Layer_2': 0.2900689838717071, 'dropout_rate_Layer_3': 0.02156592550372015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020616665394482194, 'l1_Layer_2': 2.6447524607199464e-05, 'l1_Layer_3': 0.0004574381045479968, 'n_units_Layer_1': 135, 'n_units_Layer_2': 155, 'n_units_Layer_3': 290}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.54 | sMAPE for Test Set is: 45.91% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:06:41,082]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:06:49,219]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:06:54,222]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:07:02,671]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:07:11,404]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:07:19,709]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:07:25,421]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:07:38,161]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:07:42,484]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:07:49,945]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:08:59,847]\u001b[0m Trial 273 finished with value: 4.572251753443003 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012809902263317705, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06640123819879544, 'dropout_rate_Layer_2': 0.39936933977179456, 'dropout_rate_Layer_3': 0.07577913818335591, 'dropout_rate_Layer_4': 0.15186157037130474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.933178703467168e-05, 'l1_Layer_2': 0.0005256238931589933, 'l1_Layer_3': 0.001283316497195987, 'l1_Layer_4': 0.0003241811125762869, 'n_units_Layer_1': 75, 'n_units_Layer_2': 240, 'n_units_Layer_3': 265, 'n_units_Layer_4': 245}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 13.32% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.80 | sMAPE for Test Set is: 58.18% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:09:08,244]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:09:14,247]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:09:17,916]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:09:22,322]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:09:26,225]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:09:34,322]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:09:50,068]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:10:03,683]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:10:10,919]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:11:11,336]\u001b[0m Trial 283 finished with value: 4.727114630704486 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011751034066575768, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0433592441175905, 'dropout_rate_Layer_2': 0.36251732384498947, 'dropout_rate_Layer_3': 0.04750400645425689, 'dropout_rate_Layer_4': 0.09918362277977032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.061925367854452e-05, 'l1_Layer_2': 0.001637676642998618, 'l1_Layer_3': 0.00042720830755083625, 'l1_Layer_4': 0.0006671471825447656, 'n_units_Layer_1': 65, 'n_units_Layer_2': 300, 'n_units_Layer_3': 240, 'n_units_Layer_4': 245}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 13.78% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 13.04 | sMAPE for Test Set is: 58.82% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:11:14,922]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:11:52,938]\u001b[0m Trial 285 finished with value: 4.73672863560682 and parameters: {'n_hidden': 4, 'learning_rate': 0.001265989343190946, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04814603394884434, 'dropout_rate_Layer_2': 0.35596796445868417, 'dropout_rate_Layer_3': 0.04209157400681879, 'dropout_rate_Layer_4': 0.09672878223863957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.893332760228783e-05, 'l1_Layer_2': 0.0009563245261517866, 'l1_Layer_3': 0.00040343416737121285, 'l1_Layer_4': 0.0006758828571467641, 'n_units_Layer_1': 65, 'n_units_Layer_2': 300, 'n_units_Layer_3': 240, 'n_units_Layer_4': 275}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 13.85% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 13.00 | sMAPE for Test Set is: 58.78% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:11:57,292]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:12:13,707]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:12:18,117]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:12:26,468]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:12:34,737]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:12:39,893]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:12:44,025]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:12:49,595]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:12:55,298]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:12:59,273]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:14:44,432]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:14:47,935]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:14:56,484]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:15:01,997]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:15:42,207]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:15:52,773]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:16:08,734]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:16:14,438]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:16:18,528]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:16:22,209]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:16:27,473]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:16:32,205]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:16:39,852]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:16:44,407]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:16:49,240]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:16:54,838]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:17:02,748]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:17:07,989]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:17:23,796]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:17:29,701]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:17:34,221]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:18:35,774]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:18:41,379]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:18:47,111]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:18:51,032]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:18:57,186]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:19:29,126]\u001b[0m Trial 322 finished with value: 4.117326115601778 and parameters: {'n_hidden': 3, 'learning_rate': 0.002915725642835957, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022640674413131674, 'dropout_rate_Layer_2': 0.18312454476900827, 'dropout_rate_Layer_3': 0.03257129999170958, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009923886426537435, 'l1_Layer_2': 0.0001251841164918955, 'l1_Layer_3': 0.0011571590227938669, 'n_units_Layer_1': 140, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 12.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.95 | sMAPE for Test Set is: 47.48% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:19:32,857]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:19:43,177]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:19:47,296]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:19:51,443]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:19:55,659]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:19:59,734]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:20:03,704]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:20:14,664]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:20:19,051]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:20:24,969]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:20:31,376]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:20:35,775]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:20:39,721]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:20:48,031]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:21:04,921]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:21:15,251]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:21:31,814]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:21:35,797]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:21:43,515]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:21:47,132]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:22:24,655]\u001b[0m Trial 343 finished with value: 4.7530426512350585 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009598148079116465, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028543003448050552, 'dropout_rate_Layer_2': 0.3544037338539177, 'dropout_rate_Layer_3': 0.09303291731146725, 'dropout_rate_Layer_4': 0.050689825212433585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00012118920721367083, 'l1_Layer_2': 0.003236898001332925, 'l1_Layer_3': 0.000961509023642033, 'l1_Layer_4': 0.0013663804381704031, 'n_units_Layer_1': 75, 'n_units_Layer_2': 260, 'n_units_Layer_3': 245, 'n_units_Layer_4': 260}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 13.82% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 13.39 | sMAPE for Test Set is: 59.74% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:22:34,839]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:22:50,581]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:22:58,662]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:23:04,743]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:23:10,597]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:23:15,087]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:25:02,299]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:25:09,988]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:25:13,583]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:25:17,576]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:25:22,740]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:25:28,527]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:25:32,434]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:25:36,724]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:25:44,966]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:25:58,551]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:26:03,990]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:26:09,972]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:26:15,657]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:26:30,942]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:26:36,883]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:26:43,102]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:26:48,608]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:26:53,409]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:26:58,676]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:27:36,333]\u001b[0m Trial 369 finished with value: 4.715454371335121 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013622304865945033, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05872638942281816, 'dropout_rate_Layer_2': 0.31363342322598653, 'dropout_rate_Layer_3': 0.06979094839882304, 'dropout_rate_Layer_4': 0.1523980292266603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0001816060838257058, 'l1_Layer_2': 0.0006048093062714556, 'l1_Layer_3': 0.003583611695112101, 'l1_Layer_4': 0.0005839992973243099, 'n_units_Layer_1': 80, 'n_units_Layer_2': 230, 'n_units_Layer_3': 290, 'n_units_Layer_4': 250}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 13.73% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 13.28 | sMAPE for Test Set is: 59.53% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:27:39,939]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:27:47,911]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:27:54,739]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:28:00,508]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:28:04,729]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:28:19,951]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:28:27,993]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:29:04,389]\u001b[0m Trial 377 finished with value: 4.744663566122286 and parameters: {'n_hidden': 4, 'learning_rate': 0.001400295211443215, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06833362397156074, 'dropout_rate_Layer_2': 0.333823786725182, 'dropout_rate_Layer_3': 0.08019520922461959, 'dropout_rate_Layer_4': 0.15246545467263353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00013643511775323613, 'l1_Layer_2': 0.0007091584646658387, 'l1_Layer_3': 0.003493053482364523, 'l1_Layer_4': 0.0006038966063806771, 'n_units_Layer_1': 80, 'n_units_Layer_2': 230, 'n_units_Layer_3': 285, 'n_units_Layer_4': 250}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 13.79% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 13.41 | sMAPE for Test Set is: 59.87% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:29:08,709]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:29:16,899]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:29:21,492]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:29:27,741]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:29:37,490]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:29:44,908]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:29:50,646]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:29:59,196]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:30:09,345]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:30:13,551]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:30:41,069]\u001b[0m Trial 388 finished with value: 4.747540713439885 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014037688531080682, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06475756416133757, 'dropout_rate_Layer_2': 0.33707947469771077, 'dropout_rate_Layer_3': 0.05330716861091603, 'dropout_rate_Layer_4': 0.14568003064336366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00019119941575738915, 'l1_Layer_2': 0.0006597713113997839, 'l1_Layer_3': 0.0040679270125618585, 'l1_Layer_4': 0.0006196928549299734, 'n_units_Layer_1': 60, 'n_units_Layer_2': 230, 'n_units_Layer_3': 290, 'n_units_Layer_4': 245}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 13.81% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 57.34% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:31:04,495]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:31:13,173]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:31:16,968]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:31:23,036]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:31:55,540]\u001b[0m Trial 393 finished with value: 4.161520032989247 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038196103209429035, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01739416718709043, 'dropout_rate_Layer_2': 0.22353233105384895, 'dropout_rate_Layer_3': 0.05864458309832283, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007981235251381788, 'l1_Layer_2': 2.0645298804998824e-05, 'l1_Layer_3': 0.0012691195089228576, 'n_units_Layer_1': 110, 'n_units_Layer_2': 155, 'n_units_Layer_3': 290}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 12.49% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.74 | sMAPE for Test Set is: 51.96% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:32:01,091]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:32:17,372]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:32:27,734]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:32:36,074]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:32:41,944]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:32:46,486]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:32:52,373]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:32:58,698]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:33:04,914]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:33:09,456]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:33:14,982]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:33:19,278]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:33:27,988]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:33:38,732]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:33:44,748]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:34:08,038]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:34:31,803]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:34:37,157]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:34:41,874]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:34:49,985]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:35:13,243]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:35:21,145]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:36:07,776]\u001b[0m Trial 416 finished with value: 4.134142977467685 and parameters: {'n_hidden': 3, 'learning_rate': 0.002768476078168031, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04601459414556592, 'dropout_rate_Layer_2': 0.24176827799682413, 'dropout_rate_Layer_3': 0.029930626253145663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006717219172457394, 'l1_Layer_2': 2.777126279394948e-05, 'l1_Layer_3': 0.0009048973968558964, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 12.40% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.05 | sMAPE for Test Set is: 52.49% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:36:13,443]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:36:27,623]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:37:07,192]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:37:10,940]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:37:16,810]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:37:24,953]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:37:30,778]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:39:21,670]\u001b[0m Trial 424 finished with value: 4.720818437775198 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009798844297750778, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1482131320548843, 'dropout_rate_Layer_2': 0.38756099878867023, 'dropout_rate_Layer_3': 0.33711873365179734, 'dropout_rate_Layer_4': 0.10159601281721417, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032862492568679637, 'l1_Layer_2': 0.035360041999803936, 'l1_Layer_3': 0.031242353220802103, 'l1_Layer_4': 0.0008808635178099618, 'n_units_Layer_1': 55, 'n_units_Layer_2': 95, 'n_units_Layer_3': 115, 'n_units_Layer_4': 180}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 12.79 | sMAPE for Test Set is: 58.28% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:39:25,098]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:39:33,260]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:39:37,519]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:39:42,786]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:39:58,634]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:40:03,933]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:40:07,680]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:40:12,887]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:40:18,689]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:40:22,585]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:40:30,443]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:40:35,569]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:40:41,850]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:40:49,795]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:40:57,770]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:41:02,172]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:41:07,565]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:41:11,715]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:42:39,220]\u001b[0m Trial 443 finished with value: 4.417013925165217 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007709918288378922, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015181116679897827, 'dropout_rate_Layer_2': 0.29330352873619975, 'dropout_rate_Layer_3': 0.05742643848034164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 7.060743030287716e-05, 'l1_Layer_2': 0.0012191355218617009, 'l1_Layer_3': 0.00035194911147908085, 'n_units_Layer_1': 80, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 13.03% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.44 | sMAPE for Test Set is: 57.12% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:42:44,426]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:44:23,330]\u001b[0m Trial 445 finished with value: 4.4621006980288636 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008037984426607147, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02063896208899148, 'dropout_rate_Layer_2': 0.3298134782974136, 'dropout_rate_Layer_3': 0.029912454827810644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 6.689894717604854e-05, 'l1_Layer_2': 0.0011060244450943344, 'l1_Layer_3': 0.0003824114290583217, 'n_units_Layer_1': 80, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 13.10% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.77 | sMAPE for Test Set is: 58.22% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:44:28,977]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:44:33,133]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:44:38,522]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:44:44,616]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:44:50,451]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:45:00,668]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:46:14,337]\u001b[0m Trial 452 finished with value: 4.510289431479612 and parameters: {'n_hidden': 3, 'learning_rate': 0.000822107546835209, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011512714112658078, 'dropout_rate_Layer_2': 0.29278788149996493, 'dropout_rate_Layer_3': 0.026138146542967613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 6.3075836028436e-05, 'l1_Layer_2': 0.0010911868934110657, 'l1_Layer_3': 0.00031837038152198057, 'n_units_Layer_1': 80, 'n_units_Layer_2': 295, 'n_units_Layer_3': 260}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 13.31% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 12.38 | sMAPE for Test Set is: 57.06% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:46:21,797]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:46:27,515]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:46:32,097]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:46:42,324]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:47:39,396]\u001b[0m Trial 457 finished with value: 4.465381074164834 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007718445295832434, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.036640995514626386, 'dropout_rate_Layer_2': 0.2878661626115271, 'dropout_rate_Layer_3': 2.8618372449343288e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.231748418730196e-05, 'l1_Layer_2': 0.001256865159574604, 'l1_Layer_3': 0.00036041565821077353, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 13.09% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.86 | sMAPE for Test Set is: 58.45% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:47:43,296]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:47:46,170]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:47:51,604]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:47:59,704]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:48:07,662]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:48:15,674]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:48:19,627]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:48:35,745]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:48:41,366]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:48:48,474]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:48:52,439]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:48:58,282]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:49:04,208]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:49:10,407]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:49:14,788]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:49:20,187]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:49:57,886]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:50:51,194]\u001b[0m Trial 475 finished with value: 4.479243306882777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010392025011199306, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012199936165670392, 'dropout_rate_Layer_2': 0.29506968359379165, 'dropout_rate_Layer_3': 0.0591160915053124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.07447970632967e-05, 'l1_Layer_2': 0.0026397594060616264, 'l1_Layer_3': 0.00017143212535137862, 'n_units_Layer_1': 145, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 13.23% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 12.95 | sMAPE for Test Set is: 58.71% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:50:56,888]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:51:01,371]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:51:06,171]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:51:10,683]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:51:16,729]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:51:26,525]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:51:32,664]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:51:37,412]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:51:43,087]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:51:48,124]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:51:51,991]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:51:58,191]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:52:02,306]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:52:08,982]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:52:17,921]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:52:25,389]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:52:28,786]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:52:34,721]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:52:38,517]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:52:43,135]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:52:46,940]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:52:57,161]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:53:03,573]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:53:09,014]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:53:17,409]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:53:23,454]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:53:28,947]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:53:38,123]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:53:41,737]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:53:51,276]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:53:57,256]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:54:14,604]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:54:20,279]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:56:25,172]\u001b[0m Trial 509 finished with value: 4.416209961111542 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006424790276462825, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00027286070043412887, 'dropout_rate_Layer_2': 0.29137013806732914, 'dropout_rate_Layer_3': 0.03301915232003731, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 9.404619112521652e-05, 'l1_Layer_2': 0.0018595115316252793, 'l1_Layer_3': 0.00016102702533024853, 'n_units_Layer_1': 190, 'n_units_Layer_2': 300, 'n_units_Layer_3': 245}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 12.99% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.53 | sMAPE for Test Set is: 57.54% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 13:56:35,836]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:56:40,549]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:56:44,341]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:56:50,343]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 13:56:54,712]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:00:08,082]\u001b[0m Trial 515 finished with value: 4.3671336501625895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005730128143907936, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002320841474300391, 'dropout_rate_Layer_2': 0.2727458521195293, 'dropout_rate_Layer_3': 0.011526708811922061, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.274641943606526e-05, 'l1_Layer_2': 0.004165882258011907, 'l1_Layer_3': 0.00013896332369748096, 'n_units_Layer_1': 185, 'n_units_Layer_2': 300, 'n_units_Layer_3': 245}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.22 | sMAPE for Test Set is: 53.81% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:00:12,509]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:00:20,688]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:00:28,720]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:00:32,888]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:00:36,692]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:00:46,815]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:00:56,200]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:01:04,905]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:01:09,828]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:01:15,332]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:01:25,653]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:01:30,467]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:01:34,063]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:01:39,845]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:01:45,941]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:01:51,048]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:01:56,654]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:02:01,125]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:02:07,133]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:03:31,429]\u001b[0m Trial 535 finished with value: 4.255839737944541 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006208973399014368, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01847246471602006, 'dropout_rate_Layer_2': 0.2899991082424139, 'dropout_rate_Layer_3': 0.035083135892029355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.7211488959412e-05, 'l1_Layer_2': 0.0024965487171306833, 'l1_Layer_3': 0.000163645026640214, 'n_units_Layer_1': 200, 'n_units_Layer_2': 270, 'n_units_Layer_3': 225}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 12.64% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.89 | sMAPE for Test Set is: 47.87% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:03:37,656]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:03:45,293]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:05:54,876]\u001b[0m Trial 538 finished with value: 4.353955590227685 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006533843995759313, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01696977983898116, 'dropout_rate_Layer_2': 0.2919333482089407, 'dropout_rate_Layer_3': 0.03640854653249545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.2179928224648625e-05, 'l1_Layer_2': 0.002849771397811352, 'l1_Layer_3': 0.0001475491284769646, 'n_units_Layer_1': 215, 'n_units_Layer_2': 280, 'n_units_Layer_3': 215}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 12.82% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.32 | sMAPE for Test Set is: 50.17% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:05:59,576]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:06:05,022]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:06:09,013]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:06:12,822]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:06:18,537]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:06:23,135]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:06:30,770]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:06:36,098]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:07:13,814]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:08:13,465]\u001b[0m Trial 548 finished with value: 4.191255713787825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005807579487245105, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010377090986676425, 'dropout_rate_Layer_2': 0.2593184369447194, 'dropout_rate_Layer_3': 0.01662104441465029, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.323839606455689e-05, 'l1_Layer_2': 0.0026969019971837317, 'l1_Layer_3': 0.00011765487957547937, 'n_units_Layer_1': 190, 'n_units_Layer_2': 280, 'n_units_Layer_3': 205}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 12.47% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.84 | sMAPE for Test Set is: 48.48% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:08:17,984]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:08:23,977]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:08:46,935]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:08:50,805]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:08:59,080]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:09:23,549]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:09:29,415]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:09:33,984]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:09:59,062]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:13:07,346]\u001b[0m Trial 558 finished with value: 4.203318743705751 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005573141461095809, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0005136072883741988, 'dropout_rate_Layer_2': 0.24484218473454775, 'dropout_rate_Layer_3': 0.014342414306041435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8547369917600206e-05, 'l1_Layer_2': 0.0038371151766849456, 'l1_Layer_3': 0.00016669296771320682, 'n_units_Layer_1': 195, 'n_units_Layer_2': 285, 'n_units_Layer_3': 235}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 12.48% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.53 | sMAPE for Test Set is: 46.24% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:13:10,860]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:13:14,477]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:13:18,860]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:13:27,005]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:13:32,389]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:13:38,577]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:13:42,527]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:13:52,997]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:13:56,930]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:14:02,766]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:17:28,866]\u001b[0m Trial 569 finished with value: 4.203754900345368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005116269762946331, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02582888611627189, 'dropout_rate_Layer_2': 0.24900372909447083, 'dropout_rate_Layer_3': 0.037281266831974344, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6958600143842566e-05, 'l1_Layer_2': 0.0030168058526008593, 'l1_Layer_3': 0.00011127368521374992, 'n_units_Layer_1': 215, 'n_units_Layer_2': 300, 'n_units_Layer_3': 220}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 12.47% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.94 | sMAPE for Test Set is: 48.44% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:19:01,375]\u001b[0m Trial 570 finished with value: 4.297930911346522 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005179777107467173, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025359369144726848, 'dropout_rate_Layer_2': 0.25477339854332437, 'dropout_rate_Layer_3': 0.035178434984232704, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8854383775751265e-05, 'l1_Layer_2': 0.0035520034167460055, 'l1_Layer_3': 0.00010429939655914862, 'n_units_Layer_1': 220, 'n_units_Layer_2': 265, 'n_units_Layer_3': 220}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.14 | sMAPE for Test Set is: 53.25% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:19:07,145]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:19:12,694]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:19:16,768]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:19:21,354]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:19:29,570]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:19:37,511]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:20:15,322]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:20:21,136]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:20:36,642]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:20:40,700]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:20:46,435]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:20:51,860]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:21:00,239]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:21:06,126]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:21:10,138]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:21:16,284]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:21:24,537]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:21:29,345]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:21:53,132]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:22:00,528]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:22:04,212]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:22:15,024]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:22:19,004]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:22:27,924]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:22:33,410]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:22:39,172]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:22:44,526]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:22:48,417]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:22:51,952]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:22:58,172]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:24:06,469]\u001b[0m Trial 601 finished with value: 4.371425283758778 and parameters: {'n_hidden': 3, 'learning_rate': 0.000641489652789219, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02911380294133988, 'dropout_rate_Layer_2': 0.2671598399329322, 'dropout_rate_Layer_3': 0.03010768830216922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1567224922848635e-05, 'l1_Layer_2': 0.00481768103376285, 'l1_Layer_3': 7.154200235363768e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 275, 'n_units_Layer_3': 200}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.80 | sMAPE for Test Set is: 55.54% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:24:13,728]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:25:21,983]\u001b[0m Trial 603 finished with value: 4.352016729571522 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005628137616429866, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006652923678354687, 'dropout_rate_Layer_2': 0.25181397496399577, 'dropout_rate_Layer_3': 0.013479446640638576, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3682798179008122e-05, 'l1_Layer_2': 0.006170160734736961, 'l1_Layer_3': 0.00012913324655198266, 'n_units_Layer_1': 225, 'n_units_Layer_2': 260, 'n_units_Layer_3': 215}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.21 | sMAPE for Test Set is: 53.45% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:25:27,438]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:26:26,845]\u001b[0m Trial 605 finished with value: 4.585172313276394 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005677780675649303, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005325803985344728, 'dropout_rate_Layer_2': 0.25688200309804105, 'dropout_rate_Layer_3': 0.014294720554607683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0518966811547845e-05, 'l1_Layer_2': 0.006181312006893241, 'l1_Layer_3': 0.00012037662966493409, 'n_units_Layer_1': 225, 'n_units_Layer_2': 265, 'n_units_Layer_3': 215}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 13.40% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.39 | sMAPE for Test Set is: 57.30% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:26:34,648]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:26:38,621]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:26:42,713]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:26:48,424]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:26:52,231]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:27:00,855]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:27:04,637]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:27:09,742]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:27:15,070]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:27:20,812]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:27:24,675]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:27:28,585]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:27:33,504]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:27:37,439]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:27:46,965]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:27:51,615]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:28:14,911]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:28:20,222]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:28:23,979]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:28:30,062]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:28:37,253]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:30:58,646]\u001b[0m Trial 627 finished with value: 4.411520188227713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006615423495492453, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0012609163133859944, 'dropout_rate_Layer_2': 0.27313732526582446, 'dropout_rate_Layer_3': 0.025004011282017374, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.082126197966962e-05, 'l1_Layer_2': 0.0051123802410788025, 'l1_Layer_3': 6.958602573452381e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 200}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.12 | sMAPE for Test Set is: 53.55% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:31:02,652]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:31:07,302]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:31:13,386]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:31:21,948]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:31:31,014]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:33:10,326]\u001b[0m Trial 633 finished with value: 4.28096287928924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006330841516984959, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003336137927733118, 'dropout_rate_Layer_2': 0.24493018659507315, 'dropout_rate_Layer_3': 0.024619387122529073, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.247652695923515e-05, 'l1_Layer_2': 0.003738999194051552, 'l1_Layer_3': 6.888286286539825e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 250, 'n_units_Layer_3': 220}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 12.69% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.40 | sMAPE for Test Set is: 54.33% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:33:14,565]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:35:14,222]\u001b[0m Trial 635 finished with value: 4.290760034733423 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005617200053856957, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025451347585075654, 'dropout_rate_Layer_2': 0.24476448589044264, 'dropout_rate_Layer_3': 0.02350082056723945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8965245892198894e-05, 'l1_Layer_2': 0.005281085992342711, 'l1_Layer_3': 6.672785589516251e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 12.69% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.94 | sMAPE for Test Set is: 52.76% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:35:20,695]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:37:05,939]\u001b[0m Trial 637 finished with value: 4.34712571474427 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005497844732318147, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027163980656209993, 'dropout_rate_Layer_2': 0.24770253633264316, 'dropout_rate_Layer_3': 0.00874795675861358, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1894673848819243e-05, 'l1_Layer_2': 0.003784401609498372, 'l1_Layer_3': 5.719497397082093e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 250, 'n_units_Layer_3': 220}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 12.85% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.11 | sMAPE for Test Set is: 53.32% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:40:00,996]\u001b[0m Trial 638 finished with value: 4.364086867053637 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005432695769062437, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018978305825738874, 'dropout_rate_Layer_2': 0.22505117338981567, 'dropout_rate_Layer_3': 0.007822960729113308, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7868004228930512e-05, 'l1_Layer_2': 0.003694014284384932, 'l1_Layer_3': 5.083559231819716e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 250, 'n_units_Layer_3': 220}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 52.98% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:40:06,425]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:40:10,765]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:42:34,564]\u001b[0m Trial 641 finished with value: 4.548633882653114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005026833054310889, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04894358833253434, 'dropout_rate_Layer_2': 0.22816044553617373, 'dropout_rate_Layer_3': 0.007263471000579264, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7349952471297874e-05, 'l1_Layer_2': 0.007736862045423861, 'l1_Layer_3': 5.054207280281426e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 220}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 13.30% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.08 | sMAPE for Test Set is: 56.32% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:42:38,337]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:42:42,384]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:42:45,743]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:42:51,278]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:43:15,632]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:43:21,665]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:44:30,804]\u001b[0m Trial 648 finished with value: 4.441550101541274 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005331812051777094, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022713523276338642, 'dropout_rate_Layer_2': 0.24352361461802316, 'dropout_rate_Layer_3': 0.020095088132762666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.648775767884529e-05, 'l1_Layer_2': 0.0035983719865661655, 'l1_Layer_3': 4.2347762999504676e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 250, 'n_units_Layer_3': 220}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 13.07% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 55.62% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:44:35,308]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:44:40,936]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:44:47,051]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:44:52,550]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:44:56,567]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:45:02,376]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:45:08,945]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:45:17,056]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:45:22,514]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:47:40,300]\u001b[0m Trial 658 finished with value: 4.336990856156448 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007117662315883809, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03970479767166573, 'dropout_rate_Layer_2': 0.22218372941267903, 'dropout_rate_Layer_3': 0.04182283400137586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3116574531567958e-05, 'l1_Layer_2': 0.0033840736520758244, 'l1_Layer_3': 5.867973950367286e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 245, 'n_units_Layer_3': 210}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 12.80% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.74 | sMAPE for Test Set is: 55.46% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:48:35,903]\u001b[0m Trial 659 finished with value: 4.599729682586712 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007140278953396984, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03242064983184362, 'dropout_rate_Layer_2': 0.21611653709579426, 'dropout_rate_Layer_3': 0.04102349674598557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3421249352670126e-05, 'l1_Layer_2': 0.007059546738091844, 'l1_Layer_3': 6.0990498666423296e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 260, 'n_units_Layer_3': 210}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 13.58% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.76 | sMAPE for Test Set is: 51.40% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:48:39,718]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:48:45,914]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:48:49,637]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:50:47,710]\u001b[0m Trial 663 finished with value: 4.297531837537968 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005977602758235827, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04071773761017006, 'dropout_rate_Layer_2': 0.24983437679887857, 'dropout_rate_Layer_3': 0.015869596320050243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8498539978943436e-05, 'l1_Layer_2': 0.0037344728799337066, 'l1_Layer_3': 3.24487589700531e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 245, 'n_units_Layer_3': 225}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 12.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.44 | sMAPE for Test Set is: 54.52% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:50:53,549]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:51:05,077]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:53:00,227]\u001b[0m Trial 666 finished with value: 4.315021369994464 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006045602660328001, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041275453867210765, 'dropout_rate_Layer_2': 0.2473586100339996, 'dropout_rate_Layer_3': 0.023134164008115063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8858790504524297e-05, 'l1_Layer_2': 0.005564367384996213, 'l1_Layer_3': 2.895092326093574e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 230}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 12.74% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.33 | sMAPE for Test Set is: 53.77% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:53:06,315]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:54:33,900]\u001b[0m Trial 668 finished with value: 4.350941477048331 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005917959050174296, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.042323261589102185, 'dropout_rate_Layer_2': 0.2523667848855737, 'dropout_rate_Layer_3': 0.016363390569567877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9400738469516023e-05, 'l1_Layer_2': 0.0058919994418790995, 'l1_Layer_3': 3.636863767093025e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 230}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 12.85% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 53.08% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:55:23,529]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:55:27,365]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:55:33,364]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:55:38,922]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:55:43,431]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:55:48,003]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:55:53,813]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:55:59,262]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:56:04,609]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:56:10,345]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:57:52,007]\u001b[0m Trial 679 finished with value: 4.302315780055367 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005829276822284735, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.040203315038473644, 'dropout_rate_Layer_2': 0.23472707311743263, 'dropout_rate_Layer_3': 0.045795666928378775, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9417668977825836e-05, 'l1_Layer_2': 0.004331996567580366, 'l1_Layer_3': 2.3618884259176616e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 250, 'n_units_Layer_3': 230}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.17 | sMAPE for Test Set is: 53.39% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 14:57:57,872]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:58:02,810]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:58:19,081]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 14:59:18,530]\u001b[0m Trial 683 finished with value: 4.064999710994059 and parameters: {'n_hidden': 3, 'learning_rate': 0.001205487299742923, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019473846295161704, 'dropout_rate_Layer_2': 0.16213001658801934, 'dropout_rate_Layer_3': 0.21526209361681972, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008440780485837105, 'l1_Layer_2': 0.00014170359928702888, 'l1_Layer_3': 0.0006623138235661014, 'n_units_Layer_1': 180, 'n_units_Layer_2': 275, 'n_units_Layer_3': 160}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 12.22% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.11 | sMAPE for Test Set is: 49.11% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:00:22,378]\u001b[0m Trial 684 finished with value: 4.396168623254731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007158374788660614, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05233878949363163, 'dropout_rate_Layer_2': 0.23491058812730659, 'dropout_rate_Layer_3': 0.04623190881348706, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.038486250187996e-05, 'l1_Layer_2': 0.0032913002530907077, 'l1_Layer_3': 2.678867952612308e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 250, 'n_units_Layer_3': 225}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.85 | sMAPE for Test Set is: 55.61% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:00:25,911]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:00:29,790]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:00:33,952]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:01:41,307]\u001b[0m Trial 688 finished with value: 4.422544583226494 and parameters: {'n_hidden': 3, 'learning_rate': 0.000501445013825304, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0577142954010758, 'dropout_rate_Layer_2': 0.2217154550041177, 'dropout_rate_Layer_3': 0.051952737388726175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0661040541877821e-05, 'l1_Layer_2': 0.0041278917967880165, 'l1_Layer_3': 8.457866505562773e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 235, 'n_units_Layer_3': 210}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 13.01% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.94 | sMAPE for Test Set is: 55.94% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:01:46,695]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:01:53,450]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:02:02,263]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:02:07,052]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:02:12,375]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:03:02,327]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:03:08,597]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:03:14,278]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:03:18,137]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:04:14,324]\u001b[0m Trial 698 finished with value: 4.613298338005662 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005976829230272917, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04049267897724303, 'dropout_rate_Layer_2': 0.25070013915197914, 'dropout_rate_Layer_3': 0.015907230457178095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9526913578715097e-05, 'l1_Layer_2': 0.0069286834722576355, 'l1_Layer_3': 4.755103688166224e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 245, 'n_units_Layer_3': 230}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 13.55% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.14 | sMAPE for Test Set is: 53.00% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:04:18,264]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:04:22,188]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:04:28,154]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:06:43,395]\u001b[0m Trial 702 finished with value: 4.4985272249207595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007204088392083953, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.036490575585281036, 'dropout_rate_Layer_2': 0.24014877763054115, 'dropout_rate_Layer_3': 0.005644404742666403, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2043202767114973e-05, 'l1_Layer_2': 0.009119182054596928, 'l1_Layer_3': 3.8946900397956887e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 225, 'n_units_Layer_3': 230}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 13.28% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 53.32% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:06:49,094]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:06:57,381]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:07:02,690]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:07:06,057]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:07:11,739]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:07:17,055]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:07:23,480]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:07:34,223]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:07:40,652]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:09:17,744]\u001b[0m Trial 712 finished with value: 4.342789985711793 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005557414571315385, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025575125361095716, 'dropout_rate_Layer_2': 0.2592519862391458, 'dropout_rate_Layer_3': 0.03518551843608167, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9492253221967898e-05, 'l1_Layer_2': 0.005143928255043173, 'l1_Layer_3': 9.412992463422247e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 225}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 12.82% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.01 | sMAPE for Test Set is: 53.11% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:11:47,344]\u001b[0m Trial 713 finished with value: 4.262596430956097 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005434676542881911, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02703580167708307, 'dropout_rate_Layer_2': 0.2607623460729744, 'dropout_rate_Layer_3': 0.05009402127142684, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.48875309855579e-05, 'l1_Layer_2': 0.002472278247108316, 'l1_Layer_3': 0.00010037630514897295, 'n_units_Layer_1': 245, 'n_units_Layer_2': 260, 'n_units_Layer_3': 200}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 12.60% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.09 | sMAPE for Test Set is: 53.27% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:11:51,092]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:11:59,037]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:12:03,530]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:12:12,834]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:13:46,276]\u001b[0m Trial 718 finished with value: 4.406918157554428 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006692199846551688, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011403441396662882, 'dropout_rate_Layer_2': 0.2596136750207884, 'dropout_rate_Layer_3': 0.05017908643761026, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.699295934088794e-05, 'l1_Layer_2': 0.002333187024519365, 'l1_Layer_3': 0.0001040766131174905, 'n_units_Layer_1': 245, 'n_units_Layer_2': 260, 'n_units_Layer_3': 200}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 13.00% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.90 | sMAPE for Test Set is: 55.86% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:13:52,346]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:13:56,449]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:14:02,091]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:14:10,063]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:14:13,911]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:14:24,591]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:14:30,364]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:14:38,609]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:14:43,151]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:14:46,998]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:14:56,155]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:14:59,635]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:15:04,149]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:15:11,726]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:15:16,051]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:15:22,244]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:15:27,390]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:15:33,212]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:15:39,362]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:15:50,107]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:15:54,673]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:16:02,682]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:16:08,568]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:16:12,814]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:16:18,332]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:16:27,272]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:16:37,612]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:16:41,317]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:16:47,842]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:17:07,454]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:17:12,647]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:17:18,550]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:17:22,069]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:18:56,920]\u001b[0m Trial 752 finished with value: 4.386237856875585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007533047806415433, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06092589127777406, 'dropout_rate_Layer_2': 0.2595235677836508, 'dropout_rate_Layer_3': 0.06041436927466885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8775028879953098e-05, 'l1_Layer_2': 0.0027212441493989167, 'l1_Layer_3': 7.457981582608866e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 240, 'n_units_Layer_3': 170}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 12.97% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.49 | sMAPE for Test Set is: 54.55% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:19:03,018]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:19:06,643]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:19:12,293]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:19:21,494]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:19:25,431]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:19:29,398]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:19:33,196]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:19:38,309]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:19:46,827]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:19:52,383]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:20:04,945]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:20:09,336]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:20:15,414]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:20:20,122]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:22:12,452]\u001b[0m Trial 767 finished with value: 4.338090391256734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006363075768315704, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05113040483117957, 'dropout_rate_Layer_2': 0.229174760989277, 'dropout_rate_Layer_3': 0.027004153378057054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4729725296557446e-05, 'l1_Layer_2': 0.004529789625668328, 'l1_Layer_3': 8.655794489657467e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 195, 'n_units_Layer_3': 190}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.79 | sMAPE for Test Set is: 55.54% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:22:16,608]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:22:22,179]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:22:28,316]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:22:35,123]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:22:40,648]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:22:46,312]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:22:52,172]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:22:55,891]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:23:06,523]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:23:31,790]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:23:36,263]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:23:41,937]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:23:47,872]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:23:51,988]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:23:58,147]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:24:06,168]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:24:12,011]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:24:17,690]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:24:21,216]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:24:32,039]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:24:37,515]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:26:14,167]\u001b[0m Trial 789 finished with value: 4.394723228031919 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005691974877008917, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.033639682406009744, 'dropout_rate_Layer_2': 0.24452788196125252, 'dropout_rate_Layer_3': 0.028668246523152533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5560720253074558e-05, 'l1_Layer_2': 0.003904862304674748, 'l1_Layer_3': 8.277765467094123e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 255, 'n_units_Layer_3': 180}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 12.94% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 53.08% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:26:18,239]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:26:27,440]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:26:33,055]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:26:36,963]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:30:03,519]\u001b[0m Trial 794 finished with value: 4.291478339897632 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006955748724281286, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023656962352760477, 'dropout_rate_Layer_2': 0.20552044403304912, 'dropout_rate_Layer_3': 0.03606744445937311, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.829557197691296e-05, 'l1_Layer_2': 0.003042877326063265, 'l1_Layer_3': 0.0001044054619815022, 'n_units_Layer_1': 280, 'n_units_Layer_2': 195, 'n_units_Layer_3': 190}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 12.69% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.82 | sMAPE for Test Set is: 52.47% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:30:07,934]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:30:11,937]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:32:16,768]\u001b[0m Trial 797 finished with value: 4.4706542313431905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007297807751517757, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01580990863026235, 'dropout_rate_Layer_2': 0.20470136380442702, 'dropout_rate_Layer_3': 0.024663359150775496, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.5518263149694716e-05, 'l1_Layer_2': 0.003053191775468766, 'l1_Layer_3': 0.00012160142691607824, 'n_units_Layer_1': 280, 'n_units_Layer_2': 190, 'n_units_Layer_3': 190}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 13.13% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.54 | sMAPE for Test Set is: 54.57% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:32:29,836]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:32:39,772]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:32:45,239]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:32:50,160]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:32:57,982]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:33:10,628]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:33:16,428]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:33:21,954]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:33:27,221]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:33:32,847]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:33:36,831]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:33:42,326]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:33:46,350]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:33:52,335]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:33:59,977]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:34:03,770]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:34:08,254]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:34:13,521]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:34:19,319]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:34:27,059]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:34:33,817]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:34:37,638]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:36:41,030]\u001b[0m Trial 820 finished with value: 4.3711239709712055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009641076005221358, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.054402289189072695, 'dropout_rate_Layer_2': 0.22253988312262776, 'dropout_rate_Layer_3': 0.05568256064656672, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.421965754689882e-05, 'l1_Layer_2': 0.002805426679594958, 'l1_Layer_3': 8.026715669932815e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 210, 'n_units_Layer_3': 180}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 12.84% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.77 | sMAPE for Test Set is: 55.39% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:38:13,307]\u001b[0m Trial 821 finished with value: 4.385829080878246 and parameters: {'n_hidden': 3, 'learning_rate': 0.000790806336430969, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031276780495999974, 'dropout_rate_Layer_2': 0.23807900046891642, 'dropout_rate_Layer_3': 0.03570043790046374, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9676793647492146e-05, 'l1_Layer_2': 0.0033505916377490545, 'l1_Layer_3': 0.0001065486405140654, 'n_units_Layer_1': 220, 'n_units_Layer_2': 200, 'n_units_Layer_3': 200}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.67 | sMAPE for Test Set is: 51.47% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:38:18,681]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:38:25,004]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:38:30,644]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:38:38,740]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:38:42,787]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:38:50,832]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:38:54,441]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:38:57,874]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:39:01,841]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:39:05,548]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:39:10,581]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:39:15,607]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:39:21,212]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:40:12,258]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:40:18,387]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:40:24,753]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:40:28,632]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:40:34,824]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:40:47,531]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:40:53,823]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:41:43,518]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:41:48,830]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:41:54,186]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:41:58,663]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:42:04,574]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:44:23,565]\u001b[0m Trial 847 finished with value: 4.426094643417017 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005630915926500644, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025416607388724137, 'dropout_rate_Layer_2': 0.2552114307384085, 'dropout_rate_Layer_3': 0.034438831916245936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8537146585119505e-05, 'l1_Layer_2': 0.004531942038789158, 'l1_Layer_3': 6.212671597916537e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 250, 'n_units_Layer_3': 225}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 13.08% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.30 | sMAPE for Test Set is: 50.47% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:44:31,333]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:45:22,555]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:45:28,712]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:45:32,467]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:46:21,151]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:46:26,414]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:46:32,267]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:46:42,253]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:46:46,677]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:47:12,329]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:47:18,663]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:47:22,326]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:47:28,573]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:47:36,110]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:47:40,612]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:47:44,636]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:47:57,457]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:48:02,104]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:48:08,348]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:48:13,075]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:48:19,725]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:49:08,115]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:49:12,300]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:49:18,639]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:49:24,407]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:49:30,114]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:49:36,354]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:49:40,972]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:49:46,782]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:49:51,067]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:49:55,356]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:50:02,076]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:50:06,495]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:50:12,148]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:50:19,567]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:51:09,649]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:51:13,874]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:51:20,206]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:51:28,628]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:53:33,374]\u001b[0m Trial 887 finished with value: 4.271057074851385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005712797685214704, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.040258662692112326, 'dropout_rate_Layer_2': 0.24302651084541457, 'dropout_rate_Layer_3': 0.0163273868986043, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7098231190012504e-05, 'l1_Layer_2': 0.007932556864883734, 'l1_Layer_3': 0.0001958806861953671, 'n_units_Layer_1': 195, 'n_units_Layer_2': 165, 'n_units_Layer_3': 215}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 12.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.48 | sMAPE for Test Set is: 50.95% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 15:53:53,560]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:53:57,465]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:54:05,743]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:54:10,160]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:54:13,906]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:55:52,517]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:55:59,579]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:56:06,547]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 15:59:57,605]\u001b[0m Trial 896 finished with value: 4.188102403286449 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005684305061130056, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04645208218969815, 'dropout_rate_Layer_2': 0.26100226615088645, 'dropout_rate_Layer_3': 0.038175193213946426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.290707787065068e-05, 'l1_Layer_2': 0.0033201593214266106, 'l1_Layer_3': 0.00018088441213161326, 'n_units_Layer_1': 185, 'n_units_Layer_2': 150, 'n_units_Layer_3': 215}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 12.45% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.03 | sMAPE for Test Set is: 53.07% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:00:05,793]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:00:10,502]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:00:16,551]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:00:27,312]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:01:17,747]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:01:26,163]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:01:31,781]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:01:41,386]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:01:44,812]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:03:17,814]\u001b[0m Trial 906 finished with value: 4.74954800984935 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008591947918006195, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3773419814408998, 'dropout_rate_Layer_2': 0.38820083255700466, 'dropout_rate_Layer_3': 0.358517130830964, 'dropout_rate_Layer_4': 0.08579589704997502, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0026381522773565166, 'l1_Layer_2': 0.05162483734644089, 'l1_Layer_3': 0.0003672929811585789, 'l1_Layer_4': 0.00023574140043031874, 'n_units_Layer_1': 50, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130, 'n_units_Layer_4': 190}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 13.86% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 12.51 | sMAPE for Test Set is: 57.58% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:03:22,238]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:04:13,477]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:06:44,269]\u001b[0m Trial 909 finished with value: 4.327821787438135 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006774522407790178, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07364793878088802, 'dropout_rate_Layer_2': 0.25295837510900865, 'dropout_rate_Layer_3': 0.040508537391347, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4544503424377035e-05, 'l1_Layer_2': 0.003489169946313585, 'l1_Layer_3': 0.0001853239328005059, 'n_units_Layer_1': 180, 'n_units_Layer_2': 155, 'n_units_Layer_3': 200}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.69 | sMAPE for Test Set is: 55.22% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:06:48,363]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:06:54,593]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:08:40,974]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:08:47,007]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:08:51,546]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:09:43,710]\u001b[0m Trial 915 finished with value: 4.317225078191171 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007415254493922446, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0766835454696635, 'dropout_rate_Layer_2': 0.2713821371495856, 'dropout_rate_Layer_3': 0.04598345171302075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5074804320324614e-05, 'l1_Layer_2': 0.0034931894085382543, 'l1_Layer_3': 0.0002194835221590863, 'n_units_Layer_1': 180, 'n_units_Layer_2': 155, 'n_units_Layer_3': 200}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 12.80% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.05 | sMAPE for Test Set is: 52.99% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:09:57,241]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:10:04,784]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:10:09,399]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:10:15,018]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:10:21,069]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:10:31,311]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:10:37,312]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:10:50,895]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:10:57,037]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:11:01,514]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:11:08,072]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:11:20,172]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:11:24,863]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:12:31,048]\u001b[0m Trial 929 finished with value: 4.406633412211967 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005912840524756291, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03258971393532606, 'dropout_rate_Layer_2': 0.28275247755323457, 'dropout_rate_Layer_3': 0.041976622732616445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.363206031845242e-05, 'l1_Layer_2': 0.002623437623334824, 'l1_Layer_3': 0.00024277389305009126, 'n_units_Layer_1': 185, 'n_units_Layer_2': 165, 'n_units_Layer_3': 205}. Best is trial 118 with value: 4.033488516825316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.40 | sMAPE for Test Set is: 54.23% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:12:35,205]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:13:25,679]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:13:29,618]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:14:40,343]\u001b[0m Trial 933 finished with value: 3.992547243696741 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010166243167594841, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006406675420321133, 'dropout_rate_Layer_2': 0.010694615300301635, 'dropout_rate_Layer_3': 0.0215474047029922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001593446493791972, 'l1_Layer_2': 0.00029426214004220954, 'l1_Layer_3': 0.0006391492635422338, 'n_units_Layer_1': 125, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 12.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.90 | sMAPE for Test Set is: 48.34% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:14:46,181]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:14:52,554]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:15:12,505]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:15:47,571]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:15:52,111]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:15:59,983]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:16:06,200]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:16:11,234]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:16:17,082]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:18:46,595]\u001b[0m Trial 943 finished with value: 4.323721638205332 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006694834145631524, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009913561186028605, 'dropout_rate_Layer_2': 0.2453336761426865, 'dropout_rate_Layer_3': 0.029838358962102633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.256205491965251e-05, 'l1_Layer_2': 0.003061775822168229, 'l1_Layer_3': 0.00011520846640842405, 'n_units_Layer_1': 175, 'n_units_Layer_2': 160, 'n_units_Layer_3': 220}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.68 | sMAPE for Test Set is: 55.02% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:18:50,540]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:18:56,721]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:19:01,225]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:19:50,516]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:20:05,465]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:20:09,601]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:20:13,912]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:20:20,095]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:20:25,781]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:20:30,184]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:20:34,718]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:20:42,384]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:20:49,402]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:20:55,641]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:20:59,905]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:21:05,286]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:21:10,197]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:21:18,916]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:21:26,558]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:21:32,399]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:21:36,958]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:21:41,208]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:21:47,451]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:21:53,101]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:21:57,673]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:22:47,242]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:22:51,740]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:23:45,110]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:25:01,286]\u001b[0m Trial 972 finished with value: 4.329072000123492 and parameters: {'n_hidden': 3, 'learning_rate': 0.007381149062200589, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00035276140216648766, 'dropout_rate_Layer_2': 0.2447854898983624, 'dropout_rate_Layer_3': 0.021757544018981646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.190350917765108e-05, 'l1_Layer_2': 0.011632037845871307, 'l1_Layer_3': 0.00022062859379030772, 'n_units_Layer_1': 170, 'n_units_Layer_2': 150, 'n_units_Layer_3': 220}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.43 | sMAPE for Test Set is: 51.21% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:27:13,802]\u001b[0m Trial 973 finished with value: 4.357908752670502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007830567201377592, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15910379147674458, 'dropout_rate_Layer_2': 0.263993906113888, 'dropout_rate_Layer_3': 0.032330196468933606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.26151204142797e-05, 'l1_Layer_2': 0.003626134622169812, 'l1_Layer_3': 0.00017653974769476214, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 225}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.85 | sMAPE for Test Set is: 55.77% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:27:22,254]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:27:28,044]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:27:41,773]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:27:48,601]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:27:55,146]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:28:06,415]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:28:11,171]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:28:19,491]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:28:25,731]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:28:33,702]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:28:38,506]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:28:42,798]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:29:12,989]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:29:19,350]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:29:32,671]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:29:39,819]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:29:45,559]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:30:36,035]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:30:44,126]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:31:32,228]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:31:37,867]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:31:43,788]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:31:48,911]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:31:53,098]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:31:58,003]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:32:18,201]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:32:24,011]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:32:27,258]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:32:33,553]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:33:22,320]\u001b[0m Trial 1003 finished with value: 4.360245602863461 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006586547029829967, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03250887587478652, 'dropout_rate_Layer_2': 0.26665355474837327, 'dropout_rate_Layer_3': 0.006942029152211527, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.346579917417433e-05, 'l1_Layer_2': 0.002868140432557266, 'l1_Layer_3': 7.383962806808662e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 135, 'n_units_Layer_3': 220}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.82 | sMAPE for Test Set is: 52.55% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:33:26,933]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:33:30,978]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:33:41,879]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:33:48,291]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:33:56,439]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:34:01,011]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:35:58,308]\u001b[0m Trial 1010 finished with value: 4.360410855251541 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007286106860251187, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0788287300453053, 'dropout_rate_Layer_2': 0.24146678559914522, 'dropout_rate_Layer_3': 0.13969015981543872, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.38454776905953e-05, 'l1_Layer_2': 0.00507234557723574, 'l1_Layer_3': 1.9514981269827556e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 285, 'n_units_Layer_3': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.62 | sMAPE for Test Set is: 51.51% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:36:04,129]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:36:10,380]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:36:14,312]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:36:18,254]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:36:23,120]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:36:28,539]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:36:32,292]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:36:38,696]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:36:43,127]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:36:49,379]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:36:55,534]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:38:19,924]\u001b[0m Trial 1022 finished with value: 4.477987024095916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009390604343343423, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05569332569795354, 'dropout_rate_Layer_2': 0.2591076086976475, 'dropout_rate_Layer_3': 0.02380824379461649, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.074534430138808e-05, 'l1_Layer_2': 0.003863342401898047, 'l1_Layer_3': 2.515165180075405e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 140, 'n_units_Layer_3': 205}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 12.05 | sMAPE for Test Set is: 56.30% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:38:33,543]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:38:37,392]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:40:22,969]\u001b[0m Trial 1025 finished with value: 4.39183851990176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006679176092300582, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013306190468004622, 'dropout_rate_Layer_2': 0.24945833247118301, 'dropout_rate_Layer_3': 0.0339765801690997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4960973011440976e-05, 'l1_Layer_2': 0.0032198514602186186, 'l1_Layer_3': 0.0001901659162652893, 'n_units_Layer_1': 195, 'n_units_Layer_2': 155, 'n_units_Layer_3': 215}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.84 | sMAPE for Test Set is: 52.29% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:40:26,600]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:40:31,990]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:41:22,295]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:42:10,787]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:43:20,087]\u001b[0m Trial 1030 finished with value: 4.379276523057309 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006243671070419659, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10024907297323196, 'dropout_rate_Layer_2': 0.21900972456371856, 'dropout_rate_Layer_3': 0.12211727118440296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.0924617106059724e-05, 'l1_Layer_2': 0.005090641149716445, 'l1_Layer_3': 9.96626711838167e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.75 | sMAPE for Test Set is: 55.24% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:43:27,927]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:43:34,196]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:43:39,228]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:43:43,563]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:43:47,973]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:43:53,728]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:44:02,517]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:44:19,531]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:44:42,923]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:45:09,782]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:45:14,262]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:45:18,163]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:45:25,981]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:45:32,024]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:45:37,835]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:45:41,807]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:45:46,821]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:45:51,882]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:45:57,179]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:46:03,038]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:46:07,182]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:46:11,437]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:46:15,964]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:46:22,121]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:46:26,937]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:46:30,908]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:46:34,974]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:46:40,467]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:46:44,369]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:46:48,205]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:46:55,971]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:47:46,333]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:47:50,673]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:47:56,543]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:48:00,813]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:48:06,736]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:48:11,778]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:48:33,261]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:48:38,342]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:48:44,511]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:48:50,572]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:48:54,942]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:49:00,722]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:49:06,233]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:49:17,341]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:49:23,685]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:50:15,712]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:50:20,726]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:50:25,873]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:50:30,176]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:50:35,129]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:50:40,417]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:50:45,815]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:50:58,850]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:51:03,767]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:51:09,961]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:51:16,204]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:51:20,335]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:51:26,601]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:52:19,685]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:52:23,497]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:52:27,935]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:52:32,035]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:52:40,787]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:52:44,705]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:52:50,384]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:52:58,963]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:53:03,185]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:53:06,943]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:53:10,956]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:53:15,691]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:53:30,891]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:53:39,816]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:53:44,705]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:53:49,073]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:56:20,868]\u001b[0m Trial 1106 finished with value: 4.282932357273068 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006535814228216377, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04850076464096832, 'dropout_rate_Layer_2': 0.2325346529187834, 'dropout_rate_Layer_3': 0.029166065186967127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3857755650505444e-05, 'l1_Layer_2': 0.004453788279989297, 'l1_Layer_3': 8.78027503604309e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 180, 'n_units_Layer_3': 185}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 12.70% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.78 | sMAPE for Test Set is: 55.39% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:56:25,234]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:56:30,782]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:56:35,507]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:58:53,426]\u001b[0m Trial 1110 finished with value: 4.338009903186749 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006741423913009028, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.054118011463877944, 'dropout_rate_Layer_2': 0.24518749661046146, 'dropout_rate_Layer_3': 0.016580944284157708, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2456652239655477e-05, 'l1_Layer_2': 0.005024478866791727, 'l1_Layer_3': 9.040039102490369e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 195}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 12.82% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.14 | sMAPE for Test Set is: 53.63% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 16:58:59,819]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:59:07,368]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:59:13,549]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:59:18,270]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:59:22,618]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:59:27,843]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:59:31,917]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:59:37,607]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 16:59:45,820]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:00:07,608]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:00:13,593]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:00:59,824]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:01:08,018]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:01:13,617]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:01:18,297]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:01:24,586]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:01:30,457]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:01:34,354]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:03:21,371]\u001b[0m Trial 1129 finished with value: 4.291276680832691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005940253448850274, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.049846118281044474, 'dropout_rate_Layer_2': 0.2640688705782628, 'dropout_rate_Layer_3': 0.02669986257563817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6690988277696563e-05, 'l1_Layer_2': 0.0023175238997116526, 'l1_Layer_3': 5.697954195042239e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 160, 'n_units_Layer_3': 175}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 12.67% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 54.18% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:03:26,643]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:03:39,589]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:03:45,844]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:03:49,963]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:06:29,436]\u001b[0m Trial 1134 finished with value: 4.343471883883911 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016070208819920072, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.052447421341307754, 'dropout_rate_Layer_2': 0.2505258744330195, 'dropout_rate_Layer_3': 0.08546797800485176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.805999827388407e-05, 'l1_Layer_2': 0.008353566007134158, 'l1_Layer_3': 5.0678512041788274e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 165, 'n_units_Layer_3': 170}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 12.85% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.34 | sMAPE for Test Set is: 54.26% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:06:45,973]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:06:51,375]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:07:04,306]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:07:15,037]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:07:22,957]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:07:28,031]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:07:32,121]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:07:36,617]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:07:42,390]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:07:46,978]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:08:38,681]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:08:42,460]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:08:47,441]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:08:53,414]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:08:57,744]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:09:01,845]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:09:07,996]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:09:16,523]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:09:20,797]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:11:42,624]\u001b[0m Trial 1154 finished with value: 4.356793907181511 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006871697464756846, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04496710805426821, 'dropout_rate_Layer_2': 0.25469677288987913, 'dropout_rate_Layer_3': 0.04529311380259955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4946865031994722e-05, 'l1_Layer_2': 0.0031476564117867835, 'l1_Layer_3': 5.9673613934568374e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 150, 'n_units_Layer_3': 235}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 12.83% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 54.70% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:11:48,526]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:11:55,245]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:11:59,246]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:12:07,464]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:14:52,925]\u001b[0m Trial 1159 finished with value: 4.3248091407683535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005995388845314135, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03795057505284658, 'dropout_rate_Layer_2': 0.2670304868704273, 'dropout_rate_Layer_3': 0.03749730560946355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0186947758229915e-05, 'l1_Layer_2': 0.0034725511784382585, 'l1_Layer_3': 3.320084518238608e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 195}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 12.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.24 | sMAPE for Test Set is: 53.98% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:14:59,749]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:15:05,735]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:15:11,484]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:15:16,143]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:15:20,018]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:15:29,136]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:15:35,176]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:15:39,142]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:16:32,051]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:16:36,469]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:16:41,397]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:17:01,727]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:17:05,557]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:17:29,031]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:17:32,898]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:17:38,933]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:17:44,405]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:17:52,694]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:17:57,083]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:18:05,186]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:18:09,000]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:18:18,166]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:18:22,949]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:18:28,395]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:18:34,418]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:18:41,079]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:18:46,406]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:18:51,074]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:18:59,561]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:19:03,808]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:20:49,584]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:20:53,985]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:21:00,774]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:21:05,062]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:21:10,322]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:21:19,219]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:21:23,918]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:22:23,732]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:22:29,709]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:22:34,043]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:22:38,957]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:22:43,302]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:24:17,683]\u001b[0m Trial 1202 finished with value: 4.21078401080057 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006482380044062372, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16953156522378057, 'dropout_rate_Layer_2': 0.22482465995395767, 'dropout_rate_Layer_3': 0.33148086691941003, 'dropout_rate_Layer_4': 0.07673473970600764, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.1727219320834534e-05, 'l1_Layer_2': 0.009552824557946068, 'l1_Layer_3': 1.3302296472963979e-05, 'l1_Layer_4': 4.835888489729035e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 12.55% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.62 | sMAPE for Test Set is: 46.50% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:24:52,252]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:24:56,199]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:25:55,466]\u001b[0m Trial 1205 finished with value: 4.075608893853216 and parameters: {'n_hidden': 3, 'learning_rate': 0.003255819496307484, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024220938011119356, 'dropout_rate_Layer_2': 0.11105856858758241, 'dropout_rate_Layer_3': 0.041126120489823656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009492349387184107, 'l1_Layer_2': 0.001026996579291102, 'l1_Layer_3': 0.0010153738353082399, 'n_units_Layer_1': 125, 'n_units_Layer_2': 145, 'n_units_Layer_3': 255}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 12.19% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.31 | sMAPE for Test Set is: 52.71% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:26:06,139]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:26:12,487]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:26:17,392]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:26:23,098]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:26:29,305]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:26:33,417]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:30:20,727]\u001b[0m Trial 1212 finished with value: 4.236344953462399 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020008852562213094, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05035294591648596, 'dropout_rate_Layer_2': 0.2621007726927266, 'dropout_rate_Layer_3': 0.05194929989319952, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7522497358681517e-05, 'l1_Layer_2': 0.01750546476771624, 'l1_Layer_3': 0.00012300524812957863, 'n_units_Layer_1': 180, 'n_units_Layer_2': 275, 'n_units_Layer_3': 190}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 12.62% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.83 | sMAPE for Test Set is: 52.61% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:30:25,006]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:30:35,225]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:31:27,317]\u001b[0m Trial 1215 finished with value: 4.422827974138314 and parameters: {'n_hidden': 4, 'learning_rate': 0.000747673508335042, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19005535684862507, 'dropout_rate_Layer_2': 0.21631488153049885, 'dropout_rate_Layer_3': 0.22209447493909323, 'dropout_rate_Layer_4': 0.09064786045628168, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.8220219953427255e-05, 'l1_Layer_2': 0.006996035277694041, 'l1_Layer_3': 5.062962696282762e-05, 'l1_Layer_4': 4.066203365592377e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135, 'n_units_Layer_4': 220}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 13.07% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 54.00% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:31:34,264]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:32:10,215]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:33:02,193]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:33:59,187]\u001b[0m Trial 1219 finished with value: 4.647631570644664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010106271380353178, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06740729503978421, 'dropout_rate_Layer_2': 0.2739060910992844, 'dropout_rate_Layer_3': 0.06694420228718251, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9400022501981717e-05, 'l1_Layer_2': 0.01446382723957198, 'l1_Layer_3': 9.169927519513905e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 285, 'n_units_Layer_3': 190}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 13.58% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.99 | sMAPE for Test Set is: 55.94% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:34:03,583]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:34:09,394]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:34:47,453]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:35:36,481]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:35:41,652]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:36:45,719]\u001b[0m Trial 1225 finished with value: 4.405918382843558 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005859707726047639, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20730593941916034, 'dropout_rate_Layer_2': 0.22588928101117148, 'dropout_rate_Layer_3': 0.20799782937665545, 'dropout_rate_Layer_4': 0.11207017251690153, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.3179904320314436e-05, 'l1_Layer_2': 0.009823311453399866, 'l1_Layer_3': 2.1980176983946785e-05, 'l1_Layer_4': 3.8782929085269245e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 195, 'n_units_Layer_3': 140, 'n_units_Layer_4': 215}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 13.06% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.85 | sMAPE for Test Set is: 55.70% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:36:53,049]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:37:00,219]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:37:04,970]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:37:14,998]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:37:35,306]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:37:56,305]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:38:02,734]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:38:08,458]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:38:16,138]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:38:54,448]\u001b[0m Trial 1235 finished with value: 4.494630008187818 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007422423432271166, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21796248103745183, 'dropout_rate_Layer_2': 0.23227169160592584, 'dropout_rate_Layer_3': 0.2113169985249399, 'dropout_rate_Layer_4': 0.1350297614900165, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.2425712212127744e-05, 'l1_Layer_2': 0.011967697175215494, 'l1_Layer_3': 1.2044077271900411e-05, 'l1_Layer_4': 3.699927106176501e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 195, 'n_units_Layer_3': 150, 'n_units_Layer_4': 215}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 13.25% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 12.09 | sMAPE for Test Set is: 56.33% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:39:00,279]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:39:05,216]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:39:10,909]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:39:16,668]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:39:21,934]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:39:28,712]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:39:58,397]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:40:19,112]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:40:23,964]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:41:53,249]\u001b[0m Trial 1245 finished with value: 4.3195808569146275 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006034707135885217, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2553431862218426, 'dropout_rate_Layer_2': 0.24637314960203308, 'dropout_rate_Layer_3': 0.2197715181321866, 'dropout_rate_Layer_4': 0.11088438005947586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.4833458327641634e-05, 'l1_Layer_2': 0.009754886749487197, 'l1_Layer_3': 1.6783026943876938e-05, 'l1_Layer_4': 2.7199350785390974e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 195, 'n_units_Layer_3': 150, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 12.82% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.58 | sMAPE for Test Set is: 54.90% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:43:30,777]\u001b[0m Trial 1246 finished with value: 4.300385811573079 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005884761951755195, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2143642628390363, 'dropout_rate_Layer_2': 0.23588904024442034, 'dropout_rate_Layer_3': 0.2066168407037553, 'dropout_rate_Layer_4': 0.11393874052911014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8338242388223912e-05, 'l1_Layer_2': 0.010501566366333016, 'l1_Layer_3': 1.3672883167589546e-05, 'l1_Layer_4': 3.620732888294186e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 190, 'n_units_Layer_3': 155, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.99 | sMAPE for Test Set is: 56.25% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:43:38,082]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:43:42,590]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:43:53,657]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:44:00,820]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:44:06,628]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:44:12,440]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:44:33,501]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:44:43,799]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:46:01,123]\u001b[0m Trial 1255 finished with value: 4.413513727614334 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005812409622444355, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23195404540026857, 'dropout_rate_Layer_2': 0.2485591459082992, 'dropout_rate_Layer_3': 0.1999312303145622, 'dropout_rate_Layer_4': 0.11084281612962382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.9915559020828612e-05, 'l1_Layer_2': 0.013282235624620201, 'l1_Layer_3': 1.6161186454939094e-05, 'l1_Layer_4': 3.522421223892515e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 190, 'n_units_Layer_3': 155, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 13.07% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.67 | sMAPE for Test Set is: 55.22% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:46:06,328]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:47:12,939]\u001b[0m Trial 1257 finished with value: 4.427042385346398 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005075660558803449, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20909216380750173, 'dropout_rate_Layer_2': 0.24944867684113267, 'dropout_rate_Layer_3': 0.20314313561982356, 'dropout_rate_Layer_4': 0.10920302975961485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8811035463585058e-05, 'l1_Layer_2': 0.014611042133070917, 'l1_Layer_3': 1.6398331660840913e-05, 'l1_Layer_4': 3.652909258252401e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 190, 'n_units_Layer_3': 155, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 13.09% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 55.89% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:47:36,453]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:48:28,305]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:48:50,188]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:49:04,136]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:50:23,773]\u001b[0m Trial 1262 finished with value: 4.146504640268437 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006500761081209806, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02117306108977104, 'dropout_rate_Layer_2': 0.16745562986331086, 'dropout_rate_Layer_3': 0.061101894615811045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044166094307812907, 'l1_Layer_2': 0.00366789414610058, 'l1_Layer_3': 1.6890291494615025e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 200}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 12.40% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.26 | sMAPE for Test Set is: 45.26% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:50:36,290]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:50:41,023]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:50:49,273]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:50:55,001]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:51:25,447]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:51:46,790]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:51:51,322]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:51:56,766]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:52:38,286]\u001b[0m Trial 1271 finished with value: 4.612661267232629 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005020256001359235, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2116767339255309, 'dropout_rate_Layer_2': 0.2544401691490612, 'dropout_rate_Layer_3': 0.18963352947082282, 'dropout_rate_Layer_4': 0.1125913670637549, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.9930492943616733e-05, 'l1_Layer_2': 0.014561531916825736, 'l1_Layer_3': 1.963964144947282e-05, 'l1_Layer_4': 2.9043267036737096e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 190, 'n_units_Layer_3': 165, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 13.54% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 12.84 | sMAPE for Test Set is: 58.50% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:52:54,367]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:53:04,119]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:53:14,273]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:53:17,441]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:53:33,941]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:53:44,377]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:53:49,361]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:54:21,347]\u001b[0m Trial 1279 finished with value: 4.238903962648171 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022007394435442505, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10598169436707225, 'dropout_rate_Layer_2': 0.08098285419299844, 'dropout_rate_Layer_3': 0.043597565546442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006941067134540792, 'l1_Layer_2': 0.00017108485346676322, 'l1_Layer_3': 0.00013440760459373149, 'n_units_Layer_1': 85, 'n_units_Layer_2': 145, 'n_units_Layer_3': 95}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.42 | sMAPE for Test Set is: 48.89% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:55:09,490]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:55:13,983]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:55:19,734]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:55:30,149]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:55:40,580]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:57:28,099]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:57:38,322]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:58:32,407]\u001b[0m Trial 1287 finished with value: 4.3444237413353095 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005543503038986118, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1987361162183438, 'dropout_rate_Layer_2': 0.26667813971089055, 'dropout_rate_Layer_3': 0.2019428564475792, 'dropout_rate_Layer_4': 0.12358365291416946, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.7476685324159248e-05, 'l1_Layer_2': 0.007122715027229135, 'l1_Layer_3': 1.705068458372432e-05, 'l1_Layer_4': 6.027469188880489e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 200, 'n_units_Layer_3': 165, 'n_units_Layer_4': 205}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.39 | sMAPE for Test Set is: 54.27% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 17:58:41,654]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:58:46,067]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:58:57,776]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:59:05,462]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:59:27,872]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 17:59:33,872]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:00:46,227]\u001b[0m Trial 1294 finished with value: 4.346821209278854 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005459947887198984, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21973135040945108, 'dropout_rate_Layer_2': 0.2561646532587242, 'dropout_rate_Layer_3': 0.1855258847528883, 'dropout_rate_Layer_4': 0.11132587317524836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.5188772222975716e-05, 'l1_Layer_2': 0.0076025908456889245, 'l1_Layer_3': 1.3405121954179732e-05, 'l1_Layer_4': 5.660629114914656e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 195, 'n_units_Layer_3': 175, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.95 | sMAPE for Test Set is: 56.13% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:01:21,251]\u001b[0m Trial 1295 finished with value: 4.034448853071564 and parameters: {'n_hidden': 3, 'learning_rate': 0.001889580719084122, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09299793707327512, 'dropout_rate_Layer_2': 0.06424691077127216, 'dropout_rate_Layer_3': 0.04272356928935852, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005197404403005163, 'l1_Layer_2': 0.00015629771130017765, 'l1_Layer_3': 0.00011058712564337779, 'n_units_Layer_1': 275, 'n_units_Layer_2': 130, 'n_units_Layer_3': 110}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 12.26% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.20 | sMAPE for Test Set is: 47.54% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:01:58,454]\u001b[0m Trial 1296 finished with value: 4.114352982878907 and parameters: {'n_hidden': 3, 'learning_rate': 0.002045635643241974, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08735088983009924, 'dropout_rate_Layer_2': 0.10515753854851605, 'dropout_rate_Layer_3': 0.04385349618268269, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007607790840482682, 'l1_Layer_2': 0.0001369505671595016, 'l1_Layer_3': 0.00011586420647119642, 'n_units_Layer_1': 95, 'n_units_Layer_2': 135, 'n_units_Layer_3': 85}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 12.31% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.94 | sMAPE for Test Set is: 53.27% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:03:11,804]\u001b[0m Trial 1297 finished with value: 4.354039176749118 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005040668196153805, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2214243759375017, 'dropout_rate_Layer_2': 0.2580960181680027, 'dropout_rate_Layer_3': 0.18407626983177755, 'dropout_rate_Layer_4': 0.10444837482194476, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.9407312662548624e-05, 'l1_Layer_2': 0.0064953853941436355, 'l1_Layer_3': 1.3207712952472147e-05, 'l1_Layer_4': 4.8106910879137237e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 170, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 12.97% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.01 | sMAPE for Test Set is: 53.02% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:03:15,659]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:04:52,882]\u001b[0m Trial 1299 finished with value: 4.249121344280421 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015133763048162051, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004570546966617753, 'dropout_rate_Layer_2': 0.24932759181424305, 'dropout_rate_Layer_3': 0.03703517224604084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010671116445912703, 'l1_Layer_2': 0.004027897386032171, 'l1_Layer_3': 4.340646395550095e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 280, 'n_units_Layer_3': 225}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 12.61% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.67 | sMAPE for Test Set is: 51.79% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:06:26,720]\u001b[0m Trial 1300 finished with value: 4.244279284423957 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005407724179167398, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22199917688629564, 'dropout_rate_Layer_2': 0.2518503790497451, 'dropout_rate_Layer_3': 0.1777980721562204, 'dropout_rate_Layer_4': 0.10243617696578856, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.6846417057663053e-05, 'l1_Layer_2': 0.005921171927353386, 'l1_Layer_3': 1.2895186658499973e-05, 'l1_Layer_4': 5.868200127184107e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 175, 'n_units_Layer_4': 200}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 12.63% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.59 | sMAPE for Test Set is: 55.01% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:06:33,322]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:06:37,534]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:07:06,087]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:07:12,117]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:07:17,763]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:08:00,876]\u001b[0m Trial 1306 finished with value: 4.034871611284367 and parameters: {'n_hidden': 3, 'learning_rate': 0.001947861305374336, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08813112437674822, 'dropout_rate_Layer_2': 0.0791406641066729, 'dropout_rate_Layer_3': 0.055669035033357114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006789077674077751, 'l1_Layer_2': 9.788886016262591e-05, 'l1_Layer_3': 0.00015129839048228527, 'n_units_Layer_1': 85, 'n_units_Layer_2': 135, 'n_units_Layer_3': 95}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.53 | sMAPE for Test Set is: 49.13% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:09:02,094]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:09:17,095]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:09:48,003]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:10:01,309]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:10:07,357]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:11:26,291]\u001b[0m Trial 1312 finished with value: 4.251736536709735 and parameters: {'n_hidden': 4, 'learning_rate': 0.000553998747142247, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2226324330810842, 'dropout_rate_Layer_2': 0.2576498456365629, 'dropout_rate_Layer_3': 0.18608047351862703, 'dropout_rate_Layer_4': 0.11074107353401692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.375153528791984e-05, 'l1_Layer_2': 0.00573966448088636, 'l1_Layer_3': 1.24551921900593e-05, 'l1_Layer_4': 6.383999275981223e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 195, 'n_units_Layer_3': 185, 'n_units_Layer_4': 200}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 12.63% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.36 | sMAPE for Test Set is: 54.39% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:11:39,472]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:11:46,368]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:12:43,012]\u001b[0m Trial 1315 finished with value: 4.316292738426109 and parameters: {'n_hidden': 4, 'learning_rate': 0.000563482984015963, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22396255250542113, 'dropout_rate_Layer_2': 0.26004105732874855, 'dropout_rate_Layer_3': 0.18697325837776207, 'dropout_rate_Layer_4': 0.10659611173569349, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.73111333593256e-05, 'l1_Layer_2': 0.005455121908654283, 'l1_Layer_3': 1.4114325894685484e-05, 'l1_Layer_4': 4.8164743759143935e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 190, 'n_units_Layer_3': 190, 'n_units_Layer_4': 205}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 12.80% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.99 | sMAPE for Test Set is: 53.08% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:12:49,057]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:13:46,609]\u001b[0m Trial 1317 finished with value: 4.3064696732402075 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005012388666881223, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22141561408278518, 'dropout_rate_Layer_2': 0.26709319207217025, 'dropout_rate_Layer_3': 0.1881226794428201, 'dropout_rate_Layer_4': 0.10929050978762989, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.2240633632648978e-05, 'l1_Layer_2': 0.004435393299763154, 'l1_Layer_3': 1.5555035494383436e-05, 'l1_Layer_4': 4.95613249256061e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 205, 'n_units_Layer_3': 185, 'n_units_Layer_4': 205}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.17 | sMAPE for Test Set is: 53.72% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:14:49,408]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:14:54,919]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:14:59,563]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:15:09,870]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:15:44,270]\u001b[0m Trial 1322 finished with value: 4.063031693422123 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019849115416553337, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10706332166360494, 'dropout_rate_Layer_2': 0.06315940262056774, 'dropout_rate_Layer_3': 0.02845511852086271, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006818384278445811, 'l1_Layer_2': 8.236303238397365e-05, 'l1_Layer_3': 0.00014766037111534059, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 85}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.01 | sMAPE for Test Set is: 46.69% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:16:47,734]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:17:51,302]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:18:52,881]\u001b[0m Trial 1325 finished with value: 4.2799092187917 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006053883225163504, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22091929112453473, 'dropout_rate_Layer_2': 0.25451460927863273, 'dropout_rate_Layer_3': 0.18517600061672246, 'dropout_rate_Layer_4': 0.11017931131034972, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.0331739682715393e-05, 'l1_Layer_2': 0.005215984186090956, 'l1_Layer_3': 2.0341242204330438e-05, 'l1_Layer_4': 4.825222341506914e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 200, 'n_units_Layer_3': 195, 'n_units_Layer_4': 205}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.15 | sMAPE for Test Set is: 53.59% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:18:59,580]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:19:57,033]\u001b[0m Trial 1327 finished with value: 4.322392542153541 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006103126502811309, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23450370463737313, 'dropout_rate_Layer_2': 0.26381373149916676, 'dropout_rate_Layer_3': 0.182243875559765, 'dropout_rate_Layer_4': 0.10267629082494678, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.5171132365096684e-05, 'l1_Layer_2': 0.0050055449113086715, 'l1_Layer_3': 2.1217011871448554e-05, 'l1_Layer_4': 4.8749468417239936e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 200, 'n_units_Layer_3': 185, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 12.80% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.47 | sMAPE for Test Set is: 54.64% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:20:03,352]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:20:07,081]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:20:13,360]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:20:23,971]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:20:35,356]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:20:41,735]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:22:40,731]\u001b[0m Trial 1334 finished with value: 4.175786000949711 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008198977633452204, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028708950048408115, 'dropout_rate_Layer_2': 0.240108957563972, 'dropout_rate_Layer_3': 0.033940077670265356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006689229030389152, 'l1_Layer_2': 0.0038123269111242698, 'l1_Layer_3': 7.184934615402181e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 290, 'n_units_Layer_3': 225}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.03 | sMAPE for Test Set is: 49.37% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:23:44,740]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:24:05,192]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:25:09,043]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:27:24,677]\u001b[0m Trial 1338 finished with value: 4.137542449788675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009387266002021898, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0423922462504692, 'dropout_rate_Layer_2': 0.2642902583247235, 'dropout_rate_Layer_3': 0.034612857809605546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006352634810945208, 'l1_Layer_2': 0.004412427952641428, 'l1_Layer_3': 6.409530289783849e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 295, 'n_units_Layer_3': 225}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 12.37% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.23 | sMAPE for Test Set is: 50.22% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:27:35,240]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:28:48,839]\u001b[0m Trial 1340 finished with value: 4.315035682798986 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005551547481785428, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2175343742850142, 'dropout_rate_Layer_2': 0.25849436130089226, 'dropout_rate_Layer_3': 0.19759688140465154, 'dropout_rate_Layer_4': 0.0994666601561961, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.719329261926677e-05, 'l1_Layer_2': 0.006625056471210406, 'l1_Layer_3': 1.1210788933493005e-05, 'l1_Layer_4': 7.15178811911181e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 55.35% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:30:19,166]\u001b[0m Trial 1341 finished with value: 4.25572405221964 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005732894567990912, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21151098009475017, 'dropout_rate_Layer_2': 0.25664792104399403, 'dropout_rate_Layer_3': 0.19738790642067963, 'dropout_rate_Layer_4': 0.11217571758461732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.773924923249983e-05, 'l1_Layer_2': 0.005357360739275541, 'l1_Layer_3': 1.1762104719394774e-05, 'l1_Layer_4': 7.318686095028092e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 200, 'n_units_Layer_4': 215}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 12.65% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.52 | sMAPE for Test Set is: 54.82% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:31:32,973]\u001b[0m Trial 1342 finished with value: 4.234050880526254 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005648270450770929, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20780032737505902, 'dropout_rate_Layer_2': 0.2644382554320182, 'dropout_rate_Layer_3': 0.1978032794581885, 'dropout_rate_Layer_4': 0.11152416099994653, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.793167449398005e-05, 'l1_Layer_2': 0.005021460628172375, 'l1_Layer_3': 1.1892867067618902e-05, 'l1_Layer_4': 7.943682946220417e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 185, 'n_units_Layer_3': 200, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 12.58% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 53.98% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:31:43,464]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:31:56,852]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:32:57,556]\u001b[0m Trial 1345 finished with value: 4.24399180423836 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005541229703262786, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2144911824957986, 'dropout_rate_Layer_2': 0.25590324543217774, 'dropout_rate_Layer_3': 0.18417308886545883, 'dropout_rate_Layer_4': 0.10020809344692135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.7572298387915923e-05, 'l1_Layer_2': 0.003696624139260198, 'l1_Layer_3': 1.015800522098403e-05, 'l1_Layer_4': 5.5227540627987254e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 205, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 12.62% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.12 | sMAPE for Test Set is: 53.56% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:33:01,583]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:34:19,123]\u001b[0m Trial 1347 finished with value: 4.207702263356143 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005543895619103389, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21491672612130994, 'dropout_rate_Layer_2': 0.25343853153156165, 'dropout_rate_Layer_3': 0.18511113270271462, 'dropout_rate_Layer_4': 0.09944256082170537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.385529144072413e-05, 'l1_Layer_2': 0.0039319234737582205, 'l1_Layer_3': 1.041234483412182e-05, 'l1_Layer_4': 7.185458688281186e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 200, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 12.51% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.16 | sMAPE for Test Set is: 53.62% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:34:23,139]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:35:29,144]\u001b[0m Trial 1349 finished with value: 4.249528864260271 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005527495887318118, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2132332805557072, 'dropout_rate_Layer_2': 0.25465224904503764, 'dropout_rate_Layer_3': 0.1835483556506354, 'dropout_rate_Layer_4': 0.10131984246070691, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.7110089081653684e-05, 'l1_Layer_2': 0.0035933996730677536, 'l1_Layer_3': 1.0055429298599512e-05, 'l1_Layer_4': 7.066898729230127e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 200, 'n_units_Layer_4': 215}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.89 | sMAPE for Test Set is: 52.72% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:36:10,837]\u001b[0m Trial 1350 finished with value: 4.103235806776437 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017535267365348048, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10952175315151641, 'dropout_rate_Layer_2': 0.09019838042912699, 'dropout_rate_Layer_3': 0.016301538134978758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009245018168048951, 'l1_Layer_2': 8.042007788658667e-05, 'l1_Layer_3': 6.596256848349504e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 135, 'n_units_Layer_3': 100}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 12.34% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.67 | sMAPE for Test Set is: 48.90% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:36:17,235]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:36:27,775]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:36:32,012]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:36:42,708]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:37:57,132]\u001b[0m Trial 1355 finished with value: 4.219968766482405 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005040848229841759, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2088913047950484, 'dropout_rate_Layer_2': 0.2552121833628111, 'dropout_rate_Layer_3': 0.19698896483183892, 'dropout_rate_Layer_4': 0.0986296687672095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.5266681927191793e-05, 'l1_Layer_2': 0.004458637016426425, 'l1_Layer_3': 1.2830295520820825e-05, 'l1_Layer_4': 5.491155221936311e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 200, 'n_units_Layer_4': 215}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 12.57% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 53.31% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:38:08,393]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:38:15,241]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:38:22,070]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:38:28,739]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:38:51,892]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:39:23,221]\u001b[0m Trial 1361 finished with value: 4.064489671599044 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017992682161857936, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11201227331331995, 'dropout_rate_Layer_2': 0.09394214255524337, 'dropout_rate_Layer_3': 0.008640203447340627, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007151367800588619, 'l1_Layer_2': 6.183775658489795e-05, 'l1_Layer_3': 9.700715635757842e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 95}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 12.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.86 | sMAPE for Test Set is: 49.36% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:40:54,139]\u001b[0m Trial 1362 finished with value: 4.1979054201559425 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005006280028658079, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22951547682675738, 'dropout_rate_Layer_2': 0.27253080639146227, 'dropout_rate_Layer_3': 0.190534203373084, 'dropout_rate_Layer_4': 0.11459077499302711, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.263963125015285e-05, 'l1_Layer_2': 0.002997024346920502, 'l1_Layer_3': 1.399320409194251e-05, 'l1_Layer_4': 5.09613820456508e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 200, 'n_units_Layer_4': 215}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 12.48% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.14 | sMAPE for Test Set is: 53.67% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:41:39,280]\u001b[0m Trial 1363 finished with value: 4.08154548078165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017607429690696065, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1125716530652357, 'dropout_rate_Layer_2': 0.059366195626249535, 'dropout_rate_Layer_3': 0.030235804431877254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007008485961116658, 'l1_Layer_2': 6.597640789990802e-05, 'l1_Layer_3': 8.362182454662266e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 125, 'n_units_Layer_3': 105}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 12.38% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 50.10% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:41:50,325]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:42:53,204]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:42:58,135]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:43:19,911]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:43:49,460]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:43:55,575]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:45:18,938]\u001b[0m Trial 1370 finished with value: 4.251467322282063 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006655978620257947, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23121580398295388, 'dropout_rate_Layer_2': 0.24865809740900502, 'dropout_rate_Layer_3': 0.1717431473296727, 'dropout_rate_Layer_4': 0.1079702984804489, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.195465534987456e-05, 'l1_Layer_2': 0.005339419684878133, 'l1_Layer_3': 1.5932605620771275e-05, 'l1_Layer_4': 5.255694405184319e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 205, 'n_units_Layer_4': 205}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 12.67% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.14 | sMAPE for Test Set is: 53.59% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:46:08,681]\u001b[0m Trial 1371 finished with value: 4.318003737975322 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006623413997638454, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24129978027727828, 'dropout_rate_Layer_2': 0.263112060363606, 'dropout_rate_Layer_3': 0.1697503542524126, 'dropout_rate_Layer_4': 0.10648196608797383, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.253672234832384e-05, 'l1_Layer_2': 0.005214006057112196, 'l1_Layer_3': 1.568483389221595e-05, 'l1_Layer_4': 6.952446473849996e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 205, 'n_units_Layer_4': 200}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.02 | sMAPE for Test Set is: 53.15% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:46:44,517]\u001b[0m Trial 1372 finished with value: 4.114412700438134 and parameters: {'n_hidden': 3, 'learning_rate': 0.001669912436116567, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11529074254709451, 'dropout_rate_Layer_2': 0.06142212482654488, 'dropout_rate_Layer_3': 0.03157931916812039, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007041820644677488, 'l1_Layer_2': 6.937392098710021e-05, 'l1_Layer_3': 8.265796049530168e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 100}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.13 | sMAPE for Test Set is: 47.83% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:47:26,952]\u001b[0m Trial 1373 finished with value: 4.038861127598159 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017547590070976318, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11278881839306783, 'dropout_rate_Layer_2': 0.06078094497206246, 'dropout_rate_Layer_3': 0.03202876477294157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007314438565577229, 'l1_Layer_2': 6.770230462868935e-05, 'l1_Layer_3': 5.7261649450310845e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 12.17% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.39 | sMAPE for Test Set is: 51.81% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:48:18,995]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:48:23,018]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:49:00,516]\u001b[0m Trial 1376 finished with value: 4.060465230824118 and parameters: {'n_hidden': 3, 'learning_rate': 0.001629423525679397, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12099218080717955, 'dropout_rate_Layer_2': 0.06596285693411423, 'dropout_rate_Layer_3': 0.04326969072534762, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000569611561897502, 'l1_Layer_2': 6.634123829644535e-05, 'l1_Layer_3': 8.040522913177074e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 125, 'n_units_Layer_3': 95}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 12.23% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.11 | sMAPE for Test Set is: 50.13% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:49:05,270]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:49:43,574]\u001b[0m Trial 1378 finished with value: 4.136659436166509 and parameters: {'n_hidden': 3, 'learning_rate': 0.001804393036529354, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10938339534380376, 'dropout_rate_Layer_2': 0.06262869495938737, 'dropout_rate_Layer_3': 0.05312706262405833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006084683076025793, 'l1_Layer_2': 8.690202166072672e-05, 'l1_Layer_3': 5.892256264124558e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 115, 'n_units_Layer_3': 95}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 12.48% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.66 | sMAPE for Test Set is: 49.26% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:49:56,505]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:50:07,158]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:51:10,527]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:52:03,029]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:52:09,486]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:52:14,428]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:52:19,863]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:52:44,321]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:53:48,599]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:54:01,167]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:54:12,473]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:55:12,430]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:55:18,526]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:55:22,413]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:55:42,891]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:55:47,020]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:56:12,236]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:56:23,132]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:56:55,104]\u001b[0m Trial 1397 finished with value: 4.065546657995944 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018480375073030141, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11151789253739666, 'dropout_rate_Layer_2': 0.04289435024504312, 'dropout_rate_Layer_3': 0.05265680809901448, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007370403426314857, 'l1_Layer_2': 0.00010347402785007326, 'l1_Layer_3': 6.944464951037271e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 125, 'n_units_Layer_3': 95}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 12.26% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.91 | sMAPE for Test Set is: 49.09% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:57:07,502]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:57:12,423]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 18:58:12,013]\u001b[0m Trial 1400 finished with value: 4.281912528052232 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007036778239011854, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21804946223949076, 'dropout_rate_Layer_2': 0.26589560342059393, 'dropout_rate_Layer_3': 0.1930918388344394, 'dropout_rate_Layer_4': 0.1118960322186934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.8251448999937048e-05, 'l1_Layer_2': 0.0067073334265673025, 'l1_Layer_3': 1.591812966637064e-05, 'l1_Layer_4': 7.471681772076058e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 190, 'n_units_Layer_3': 200, 'n_units_Layer_4': 220}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 12.74% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.36 | sMAPE for Test Set is: 54.23% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:58:39,835]\u001b[0m Trial 1401 finished with value: 4.116754543223042 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018869316546021506, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11013927987499603, 'dropout_rate_Layer_2': 0.047241721355714, 'dropout_rate_Layer_3': 0.06094270842661405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000614715987077394, 'l1_Layer_2': 6.579766527848751e-05, 'l1_Layer_3': 8.054937454131543e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 85}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 12.36% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.92 | sMAPE for Test Set is: 46.81% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 18:58:51,544]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:01:11,542]\u001b[0m Trial 1403 finished with value: 4.2720347918611665 and parameters: {'n_hidden': 3, 'learning_rate': 0.000503021324553974, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02420327516383142, 'dropout_rate_Layer_2': 0.03564454848431958, 'dropout_rate_Layer_3': 0.30700228524992457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004149713191140343, 'l1_Layer_2': 0.0041445582208655485, 'l1_Layer_3': 0.0001159316944974572, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 230}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 54.11% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:01:16,198]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:01:29,715]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:02:44,970]\u001b[0m Trial 1406 finished with value: 4.301566705077721 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006123640835879945, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21787573595490525, 'dropout_rate_Layer_2': 0.258874120058663, 'dropout_rate_Layer_3': 0.1479763559958404, 'dropout_rate_Layer_4': 0.11882215284787184, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.2224654869089784e-05, 'l1_Layer_2': 0.005336641293025017, 'l1_Layer_3': 1.3960375165373177e-05, 'l1_Layer_4': 7.448037140792467e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 190, 'n_units_Layer_3': 205, 'n_units_Layer_4': 210}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 12.83% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 52.68% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:03:46,611]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:04:11,151]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:04:42,305]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:04:46,737]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:04:57,814]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:05:36,199]\u001b[0m Trial 1412 finished with value: 4.084396934831027 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016529613474438334, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1122174776143686, 'dropout_rate_Layer_2': 0.04640369982584738, 'dropout_rate_Layer_3': 0.04615435560789547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005370049970992999, 'l1_Layer_2': 0.00010923886363381603, 'l1_Layer_3': 5.513870190376707e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 90}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.76 | sMAPE for Test Set is: 46.69% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:05:48,839]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:05:55,328]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:06:01,788]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:07:15,459]\u001b[0m Trial 1416 finished with value: 4.200543577644413 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005442636488223373, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21461665434102753, 'dropout_rate_Layer_2': 0.26642555582005223, 'dropout_rate_Layer_3': 0.1838108510098516, 'dropout_rate_Layer_4': 0.12328942364713513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.3425898354184043e-05, 'l1_Layer_2': 0.0028376680509853637, 'l1_Layer_3': 1.4649629188334885e-05, 'l1_Layer_4': 8.707205226926205e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 200, 'n_units_Layer_3': 205, 'n_units_Layer_4': 205}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 12.54% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 52.48% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:07:22,061]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:07:34,722]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:07:39,781]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:07:52,490]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:09:00,365]\u001b[0m Trial 1421 finished with value: 4.1908742339828615 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006785610475921435, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22716025117356764, 'dropout_rate_Layer_2': 0.2572781512269838, 'dropout_rate_Layer_3': 0.16981807164031337, 'dropout_rate_Layer_4': 0.12173269893577424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.6358662175070695e-05, 'l1_Layer_2': 0.0030478850775096547, 'l1_Layer_3': 1.705307683077883e-05, 'l1_Layer_4': 6.793752846986994e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 185, 'n_units_Layer_4': 205}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 12.50% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.06 | sMAPE for Test Set is: 53.37% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:10:44,409]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:10:51,363]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:12:41,687]\u001b[0m Trial 1424 finished with value: 4.411285592563991 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012092439427992838, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03372749796572551, 'dropout_rate_Layer_2': 0.049446361760405, 'dropout_rate_Layer_3': 0.2366234584978627, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005565560607096412, 'l1_Layer_2': 0.004052229373801282, 'l1_Layer_3': 6.397085173099082e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 295, 'n_units_Layer_3': 230}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.42 | sMAPE for Test Set is: 57.47% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:14:23,750]\u001b[0m Trial 1425 finished with value: 4.214244472034817 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006520824637293448, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23892735007006785, 'dropout_rate_Layer_2': 0.2519353030889162, 'dropout_rate_Layer_3': 0.1689987233263774, 'dropout_rate_Layer_4': 0.13190460229237028, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.7260026343639224e-05, 'l1_Layer_2': 0.0029691386747630433, 'l1_Layer_3': 1.7251874197153785e-05, 'l1_Layer_4': 6.63431348361511e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 210, 'n_units_Layer_4': 195}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 12.51% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 52.74% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:14:35,985]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:14:42,640]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:15:34,793]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:15:39,884]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:15:44,528]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:15:51,080]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:15:57,547]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:16:48,081]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:17:19,549]\u001b[0m Trial 1434 finished with value: 4.105206142580155 and parameters: {'n_hidden': 3, 'learning_rate': 0.001760097848681987, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12276692349953362, 'dropout_rate_Layer_2': 0.04034549019348947, 'dropout_rate_Layer_3': 0.04520706592713181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007712090171814803, 'l1_Layer_2': 5.744512453651132e-05, 'l1_Layer_3': 6.387355778942447e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 80}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 12.37% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.83 | sMAPE for Test Set is: 49.76% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:17:58,236]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:18:23,378]\u001b[0m Trial 1436 finished with value: 4.126426843126448 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017235080844302873, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12262947099228944, 'dropout_rate_Layer_2': 0.0474144519517046, 'dropout_rate_Layer_3': 0.0496052938263019, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008082306764528549, 'l1_Layer_2': 5.891458191814417e-05, 'l1_Layer_3': 6.142536899312752e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 110, 'n_units_Layer_3': 80}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 12.36% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.94 | sMAPE for Test Set is: 46.77% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:18:33,697]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:19:36,524]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:19:49,043]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:20:01,582]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:20:25,190]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:21:26,662]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:21:54,413]\u001b[0m Trial 1443 finished with value: 4.125985843890817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017728512048684922, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13072117023110405, 'dropout_rate_Layer_2': 0.033911663128035785, 'dropout_rate_Layer_3': 0.057682422117180866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005384757435647192, 'l1_Layer_2': 5.951882557070128e-05, 'l1_Layer_3': 6.606971469202725e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 100, 'n_units_Layer_3': 70}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 12.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.10 | sMAPE for Test Set is: 47.81% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:22:00,004]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:22:24,775]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:22:55,837]\u001b[0m Trial 1446 finished with value: 4.078357694747839 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018202038104113002, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1254526287042831, 'dropout_rate_Layer_2': 0.034325757910840304, 'dropout_rate_Layer_3': 0.06317622181175754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005225328201654364, 'l1_Layer_2': 5.6273294541901396e-05, 'l1_Layer_3': 6.799024538827587e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 70}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 12.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.45 | sMAPE for Test Set is: 40.20% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:23:24,576]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:23:31,118]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:23:59,187]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:24:21,083]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:24:27,157]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:24:33,867]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:24:44,471]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:24:55,612]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:24:59,958]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:25:05,759]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:25:10,043]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:27:04,828]\u001b[0m Trial 1458 finished with value: 4.3637720134316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005781127795181501, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02915816100280906, 'dropout_rate_Layer_2': 0.22019878099561235, 'dropout_rate_Layer_3': 0.15568511240260818, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010152047087201199, 'l1_Layer_2': 0.006618497503879886, 'l1_Layer_3': 8.280968537740625e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 250, 'n_units_Layer_3': 230}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.58 | sMAPE for Test Set is: 51.39% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:27:11,376]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:27:31,115]\u001b[0m Trial 1460 finished with value: 4.118439848816761 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018538761662988989, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1275153093194885, 'dropout_rate_Layer_2': 0.05020389164952677, 'dropout_rate_Layer_3': 0.07544410542989544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000678076623866923, 'l1_Layer_2': 5.872721142256498e-05, 'l1_Layer_3': 9.535398995822356e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 80}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.64 | sMAPE for Test Set is: 40.75% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:27:36,454]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:27:43,141]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:27:53,465]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:28:04,302]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:28:11,455]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:28:15,385]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:28:26,459]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:28:34,706]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:29:06,490]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:29:12,200]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:29:18,285]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:29:30,529]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:29:36,620]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:30:02,449]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:30:13,526]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:30:45,337]\u001b[0m Trial 1476 finished with value: 4.06833092636708 and parameters: {'n_hidden': 3, 'learning_rate': 0.001408599899794501, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11853122430672841, 'dropout_rate_Layer_2': 0.03358620023125662, 'dropout_rate_Layer_3': 0.039360164842092836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005234564526789597, 'l1_Layer_2': 5.202333287088773e-05, 'l1_Layer_3': 0.00010101721992472604, 'n_units_Layer_1': 90, 'n_units_Layer_2': 120, 'n_units_Layer_3': 60}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.51 | sMAPE for Test Set is: 40.26% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:31:42,895]\u001b[0m Trial 1477 finished with value: 4.206216397405337 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005425677194474425, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2277565594931356, 'dropout_rate_Layer_2': 0.23968210633320913, 'dropout_rate_Layer_3': 0.14584027364199204, 'dropout_rate_Layer_4': 0.10684596674883569, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.4526487521383651e-05, 'l1_Layer_2': 0.00233699927147813, 'l1_Layer_3': 1.184977415979752e-05, 'l1_Layer_4': 8.476566907354875e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 200, 'n_units_Layer_3': 185, 'n_units_Layer_4': 220}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 12.54% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 52.12% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:32:43,573]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:32:48,531]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:32:54,430]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:32:59,472]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:33:04,914]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:33:15,840]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:33:24,680]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:34:14,420]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:34:26,538]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:34:45,979]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:34:49,530]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:35:16,361]\u001b[0m Trial 1489 finished with value: 4.1151645067095535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017770457612006376, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12315269623905567, 'dropout_rate_Layer_2': 0.046064456403579146, 'dropout_rate_Layer_3': 0.05862483173310872, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007012721875791334, 'l1_Layer_2': 7.710483867772826e-05, 'l1_Layer_3': 4.473108657764258e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 120, 'n_units_Layer_3': 65}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 12.33% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.80 | sMAPE for Test Set is: 42.07% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-30 19:35:21,209]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:35:51,431]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:35:56,179]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:36:02,299]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:36:33,699]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:36:45,668]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:36:51,790]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:37:05,256]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:37:11,932]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-30 19:37:35,786]\u001b[0m Trial 1499 finished with value: 4.04061674117716 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018718805497227235, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1341364654892351, 'dropout_rate_Layer_2': 0.02179491023736885, 'dropout_rate_Layer_3': 0.04321199987575272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006643461485657914, 'l1_Layer_2': 8.299891167044372e-05, 'l1_Layer_3': 5.136855776610095e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 75}. Best is trial 933 with value: 3.992547243696741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 12.25% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 39.99% | rMAE for Test Set is: 0.65\n",
      "for 2020-01-01, MAE is:1.85 & sMAPE is:6.67% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :1.85 & 6.67% & 0.25\n",
      "for 2020-01-02, MAE is:2.35 & sMAPE is:10.40% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 8.54% & 0.25\n",
      "for 2020-01-03, MAE is:5.15 & sMAPE is:34.92% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 17.33% & 0.28\n",
      "for 2020-01-04, MAE is:4.44 & sMAPE is:28.96% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.45 & 20.24% & 0.29\n",
      "for 2020-01-05, MAE is:4.62 & sMAPE is:17.66% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 19.72% & 0.58\n",
      "for 2020-01-06, MAE is:3.58 & sMAPE is:12.63% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 18.54% & 0.59\n",
      "for 2020-01-07, MAE is:5.16 & sMAPE is:14.83% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 18.01% & 0.59\n",
      "for 2020-01-08, MAE is:5.50 & sMAPE is:35.33% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 20.18% & 0.62\n",
      "for 2020-01-09, MAE is:4.59 & sMAPE is:13.72% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 19.46% & 0.64\n",
      "for 2020-01-10, MAE is:5.49 & sMAPE is:17.16% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 19.23% & 0.64\n",
      "for 2020-01-11, MAE is:2.05 & sMAPE is:8.37% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 18.24% & 0.61\n",
      "for 2020-01-12, MAE is:2.41 & sMAPE is:10.59% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 17.61% & 0.59\n",
      "for 2020-01-13, MAE is:7.88 & sMAPE is:22.52% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 17.98% & 0.61\n",
      "for 2020-01-14, MAE is:4.11 & sMAPE is:18.16% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 18.00% & 0.60\n",
      "for 2020-01-15, MAE is:2.07 & sMAPE is:10.52% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 17.50% & 0.58\n",
      "for 2020-01-16, MAE is:4.54 & sMAPE is:15.21% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 17.35% & 0.59\n",
      "for 2020-01-17, MAE is:3.96 & sMAPE is:13.59% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 17.13% & 0.59\n",
      "for 2020-01-18, MAE is:2.32 & sMAPE is:9.27% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 16.70% & 0.62\n",
      "for 2020-01-19, MAE is:7.47 & sMAPE is:24.99% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 17.13% & 0.64\n",
      "for 2020-01-20, MAE is:7.90 & sMAPE is:22.45% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 17.40% & 0.69\n",
      "for 2020-01-21, MAE is:4.41 & sMAPE is:16.26% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 17.34% & 0.70\n",
      "for 2020-01-22, MAE is:12.79 & sMAPE is:34.95% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 18.14% & 0.71\n",
      "for 2020-01-23, MAE is:11.22 & sMAPE is:30.43% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 18.68% & 0.72\n",
      "for 2020-01-24, MAE is:2.30 & sMAPE is:10.79% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 18.35% & 0.70\n",
      "for 2020-01-25, MAE is:3.99 & sMAPE is:16.67% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 18.28% & 0.72\n",
      "for 2020-01-26, MAE is:4.21 & sMAPE is:18.25% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 18.28% & 0.70\n",
      "for 2020-01-27, MAE is:6.46 & sMAPE is:25.92% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 18.56% & 0.69\n",
      "for 2020-01-28, MAE is:4.50 & sMAPE is:16.49% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 18.49% & 0.71\n",
      "for 2020-01-29, MAE is:4.32 & sMAPE is:17.96% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 18.47% & 0.69\n",
      "for 2020-01-30, MAE is:5.67 & sMAPE is:23.23% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 18.63% & 0.68\n",
      "for 2020-01-31, MAE is:3.43 & sMAPE is:16.50% & rMAE is:3.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 18.56% & 0.76\n",
      "for 2020-02-01, MAE is:6.04 & sMAPE is:34.81% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 19.07% & 0.76\n",
      "for 2020-02-02, MAE is:3.99 & sMAPE is:22.95% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 19.19% & 0.76\n",
      "for 2020-02-03, MAE is:5.38 & sMAPE is:20.00% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 19.21% & 0.76\n",
      "for 2020-02-04, MAE is:4.69 & sMAPE is:17.13% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 19.15% & 0.77\n",
      "for 2020-02-05, MAE is:7.51 & sMAPE is:31.98% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 19.51% & 0.79\n",
      "for 2020-02-06, MAE is:5.61 & sMAPE is:26.03% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 19.68% & 0.79\n",
      "for 2020-02-07, MAE is:8.71 & sMAPE is:30.97% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 19.98% & 0.80\n",
      "for 2020-02-08, MAE is:2.84 & sMAPE is:17.98% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 19.93% & 0.85\n",
      "for 2020-02-09, MAE is:11.04 & sMAPE is:82.95% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 21.51% & 0.86\n",
      "for 2020-02-10, MAE is:13.14 & sMAPE is:102.87% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 23.49% & 0.86\n",
      "for 2020-02-11, MAE is:9.15 & sMAPE is:54.61% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 24.23% & 0.85\n",
      "for 2020-02-12, MAE is:4.34 & sMAPE is:26.74% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 24.29% & 0.85\n",
      "for 2020-02-13, MAE is:11.08 & sMAPE is:37.41% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 24.59% & 0.86\n",
      "for 2020-02-14, MAE is:12.42 & sMAPE is:46.11% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 25.07% & 0.88\n",
      "for 2020-02-15, MAE is:4.92 & sMAPE is:35.05% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 25.28% & 0.92\n",
      "for 2020-02-16, MAE is:7.74 & sMAPE is:55.38% & rMAE is:3.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 25.92% & 0.97\n",
      "for 2020-02-17, MAE is:8.61 & sMAPE is:56.09% & rMAE is:3.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 26.55% & 1.03\n",
      "for 2020-02-18, MAE is:5.27 & sMAPE is:31.54% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 26.65% & 1.03\n",
      "for 2020-02-19, MAE is:8.81 & sMAPE is:30.93% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 26.74% & 1.02\n",
      "for 2020-02-20, MAE is:13.76 & sMAPE is:66.22% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 27.51% & 1.02\n",
      "for 2020-02-21, MAE is:8.86 & sMAPE is:58.34% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 28.11% & 1.01\n",
      "for 2020-02-22, MAE is:7.66 & sMAPE is:72.61% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 28.95% & 1.02\n",
      "for 2020-02-23, MAE is:6.41 & sMAPE is:50.17% & rMAE is:7.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 29.34% & 1.14\n",
      "for 2020-02-24, MAE is:13.05 & sMAPE is:48.73% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 29.69% & 1.13\n",
      "for 2020-02-25, MAE is:5.68 & sMAPE is:28.40% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 29.67% & 1.13\n",
      "for 2020-02-26, MAE is:9.25 & sMAPE is:40.66% & rMAE is:3.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 29.86% & 1.18\n",
      "for 2020-02-27, MAE is:12.47 & sMAPE is:30.28% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 29.87% & 1.17\n",
      "for 2020-02-28, MAE is:5.37 & sMAPE is:16.66% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 29.64% & 1.15\n",
      "for 2020-02-29, MAE is:10.41 & sMAPE is:60.85% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 30.16% & 1.17\n",
      "for 2020-03-01, MAE is:5.34 & sMAPE is:37.84% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 30.29% & 1.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-02, MAE is:8.51 & sMAPE is:31.11% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 30.30% & 1.19\n",
      "for 2020-03-03, MAE is:6.92 & sMAPE is:23.57% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 30.20% & 1.18\n",
      "for 2020-03-04, MAE is:11.10 & sMAPE is:34.93% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 30.27% & 1.19\n",
      "for 2020-03-05, MAE is:8.67 & sMAPE is:29.11% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 30.25% & 1.18\n",
      "for 2020-03-06, MAE is:4.80 & sMAPE is:20.61% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 30.11% & 1.17\n",
      "for 2020-03-07, MAE is:9.47 & sMAPE is:44.78% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 30.33% & 1.17\n",
      "for 2020-03-08, MAE is:5.91 & sMAPE is:45.90% & rMAE is:4.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 30.55% & 1.22\n",
      "for 2020-03-09, MAE is:11.06 & sMAPE is:42.37% & rMAE is:2.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 30.73% & 1.24\n",
      "for 2020-03-10, MAE is:14.73 & sMAPE is:71.58% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 31.31% & 1.23\n",
      "for 2020-03-11, MAE is:13.68 & sMAPE is:86.79% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 32.09% & 1.23\n",
      "for 2020-03-12, MAE is:11.41 & sMAPE is:71.15% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 32.63% & 1.22\n",
      "for 2020-03-13, MAE is:8.78 & sMAPE is:57.41% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 32.97% & 1.21\n",
      "for 2020-03-14, MAE is:6.43 & sMAPE is:37.58% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 33.04% & 1.21\n",
      "for 2020-03-15, MAE is:8.07 & sMAPE is:70.64% & rMAE is:3.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 33.54% & 1.23\n",
      "for 2020-03-16, MAE is:7.58 & sMAPE is:32.65% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 33.53% & 1.23\n",
      "for 2020-03-17, MAE is:11.78 & sMAPE is:58.28% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 33.85% & 1.23\n",
      "for 2020-03-18, MAE is:13.05 & sMAPE is:72.36% & rMAE is:3.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 34.34% & 1.26\n",
      "for 2020-03-19, MAE is:8.29 & sMAPE is:48.22% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 34.52% & 1.25\n",
      "for 2020-03-20, MAE is:7.49 & sMAPE is:43.18% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 34.62% & 1.25\n",
      "for 2020-03-21, MAE is:3.63 & sMAPE is:32.23% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 34.59% & 1.24\n",
      "for 2020-03-22, MAE is:4.54 & sMAPE is:45.77% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 34.73% & 1.24\n",
      "for 2020-03-23, MAE is:10.18 & sMAPE is:64.59% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 35.09% & 1.24\n",
      "for 2020-03-24, MAE is:9.59 & sMAPE is:69.74% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 35.50% & 1.23\n",
      "for 2020-03-25, MAE is:7.46 & sMAPE is:62.54% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 35.82% & 1.24\n",
      "for 2020-03-26, MAE is:7.46 & sMAPE is:57.66% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 36.08% & 1.25\n",
      "for 2020-03-27, MAE is:7.14 & sMAPE is:52.10% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 36.26% & 1.24\n",
      "for 2020-03-28, MAE is:8.95 & sMAPE is:82.61% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 36.79% & 1.25\n",
      "for 2020-03-29, MAE is:6.48 & sMAPE is:70.54% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 37.17% & 1.25\n",
      "for 2020-03-30, MAE is:4.81 & sMAPE is:23.12% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 37.01% & 1.24\n",
      "for 2020-03-31, MAE is:16.24 & sMAPE is:100.15% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 37.70% & 1.26\n",
      "for 2020-04-01, MAE is:7.88 & sMAPE is:77.82% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 38.14% & 1.28\n",
      "for 2020-04-02, MAE is:11.19 & sMAPE is:93.28% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 38.73% & 1.28\n",
      "for 2020-04-03, MAE is:12.24 & sMAPE is:105.31% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 39.44% & 1.28\n",
      "for 2020-04-04, MAE is:7.00 & sMAPE is:64.36% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 39.70% & 1.28\n",
      "for 2020-04-05, MAE is:8.09 & sMAPE is:84.46% & rMAE is:5.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 40.17% & 1.33\n",
      "for 2020-04-06, MAE is:12.54 & sMAPE is:87.79% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 40.66% & 1.32\n",
      "for 2020-04-07, MAE is:8.63 & sMAPE is:68.32% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 40.94% & 1.33\n",
      "for 2020-04-08, MAE is:9.16 & sMAPE is:69.20% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 41.23% & 1.32\n",
      "for 2020-04-09, MAE is:7.25 & sMAPE is:58.85% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 41.40% & 1.32\n",
      "for 2020-04-10, MAE is:6.67 & sMAPE is:41.53% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 41.40% & 1.31\n",
      "for 2020-04-11, MAE is:5.43 & sMAPE is:42.96% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 41.42% & 1.30\n",
      "for 2020-04-12, MAE is:10.20 & sMAPE is:99.36% & rMAE is:14.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 41.98% & 1.43\n",
      "for 2020-04-13, MAE is:12.16 & sMAPE is:133.29% & rMAE is:2.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 42.86% & 1.45\n",
      "for 2020-04-14, MAE is:8.19 & sMAPE is:50.93% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 42.94% & 1.45\n",
      "for 2020-04-15, MAE is:12.41 & sMAPE is:99.64% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 43.47% & 1.44\n",
      "for 2020-04-16, MAE is:12.09 & sMAPE is:95.15% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 43.96% & 1.44\n",
      "for 2020-04-17, MAE is:9.60 & sMAPE is:47.50% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 43.99% & 1.44\n",
      "for 2020-04-18, MAE is:3.82 & sMAPE is:19.49% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 43.76% & 1.43\n",
      "for 2020-04-19, MAE is:7.83 & sMAPE is:57.89% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 43.89% & 1.42\n",
      "for 2020-04-20, MAE is:9.75 & sMAPE is:71.06% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 44.14% & 1.42\n",
      "for 2020-04-21, MAE is:11.46 & sMAPE is:82.73% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 44.48% & 1.42\n",
      "for 2020-04-22, MAE is:6.86 & sMAPE is:54.19% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 44.57% & 1.42\n",
      "for 2020-04-23, MAE is:10.39 & sMAPE is:44.59% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 44.57% & 1.41\n",
      "for 2020-04-24, MAE is:6.02 & sMAPE is:30.52% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 44.44% & 1.40\n",
      "for 2020-04-25, MAE is:4.97 & sMAPE is:35.18% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 44.37% & 1.40\n",
      "for 2020-04-26, MAE is:6.23 & sMAPE is:38.15% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 44.31% & 1.40\n",
      "for 2020-04-27, MAE is:6.25 & sMAPE is:25.88% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 44.16% & 1.39\n",
      "for 2020-04-28, MAE is:3.45 & sMAPE is:15.06% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 43.91% & 1.38\n",
      "for 2020-04-29, MAE is:3.83 & sMAPE is:19.68% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 43.71% & 1.37\n",
      "for 2020-04-30, MAE is:4.76 & sMAPE is:28.05% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 43.58% & 1.36\n",
      "for 2020-05-01, MAE is:8.55 & sMAPE is:69.87% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 43.80% & 1.36\n",
      "for 2020-05-02, MAE is:6.01 & sMAPE is:52.14% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 43.86% & 1.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-03, MAE is:7.23 & sMAPE is:52.37% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 43.93% & 1.35\n",
      "for 2020-05-04, MAE is:7.26 & sMAPE is:42.18% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 43.92% & 1.35\n",
      "for 2020-05-05, MAE is:4.74 & sMAPE is:27.61% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 43.79% & 1.34\n",
      "for 2020-05-06, MAE is:8.80 & sMAPE is:61.92% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 43.93% & 1.34\n",
      "for 2020-05-07, MAE is:5.86 & sMAPE is:52.12% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 44.00% & 1.34\n",
      "for 2020-05-08, MAE is:7.40 & sMAPE is:70.03% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 44.20% & 1.33\n",
      "for 2020-05-09, MAE is:5.48 & sMAPE is:53.30% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 44.27% & 1.33\n",
      "for 2020-05-10, MAE is:7.22 & sMAPE is:63.16% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 44.41% & 1.34\n",
      "for 2020-05-11, MAE is:5.42 & sMAPE is:33.67% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 44.33% & 1.34\n",
      "for 2020-05-12, MAE is:8.98 & sMAPE is:58.90% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 44.44% & 1.34\n",
      "for 2020-05-13, MAE is:10.74 & sMAPE is:46.33% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 44.45% & 1.33\n",
      "for 2020-05-14, MAE is:6.82 & sMAPE is:34.12% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 44.38% & 1.33\n",
      "for 2020-05-15, MAE is:7.38 & sMAPE is:46.62% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 44.39% & 1.34\n",
      "for 2020-05-16, MAE is:5.46 & sMAPE is:45.22% & rMAE is:4.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 44.40% & 1.36\n",
      "for 2020-05-17, MAE is:5.09 & sMAPE is:44.15% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 44.40% & 1.36\n",
      "for 2020-05-18, MAE is:5.67 & sMAPE is:35.43% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 44.33% & 1.36\n",
      "for 2020-05-19, MAE is:4.54 & sMAPE is:26.24% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 44.20% & 1.35\n",
      "for 2020-05-20, MAE is:13.77 & sMAPE is:51.56% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 44.26% & 1.35\n",
      "for 2020-05-21, MAE is:2.86 & sMAPE is:18.61% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 44.08% & 1.35\n",
      "for 2020-05-22, MAE is:7.72 & sMAPE is:65.50% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 44.23% & 1.35\n",
      "for 2020-05-23, MAE is:8.47 & sMAPE is:93.54% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 44.57% & 1.35\n",
      "for 2020-05-24, MAE is:10.10 & sMAPE is:108.33% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 45.01% & 1.36\n",
      "for 2020-05-25, MAE is:3.15 & sMAPE is:27.09% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 44.88% & 1.35\n",
      "for 2020-05-26, MAE is:16.82 & sMAPE is:66.50% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 45.03% & 1.35\n",
      "for 2020-05-27, MAE is:10.35 & sMAPE is:56.60% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 45.11% & 1.35\n",
      "for 2020-05-28, MAE is:8.17 & sMAPE is:53.33% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 45.17% & 1.35\n",
      "for 2020-05-29, MAE is:4.59 & sMAPE is:33.55% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 45.09% & 1.34\n",
      "for 2020-05-30, MAE is:6.48 & sMAPE is:79.71% & rMAE is:4.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 45.32% & 1.36\n",
      "for 2020-05-31, MAE is:10.55 & sMAPE is:147.55% & rMAE is:3.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 45.99% & 1.38\n",
      "for 2020-06-01, MAE is:7.69 & sMAPE is:71.15% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 46.15% & 1.37\n",
      "for 2020-06-02, MAE is:11.35 & sMAPE is:44.84% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 46.15% & 1.37\n",
      "for 2020-06-03, MAE is:14.06 & sMAPE is:46.77% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 46.15% & 1.37\n",
      "for 2020-06-04, MAE is:5.49 & sMAPE is:21.39% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 45.99% & 1.37\n",
      "for 2020-06-05, MAE is:6.42 & sMAPE is:35.92% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 45.93% & 1.36\n",
      "for 2020-06-06, MAE is:14.74 & sMAPE is:134.40% & rMAE is:5.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 46.49% & 1.39\n",
      "for 2020-06-07, MAE is:7.12 & sMAPE is:76.89% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 46.68% & 1.39\n",
      "for 2020-06-08, MAE is:9.43 & sMAPE is:51.13% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 46.71% & 1.38\n",
      "for 2020-06-09, MAE is:11.59 & sMAPE is:51.15% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 46.73% & 1.38\n",
      "for 2020-06-10, MAE is:7.58 & sMAPE is:47.88% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 46.74% & 1.38\n",
      "for 2020-06-11, MAE is:16.59 & sMAPE is:132.08% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 47.26% & 1.37\n",
      "for 2020-06-12, MAE is:11.44 & sMAPE is:135.15% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 47.80% & 1.37\n",
      "for 2020-06-13, MAE is:9.42 & sMAPE is:133.08% & rMAE is:3.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 48.32% & 1.38\n",
      "for 2020-06-14, MAE is:9.99 & sMAPE is:115.65% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 48.72% & 1.38\n",
      "for 2020-06-15, MAE is:8.79 & sMAPE is:47.96% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 48.72% & 1.39\n",
      "for 2020-06-16, MAE is:6.94 & sMAPE is:36.72% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 48.65% & 1.38\n",
      "for 2020-06-17, MAE is:18.85 & sMAPE is:71.15% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 48.78% & 1.38\n",
      "for 2020-06-18, MAE is:13.37 & sMAPE is:44.10% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 48.75% & 1.38\n",
      "for 2020-06-19, MAE is:10.95 & sMAPE is:84.96% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 48.96% & 1.38\n",
      "for 2020-06-20, MAE is:5.97 & sMAPE is:58.26% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 49.02% & 1.38\n",
      "for 2020-06-21, MAE is:3.96 & sMAPE is:39.33% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 48.96% & 1.37\n",
      "for 2020-06-22, MAE is:13.36 & sMAPE is:42.51% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 48.92% & 1.37\n",
      "for 2020-06-23, MAE is:18.54 & sMAPE is:44.37% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 48.90% & 1.37\n",
      "for 2020-06-24, MAE is:5.58 & sMAPE is:13.94% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 48.70% & 1.36\n",
      "for 2020-06-25, MAE is:44.36 & sMAPE is:51.75% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 48.72% & 1.36\n",
      "for 2020-06-26, MAE is:7.62 & sMAPE is:16.27% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 48.53% & 1.35\n",
      "for 2020-06-27, MAE is:8.88 & sMAPE is:31.18% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 48.44% & 1.35\n",
      "for 2020-06-28, MAE is:6.52 & sMAPE is:27.05% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 48.32% & 1.34\n",
      "for 2020-06-29, MAE is:11.99 & sMAPE is:47.06% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 48.31% & 1.34\n",
      "for 2020-06-30, MAE is:17.23 & sMAPE is:90.19% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.12 & 48.54% & 1.34\n",
      "for 2020-07-01, MAE is:8.62 & sMAPE is:64.59% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 48.63% & 1.33\n",
      "for 2020-07-02, MAE is:7.36 & sMAPE is:23.81% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.12 & 48.50% & 1.33\n",
      "for 2020-07-03, MAE is:7.03 & sMAPE is:22.54% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.12 & 48.35% & 1.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-04, MAE is:23.23 & sMAPE is:162.18% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 48.97% & 1.32\n",
      "for 2020-07-05, MAE is:12.17 & sMAPE is:165.62% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 49.59% & 1.31\n",
      "for 2020-07-06, MAE is:13.69 & sMAPE is:159.48% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 50.18% & 1.31\n",
      "for 2020-07-07, MAE is:6.88 & sMAPE is:77.61% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 50.32% & 1.31\n",
      "for 2020-07-08, MAE is:12.09 & sMAPE is:47.87% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 50.31% & 1.31\n",
      "for 2020-07-09, MAE is:8.05 & sMAPE is:23.95% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 50.17% & 1.31\n",
      "for 2020-07-10, MAE is:7.93 & sMAPE is:35.16% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 50.09% & 1.31\n",
      "for 2020-07-11, MAE is:5.47 & sMAPE is:47.67% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 50.08% & 1.30\n",
      "for 2020-07-12, MAE is:6.21 & sMAPE is:40.08% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.23 & 50.03% & 1.30\n",
      "for 2020-07-13, MAE is:11.24 & sMAPE is:42.82% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 49.99% & 1.30\n",
      "for 2020-07-14, MAE is:8.36 & sMAPE is:27.61% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 49.88% & 1.29\n",
      "for 2020-07-15, MAE is:9.02 & sMAPE is:28.12% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 49.77% & 1.29\n",
      "for 2020-07-16, MAE is:9.18 & sMAPE is:27.05% & rMAE is:2.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 49.65% & 1.30\n",
      "for 2020-07-17, MAE is:6.01 & sMAPE is:19.10% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 49.50% & 1.30\n",
      "for 2020-07-18, MAE is:5.86 & sMAPE is:20.60% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.23 & 49.35% & 1.29\n",
      "for 2020-07-19, MAE is:5.30 & sMAPE is:28.95% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 49.25% & 1.29\n",
      "for 2020-07-20, MAE is:5.37 & sMAPE is:19.50% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.21 & 49.10% & 1.29\n",
      "for 2020-07-21, MAE is:11.53 & sMAPE is:59.11% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 49.15% & 1.29\n",
      "for 2020-07-22, MAE is:7.81 & sMAPE is:49.83% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 49.16% & 1.28\n",
      "for 2020-07-23, MAE is:8.28 & sMAPE is:40.88% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 49.12% & 1.28\n",
      "for 2020-07-24, MAE is:11.10 & sMAPE is:64.98% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.23 & 49.19% & 1.28\n",
      "for 2020-07-25, MAE is:5.39 & sMAPE is:29.84% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 49.10% & 1.28\n",
      "for 2020-07-26, MAE is:11.72 & sMAPE is:95.26% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 49.32% & 1.27\n",
      "for 2020-07-27, MAE is:5.16 & sMAPE is:35.32% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 49.25% & 1.27\n",
      "for 2020-07-28, MAE is:12.04 & sMAPE is:87.26% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 49.44% & 1.27\n",
      "for 2020-07-29, MAE is:19.27 & sMAPE is:165.14% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :8.29 & 49.98% & 1.27\n",
      "for 2020-07-30, MAE is:15.46 & sMAPE is:133.53% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 50.38% & 1.27\n",
      "for 2020-07-31, MAE is:16.01 & sMAPE is:82.04% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :8.36 & 50.53% & 1.27\n",
      "for 2020-08-01, MAE is:4.50 & sMAPE is:15.66% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.34 & 50.36% & 1.27\n",
      "for 2020-08-02, MAE is:7.11 & sMAPE is:35.08% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.34 & 50.29% & 1.26\n",
      "for 2020-08-03, MAE is:4.82 & sMAPE is:13.66% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 50.12% & 1.26\n",
      "for 2020-08-04, MAE is:3.11 & sMAPE is:9.02% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.30 & 49.93% & 1.25\n",
      "for 2020-08-05, MAE is:7.05 & sMAPE is:22.65% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.29 & 49.81% & 1.25\n",
      "for 2020-08-06, MAE is:7.13 & sMAPE is:21.97% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.29 & 49.68% & 1.25\n",
      "for 2020-08-07, MAE is:6.96 & sMAPE is:21.06% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 49.55% & 1.24\n",
      "for 2020-08-08, MAE is:6.16 & sMAPE is:20.49% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 49.42% & 1.24\n",
      "for 2020-08-09, MAE is:3.43 & sMAPE is:11.59% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 49.25% & 1.24\n",
      "for 2020-08-10, MAE is:7.83 & sMAPE is:20.17% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 49.12% & 1.24\n",
      "for 2020-08-11, MAE is:5.93 & sMAPE is:16.38% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 48.97% & 1.24\n",
      "for 2020-08-12, MAE is:13.70 & sMAPE is:32.04% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 48.90% & 1.24\n",
      "for 2020-08-13, MAE is:9.28 & sMAPE is:20.56% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 48.77% & 1.24\n",
      "for 2020-08-14, MAE is:3.85 & sMAPE is:8.89% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 48.60% & 1.23\n",
      "for 2020-08-15, MAE is:3.06 & sMAPE is:9.15% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 48.42% & 1.24\n",
      "for 2020-08-16, MAE is:3.73 & sMAPE is:12.71% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 48.27% & 1.24\n",
      "for 2020-08-17, MAE is:16.50 & sMAPE is:32.69% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 48.20% & 1.24\n",
      "for 2020-08-18, MAE is:28.88 & sMAPE is:35.69% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 48.15% & 1.24\n",
      "for 2020-08-19, MAE is:13.82 & sMAPE is:21.58% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 48.03% & 1.24\n",
      "for 2020-08-20, MAE is:11.99 & sMAPE is:23.01% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 47.92% & 1.24\n",
      "for 2020-08-21, MAE is:11.06 & sMAPE is:23.10% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 47.82% & 1.24\n",
      "for 2020-08-22, MAE is:11.44 & sMAPE is:40.41% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 47.79% & 1.24\n",
      "for 2020-08-23, MAE is:5.41 & sMAPE is:24.18% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 47.69% & 1.24\n",
      "for 2020-08-24, MAE is:12.28 & sMAPE is:28.06% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 47.60% & 1.24\n",
      "for 2020-08-25, MAE is:10.10 & sMAPE is:19.52% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 47.49% & 1.24\n",
      "for 2020-08-26, MAE is:6.34 & sMAPE is:17.15% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 47.36% & 1.23\n",
      "for 2020-08-27, MAE is:12.40 & sMAPE is:30.57% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 47.29% & 1.23\n",
      "for 2020-08-28, MAE is:9.75 & sMAPE is:21.14% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 47.18% & 1.23\n",
      "for 2020-08-29, MAE is:7.38 & sMAPE is:23.12% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 47.08% & 1.23\n",
      "for 2020-08-30, MAE is:3.17 & sMAPE is:9.55% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 46.93% & 1.22\n",
      "for 2020-08-31, MAE is:16.41 & sMAPE is:32.48% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 46.87% & 1.23\n",
      "for 2020-09-01, MAE is:3.39 & sMAPE is:6.53% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 46.70% & 1.23\n",
      "for 2020-09-02, MAE is:7.36 & sMAPE is:15.56% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 46.58% & 1.23\n",
      "for 2020-09-03, MAE is:6.47 & sMAPE is:15.57% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 46.45% & 1.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-04, MAE is:4.95 & sMAPE is:13.32% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 46.32% & 1.22\n",
      "for 2020-09-05, MAE is:3.89 & sMAPE is:11.78% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.36 & 46.18% & 1.22\n",
      "for 2020-09-06, MAE is:5.96 & sMAPE is:18.21% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 46.07% & 1.22\n",
      "for 2020-09-07, MAE is:7.30 & sMAPE is:19.38% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 45.96% & 1.22\n",
      "for 2020-09-08, MAE is:7.41 & sMAPE is:27.28% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.34 & 45.89% & 1.21\n",
      "for 2020-09-09, MAE is:9.83 & sMAPE is:32.63% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 45.83% & 1.21\n",
      "for 2020-09-10, MAE is:19.40 & sMAPE is:55.44% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 45.87% & 1.21\n",
      "for 2020-09-11, MAE is:7.84 & sMAPE is:18.99% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 45.77% & 1.21\n",
      "for 2020-09-12, MAE is:2.66 & sMAPE is:9.09% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 45.62% & 1.21\n",
      "for 2020-09-13, MAE is:7.39 & sMAPE is:33.22% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.36 & 45.57% & 1.21\n",
      "for 2020-09-14, MAE is:17.44 & sMAPE is:41.49% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 45.56% & 1.21\n",
      "for 2020-09-15, MAE is:18.65 & sMAPE is:26.44% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 45.48% & 1.21\n",
      "for 2020-09-16, MAE is:17.75 & sMAPE is:35.05% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 45.44% & 1.21\n",
      "for 2020-09-17, MAE is:11.18 & sMAPE is:33.54% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 45.40% & 1.21\n",
      "for 2020-09-18, MAE is:13.83 & sMAPE is:32.32% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 45.35% & 1.21\n",
      "for 2020-09-19, MAE is:7.38 & sMAPE is:23.37% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 45.27% & 1.21\n",
      "for 2020-09-20, MAE is:4.60 & sMAPE is:16.14% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 45.15% & 1.21\n",
      "for 2020-09-21, MAE is:10.87 & sMAPE is:46.15% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 45.16% & 1.21\n",
      "for 2020-09-22, MAE is:9.70 & sMAPE is:46.89% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 45.17% & 1.21\n",
      "for 2020-09-23, MAE is:5.68 & sMAPE is:20.62% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 45.07% & 1.20\n",
      "for 2020-09-24, MAE is:5.79 & sMAPE is:35.47% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 45.04% & 1.20\n",
      "for 2020-09-25, MAE is:8.91 & sMAPE is:41.31% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 45.02% & 1.20\n",
      "for 2020-09-26, MAE is:4.29 & sMAPE is:59.14% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 45.08% & 1.19\n",
      "for 2020-09-27, MAE is:3.90 & sMAPE is:55.93% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 45.12% & 1.19\n",
      "for 2020-09-28, MAE is:17.55 & sMAPE is:52.98% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 45.14% & 1.19\n",
      "for 2020-09-29, MAE is:14.85 & sMAPE is:27.11% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 45.08% & 1.19\n",
      "for 2020-09-30, MAE is:6.51 & sMAPE is:15.25% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 44.97% & 1.18\n",
      "for 2020-10-01, MAE is:7.62 & sMAPE is:25.24% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 44.90% & 1.18\n",
      "for 2020-10-02, MAE is:8.80 & sMAPE is:47.98% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 44.91% & 1.18\n",
      "for 2020-10-03, MAE is:3.49 & sMAPE is:50.49% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 44.93% & 1.18\n",
      "for 2020-10-04, MAE is:6.25 & sMAPE is:67.17% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 45.01% & 1.18\n",
      "for 2020-10-05, MAE is:4.69 & sMAPE is:22.93% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 44.93% & 1.18\n",
      "for 2020-10-06, MAE is:5.84 & sMAPE is:20.78% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 44.84% & 1.18\n",
      "for 2020-10-07, MAE is:9.78 & sMAPE is:38.17% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 44.82% & 1.18\n",
      "for 2020-10-08, MAE is:6.19 & sMAPE is:28.73% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 44.76% & 1.18\n",
      "for 2020-10-09, MAE is:14.94 & sMAPE is:57.13% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 44.81% & 1.18\n",
      "for 2020-10-10, MAE is:7.10 & sMAPE is:35.16% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 44.77% & 1.17\n",
      "for 2020-10-11, MAE is:11.67 & sMAPE is:48.10% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 44.78% & 1.17\n",
      "for 2020-10-12, MAE is:6.20 & sMAPE is:13.62% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 44.68% & 1.17\n",
      "for 2020-10-13, MAE is:11.94 & sMAPE is:25.48% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 44.61% & 1.17\n",
      "for 2020-10-14, MAE is:8.99 & sMAPE is:32.48% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 44.57% & 1.16\n",
      "for 2020-10-15, MAE is:13.51 & sMAPE is:43.39% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 44.56% & 1.16\n",
      "for 2020-10-16, MAE is:13.85 & sMAPE is:38.78% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 44.54% & 1.16\n",
      "for 2020-10-17, MAE is:9.88 & sMAPE is:31.99% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 44.50% & 1.16\n",
      "for 2020-10-18, MAE is:3.23 & sMAPE is:13.55% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 44.39% & 1.16\n",
      "for 2020-10-19, MAE is:8.63 & sMAPE is:26.18% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 44.33% & 1.16\n",
      "for 2020-10-20, MAE is:6.48 & sMAPE is:20.60% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 44.25% & 1.16\n",
      "for 2020-10-21, MAE is:8.47 & sMAPE is:28.38% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 44.20% & 1.16\n",
      "for 2020-10-22, MAE is:2.93 & sMAPE is:19.01% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 44.11% & 1.15\n",
      "for 2020-10-23, MAE is:18.10 & sMAPE is:54.22% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 44.15% & 1.16\n",
      "for 2020-10-24, MAE is:5.26 & sMAPE is:26.88% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 44.09% & 1.16\n",
      "for 2020-10-25, MAE is:7.69 & sMAPE is:50.07% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 44.11% & 1.15\n",
      "for 2020-10-26, MAE is:7.19 & sMAPE is:26.32% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 44.05% & 1.15\n",
      "for 2020-10-27, MAE is:13.37 & sMAPE is:55.74% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 44.09% & 1.15\n",
      "for 2020-10-28, MAE is:9.33 & sMAPE is:56.13% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 44.13% & 1.15\n",
      "for 2020-10-29, MAE is:12.66 & sMAPE is:46.27% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 44.13% & 1.15\n",
      "for 2020-10-30, MAE is:7.58 & sMAPE is:38.22% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 44.11% & 1.15\n",
      "for 2020-10-31, MAE is:5.99 & sMAPE is:43.77% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 44.11% & 1.15\n",
      "for 2020-11-01, MAE is:8.52 & sMAPE is:84.02% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 44.24% & 1.15\n",
      "for 2020-11-02, MAE is:10.84 & sMAPE is:131.93% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 44.53% & 1.14\n",
      "for 2020-11-03, MAE is:13.38 & sMAPE is:93.24% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 44.69% & 1.14\n",
      "for 2020-11-04, MAE is:20.68 & sMAPE is:128.11% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 44.96% & 1.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-05, MAE is:14.19 & sMAPE is:131.36% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 45.24% & 1.14\n",
      "for 2020-11-06, MAE is:17.31 & sMAPE is:67.10% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.62 & 45.31% & 1.15\n",
      "for 2020-11-07, MAE is:11.64 & sMAPE is:41.51% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 45.29% & 1.14\n",
      "for 2020-11-08, MAE is:13.28 & sMAPE is:58.05% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.65 & 45.34% & 1.14\n",
      "for 2020-11-09, MAE is:16.59 & sMAPE is:41.24% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.67 & 45.32% & 1.14\n",
      "for 2020-11-10, MAE is:14.07 & sMAPE is:19.14% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.69 & 45.24% & 1.14\n",
      "for 2020-11-11, MAE is:10.36 & sMAPE is:24.55% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.69 & 45.17% & 1.13\n",
      "for 2020-11-12, MAE is:14.49 & sMAPE is:45.50% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.71 & 45.17% & 1.13\n",
      "for 2020-11-13, MAE is:12.41 & sMAPE is:36.79% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 45.15% & 1.13\n",
      "for 2020-11-14, MAE is:8.96 & sMAPE is:21.45% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 45.07% & 1.13\n",
      "for 2020-11-15, MAE is:18.69 & sMAPE is:102.11% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 45.25% & 1.13\n",
      "for 2020-11-16, MAE is:9.58 & sMAPE is:63.07% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 45.31% & 1.13\n",
      "for 2020-11-17, MAE is:11.01 & sMAPE is:49.61% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 45.32% & 1.13\n",
      "for 2020-11-18, MAE is:14.40 & sMAPE is:81.76% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.78 & 45.43% & 1.12\n",
      "for 2020-11-19, MAE is:20.27 & sMAPE is:107.47% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 45.63% & 1.12\n",
      "for 2020-11-20, MAE is:24.89 & sMAPE is:51.03% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 45.64% & 1.12\n",
      "for 2020-11-21, MAE is:40.77 & sMAPE is:107.96% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.96 & 45.83% & 1.12\n",
      "for 2020-11-22, MAE is:20.37 & sMAPE is:155.58% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.00 & 46.17% & 1.12\n",
      "for 2020-11-23, MAE is:12.88 & sMAPE is:68.30% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.01 & 46.24% & 1.12\n",
      "for 2020-11-24, MAE is:11.91 & sMAPE is:59.33% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :9.02 & 46.28% & 1.12\n",
      "for 2020-11-25, MAE is:9.59 & sMAPE is:36.20% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.02 & 46.25% & 1.12\n",
      "for 2020-11-26, MAE is:25.37 & sMAPE is:65.38% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :9.07 & 46.30% & 1.12\n",
      "for 2020-11-27, MAE is:16.69 & sMAPE is:35.71% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :9.09 & 46.27% & 1.12\n",
      "for 2020-11-28, MAE is:4.46 & sMAPE is:9.10% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :9.08 & 46.16% & 1.12\n",
      "for 2020-11-29, MAE is:6.79 & sMAPE is:14.94% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :9.07 & 46.07% & 1.12\n",
      "for 2020-11-30, MAE is:37.49 & sMAPE is:40.32% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :9.16 & 46.05% & 1.11\n",
      "for 2020-12-01, MAE is:17.47 & sMAPE is:23.89% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :9.18 & 45.98% & 1.11\n",
      "for 2020-12-02, MAE is:11.80 & sMAPE is:18.33% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.19 & 45.90% & 1.11\n",
      "for 2020-12-03, MAE is:16.19 & sMAPE is:53.90% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :9.21 & 45.93% & 1.11\n",
      "for 2020-12-04, MAE is:9.84 & sMAPE is:28.90% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :9.21 & 45.87% & 1.11\n",
      "for 2020-12-05, MAE is:7.60 & sMAPE is:24.91% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :9.21 & 45.81% & 1.11\n",
      "for 2020-12-06, MAE is:6.98 & sMAPE is:27.28% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.20 & 45.76% & 1.10\n",
      "for 2020-12-07, MAE is:28.31 & sMAPE is:74.62% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.26 & 45.84% & 1.10\n",
      "for 2020-12-08, MAE is:25.41 & sMAPE is:56.96% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.31 & 45.88% & 1.10\n",
      "for 2020-12-09, MAE is:22.98 & sMAPE is:41.58% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 45.86% & 1.10\n",
      "for 2020-12-10, MAE is:17.13 & sMAPE is:30.14% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 45.82% & 1.10\n",
      "for 2020-12-11, MAE is:11.33 & sMAPE is:25.93% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 45.76% & 1.10\n",
      "for 2020-12-12, MAE is:15.35 & sMAPE is:42.74% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 45.75% & 1.10\n",
      "for 2020-12-13, MAE is:7.79 & sMAPE is:15.17% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 45.66% & 1.10\n",
      "for 2020-12-14, MAE is:34.56 & sMAPE is:53.41% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.46 & 45.69% & 1.10\n",
      "for 2020-12-15, MAE is:7.81 & sMAPE is:16.28% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 45.60% & 1.10\n",
      "for 2020-12-16, MAE is:9.10 & sMAPE is:25.55% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 45.54% & 1.10\n",
      "for 2020-12-17, MAE is:8.32 & sMAPE is:22.60% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 45.48% & 1.09\n",
      "for 2020-12-18, MAE is:9.26 & sMAPE is:26.74% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 45.43% & 1.09\n",
      "for 2020-12-19, MAE is:3.70 & sMAPE is:18.49% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :9.43 & 45.35% & 1.09\n",
      "for 2020-12-20, MAE is:4.62 & sMAPE is:23.12% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 45.29% & 1.09\n",
      "for 2020-12-21, MAE is:9.79 & sMAPE is:36.91% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 45.26% & 1.08\n",
      "for 2020-12-22, MAE is:5.45 & sMAPE is:24.71% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.41 & 45.21% & 1.08\n",
      "for 2020-12-23, MAE is:14.20 & sMAPE is:43.35% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 45.20% & 1.08\n",
      "for 2020-12-24, MAE is:7.87 & sMAPE is:40.61% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 45.19% & 1.08\n",
      "for 2020-12-25, MAE is:10.71 & sMAPE is:40.69% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 45.18% & 1.08\n",
      "for 2020-12-26, MAE is:5.29 & sMAPE is:28.28% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.41 & 45.13% & 1.08\n",
      "for 2020-12-27, MAE is:5.14 & sMAPE is:61.00% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :9.40 & 45.17% & 1.08\n",
      "for 2020-12-28, MAE is:16.28 & sMAPE is:60.63% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 45.22% & 1.08\n",
      "for 2020-12-29, MAE is:19.52 & sMAPE is:59.39% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 45.25% & 1.08\n",
      "for 2020-12-30, MAE is:14.40 & sMAPE is:37.54% & rMAE is:2.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.46 & 45.23% & 1.09\n",
      "for 2020-12-31, MAE is:15.52 & sMAPE is:41.64% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.47 & 45.22% & 1.09\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:03:57,872]\u001b[0m A new study created in RDB with name: SE_4_2021\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:04:17,090]\u001b[0m Trial 0 finished with value: 13.63002799594635 and parameters: {'n_hidden': 4, 'learning_rate': 0.01964219392381131, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2631298459593683, 'dropout_rate_Layer_2': 0.37217768275567337, 'dropout_rate_Layer_3': 0.23356429238410611, 'dropout_rate_Layer_4': 0.2895177235751562, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012792200211888852, 'l1_Layer_2': 0.012110013329057133, 'l1_Layer_3': 0.0032357461094841447, 'l1_Layer_4': 2.5278958822460455e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 235, 'n_units_Layer_3': 195, 'n_units_Layer_4': 195}. Best is trial 0 with value: 13.63002799594635.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.63 | sMAPE for Validation Set is: 60.30% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 39.88 | sMAPE for Test Set is: 50.38% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:04:47,335]\u001b[0m Trial 1 finished with value: 13.840489378657294 and parameters: {'n_hidden': 4, 'learning_rate': 0.06565668274609418, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04935183554893055, 'dropout_rate_Layer_2': 0.3489223544960258, 'dropout_rate_Layer_3': 0.3973398508480647, 'dropout_rate_Layer_4': 0.35895232416739825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.721154410662058e-05, 'l1_Layer_2': 0.011397007896641838, 'l1_Layer_3': 1.1482993363518403e-05, 'l1_Layer_4': 0.034348763313160335, 'n_units_Layer_1': 75, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270, 'n_units_Layer_4': 55}. Best is trial 0 with value: 13.63002799594635.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.84 | sMAPE for Validation Set is: 60.50% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 36.20 | sMAPE for Test Set is: 45.21% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:05:06,015]\u001b[0m Trial 2 finished with value: 14.518620283690007 and parameters: {'n_hidden': 3, 'learning_rate': 0.02043439289550321, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1669226097601424, 'dropout_rate_Layer_2': 0.2883681312389442, 'dropout_rate_Layer_3': 0.019627450864788412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019638194370642372, 'l1_Layer_2': 0.0009449992203604101, 'l1_Layer_3': 1.7508089836152578e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 150, 'n_units_Layer_3': 230}. Best is trial 0 with value: 13.63002799594635.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.52 | sMAPE for Validation Set is: 62.14% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 45.57 | sMAPE for Test Set is: 60.88% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:05:12,122]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:07:30,849]\u001b[0m Trial 4 finished with value: 9.639965176260516 and parameters: {'n_hidden': 4, 'learning_rate': 0.0044768196495760726, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01813082704135005, 'dropout_rate_Layer_2': 0.3956950463695265, 'dropout_rate_Layer_3': 0.2827276319967715, 'dropout_rate_Layer_4': 0.36034107667384696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017941955197833077, 'l1_Layer_2': 7.691587829351679e-05, 'l1_Layer_3': 0.0005540614709872965, 'l1_Layer_4': 5.644504058283056e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 280, 'n_units_Layer_3': 100, 'n_units_Layer_4': 230}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.64 | sMAPE for Validation Set is: 50.60% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 23.04 | sMAPE for Test Set is: 31.63% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:07:34,524]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:07:57,778]\u001b[0m Trial 6 finished with value: 12.926502934086622 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018587276846634376, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13438212346518613, 'dropout_rate_Layer_2': 0.34303608373935657, 'dropout_rate_Layer_3': 0.2869303017026118, 'dropout_rate_Layer_4': 0.07404787993368181, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032985313997028823, 'l1_Layer_2': 0.0006837745913772087, 'l1_Layer_3': 0.019025392329337712, 'l1_Layer_4': 3.733517467726048e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145, 'n_units_Layer_4': 60}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.93 | sMAPE for Validation Set is: 58.64% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 38.62 | sMAPE for Test Set is: 48.27% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:08:15,731]\u001b[0m Trial 7 finished with value: 13.196304717559778 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013878420558099073, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3750512572232201, 'dropout_rate_Layer_2': 0.0972247107702501, 'dropout_rate_Layer_3': 0.2871549569339343, 'dropout_rate_Layer_4': 0.11611594516575559, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00591468720976618, 'l1_Layer_2': 0.00258532431426045, 'l1_Layer_3': 3.943169225185429e-05, 'l1_Layer_4': 0.00443349752716847, 'n_units_Layer_1': 265, 'n_units_Layer_2': 170, 'n_units_Layer_3': 205, 'n_units_Layer_4': 215}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.20 | sMAPE for Validation Set is: 59.09% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 49.60 | sMAPE for Test Set is: 71.16% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:08:21,139]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:08:25,195]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:08:30,167]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:08:34,008]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:08:57,971]\u001b[0m Trial 12 finished with value: 10.845431154892195 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005803798669617899, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2712327827555407, 'dropout_rate_Layer_2': 0.10178962983560447, 'dropout_rate_Layer_3': 0.006047974741380413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.844131124922532e-05, 'l1_Layer_2': 4.019412803572293e-05, 'l1_Layer_3': 1.2034156181304909e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.85 | sMAPE for Validation Set is: 51.16% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 34.25 | sMAPE for Test Set is: 42.09% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:09:02,078]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:09:05,605]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:09:10,767]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:09:15,155]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:09:22,681]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:09:26,549]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:09:34,015]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:09:37,328]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:09:40,342]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:09:48,169]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:10:03,838]\u001b[0m Trial 23 finished with value: 11.71056829040761 and parameters: {'n_hidden': 4, 'learning_rate': 0.007526499878734503, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08297683443513844, 'dropout_rate_Layer_2': 0.3909294729347276, 'dropout_rate_Layer_3': 0.20095302093298115, 'dropout_rate_Layer_4': 0.2752280732307827, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3675207678956736e-05, 'l1_Layer_2': 0.00031391170104625116, 'l1_Layer_3': 9.838572463932424e-05, 'l1_Layer_4': 1.2110610199038055e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 130, 'n_units_Layer_4': 70}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.71 | sMAPE for Validation Set is: 54.74% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 38.02 | sMAPE for Test Set is: 47.69% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:10:17,792]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:10:21,242]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:10:50,940]\u001b[0m Trial 26 finished with value: 10.531006379398685 and parameters: {'n_hidden': 3, 'learning_rate': 0.06883697211605946, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.043271519703518106, 'dropout_rate_Layer_2': 0.14844636279864518, 'dropout_rate_Layer_3': 0.1515657827694628, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.850470479172522e-05, 'l1_Layer_2': 0.011397449662476956, 'l1_Layer_3': 2.312548179405708e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 90, 'n_units_Layer_3': 180}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.53 | sMAPE for Validation Set is: 49.33% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 25.98 | sMAPE for Test Set is: 33.65% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:10:53,953]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:10:57,536]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:11:00,845]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:11:04,478]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:11:14,638]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:11:20,050]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:11:25,130]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:11:30,405]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:11:35,644]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:11:39,314]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:11:53,221]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:11:57,160]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:12:00,941]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:12:11,890]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:12:15,849]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:12:22,797]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:12:46,259]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:12:49,469]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:12:54,803]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:13:06,189]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:13:09,685]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:13:23,541]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:13:42,304]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:13:47,343]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:14:10,812]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:14:16,784]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:14:21,569]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:14:25,788]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:14:35,072]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:14:42,345]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:14:46,525]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:14:50,697]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:14:56,156]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:14:59,928]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:15:06,138]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:15:10,785]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:15:15,495]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:15:24,758]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:15:33,213]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:15:37,039]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:15:42,293]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:15:50,590]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:16:00,830]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:16:25,754]\u001b[0m Trial 70 finished with value: 9.87410164970389 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011161343791676228, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2181212731682113, 'dropout_rate_Layer_2': 0.27990635476851694, 'dropout_rate_Layer_3': 0.15320478836802667, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03750612144388683, 'l1_Layer_2': 1.83239653721051e-05, 'l1_Layer_3': 6.493671377200548e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 80}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.87 | sMAPE for Validation Set is: 46.24% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 28.80 | sMAPE for Test Set is: 36.01% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:16:40,336]\u001b[0m Trial 71 finished with value: 10.896556145208459 and parameters: {'n_hidden': 4, 'learning_rate': 0.003951053175536406, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16802480196275918, 'dropout_rate_Layer_2': 0.29707734933411234, 'dropout_rate_Layer_3': 0.26891662780516856, 'dropout_rate_Layer_4': 0.006119084963472007, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00043009206110710183, 'l1_Layer_2': 0.0007650794500576776, 'l1_Layer_3': 0.0005530958595508232, 'l1_Layer_4': 2.0331961048521565e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 110, 'n_units_Layer_3': 210, 'n_units_Layer_4': 165}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.90 | sMAPE for Validation Set is: 51.91% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 35.17 | sMAPE for Test Set is: 43.19% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:16:45,689]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:16:59,424]\u001b[0m Trial 73 finished with value: 11.138368697786289 and parameters: {'n_hidden': 4, 'learning_rate': 0.0041407012476504905, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17179727428940866, 'dropout_rate_Layer_2': 0.37885612850617356, 'dropout_rate_Layer_3': 0.29195012141376625, 'dropout_rate_Layer_4': 0.1360179734900069, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004626243864582254, 'l1_Layer_2': 0.0007776424218142476, 'l1_Layer_3': 0.0004972749473250978, 'l1_Layer_4': 4.233439368776947e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 110, 'n_units_Layer_3': 210, 'n_units_Layer_4': 160}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.14 | sMAPE for Validation Set is: 53.02% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 36.80 | sMAPE for Test Set is: 45.63% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:17:12,202]\u001b[0m Trial 74 finished with value: 11.017662562699703 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020733743622753493, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16883415896278242, 'dropout_rate_Layer_2': 0.3778725635211675, 'dropout_rate_Layer_3': 0.2962241035475525, 'dropout_rate_Layer_4': 0.05952730439523133, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001746265159317824, 'l1_Layer_2': 0.001069608706604113, 'l1_Layer_3': 0.0004508152833911286, 'l1_Layer_4': 2.9863219992802894e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 65, 'n_units_Layer_3': 255, 'n_units_Layer_4': 210}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.02 | sMAPE for Validation Set is: 51.81% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 39.92 | sMAPE for Test Set is: 50.94% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:17:21,776]\u001b[0m Trial 75 finished with value: 10.949258478026536 and parameters: {'n_hidden': 4, 'learning_rate': 0.002096239530586517, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17281846298051773, 'dropout_rate_Layer_2': 0.37896095584072936, 'dropout_rate_Layer_3': 0.29267964515014483, 'dropout_rate_Layer_4': 0.05918640334845785, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003826238544026873, 'l1_Layer_2': 0.0011214762358681407, 'l1_Layer_3': 0.0005804947414983031, 'l1_Layer_4': 2.4525117295646316e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 65, 'n_units_Layer_3': 285, 'n_units_Layer_4': 205}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.95 | sMAPE for Validation Set is: 51.73% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 37.26 | sMAPE for Test Set is: 46.45% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:17:28,144]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:17:38,203]\u001b[0m Trial 77 finished with value: 10.97697450784809 and parameters: {'n_hidden': 4, 'learning_rate': 0.002095477673499901, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17444256137886732, 'dropout_rate_Layer_2': 0.3782116588633903, 'dropout_rate_Layer_3': 0.29455180885031007, 'dropout_rate_Layer_4': 0.05058462898005466, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003784298129036155, 'l1_Layer_2': 0.0011848738735028479, 'l1_Layer_3': 0.0004938719490761221, 'l1_Layer_4': 2.2209341451478817e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280, 'n_units_Layer_4': 200}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.98 | sMAPE for Validation Set is: 51.29% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 40.78 | sMAPE for Test Set is: 52.41% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:17:58,777]\u001b[0m Trial 78 finished with value: 10.650190394931961 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005401225203629836, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31427180727876924, 'dropout_rate_Layer_2': 0.2761172186011129, 'dropout_rate_Layer_3': 0.1064636589684177, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09906835406012841, 'l1_Layer_2': 0.00014904637563860207, 'l1_Layer_3': 1.5013969667802697e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 60, 'n_units_Layer_3': 55}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.65 | sMAPE for Validation Set is: 50.43% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 35.23 | sMAPE for Test Set is: 43.43% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:18:10,263]\u001b[0m Trial 79 finished with value: 10.766800720242294 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021375194752688187, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1785540672307719, 'dropout_rate_Layer_2': 0.37739218452081125, 'dropout_rate_Layer_3': 0.29625862813699716, 'dropout_rate_Layer_4': 0.048825076510564336, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000414244528515678, 'l1_Layer_2': 0.0010352192650436888, 'l1_Layer_3': 0.00048740099997754194, 'l1_Layer_4': 3.513903342821531e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 65, 'n_units_Layer_3': 285, 'n_units_Layer_4': 200}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.77 | sMAPE for Validation Set is: 50.93% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 37.17 | sMAPE for Test Set is: 46.39% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:19:01,789]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:19:04,675]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:19:07,943]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:19:14,864]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:19:23,910]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:19:34,547]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:19:40,531]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:19:45,402]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:19:53,930]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:20:05,383]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:20:12,074]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:20:22,326]\u001b[0m Trial 91 finished with value: 10.797822568808426 and parameters: {'n_hidden': 4, 'learning_rate': 0.002958104868913475, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16372414101108076, 'dropout_rate_Layer_2': 0.3983387327443296, 'dropout_rate_Layer_3': 0.28026292016074433, 'dropout_rate_Layer_4': 0.06925489641731593, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00024054107256150085, 'l1_Layer_2': 0.0013624042051645691, 'l1_Layer_3': 0.0006586088394253862, 'l1_Layer_4': 4.202357127234489e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 75, 'n_units_Layer_3': 290, 'n_units_Layer_4': 245}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.80 | sMAPE for Validation Set is: 50.95% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 38.77 | sMAPE for Test Set is: 49.00% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:20:40,423]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:20:43,833]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:20:55,661]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:21:35,928]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:21:42,701]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:21:55,697]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:22:32,479]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:22:38,675]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:22:41,732]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:23:13,668]\u001b[0m Trial 101 finished with value: 10.214422550708358 and parameters: {'n_hidden': 3, 'learning_rate': 0.04794159133542291, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2654699814838338, 'dropout_rate_Layer_2': 0.14720850085983447, 'dropout_rate_Layer_3': 0.18872985414126536, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021671783439397812, 'l1_Layer_2': 0.015120342062050617, 'l1_Layer_3': 1.2581637724914011e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 80, 'n_units_Layer_3': 240}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.21 | sMAPE for Validation Set is: 48.59% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 30.85 | sMAPE for Test Set is: 39.23% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:23:24,256]\u001b[0m Trial 102 finished with value: 10.982384768338145 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028958191667968493, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22311706984934476, 'dropout_rate_Layer_2': 0.3468569441784299, 'dropout_rate_Layer_3': 0.24519501070586514, 'dropout_rate_Layer_4': 0.0877354607520609, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011664575650968937, 'l1_Layer_2': 0.0025301558536480976, 'l1_Layer_3': 0.001079347006060907, 'l1_Layer_4': 3.357192443999592e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 75, 'n_units_Layer_3': 270, 'n_units_Layer_4': 230}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.98 | sMAPE for Validation Set is: 51.95% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 39.24 | sMAPE for Test Set is: 49.70% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:23:32,720]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:23:38,321]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:23:45,895]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:24:08,477]\u001b[0m Trial 106 finished with value: 11.958329018581324 and parameters: {'n_hidden': 3, 'learning_rate': 0.001956715550999614, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026580210570496157, 'dropout_rate_Layer_2': 0.23617633806991073, 'dropout_rate_Layer_3': 0.021274589229272858, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001492240490454531, 'l1_Layer_2': 0.0036852442947803918, 'l1_Layer_3': 0.024424471388343628, 'n_units_Layer_1': 160, 'n_units_Layer_2': 75, 'n_units_Layer_3': 300}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.96 | sMAPE for Validation Set is: 55.30% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 39.35 | sMAPE for Test Set is: 49.57% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:24:14,318]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:24:20,787]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:24:36,008]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:24:45,479]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:24:48,453]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:24:51,557]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:25:03,853]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:25:07,961]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:25:11,304]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:25:19,551]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:25:22,238]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:25:34,481]\u001b[0m Trial 118 finished with value: 11.01553120989432 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027172501083253748, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20413421300882512, 'dropout_rate_Layer_2': 0.3848125616468214, 'dropout_rate_Layer_3': 0.28210814950884466, 'dropout_rate_Layer_4': 0.063450907691155, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00034822246428625834, 'l1_Layer_2': 0.0025349776708724022, 'l1_Layer_3': 0.0010333469486502802, 'l1_Layer_4': 6.033503832865101e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 90, 'n_units_Layer_3': 290, 'n_units_Layer_4': 170}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.02 | sMAPE for Validation Set is: 52.03% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 39.10 | sMAPE for Test Set is: 49.44% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:25:37,948]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:25:42,853]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:25:46,324]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:25:54,642]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:26:03,818]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:26:13,661]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:26:16,609]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:26:26,972]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:26:31,088]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:26:36,647]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:26:48,558]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:26:54,230]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:27:03,966]\u001b[0m Trial 131 finished with value: 10.929356713144449 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024995810025371123, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1747231886894976, 'dropout_rate_Layer_2': 0.389106526698405, 'dropout_rate_Layer_3': 0.28561226159604053, 'dropout_rate_Layer_4': 0.06220033419901392, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012786246355898998, 'l1_Layer_2': 0.0006475441851971504, 'l1_Layer_3': 0.000323971781825912, 'l1_Layer_4': 2.8587513314794868e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 55, 'n_units_Layer_3': 280, 'n_units_Layer_4': 200}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.93 | sMAPE for Validation Set is: 51.59% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 38.85 | sMAPE for Test Set is: 48.87% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:27:17,131]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:27:32,480]\u001b[0m Trial 133 finished with value: 11.6653665213244 and parameters: {'n_hidden': 4, 'learning_rate': 0.011407013678403176, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02923555264023811, 'dropout_rate_Layer_2': 0.37051052061103756, 'dropout_rate_Layer_3': 0.39994863990513546, 'dropout_rate_Layer_4': 0.33346247021984643, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006414073738920234, 'l1_Layer_2': 4.275803152965886e-05, 'l1_Layer_3': 0.0011530307327639745, 'l1_Layer_4': 5.1818234051175784e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 145, 'n_units_Layer_3': 175, 'n_units_Layer_4': 215}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.67 | sMAPE for Validation Set is: 53.88% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 30.30 | sMAPE for Test Set is: 42.48% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:27:36,115]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:27:39,346]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:27:44,650]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:27:47,787]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:27:51,681]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:27:59,928]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:28:03,223]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:28:06,375]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:28:10,005]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:28:13,922]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:28:21,225]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:28:34,413]\u001b[0m Trial 145 finished with value: 11.04332636770321 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024113110182137332, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16096124819485796, 'dropout_rate_Layer_2': 0.3752647567990094, 'dropout_rate_Layer_3': 0.30450044501693735, 'dropout_rate_Layer_4': 0.04853386718026959, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003020058717004422, 'l1_Layer_2': 0.0013072881903196552, 'l1_Layer_3': 0.0003502813876139624, 'l1_Layer_4': 3.113133458377105e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275, 'n_units_Layer_4': 235}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.04 | sMAPE for Validation Set is: 51.71% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 41.38 | sMAPE for Test Set is: 53.36% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:28:37,935]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:28:41,640]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:28:56,107]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:30:12,330]\u001b[0m Trial 149 finished with value: 12.133799993529182 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023199956225725435, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33944146602718656, 'dropout_rate_Layer_2': 0.14456098561627226, 'dropout_rate_Layer_3': 0.07351756808370516, 'dropout_rate_Layer_4': 0.04062918635694546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.011223275853191751, 'l1_Layer_2': 0.00048693073308826555, 'l1_Layer_3': 0.006103488630333343, 'l1_Layer_4': 0.0005249185363587004, 'n_units_Layer_1': 240, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300, 'n_units_Layer_4': 65}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.13 | sMAPE for Validation Set is: 55.93% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 35.80 | sMAPE for Test Set is: 44.03% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:30:22,717]\u001b[0m Trial 150 finished with value: 11.11956948763813 and parameters: {'n_hidden': 4, 'learning_rate': 0.002679975205063415, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1528511896946109, 'dropout_rate_Layer_2': 0.3876877541332838, 'dropout_rate_Layer_3': 0.25017750102917186, 'dropout_rate_Layer_4': 0.0665980704383983, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011765421649179598, 'l1_Layer_2': 0.000957836653639004, 'l1_Layer_3': 0.0012966774045800064, 'l1_Layer_4': 4.944877828174511e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 65, 'n_units_Layer_3': 295, 'n_units_Layer_4': 205}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.12 | sMAPE for Validation Set is: 52.21% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 40.74 | sMAPE for Test Set is: 52.14% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:30:35,971]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:30:39,484]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:30:42,246]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:30:45,693]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:30:58,101]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:31:19,573]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:31:26,581]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:31:31,740]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:31:34,990]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:31:39,400]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:31:48,480]\u001b[0m Trial 161 finished with value: 11.010888376541454 and parameters: {'n_hidden': 4, 'learning_rate': 0.002474967406472445, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1626730029429195, 'dropout_rate_Layer_2': 0.3695844283081125, 'dropout_rate_Layer_3': 0.3064728364570034, 'dropout_rate_Layer_4': 0.04743098134529528, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000267269317168116, 'l1_Layer_2': 0.0012315248753491117, 'l1_Layer_3': 0.0003600223738857644, 'l1_Layer_4': 3.405803510187838e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275, 'n_units_Layer_4': 235}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.01 | sMAPE for Validation Set is: 52.02% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 38.70 | sMAPE for Test Set is: 48.67% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:31:52,834]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:31:58,379]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:32:04,453]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:32:09,335]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:32:14,547]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:32:24,196]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:32:29,476]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:32:36,438]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:32:47,778]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:32:50,959]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:33:01,551]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:33:13,031]\u001b[0m Trial 173 finished with value: 11.464542441901612 and parameters: {'n_hidden': 4, 'learning_rate': 0.012949239428034637, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.039166836666475156, 'dropout_rate_Layer_2': 0.34205517693319126, 'dropout_rate_Layer_3': 0.37749463273439815, 'dropout_rate_Layer_4': 0.3456785877602132, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002991321851091518, 'l1_Layer_2': 0.00015889438218988637, 'l1_Layer_3': 0.0012040498612473282, 'l1_Layer_4': 0.00020298235061233839, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 195, 'n_units_Layer_4': 235}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.46 | sMAPE for Validation Set is: 53.62% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 28.18 | sMAPE for Test Set is: 38.41% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:33:25,926]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:33:41,836]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:33:45,320]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:33:49,183]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:33:52,254]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:33:56,836]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:34:01,250]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:34:05,101]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:34:08,270]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:34:17,062]\u001b[0m Trial 183 finished with value: 11.01482787629024 and parameters: {'n_hidden': 4, 'learning_rate': 0.002501339011197547, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15998046589528675, 'dropout_rate_Layer_2': 0.3729165049857027, 'dropout_rate_Layer_3': 0.30653028836727214, 'dropout_rate_Layer_4': 0.04884134008166608, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003400828687960076, 'l1_Layer_2': 0.0012555107097708676, 'l1_Layer_3': 0.000473003660783596, 'l1_Layer_4': 3.3529891171779834e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275, 'n_units_Layer_4': 250}. Best is trial 4 with value: 9.639965176260516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.01 | sMAPE for Validation Set is: 51.83% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 39.00 | sMAPE for Test Set is: 49.31% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:34:26,828]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:34:45,174]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:35:01,931]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:35:39,915]\u001b[0m Trial 187 finished with value: 9.549393378623185 and parameters: {'n_hidden': 3, 'learning_rate': 0.005356905518109891, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011512973499562207, 'dropout_rate_Layer_2': 0.19537738410800504, 'dropout_rate_Layer_3': 0.018034154752680966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018996569703474275, 'l1_Layer_2': 0.0008417378082943408, 'l1_Layer_3': 1.377441490699e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 195, 'n_units_Layer_3': 260}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.55 | sMAPE for Validation Set is: 46.77% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 31.44 | sMAPE for Test Set is: 38.21% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:35:49,912]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:35:52,867]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:36:01,985]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:36:04,754]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:36:07,505]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:36:13,451]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:36:18,799]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:36:22,498]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:36:28,442]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:36:31,860]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:36:35,794]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:36:38,789]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:36:47,083]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:37:33,461]\u001b[0m Trial 201 finished with value: 10.494264155366185 and parameters: {'n_hidden': 3, 'learning_rate': 0.006592023242138459, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2704694439734503, 'dropout_rate_Layer_2': 0.15817006090236188, 'dropout_rate_Layer_3': 0.07192160089623308, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001070699934707587, 'l1_Layer_2': 0.0008132266927402858, 'l1_Layer_3': 1.0943189329187192e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.49 | sMAPE for Validation Set is: 49.96% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 35.73 | sMAPE for Test Set is: 43.79% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:37:46,971]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:37:51,680]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:38:02,325]\u001b[0m Trial 204 finished with value: 11.038219320284844 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021836312103103227, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18759273262751963, 'dropout_rate_Layer_2': 0.3772277572583941, 'dropout_rate_Layer_3': 0.3053923253941635, 'dropout_rate_Layer_4': 0.05070144277138406, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00031626484049130206, 'l1_Layer_2': 0.0012521555541517538, 'l1_Layer_3': 0.000361481725815856, 'l1_Layer_4': 2.981788279371775e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275, 'n_units_Layer_4': 235}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.04 | sMAPE for Validation Set is: 51.87% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 39.92 | sMAPE for Test Set is: 50.72% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:38:07,767]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:38:17,652]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:38:21,898]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:38:25,259]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:38:28,996]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:38:32,766]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:38:36,360]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:38:39,357]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:38:45,556]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:38:56,010]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:39:08,149]\u001b[0m Trial 215 finished with value: 11.453997263846402 and parameters: {'n_hidden': 4, 'learning_rate': 0.01800738153400142, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04209673067680249, 'dropout_rate_Layer_2': 0.36194217404508894, 'dropout_rate_Layer_3': 0.3680020290877911, 'dropout_rate_Layer_4': 0.3190993463837382, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00033220535093642046, 'l1_Layer_2': 0.0005644036999840968, 'l1_Layer_3': 0.0012100134197035814, 'l1_Layer_4': 0.0001329835447287239, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 150, 'n_units_Layer_4': 160}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.45 | sMAPE for Validation Set is: 53.55% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 30.83 | sMAPE for Test Set is: 43.13% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:39:20,047]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:39:25,315]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:39:36,979]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:39:50,748]\u001b[0m Trial 219 finished with value: 11.093329198637159 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022884419081784955, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15984458461205728, 'dropout_rate_Layer_2': 0.3906975858394853, 'dropout_rate_Layer_3': 0.3055492649666209, 'dropout_rate_Layer_4': 0.0463072722441744, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002796481377910554, 'l1_Layer_2': 0.0013816491216427226, 'l1_Layer_3': 0.0003442498410024229, 'l1_Layer_4': 3.070848485940444e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275, 'n_units_Layer_4': 235}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.09 | sMAPE for Validation Set is: 52.08% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 39.59 | sMAPE for Test Set is: 50.23% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:39:53,887]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:39:59,198]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:40:06,595]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:40:15,864]\u001b[0m Trial 223 finished with value: 10.862657502793335 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021423121489806533, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1516000462931359, 'dropout_rate_Layer_2': 0.3769436165579535, 'dropout_rate_Layer_3': 0.24539835683784225, 'dropout_rate_Layer_4': 0.05509225647468507, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013048982098159688, 'l1_Layer_2': 0.001000386182173569, 'l1_Layer_3': 0.0008302172356401411, 'l1_Layer_4': 1.5994876867165917e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 260, 'n_units_Layer_4': 215}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.86 | sMAPE for Validation Set is: 51.02% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 39.98 | sMAPE for Test Set is: 50.80% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:40:19,395]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:40:23,676]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:40:43,620]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:41:13,573]\u001b[0m Trial 227 finished with value: 11.605044187897319 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005895241269975852, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31302328496652154, 'dropout_rate_Layer_2': 0.2526746107803242, 'dropout_rate_Layer_3': 0.10150059214076834, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08479723878780926, 'l1_Layer_2': 0.003701475742602877, 'l1_Layer_3': 1.0024762885726732e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 50, 'n_units_Layer_3': 55}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.61 | sMAPE for Validation Set is: 54.56% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 34.86 | sMAPE for Test Set is: 42.88% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:41:24,450]\u001b[0m Trial 228 finished with value: 10.846983814553852 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026266540925527953, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11745058985091186, 'dropout_rate_Layer_2': 0.3480953084291286, 'dropout_rate_Layer_3': 0.2523075806208057, 'dropout_rate_Layer_4': 0.041988217278454504, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011934171565107008, 'l1_Layer_2': 0.0007058573976029121, 'l1_Layer_3': 0.0006393638504681935, 'l1_Layer_4': 1.7032314541301007e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 85, 'n_units_Layer_3': 250, 'n_units_Layer_4': 195}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.85 | sMAPE for Validation Set is: 51.35% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 38.51 | sMAPE for Test Set is: 48.41% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:41:42,308]\u001b[0m Trial 229 finished with value: 10.600147431053934 and parameters: {'n_hidden': 3, 'learning_rate': 0.000874518708660331, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2662798867389524, 'dropout_rate_Layer_2': 0.2933099721598097, 'dropout_rate_Layer_3': 0.11512442185087662, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.050481197435033896, 'l1_Layer_2': 0.00022888475130236486, 'l1_Layer_3': 2.010080320403781e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.60 | sMAPE for Validation Set is: 49.86% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 34.60 | sMAPE for Test Set is: 42.62% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:42:01,265]\u001b[0m Trial 230 finished with value: 10.861784398177207 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012951628856419169, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2569504268831997, 'dropout_rate_Layer_2': 0.30693586691123675, 'dropout_rate_Layer_3': 0.21086200389365217, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.051488280437678884, 'l1_Layer_2': 0.00032092438622284753, 'l1_Layer_3': 3.607849230112556e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 75, 'n_units_Layer_3': 65}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.86 | sMAPE for Validation Set is: 51.47% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 33.14 | sMAPE for Test Set is: 40.76% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:42:04,848]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:42:10,505]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:42:13,643]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:42:18,791]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:42:25,122]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:42:31,315]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:43:19,965]\u001b[0m Trial 237 finished with value: 10.677271523006338 and parameters: {'n_hidden': 3, 'learning_rate': 0.007879856157761718, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1731048791117628, 'dropout_rate_Layer_2': 0.1747878957570063, 'dropout_rate_Layer_3': 0.07604079571789513, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001186441835719891, 'l1_Layer_2': 0.0006406255879902671, 'l1_Layer_3': 4.933316408544156e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 130, 'n_units_Layer_3': 235}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.68 | sMAPE for Validation Set is: 51.27% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 35.29 | sMAPE for Test Set is: 43.10% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:43:57,590]\u001b[0m Trial 238 finished with value: 10.110240724202983 and parameters: {'n_hidden': 3, 'learning_rate': 0.006895356496466426, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0824109149729018, 'dropout_rate_Layer_2': 0.19299149532697785, 'dropout_rate_Layer_3': 0.07230206880454108, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009751503109246227, 'l1_Layer_2': 0.0017451245569381883, 'l1_Layer_3': 4.630899637775233e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 200}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.11 | sMAPE for Validation Set is: 48.18% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 34.95 | sMAPE for Test Set is: 42.53% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:44:03,743]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:44:08,743]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:44:11,965]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:44:15,716]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:44:25,233]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:44:30,906]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:44:52,874]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:44:58,164]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:45:03,274]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:45:06,806]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:45:19,336]\u001b[0m Trial 249 finished with value: 10.772969530379209 and parameters: {'n_hidden': 4, 'learning_rate': 0.002291197231147088, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12041304072349825, 'dropout_rate_Layer_2': 0.3816606945383559, 'dropout_rate_Layer_3': 0.251953561065464, 'dropout_rate_Layer_4': 0.0763784931514642, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002407000040444065, 'l1_Layer_2': 0.0012439320779944335, 'l1_Layer_3': 0.0007575332209521819, 'l1_Layer_4': 2.783068227200492e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260, 'n_units_Layer_4': 155}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.77 | sMAPE for Validation Set is: 51.19% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 37.25 | sMAPE for Test Set is: 46.47% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:45:32,526]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:45:35,632]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:45:47,286]\u001b[0m Trial 252 finished with value: 11.27796878840598 and parameters: {'n_hidden': 4, 'learning_rate': 0.007591621359251085, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047509914714168655, 'dropout_rate_Layer_2': 0.3860948493877752, 'dropout_rate_Layer_3': 0.36456402862922427, 'dropout_rate_Layer_4': 0.32729991094726224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005142714192011947, 'l1_Layer_2': 0.0002095848348301514, 'l1_Layer_3': 0.0015578123768469157, 'l1_Layer_4': 0.00014448869349088154, 'n_units_Layer_1': 100, 'n_units_Layer_2': 155, 'n_units_Layer_3': 185, 'n_units_Layer_4': 150}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.28 | sMAPE for Validation Set is: 52.71% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 27.95 | sMAPE for Test Set is: 37.60% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:45:50,262]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:45:53,876]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:45:57,491]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:46:03,204]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:46:06,597]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:46:09,920]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:46:16,052]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:46:31,798]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:46:34,665]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:46:49,901]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:46:54,941]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:46:59,423]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:47:08,628]\u001b[0m Trial 265 finished with value: 15.278424643283657 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031713072417899235, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10915019937802162, 'dropout_rate_Layer_2': 0.29659941832853826, 'dropout_rate_Layer_3': 0.02846701815673014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005578769976707552, 'l1_Layer_2': 0.0013993673251486965, 'l1_Layer_3': 3.513475582567217e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.28 | sMAPE for Validation Set is: 65.54% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 59.37 | sMAPE for Test Set is: 93.55% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:47:28,498]\u001b[0m Trial 266 finished with value: 15.48597120565735 and parameters: {'n_hidden': 4, 'learning_rate': 0.010082844024599682, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04650583132853883, 'dropout_rate_Layer_2': 0.23284611741264966, 'dropout_rate_Layer_3': 0.09979960086195014, 'dropout_rate_Layer_4': 0.39182068049202323, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.004222496389515987, 'l1_Layer_2': 7.978997947710402e-05, 'l1_Layer_3': 0.0004519741684828922, 'l1_Layer_4': 0.002086139103541717, 'n_units_Layer_1': 140, 'n_units_Layer_2': 230, 'n_units_Layer_3': 265, 'n_units_Layer_4': 50}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.49 | sMAPE for Validation Set is: 65.50% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 57.39 | sMAPE for Test Set is: 87.97% | rMAE for Test Set is: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:47:32,243]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:47:51,833]\u001b[0m Trial 268 finished with value: 12.083580284428576 and parameters: {'n_hidden': 4, 'learning_rate': 0.007864189174799788, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04728286965047755, 'dropout_rate_Layer_2': 0.3624096350827167, 'dropout_rate_Layer_3': 0.3654740022605291, 'dropout_rate_Layer_4': 0.35462385664229185, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004951404668852052, 'l1_Layer_2': 0.0011823630319915818, 'l1_Layer_3': 0.00026904582945561745, 'l1_Layer_4': 5.7806235732583995e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 145, 'n_units_Layer_3': 190, 'n_units_Layer_4': 140}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.08 | sMAPE for Validation Set is: 55.88% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 28.78 | sMAPE for Test Set is: 38.44% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:47:55,041]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:48:15,131]\u001b[0m Trial 270 finished with value: 11.957490260001123 and parameters: {'n_hidden': 4, 'learning_rate': 0.0104671058310605, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04857701613752647, 'dropout_rate_Layer_2': 0.36049684816235567, 'dropout_rate_Layer_3': 0.36346752214095934, 'dropout_rate_Layer_4': 0.3201217476881783, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004521348003317165, 'l1_Layer_2': 0.0012872599173857698, 'l1_Layer_3': 0.0006450804920854864, 'l1_Layer_4': 4.7491641104497204e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 190, 'n_units_Layer_4': 140}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.96 | sMAPE for Validation Set is: 55.47% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 31.00 | sMAPE for Test Set is: 40.78% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:48:26,592]\u001b[0m Trial 271 finished with value: 11.47107723505716 and parameters: {'n_hidden': 4, 'learning_rate': 0.007658313322751489, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047970271842770654, 'dropout_rate_Layer_2': 0.35856070807512364, 'dropout_rate_Layer_3': 0.36563486694087155, 'dropout_rate_Layer_4': 0.35733087083549303, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005099896442563811, 'l1_Layer_2': 0.0012761322040079222, 'l1_Layer_3': 0.0002990984619669352, 'l1_Layer_4': 5.199820969088662e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 145, 'n_units_Layer_3': 190, 'n_units_Layer_4': 140}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.47 | sMAPE for Validation Set is: 53.83% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 27.12 | sMAPE for Test Set is: 36.73% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:48:35,402]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:48:42,283]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:48:47,850]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:48:51,668]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:49:11,829]\u001b[0m Trial 276 finished with value: 12.0607003528007 and parameters: {'n_hidden': 4, 'learning_rate': 0.00988952133595666, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07831668953019869, 'dropout_rate_Layer_2': 0.38818340492977144, 'dropout_rate_Layer_3': 0.3831312683120114, 'dropout_rate_Layer_4': 0.318615898607394, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005657250583611101, 'l1_Layer_2': 0.0004558700187988083, 'l1_Layer_3': 0.0006606415014160477, 'l1_Layer_4': 9.642417472528248e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 150, 'n_units_Layer_3': 180, 'n_units_Layer_4': 145}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.06 | sMAPE for Validation Set is: 55.93% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 28.55 | sMAPE for Test Set is: 38.07% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:49:15,045]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:49:18,690]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:49:24,070]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:49:29,658]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:49:32,991]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:49:36,248]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:49:39,999]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:49:43,304]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:49:57,800]\u001b[0m Trial 285 finished with value: 11.475427321068315 and parameters: {'n_hidden': 4, 'learning_rate': 0.005413888602378256, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06284091936636182, 'dropout_rate_Layer_2': 0.3344411357337348, 'dropout_rate_Layer_3': 0.3536493226070045, 'dropout_rate_Layer_4': 0.3364569537358814, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00038529848536301135, 'l1_Layer_2': 0.001411635203202414, 'l1_Layer_3': 0.0004111654808525609, 'l1_Layer_4': 4.3330066978428365e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 200, 'n_units_Layer_4': 130}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.48 | sMAPE for Validation Set is: 53.69% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 25.97 | sMAPE for Test Set is: 35.14% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:50:01,193]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:50:04,856]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:50:08,588]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:50:34,386]\u001b[0m Trial 289 finished with value: 10.717204207453113 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005705588497493162, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30695093697543646, 'dropout_rate_Layer_2': 0.3179539021267794, 'dropout_rate_Layer_3': 0.10870362691867683, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09192757864608293, 'l1_Layer_2': 0.00016862669209405056, 'l1_Layer_3': 1.184499985682164e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 50, 'n_units_Layer_3': 60}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.72 | sMAPE for Validation Set is: 50.69% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 35.24 | sMAPE for Test Set is: 43.48% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:50:37,586]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:50:41,920]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:50:45,620]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:50:49,834]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:51:43,172]\u001b[0m Trial 294 finished with value: 9.552729902141689 and parameters: {'n_hidden': 3, 'learning_rate': 0.004685742362469113, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005601145273271, 'dropout_rate_Layer_2': 0.16543596374727382, 'dropout_rate_Layer_3': 0.052336447763079275, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007224618298085209, 'l1_Layer_2': 0.0010802491863949341, 'l1_Layer_3': 1.0178045478628189e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 190, 'n_units_Layer_3': 220}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.55 | sMAPE for Validation Set is: 47.09% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 32.30 | sMAPE for Test Set is: 39.11% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:52:08,617]\u001b[0m Trial 295 finished with value: 10.657378289413984 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005158996136092684, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32902661100305686, 'dropout_rate_Layer_2': 0.34948953203234534, 'dropout_rate_Layer_3': 0.16448838955025863, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04105604803133536, 'l1_Layer_2': 0.0006269331586635167, 'l1_Layer_3': 1.667131880691138e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 65, 'n_units_Layer_3': 50}. Best is trial 187 with value: 9.549393378623185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.66 | sMAPE for Validation Set is: 50.58% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 33.83 | sMAPE for Test Set is: 41.53% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:52:13,257]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:53:04,668]\u001b[0m Trial 297 finished with value: 9.24353501239001 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041791737368406506, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004975432708486327, 'dropout_rate_Layer_2': 0.17551709135946816, 'dropout_rate_Layer_3': 0.040004316320770894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005211832414061692, 'l1_Layer_2': 0.0020714451005045707, 'l1_Layer_3': 2.452480987372301e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 195, 'n_units_Layer_3': 210}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.24 | sMAPE for Validation Set is: 47.16% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 28.72 | sMAPE for Test Set is: 36.39% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:53:19,190]\u001b[0m Trial 298 finished with value: 10.971680031380615 and parameters: {'n_hidden': 4, 'learning_rate': 0.00348251402438203, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018673530952880227, 'dropout_rate_Layer_2': 0.32145510951669853, 'dropout_rate_Layer_3': 0.3280369982678761, 'dropout_rate_Layer_4': 0.38223928933374596, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006666168746767929, 'l1_Layer_2': 0.0016747664799995337, 'l1_Layer_3': 0.00031753156892699007, 'l1_Layer_4': 0.00015464140170804951, 'n_units_Layer_1': 100, 'n_units_Layer_2': 130, 'n_units_Layer_3': 210, 'n_units_Layer_4': 125}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.97 | sMAPE for Validation Set is: 51.87% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 25.71 | sMAPE for Test Set is: 33.99% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:53:22,611]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:53:32,653]\u001b[0m Trial 300 finished with value: 10.845767886886579 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022467916316362127, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16636193437087649, 'dropout_rate_Layer_2': 0.36669665467621504, 'dropout_rate_Layer_3': 0.30738940740671417, 'dropout_rate_Layer_4': 0.02772761698643586, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00016686571064051698, 'l1_Layer_2': 0.0007937704010448552, 'l1_Layer_3': 0.0009430443437671061, 'l1_Layer_4': 2.1324473710585313e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 60, 'n_units_Layer_3': 285, 'n_units_Layer_4': 225}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.85 | sMAPE for Validation Set is: 51.13% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 38.36 | sMAPE for Test Set is: 48.15% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:53:38,000]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:53:56,549]\u001b[0m Trial 302 finished with value: 11.779203443646765 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032977120947796, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009657898310934927, 'dropout_rate_Layer_2': 0.3265238409071409, 'dropout_rate_Layer_3': 0.3237255028770921, 'dropout_rate_Layer_4': 0.3809821630689205, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003936352330524182, 'l1_Layer_2': 0.0015031789161095237, 'l1_Layer_3': 0.0003188815754301388, 'l1_Layer_4': 0.00016094737851080025, 'n_units_Layer_1': 105, 'n_units_Layer_2': 125, 'n_units_Layer_3': 200, 'n_units_Layer_4': 130}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.78 | sMAPE for Validation Set is: 54.82% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 29.08 | sMAPE for Test Set is: 39.39% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:53:59,932]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:54:03,396]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:54:06,577]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:54:11,923]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:54:15,285]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:54:27,667]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:54:31,772]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:54:45,820]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:54:51,238]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:54:54,916]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:55:00,817]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:55:11,868]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:55:29,513]\u001b[0m Trial 315 finished with value: 11.562755690537456 and parameters: {'n_hidden': 4, 'learning_rate': 0.003215144225128598, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03942796312873963, 'dropout_rate_Layer_2': 0.35539117198111225, 'dropout_rate_Layer_3': 0.31208462438295403, 'dropout_rate_Layer_4': 0.363688155097361, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002514793991162765, 'l1_Layer_2': 0.0005630941276940241, 'l1_Layer_3': 0.0008500782921135779, 'l1_Layer_4': 0.00014895998574633668, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 165, 'n_units_Layer_4': 155}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.56 | sMAPE for Validation Set is: 54.16% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 25.90 | sMAPE for Test Set is: 34.49% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:55:33,348]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:55:51,850]\u001b[0m Trial 317 finished with value: 11.037580618402309 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028471074085381315, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0565453540700693, 'dropout_rate_Layer_2': 0.3537106422510221, 'dropout_rate_Layer_3': 0.31150488035275475, 'dropout_rate_Layer_4': 0.36593832387582803, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00025836848858840154, 'l1_Layer_2': 0.0005854566064333206, 'l1_Layer_3': 0.0005254223418388306, 'l1_Layer_4': 0.00014382173822836213, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 165, 'n_units_Layer_4': 155}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.04 | sMAPE for Validation Set is: 52.34% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 25.82 | sMAPE for Test Set is: 34.53% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:55:55,420]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:56:21,332]\u001b[0m Trial 319 finished with value: 10.451572759368403 and parameters: {'n_hidden': 4, 'learning_rate': 0.004353267456923112, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07417725156478036, 'dropout_rate_Layer_2': 0.39195534720192804, 'dropout_rate_Layer_3': 0.32856394367220254, 'dropout_rate_Layer_4': 0.37538117723112624, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017099474717643652, 'l1_Layer_2': 0.00037451179480240147, 'l1_Layer_3': 0.0005179107954666773, 'l1_Layer_4': 0.0003053916819960132, 'n_units_Layer_1': 135, 'n_units_Layer_2': 170, 'n_units_Layer_3': 225, 'n_units_Layer_4': 165}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.45 | sMAPE for Validation Set is: 49.99% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 25.87 | sMAPE for Test Set is: 34.29% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:56:47,997]\u001b[0m Trial 320 finished with value: 9.60336390182791 and parameters: {'n_hidden': 3, 'learning_rate': 0.0043837755855722135, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005957261852233965, 'dropout_rate_Layer_2': 0.15825650986634995, 'dropout_rate_Layer_3': 0.0419373759808976, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046949694522338477, 'l1_Layer_2': 0.00037014568315625173, 'l1_Layer_3': 2.2522975445025347e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 215, 'n_units_Layer_3': 225}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.60 | sMAPE for Validation Set is: 46.56% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 33.86 | sMAPE for Test Set is: 41.13% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:57:09,139]\u001b[0m Trial 321 finished with value: 10.41510689144347 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025507524543552256, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08034745985951885, 'dropout_rate_Layer_2': 0.39434575357895024, 'dropout_rate_Layer_3': 0.2904208504270976, 'dropout_rate_Layer_4': 0.3943314768020439, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001719237709644455, 'l1_Layer_2': 0.0003519622341247217, 'l1_Layer_3': 0.0002965741998083158, 'l1_Layer_4': 0.00034246439448355146, 'n_units_Layer_1': 140, 'n_units_Layer_2': 165, 'n_units_Layer_3': 240, 'n_units_Layer_4': 160}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.42 | sMAPE for Validation Set is: 49.71% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 23.92 | sMAPE for Test Set is: 31.90% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:57:12,212]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:57:15,764]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:57:18,796]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:57:39,308]\u001b[0m Trial 325 finished with value: 11.126223128782785 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023182753329418363, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08333424051100122, 'dropout_rate_Layer_2': 0.39063573982996974, 'dropout_rate_Layer_3': 0.2891724329546437, 'dropout_rate_Layer_4': 0.397103172346457, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00016103266016138224, 'l1_Layer_2': 0.0003408663303474042, 'l1_Layer_3': 0.000519471249994237, 'l1_Layer_4': 0.0003898469861643838, 'n_units_Layer_1': 160, 'n_units_Layer_2': 170, 'n_units_Layer_3': 225, 'n_units_Layer_4': 155}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.13 | sMAPE for Validation Set is: 53.01% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 35.04 | sMAPE for Test Set is: 43.04% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:57:53,942]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:57:57,091]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:58:00,023]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:58:18,824]\u001b[0m Trial 329 finished with value: 11.09206278839926 and parameters: {'n_hidden': 4, 'learning_rate': 0.002349683169998553, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07935121000039325, 'dropout_rate_Layer_2': 0.39033911603230736, 'dropout_rate_Layer_3': 0.2884392666948203, 'dropout_rate_Layer_4': 0.39578634462887485, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017733116183676477, 'l1_Layer_2': 0.00035670628849203103, 'l1_Layer_3': 0.0005728525178409561, 'l1_Layer_4': 0.00038355253887520873, 'n_units_Layer_1': 160, 'n_units_Layer_2': 170, 'n_units_Layer_3': 240, 'n_units_Layer_4': 165}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.09 | sMAPE for Validation Set is: 52.91% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 35.40 | sMAPE for Test Set is: 43.58% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:58:37,526]\u001b[0m Trial 330 finished with value: 10.205308465050013 and parameters: {'n_hidden': 3, 'learning_rate': 0.001209756954037865, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29117226859088613, 'dropout_rate_Layer_2': 0.2523592413980504, 'dropout_rate_Layer_3': 0.08513151849859883, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02545048181851606, 'l1_Layer_2': 0.0001344833351732842, 'l1_Layer_3': 9.33185503890007e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 60, 'n_units_Layer_3': 75}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.21 | sMAPE for Validation Set is: 47.36% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 29.84 | sMAPE for Test Set is: 36.94% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:58:52,153]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:59:07,895]\u001b[0m Trial 332 finished with value: 10.661605006769618 and parameters: {'n_hidden': 3, 'learning_rate': 0.00228778401742666, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0848096972247038, 'dropout_rate_Layer_2': 0.3907057091624292, 'dropout_rate_Layer_3': 0.28714092984680306, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001768120994941253, 'l1_Layer_2': 0.0003682473288711556, 'l1_Layer_3': 0.0005638640260103074, 'n_units_Layer_1': 155, 'n_units_Layer_2': 170, 'n_units_Layer_3': 230}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.66 | sMAPE for Validation Set is: 50.92% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 36.93 | sMAPE for Test Set is: 45.73% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:59:20,940]\u001b[0m Trial 333 finished with value: 10.92467057914787 and parameters: {'n_hidden': 3, 'learning_rate': 0.002284002655939374, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09014416952496589, 'dropout_rate_Layer_2': 0.39660082076451175, 'dropout_rate_Layer_3': 0.29231624272768525, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015849442700743933, 'l1_Layer_2': 0.00032515675220023277, 'l1_Layer_3': 0.0005682822052300413, 'n_units_Layer_1': 160, 'n_units_Layer_2': 170, 'n_units_Layer_3': 245}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.92 | sMAPE for Validation Set is: 52.21% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 36.62 | sMAPE for Test Set is: 45.31% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 00:59:24,303]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:59:35,392]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 00:59:57,716]\u001b[0m Trial 336 finished with value: 10.696004240333536 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016922239543803743, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07666314940561879, 'dropout_rate_Layer_2': 0.3998131586240549, 'dropout_rate_Layer_3': 0.26896989327765736, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016110474417499804, 'l1_Layer_2': 0.00027387173475584733, 'l1_Layer_3': 0.0005478043626296237, 'n_units_Layer_1': 165, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.70 | sMAPE for Validation Set is: 51.65% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 34.90 | sMAPE for Test Set is: 42.69% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:00:01,710]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:00:05,494]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:00:30,703]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:00:46,181]\u001b[0m Trial 340 finished with value: 10.585763040217627 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018828428569492718, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0718318438584989, 'dropout_rate_Layer_2': 0.39870242417650986, 'dropout_rate_Layer_3': 0.27389504845719864, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011008637396428002, 'l1_Layer_2': 0.0002703995551910722, 'l1_Layer_3': 0.0003558040628799479, 'n_units_Layer_1': 165, 'n_units_Layer_2': 185, 'n_units_Layer_3': 265}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.59 | sMAPE for Validation Set is: 51.09% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 34.26 | sMAPE for Test Set is: 41.89% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:00:57,629]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:01:14,882]\u001b[0m Trial 342 finished with value: 10.49731124208941 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016905979107664506, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07128090244755149, 'dropout_rate_Layer_2': 0.3989219765173535, 'dropout_rate_Layer_3': 0.30234599222283415, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011621248410338415, 'l1_Layer_2': 0.00029389264421144566, 'l1_Layer_3': 0.00024948880617540467, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 260}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.50 | sMAPE for Validation Set is: 50.51% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 35.22 | sMAPE for Test Set is: 43.29% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:01:20,147]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:01:24,447]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:01:43,092]\u001b[0m Trial 345 finished with value: 10.446723440908789 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017032695850417135, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07240437902357036, 'dropout_rate_Layer_2': 0.39924835194009656, 'dropout_rate_Layer_3': 0.3004439844606862, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011755632842464548, 'l1_Layer_2': 0.0003077584514614501, 'l1_Layer_3': 0.00019281612736889698, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.45 | sMAPE for Validation Set is: 50.65% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 34.24 | sMAPE for Test Set is: 41.80% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:01:48,383]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:01:52,150]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:01:55,326]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:02:04,302]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:03:12,826]\u001b[0m Trial 350 finished with value: 9.64324443627948 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033346833234916343, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.001922077599264127, 'dropout_rate_Layer_2': 0.13845073494537932, 'dropout_rate_Layer_3': 0.00932546448839716, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003407261776579476, 'l1_Layer_2': 0.003008205982300905, 'l1_Layer_3': 1.0596308486027472e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.64 | sMAPE for Validation Set is: 46.57% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 31.50 | sMAPE for Test Set is: 37.95% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:03:16,202]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:03:21,836]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:03:36,489]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:03:39,495]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:03:44,867]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:03:48,045]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:03:53,466]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:04:03,528]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:04:06,827]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:04:39,960]\u001b[0m Trial 360 finished with value: 10.68069794436794 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018084731622891462, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07312181245436958, 'dropout_rate_Layer_2': 0.39955596591083437, 'dropout_rate_Layer_3': 0.30054643686084465, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011858415507579266, 'l1_Layer_2': 0.000297715296466544, 'l1_Layer_3': 0.00019210680830270436, 'n_units_Layer_1': 180, 'n_units_Layer_2': 185, 'n_units_Layer_3': 275}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.68 | sMAPE for Validation Set is: 51.64% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 35.28 | sMAPE for Test Set is: 43.16% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:04:43,116]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:04:46,367]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:04:50,744]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:04:53,963]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:05:09,248]\u001b[0m Trial 365 finished with value: 10.849754026363376 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018134556218802587, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07345593515515786, 'dropout_rate_Layer_2': 0.3982151293115248, 'dropout_rate_Layer_3': 0.2748278658689304, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011632891531579576, 'l1_Layer_2': 0.00019436248537143156, 'l1_Layer_3': 0.00016529975330828784, 'n_units_Layer_1': 180, 'n_units_Layer_2': 200, 'n_units_Layer_3': 280}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.85 | sMAPE for Validation Set is: 52.05% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 37.35 | sMAPE for Test Set is: 46.26% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:05:29,906]\u001b[0m Trial 366 finished with value: 10.530523811856574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014479514130853585, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11185224990886342, 'dropout_rate_Layer_2': 0.37650624250241355, 'dropout_rate_Layer_3': 0.3032046786991006, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.107178999312727e-05, 'l1_Layer_2': 0.0002435109644121739, 'l1_Layer_3': 0.00022193939421335872, 'n_units_Layer_1': 170, 'n_units_Layer_2': 185, 'n_units_Layer_3': 275}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.53 | sMAPE for Validation Set is: 50.95% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 34.61 | sMAPE for Test Set is: 42.44% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:05:37,017]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:05:43,307]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:06:09,138]\u001b[0m Trial 369 finished with value: 10.734532886175723 and parameters: {'n_hidden': 3, 'learning_rate': 0.001432917155386688, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10723851745195781, 'dropout_rate_Layer_2': 0.3770293023670052, 'dropout_rate_Layer_3': 0.3052037168468736, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.086278683939006e-05, 'l1_Layer_2': 0.0002542863196014271, 'l1_Layer_3': 0.0002440197171540553, 'n_units_Layer_1': 175, 'n_units_Layer_2': 185, 'n_units_Layer_3': 270}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.73 | sMAPE for Validation Set is: 51.79% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 36.89 | sMAPE for Test Set is: 45.59% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:06:12,734]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:06:23,907]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:06:54,945]\u001b[0m Trial 372 finished with value: 10.46709623342105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015580707286292268, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09610525076943036, 'dropout_rate_Layer_2': 0.38053128323603896, 'dropout_rate_Layer_3': 0.2537396853730236, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.284239451459518e-05, 'l1_Layer_2': 0.0004454396279699366, 'l1_Layer_3': 0.00018750143837948293, 'n_units_Layer_1': 170, 'n_units_Layer_2': 185, 'n_units_Layer_3': 260}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.47 | sMAPE for Validation Set is: 50.77% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 35.48 | sMAPE for Test Set is: 43.45% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:07:04,386]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:07:08,116]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:07:21,640]\u001b[0m Trial 375 finished with value: 10.783833391190461 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013062176112111688, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10101759422351374, 'dropout_rate_Layer_2': 0.37984870392151626, 'dropout_rate_Layer_3': 0.251365831924404, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.069196734157836e-05, 'l1_Layer_2': 0.00019503443459754327, 'l1_Layer_3': 0.00014435680535858911, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.78 | sMAPE for Validation Set is: 51.58% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 35.47 | sMAPE for Test Set is: 43.66% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:07:25,773]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:07:42,830]\u001b[0m Trial 377 finished with value: 10.45400674784748 and parameters: {'n_hidden': 3, 'learning_rate': 0.000795489118037407, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2992207450007115, 'dropout_rate_Layer_2': 0.2673486323329378, 'dropout_rate_Layer_3': 0.11198611778728938, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06732077798142509, 'l1_Layer_2': 0.00015326749350266807, 'l1_Layer_3': 1.4223641857625415e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 60, 'n_units_Layer_3': 75}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.45 | sMAPE for Validation Set is: 49.23% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 34.64 | sMAPE for Test Set is: 42.60% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:07:46,499]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:07:50,277]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:07:53,279]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:08:04,542]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:08:32,433]\u001b[0m Trial 382 finished with value: 9.60959796417584 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034849123442607923, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04778146808596834, 'dropout_rate_Layer_2': 0.22576365006818325, 'dropout_rate_Layer_3': 0.10381558203043942, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012113679038658156, 'l1_Layer_2': 0.0009755126922419827, 'l1_Layer_3': 8.254794973202174e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 150, 'n_units_Layer_3': 220}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.61 | sMAPE for Validation Set is: 46.37% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 34.48 | sMAPE for Test Set is: 42.00% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:08:35,634]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:08:40,450]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:08:50,672]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:08:55,031]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:08:57,650]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:09:02,551]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:09:12,968]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:09:34,541]\u001b[0m Trial 390 finished with value: 10.34782228747893 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015623247094805226, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10922203834842395, 'dropout_rate_Layer_2': 0.39970470654966156, 'dropout_rate_Layer_3': 0.31595066009827094, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010542548802975287, 'l1_Layer_2': 0.00012402641874918193, 'l1_Layer_3': 0.0002661139703777422, 'n_units_Layer_1': 180, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.35 | sMAPE for Validation Set is: 50.04% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 36.49 | sMAPE for Test Set is: 45.08% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:09:37,873]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:09:43,346]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:09:46,394]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:09:50,553]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:09:55,491]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:09:59,654]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:10:19,895]\u001b[0m Trial 397 finished with value: 10.328115181236656 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010609221500130388, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.126468072926691, 'dropout_rate_Layer_2': 0.3711232461559253, 'dropout_rate_Layer_3': 0.31794296286884416, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.122880643167438e-05, 'l1_Layer_2': 0.00011000510332009255, 'l1_Layer_3': 0.0002791139770582827, 'n_units_Layer_1': 150, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.33 | sMAPE for Validation Set is: 50.31% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 33.59 | sMAPE for Test Set is: 41.14% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:10:42,549]\u001b[0m Trial 398 finished with value: 10.35780341121369 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010045784724091015, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12651196649703922, 'dropout_rate_Layer_2': 0.3675487104986688, 'dropout_rate_Layer_3': 0.31544937584566235, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4392426756573316e-05, 'l1_Layer_2': 0.0001409553482375802, 'l1_Layer_3': 0.0002536325420215066, 'n_units_Layer_1': 150, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.36 | sMAPE for Validation Set is: 50.44% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 33.53 | sMAPE for Test Set is: 41.06% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:10:45,997]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:11:18,754]\u001b[0m Trial 400 finished with value: 9.930208247713642 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007589473431212808, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28740017643440713, 'dropout_rate_Layer_2': 0.2938237894546487, 'dropout_rate_Layer_3': 0.15944459245665082, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.033969109896072325, 'l1_Layer_2': 7.651167923066953e-05, 'l1_Layer_3': 1.362302521274092e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 85, 'n_units_Layer_3': 90}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.93 | sMAPE for Validation Set is: 45.74% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 28.82 | sMAPE for Test Set is: 36.13% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:11:22,403]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:11:25,974]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:11:29,156]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:11:53,542]\u001b[0m Trial 404 finished with value: 10.447715532033667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009698764201541725, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11919300912642147, 'dropout_rate_Layer_2': 0.36671698936583563, 'dropout_rate_Layer_3': 0.31315570004188503, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.928006676169989e-05, 'l1_Layer_2': 0.0001089918617508791, 'l1_Layer_3': 0.0002756241557569849, 'n_units_Layer_1': 150, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.45 | sMAPE for Validation Set is: 50.85% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 33.72 | sMAPE for Test Set is: 41.32% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:11:57,666]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:12:22,881]\u001b[0m Trial 406 finished with value: 9.993122570183624 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006920776808845304, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29057728077054557, 'dropout_rate_Layer_2': 0.2251247480102273, 'dropout_rate_Layer_3': 0.1691995236635888, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.034762469286846155, 'l1_Layer_2': 3.288396369105148e-05, 'l1_Layer_3': 1.4380757959912688e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 110, 'n_units_Layer_3': 95}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.99 | sMAPE for Validation Set is: 45.92% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 26.52 | sMAPE for Test Set is: 34.10% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:12:26,277]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:12:38,000]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:12:51,834]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:13:06,006]\u001b[0m Trial 410 finished with value: 10.768725774117721 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010398446480431782, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12483950379091788, 'dropout_rate_Layer_2': 0.36656294518462773, 'dropout_rate_Layer_3': 0.3155439765749399, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.8651069634713157e-05, 'l1_Layer_2': 0.0001350789286756125, 'l1_Layer_3': 0.0002666127088103404, 'n_units_Layer_1': 150, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.77 | sMAPE for Validation Set is: 51.47% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 33.92 | sMAPE for Test Set is: 41.79% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:13:11,473]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:13:15,850]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:13:18,890]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:13:22,705]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:13:47,039]\u001b[0m Trial 415 finished with value: 10.400189520367453 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008903397583962437, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1390774921977564, 'dropout_rate_Layer_2': 0.3791914376955179, 'dropout_rate_Layer_3': 0.32310989771886156, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.162098247569145e-05, 'l1_Layer_2': 0.00011552405353252306, 'l1_Layer_3': 0.00012786160577904867, 'n_units_Layer_1': 135, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.40 | sMAPE for Validation Set is: 50.62% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 32.81 | sMAPE for Test Set is: 40.11% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:13:51,285]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:13:56,352]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:14:00,046]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:14:10,514]\u001b[0m Trial 419 finished with value: 10.762965308059224 and parameters: {'n_hidden': 4, 'learning_rate': 0.002456150808824973, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2977045537232832, 'dropout_rate_Layer_2': 0.3162341759734567, 'dropout_rate_Layer_3': 0.2196175069227696, 'dropout_rate_Layer_4': 0.04709257384409651, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.675109132120612e-05, 'l1_Layer_2': 0.0005747065356840268, 'l1_Layer_3': 1.7984183209350396e-05, 'l1_Layer_4': 3.384000339427051e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 75, 'n_units_Layer_3': 270, 'n_units_Layer_4': 185}. Best is trial 297 with value: 9.24353501239001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.76 | sMAPE for Validation Set is: 50.82% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 39.15 | sMAPE for Test Set is: 49.57% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:14:13,438]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:14:59,378]\u001b[0m Trial 421 finished with value: 9.139173880978769 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006491315222229987, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28584980127873816, 'dropout_rate_Layer_2': 0.2674771448733952, 'dropout_rate_Layer_3': 0.13875316793989262, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03516300961455028, 'l1_Layer_2': 3.682634383204224e-05, 'l1_Layer_3': 3.166376248258749e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 145, 'n_units_Layer_3': 125}. Best is trial 421 with value: 9.139173880978769.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.14 | sMAPE for Validation Set is: 43.07% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 27.87 | sMAPE for Test Set is: 34.44% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:15:05,185]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:15:10,402]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:15:26,586]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:15:31,147]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:15:58,953]\u001b[0m Trial 426 finished with value: 9.13564150246336 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015564988355523494, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11622834159262177, 'dropout_rate_Layer_2': 0.3532102279286282, 'dropout_rate_Layer_3': 0.3318154815299189, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.927784243207318e-05, 'l1_Layer_2': 0.00015176871796936318, 'l1_Layer_3': 0.0001656986581797747, 'n_units_Layer_1': 205, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 426 with value: 9.13564150246336.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.14 | sMAPE for Validation Set is: 43.96% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 37.46 | sMAPE for Test Set is: 46.34% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:16:04,905]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:16:10,403]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:16:24,723]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:16:34,723]\u001b[0m Trial 430 finished with value: 10.896342687292462 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022145548179497935, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24085098881648281, 'dropout_rate_Layer_2': 0.31385636317922605, 'dropout_rate_Layer_3': 0.19173197612341078, 'dropout_rate_Layer_4': 0.07348824060436725, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003675599566903002, 'l1_Layer_2': 1.3283054220815417e-05, 'l1_Layer_3': 1.1084216194689944e-05, 'l1_Layer_4': 3.4480965479874314e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 75, 'n_units_Layer_3': 285, 'n_units_Layer_4': 190}. Best is trial 426 with value: 9.13564150246336.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.90 | sMAPE for Validation Set is: 51.26% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 39.92 | sMAPE for Test Set is: 50.88% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:17:18,181]\u001b[0m Trial 431 finished with value: 8.908739900226008 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006161895130959558, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2504283787148115, 'dropout_rate_Layer_2': 0.2799279079223045, 'dropout_rate_Layer_3': 0.1774026838369559, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03439117965294426, 'l1_Layer_2': 1.5244319725868051e-05, 'l1_Layer_3': 3.401079494425123e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 145, 'n_units_Layer_3': 130}. Best is trial 431 with value: 8.908739900226008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.91 | sMAPE for Validation Set is: 42.12% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 28.67 | sMAPE for Test Set is: 35.05% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:17:45,247]\u001b[0m Trial 432 finished with value: 9.32691685566663 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005531573667514271, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13827344782579715, 'dropout_rate_Layer_2': 0.35003398501563365, 'dropout_rate_Layer_3': 0.3308245700868534, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.4217474259887154e-05, 'l1_Layer_2': 0.0001499785731809439, 'l1_Layer_3': 0.00016657396841098594, 'n_units_Layer_1': 190, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 431 with value: 8.908739900226008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.33 | sMAPE for Validation Set is: 45.00% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 36.05 | sMAPE for Test Set is: 44.26% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:17:48,920]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:18:09,433]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:18:34,812]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:18:38,177]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:18:41,718]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:18:51,718]\u001b[0m Trial 438 finished with value: 11.284791660477081 and parameters: {'n_hidden': 4, 'learning_rate': 0.002619846635811835, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24733459257375306, 'dropout_rate_Layer_2': 0.3763288447906851, 'dropout_rate_Layer_3': 0.24782801666488594, 'dropout_rate_Layer_4': 0.05004848659429169, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005060455588770678, 'l1_Layer_2': 0.0030664349957735962, 'l1_Layer_3': 1.1658797431469814e-05, 'l1_Layer_4': 2.0094644090631732e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 65, 'n_units_Layer_3': 290, 'n_units_Layer_4': 180}. Best is trial 431 with value: 8.908739900226008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.28 | sMAPE for Validation Set is: 52.79% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 40.84 | sMAPE for Test Set is: 52.41% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:18:56,765]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:19:04,456]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:19:23,602]\u001b[0m Trial 441 finished with value: 9.195195607435625 and parameters: {'n_hidden': 3, 'learning_rate': 0.001251404842072892, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12757458877417285, 'dropout_rate_Layer_2': 0.35391949036099674, 'dropout_rate_Layer_3': 0.3215273627079122, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.1558355972631666e-05, 'l1_Layer_2': 9.489612198082723e-05, 'l1_Layer_3': 0.00016071903541855758, 'n_units_Layer_1': 200, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 431 with value: 8.908739900226008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.20 | sMAPE for Validation Set is: 44.52% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 37.96 | sMAPE for Test Set is: 46.95% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:19:28,918]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:19:32,043]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:19:36,734]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:20:16,086]\u001b[0m Trial 445 finished with value: 9.05153801973553 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006690563550503502, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2608381887625227, 'dropout_rate_Layer_2': 0.25408429706354263, 'dropout_rate_Layer_3': 0.15778024146333183, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028701424660123064, 'l1_Layer_2': 3.6512061276854324e-05, 'l1_Layer_3': 3.058530490900634e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 175, 'n_units_Layer_3': 120}. Best is trial 431 with value: 8.908739900226008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.05 | sMAPE for Validation Set is: 42.48% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 28.82 | sMAPE for Test Set is: 35.26% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:20:48,224]\u001b[0m Trial 446 finished with value: 9.010220256884034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006600600167764227, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2581027387336421, 'dropout_rate_Layer_2': 0.2586918118663223, 'dropout_rate_Layer_3': 0.15310877047143295, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028903721243271955, 'l1_Layer_2': 3.7183895674438364e-05, 'l1_Layer_3': 3.0413593924565865e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 120}. Best is trial 431 with value: 8.908739900226008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.01 | sMAPE for Validation Set is: 42.35% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 27.68 | sMAPE for Test Set is: 33.95% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:20:51,862]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:20:57,083]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:21:08,883]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:21:18,912]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:21:50,158]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:21:53,514]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:21:56,739]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:22:18,339]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:22:22,563]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:22:26,297]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:22:59,077]\u001b[0m Trial 457 finished with value: 9.226902509601778 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011310244252195902, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1528411900680436, 'dropout_rate_Layer_2': 0.3530298302623599, 'dropout_rate_Layer_3': 0.32365028311264304, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.084494732503929e-05, 'l1_Layer_2': 9.479589455531192e-05, 'l1_Layer_3': 0.00016842889023901814, 'n_units_Layer_1': 225, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285}. Best is trial 431 with value: 8.908739900226008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.23 | sMAPE for Validation Set is: 44.81% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 36.38 | sMAPE for Test Set is: 44.61% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:23:47,863]\u001b[0m Trial 458 finished with value: 8.707366916804384 and parameters: {'n_hidden': 3, 'learning_rate': 0.000502778312432542, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2388923638337503, 'dropout_rate_Layer_2': 0.28073191812093684, 'dropout_rate_Layer_3': 0.17333754601723542, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0106158688427511, 'l1_Layer_2': 3.533526095461312e-05, 'l1_Layer_3': 4.7661657249408466e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 210, 'n_units_Layer_3': 110}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.71 | sMAPE for Validation Set is: 41.96% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 28.66 | sMAPE for Test Set is: 34.86% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:23:51,163]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:24:02,084]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:24:05,811]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:24:09,305]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:24:32,208]\u001b[0m Trial 463 finished with value: 9.1842709640188 and parameters: {'n_hidden': 3, 'learning_rate': 0.001207615819281812, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14755204130763, 'dropout_rate_Layer_2': 0.3586413391522056, 'dropout_rate_Layer_3': 0.32148984448552864, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.837673082355661e-05, 'l1_Layer_2': 6.619061453621058e-05, 'l1_Layer_3': 9.365254491563938e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.18 | sMAPE for Validation Set is: 43.80% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 36.88 | sMAPE for Test Set is: 45.63% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:24:35,469]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:24:39,316]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:24:42,601]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:24:46,201]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:24:51,840]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:25:45,816]\u001b[0m Trial 469 finished with value: 8.751446290146646 and parameters: {'n_hidden': 3, 'learning_rate': 0.00055101823591496, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23173193415409055, 'dropout_rate_Layer_2': 0.32384554184537334, 'dropout_rate_Layer_3': 0.2008909540341927, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011036973708225527, 'l1_Layer_2': 5.472530702344638e-05, 'l1_Layer_3': 0.00019015293577314475, 'n_units_Layer_1': 140, 'n_units_Layer_2': 210, 'n_units_Layer_3': 155}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.75 | sMAPE for Validation Set is: 41.88% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 29.74 | sMAPE for Test Set is: 36.15% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:25:49,772]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:25:53,549]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:25:56,698]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:25:59,914]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:26:04,295]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:26:07,551]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:27:11,237]\u001b[0m Trial 476 finished with value: 8.761438735798208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005177387186243446, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23232181914968303, 'dropout_rate_Layer_2': 0.32451339384009575, 'dropout_rate_Layer_3': 0.1909224751681698, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00926407718258709, 'l1_Layer_2': 1.571847518119253e-05, 'l1_Layer_3': 6.59629725689791e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 215, 'n_units_Layer_3': 165}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.76 | sMAPE for Validation Set is: 41.54% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 29.81 | sMAPE for Test Set is: 36.05% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:27:16,581]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:27:21,517]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:27:25,258]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:28:10,998]\u001b[0m Trial 480 finished with value: 8.723894472917197 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005244570617876019, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23454211173942863, 'dropout_rate_Layer_2': 0.3219409781283865, 'dropout_rate_Layer_3': 0.20188158928348945, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012235446879456728, 'l1_Layer_2': 1.5583321234201074e-05, 'l1_Layer_3': 6.038387549778706e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 215, 'n_units_Layer_3': 160}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.72 | sMAPE for Validation Set is: 42.46% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 29.42 | sMAPE for Test Set is: 35.66% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:28:15,263]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:28:26,422]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:28:29,742]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:29:04,943]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:29:09,024]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:29:12,562]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:29:16,082]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:30:11,166]\u001b[0m Trial 488 finished with value: 9.152426859971374 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012779180564770594, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.050568847290589254, 'dropout_rate_Layer_2': 0.0819812963057771, 'dropout_rate_Layer_3': 0.16758392327274346, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.519560802778437e-05, 'l1_Layer_2': 0.0003297510460484033, 'l1_Layer_3': 6.780216015750652e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 280}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.15 | sMAPE for Validation Set is: 46.74% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 22.97 | sMAPE for Test Set is: 32.46% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:30:29,255]\u001b[0m Trial 489 finished with value: 9.264162590546169 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012254246658976254, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.142145311415385, 'dropout_rate_Layer_2': 0.35170925807352094, 'dropout_rate_Layer_3': 0.3403009826680939, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.781236047139155e-05, 'l1_Layer_2': 5.8192311000240813e-05, 'l1_Layer_3': 9.171005338990493e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.26 | sMAPE for Validation Set is: 44.17% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 38.61 | sMAPE for Test Set is: 48.35% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:30:32,664]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:30:35,776]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:30:40,134]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:30:43,501]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:30:47,321]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:31:07,390]\u001b[0m Trial 495 finished with value: 9.264998108316817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011870744321050707, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14768149244440176, 'dropout_rate_Layer_2': 0.35166615589572503, 'dropout_rate_Layer_3': 0.3454378199992821, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.978684310197262e-05, 'l1_Layer_2': 6.263916342392287e-05, 'l1_Layer_3': 9.693244814759325e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.26 | sMAPE for Validation Set is: 44.66% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 36.17 | sMAPE for Test Set is: 44.38% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:31:10,529]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:31:14,303]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:31:17,831]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:31:20,931]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:31:24,142]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:31:40,593]\u001b[0m Trial 501 finished with value: 10.608716206320372 and parameters: {'n_hidden': 4, 'learning_rate': 0.002205030125019872, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15857482842616583, 'dropout_rate_Layer_2': 0.3885293128398204, 'dropout_rate_Layer_3': 0.17191210970770746, 'dropout_rate_Layer_4': 0.07694111713367167, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001551542788675797, 'l1_Layer_2': 0.0006269836575998623, 'l1_Layer_3': 1.936737746792331e-05, 'l1_Layer_4': 4.806608789704685e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 120, 'n_units_Layer_3': 270, 'n_units_Layer_4': 200}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.61 | sMAPE for Validation Set is: 50.31% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 36.81 | sMAPE for Test Set is: 46.10% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:31:43,806]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:31:47,105]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:32:16,466]\u001b[0m Trial 504 finished with value: 9.344346274674326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011887314615476928, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14778337971357647, 'dropout_rate_Layer_2': 0.35127211077338166, 'dropout_rate_Layer_3': 0.3447033881177963, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6252569798288585e-05, 'l1_Layer_2': 5.9202289207883e-05, 'l1_Layer_3': 9.042530765170128e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.34 | sMAPE for Validation Set is: 45.08% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 37.50 | sMAPE for Test Set is: 46.42% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:32:50,189]\u001b[0m Trial 505 finished with value: 9.229898027537898 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011360111416329332, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05245844366512337, 'dropout_rate_Layer_2': 0.07270660340045412, 'dropout_rate_Layer_3': 0.17700145221626784, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.340860564425791e-05, 'l1_Layer_2': 0.0003300304241798053, 'l1_Layer_3': 8.16192404618502e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.23 | sMAPE for Validation Set is: 48.74% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 23.32 | sMAPE for Test Set is: 31.57% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:32:53,698]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:32:56,838]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:33:17,339]\u001b[0m Trial 508 finished with value: 9.59077420962997 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012494508850510976, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15306597601875097, 'dropout_rate_Layer_2': 0.3342556611577911, 'dropout_rate_Layer_3': 0.3441024963545577, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3014403013607082e-05, 'l1_Layer_2': 5.913628977868653e-05, 'l1_Layer_3': 9.028265374908643e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.59 | sMAPE for Validation Set is: 46.40% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 36.45 | sMAPE for Test Set is: 44.96% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:33:21,304]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:33:26,095]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:33:30,643]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:34:06,861]\u001b[0m Trial 512 finished with value: 9.099961807936458 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011136155406127545, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04772982042361464, 'dropout_rate_Layer_2': 0.08110326446320251, 'dropout_rate_Layer_3': 0.17091383814166214, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010064718842159561, 'l1_Layer_2': 0.00024048677387639435, 'l1_Layer_3': 7.628939445194095e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 300, 'n_units_Layer_3': 285}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.10 | sMAPE for Validation Set is: 46.81% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.75 | sMAPE for Test Set is: 32.73% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:34:35,061]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:34:38,913]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:34:42,689]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:35:12,782]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:35:17,482]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:35:21,026]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:35:24,474]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:35:29,657]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:35:59,370]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:36:02,701]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:36:06,171]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:36:29,831]\u001b[0m Trial 524 finished with value: 9.32548589424212 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011777682651424705, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1684953226033676, 'dropout_rate_Layer_2': 0.34411012447786765, 'dropout_rate_Layer_3': 0.3341987977406954, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.657963159481495e-05, 'l1_Layer_2': 8.700796680567334e-05, 'l1_Layer_3': 8.181402274760785e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 458 with value: 8.707366916804384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.33 | sMAPE for Validation Set is: 45.07% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 36.96 | sMAPE for Test Set is: 45.75% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:36:33,274]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:36:36,482]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:37:26,963]\u001b[0m Trial 527 finished with value: 8.659490516548258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005306952968878897, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22285776368496474, 'dropout_rate_Layer_2': 0.30305681354507535, 'dropout_rate_Layer_3': 0.17739131331263977, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005717211899700344, 'l1_Layer_2': 5.4184548495586835e-05, 'l1_Layer_3': 5.161355079194315e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150}. Best is trial 527 with value: 8.659490516548258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.66 | sMAPE for Validation Set is: 42.14% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 32.41 | sMAPE for Test Set is: 39.33% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:37:30,969]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:37:34,524]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:37:40,952]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:37:45,221]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:37:48,537]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:38:12,562]\u001b[0m Trial 533 finished with value: 9.258177553208938 and parameters: {'n_hidden': 3, 'learning_rate': 0.001222165999649673, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1694870107750917, 'dropout_rate_Layer_2': 0.34790507390616365, 'dropout_rate_Layer_3': 0.3376034470286897, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.631417883428309e-05, 'l1_Layer_2': 5.7763034805936964e-05, 'l1_Layer_3': 7.809841360282126e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 527 with value: 8.659490516548258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.26 | sMAPE for Validation Set is: 44.48% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 36.71 | sMAPE for Test Set is: 45.40% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:38:36,356]\u001b[0m Trial 534 finished with value: 9.270818819221015 and parameters: {'n_hidden': 3, 'learning_rate': 0.001188702705267412, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1626992847115595, 'dropout_rate_Layer_2': 0.3484032079175549, 'dropout_rate_Layer_3': 0.3348478110417659, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7022622903484138e-05, 'l1_Layer_2': 5.1442127257118735e-05, 'l1_Layer_3': 7.36192562827967e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 527 with value: 8.659490516548258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.27 | sMAPE for Validation Set is: 44.60% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 35.17 | sMAPE for Test Set is: 43.10% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:39:07,533]\u001b[0m Trial 535 finished with value: 9.117477173653944 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009310876338377978, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.048097088499308174, 'dropout_rate_Layer_2': 0.08208870659220625, 'dropout_rate_Layer_3': 0.1646139982334304, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4583608061675276e-05, 'l1_Layer_2': 0.0002938334062180722, 'l1_Layer_3': 6.934682328220487e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285}. Best is trial 527 with value: 8.659490516548258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.12 | sMAPE for Validation Set is: 46.16% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 22.60 | sMAPE for Test Set is: 31.66% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:39:11,284]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:39:38,413]\u001b[0m Trial 537 finished with value: 9.257976485111145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011930711256308618, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16993011611199868, 'dropout_rate_Layer_2': 0.3432079420791178, 'dropout_rate_Layer_3': 0.33685758086945466, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6125012319598604e-05, 'l1_Layer_2': 5.2354074685329915e-05, 'l1_Layer_3': 7.047670546441378e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 527 with value: 8.659490516548258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.26 | sMAPE for Validation Set is: 44.68% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 35.22 | sMAPE for Test Set is: 43.18% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:39:41,572]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:39:45,426]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:39:48,753]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:39:52,325]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:40:24,756]\u001b[0m Trial 542 finished with value: 9.372273193869324 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012018749621095111, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16958485526678138, 'dropout_rate_Layer_2': 0.3468426385486757, 'dropout_rate_Layer_3': 0.3385135992795518, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5481212444319694e-05, 'l1_Layer_2': 5.3836549861329304e-05, 'l1_Layer_3': 7.22564038461721e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 527 with value: 8.659490516548258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.37 | sMAPE for Validation Set is: 45.04% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 36.52 | sMAPE for Test Set is: 44.88% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:40:51,143]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:41:01,905]\u001b[0m Trial 544 finished with value: 10.42172252213259 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011831578540721795, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1724317032124867, 'dropout_rate_Layer_2': 0.34548017435341166, 'dropout_rate_Layer_3': 0.3352233219327187, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.377520114713767e-05, 'l1_Layer_2': 4.8596987373235826e-05, 'l1_Layer_3': 6.755944846273314e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 527 with value: 8.659490516548258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.42 | sMAPE for Validation Set is: 48.25% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 36.72 | sMAPE for Test Set is: 45.78% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:41:54,857]\u001b[0m Trial 545 finished with value: 8.61020861161819 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005022357695768927, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2066524490844068, 'dropout_rate_Layer_2': 0.317787493622382, 'dropout_rate_Layer_3': 0.18676913621392924, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004856726853121321, 'l1_Layer_2': 1.0038917990622985e-05, 'l1_Layer_3': 4.425771516712216e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 190, 'n_units_Layer_3': 170}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 42.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 32.46 | sMAPE for Test Set is: 39.32% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:42:06,672]\u001b[0m Trial 546 finished with value: 10.258234567990876 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012096111358154114, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16682163048066403, 'dropout_rate_Layer_2': 0.3503306812873617, 'dropout_rate_Layer_3': 0.3578844974645227, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7755465592962386e-05, 'l1_Layer_2': 8.133330931469601e-05, 'l1_Layer_3': 4.9628101674836654e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 140, 'n_units_Layer_3': 300}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.26 | sMAPE for Validation Set is: 47.75% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 37.58 | sMAPE for Test Set is: 46.99% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:42:09,708]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:42:13,679]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:42:19,613]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:42:26,034]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:42:42,998]\u001b[0m Trial 551 finished with value: 9.283888473069105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008983248588969544, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18355443998486956, 'dropout_rate_Layer_2': 0.32877061804454877, 'dropout_rate_Layer_3': 0.33265623369148256, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2857440657030643e-05, 'l1_Layer_2': 3.456939477535243e-05, 'l1_Layer_3': 6.86161681188995e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 150, 'n_units_Layer_3': 270}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.28 | sMAPE for Validation Set is: 44.99% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 35.27 | sMAPE for Test Set is: 43.16% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:42:46,713]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:42:49,930]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:43:08,469]\u001b[0m Trial 554 finished with value: 9.50680244098522 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009078564398060362, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18361484270390516, 'dropout_rate_Layer_2': 0.33066642011262803, 'dropout_rate_Layer_3': 0.3482486978371731, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.059212238261382e-05, 'l1_Layer_2': 3.852169578955309e-05, 'l1_Layer_3': 5.832035556516071e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 150, 'n_units_Layer_3': 270}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.51 | sMAPE for Validation Set is: 45.35% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 37.53 | sMAPE for Test Set is: 46.70% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:43:13,065]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:43:16,382]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:43:19,647]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:43:59,567]\u001b[0m Trial 558 finished with value: 8.84651360092126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008414254864050494, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22548818047637548, 'dropout_rate_Layer_2': 0.33540694816496386, 'dropout_rate_Layer_3': 0.193259802033183, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004956173808918806, 'l1_Layer_2': 1.331271592923128e-05, 'l1_Layer_3': 4.16804774822571e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 220, 'n_units_Layer_3': 155}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.85 | sMAPE for Validation Set is: 42.71% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 33.63 | sMAPE for Test Set is: 40.74% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:44:02,803]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:44:06,056]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:44:10,368]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:44:32,257]\u001b[0m Trial 562 finished with value: 9.926754570657055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007730286718294645, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16113835402458174, 'dropout_rate_Layer_2': 0.3561940372297997, 'dropout_rate_Layer_3': 0.33139307776934035, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.756832748529124e-05, 'l1_Layer_2': 3.2851374233006625e-05, 'l1_Layer_3': 4.124870107511577e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.93 | sMAPE for Validation Set is: 47.89% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 35.69 | sMAPE for Test Set is: 43.82% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:44:35,371]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:45:06,083]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:45:09,179]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:45:25,545]\u001b[0m Trial 566 finished with value: 9.428201019789405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013237327407642906, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14457343906492595, 'dropout_rate_Layer_2': 0.32255435030239793, 'dropout_rate_Layer_3': 0.35553396208015736, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.381391420189112e-05, 'l1_Layer_2': 4.758432782058796e-05, 'l1_Layer_3': 8.328647659963049e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.43 | sMAPE for Validation Set is: 45.46% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 37.08 | sMAPE for Test Set is: 46.01% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:45:29,333]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:46:01,350]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:46:04,556]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:46:07,920]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:46:11,210]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:46:14,956]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:46:18,675]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:47:04,519]\u001b[0m Trial 574 finished with value: 8.751234111965546 and parameters: {'n_hidden': 3, 'learning_rate': 0.000774022356582296, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2218883757470998, 'dropout_rate_Layer_2': 0.334957852810426, 'dropout_rate_Layer_3': 0.1809755808639595, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007323480629789346, 'l1_Layer_2': 2.2755839441562317e-05, 'l1_Layer_3': 4.4011603734081224e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 205, 'n_units_Layer_3': 195}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.75 | sMAPE for Validation Set is: 41.88% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 32.16 | sMAPE for Test Set is: 38.79% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:47:08,768]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:47:41,837]\u001b[0m Trial 576 finished with value: 9.367159740191676 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011301739374208815, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16214301031895845, 'dropout_rate_Layer_2': 0.34431163601054066, 'dropout_rate_Layer_3': 0.336822997916822, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.857283985013103e-05, 'l1_Layer_2': 7.119353340007488e-05, 'l1_Layer_3': 0.00010475801179466727, 'n_units_Layer_1': 245, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.37 | sMAPE for Validation Set is: 45.16% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 36.51 | sMAPE for Test Set is: 44.80% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:47:45,171]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:47:49,257]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:48:10,942]\u001b[0m Trial 579 finished with value: 9.598062455951892 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011121610411118374, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18127712629877185, 'dropout_rate_Layer_2': 0.33802740644295337, 'dropout_rate_Layer_3': 0.3360600447586665, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1243020775027928e-05, 'l1_Layer_2': 8.926610153427862e-05, 'l1_Layer_3': 0.0001024374866918665, 'n_units_Layer_1': 265, 'n_units_Layer_2': 120, 'n_units_Layer_3': 270}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.60 | sMAPE for Validation Set is: 46.82% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 37.33 | sMAPE for Test Set is: 46.50% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:48:36,143]\u001b[0m Trial 580 finished with value: 9.259696483276128 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006859572090314083, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16144130134702436, 'dropout_rate_Layer_2': 0.32663898865299895, 'dropout_rate_Layer_3': 0.3252918502074365, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.896619707871235e-05, 'l1_Layer_2': 6.535354642592601e-05, 'l1_Layer_3': 6.605649027633485e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.26 | sMAPE for Validation Set is: 44.64% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 36.13 | sMAPE for Test Set is: 44.37% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:48:59,551]\u001b[0m Trial 581 finished with value: 9.516887482062137 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006783667317003906, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14455344116789323, 'dropout_rate_Layer_2': 0.32619836669113794, 'dropout_rate_Layer_3': 0.34498457341912536, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2083490833485004e-05, 'l1_Layer_2': 6.7428379977959e-05, 'l1_Layer_3': 6.70252363262487e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 150, 'n_units_Layer_3': 295}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.52 | sMAPE for Validation Set is: 45.60% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 35.72 | sMAPE for Test Set is: 43.89% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:49:44,160]\u001b[0m Trial 582 finished with value: 8.96730064609893 and parameters: {'n_hidden': 3, 'learning_rate': 0.00076628340545292, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21934637436260648, 'dropout_rate_Layer_2': 0.33904885435740456, 'dropout_rate_Layer_3': 0.18870246339904126, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008149858163199231, 'l1_Layer_2': 2.0270979283206088e-05, 'l1_Layer_3': 0.00011683432502667987, 'n_units_Layer_1': 135, 'n_units_Layer_2': 205, 'n_units_Layer_3': 205}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.97 | sMAPE for Validation Set is: 42.45% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 31.33 | sMAPE for Test Set is: 37.82% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:49:47,236]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:50:12,023]\u001b[0m Trial 584 finished with value: 9.486452535835813 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008590950539223696, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13294477323572726, 'dropout_rate_Layer_2': 0.3085135762005738, 'dropout_rate_Layer_3': 0.3274199306889107, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.962687408416815e-05, 'l1_Layer_2': 6.0385049697954043e-05, 'l1_Layer_3': 8.269012177501573e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.49 | sMAPE for Validation Set is: 45.93% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 35.81 | sMAPE for Test Set is: 43.89% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:50:58,915]\u001b[0m Trial 585 finished with value: 8.965327110224946 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009682805758728753, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24064977163603615, 'dropout_rate_Layer_2': 0.3227298396102567, 'dropout_rate_Layer_3': 0.22392547481653713, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004779380278645197, 'l1_Layer_2': 1.3000873097183314e-05, 'l1_Layer_3': 4.167526402610355e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 225, 'n_units_Layer_3': 135}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.97 | sMAPE for Validation Set is: 43.16% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 33.71 | sMAPE for Test Set is: 40.77% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:51:02,570]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:51:18,831]\u001b[0m Trial 587 finished with value: 10.867246354314721 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021086690531777075, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18022287169757728, 'dropout_rate_Layer_2': 0.31082851505813625, 'dropout_rate_Layer_3': 0.2861381109288704, 'dropout_rate_Layer_4': 0.06303110565010983, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003249694080457878, 'l1_Layer_2': 0.0002555247220319849, 'l1_Layer_3': 0.0002272602106008576, 'l1_Layer_4': 0.00020306394679670963, 'n_units_Layer_1': 100, 'n_units_Layer_2': 75, 'n_units_Layer_3': 230, 'n_units_Layer_4': 160}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.87 | sMAPE for Validation Set is: 51.69% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 38.04 | sMAPE for Test Set is: 47.79% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:51:31,335]\u001b[0m Trial 588 finished with value: 10.922064078166292 and parameters: {'n_hidden': 4, 'learning_rate': 0.002041501467545197, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18305875107130076, 'dropout_rate_Layer_2': 0.29658026779728225, 'dropout_rate_Layer_3': 0.28598110861846815, 'dropout_rate_Layer_4': 0.0675407588850259, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003350941063897108, 'l1_Layer_2': 0.00022038173286004887, 'l1_Layer_3': 0.0003154808935070798, 'l1_Layer_4': 4.5212717816503726e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 80, 'n_units_Layer_3': 235, 'n_units_Layer_4': 165}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.92 | sMAPE for Validation Set is: 51.87% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 37.67 | sMAPE for Test Set is: 47.22% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:51:37,320]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:51:41,338]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:51:45,100]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:51:49,515]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:51:53,450]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:51:58,155]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:52:04,528]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:52:08,374]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:52:28,417]\u001b[0m Trial 597 finished with value: 9.59606293975809 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009396992643838352, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14646156246620298, 'dropout_rate_Layer_2': 0.3183590990326359, 'dropout_rate_Layer_3': 0.3522286470430146, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0006536425610193e-05, 'l1_Layer_2': 7.640042798007487e-05, 'l1_Layer_3': 6.332855357622612e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.60 | sMAPE for Validation Set is: 46.29% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 36.72 | sMAPE for Test Set is: 45.28% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:52:32,859]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:52:59,317]\u001b[0m Trial 599 finished with value: 9.255524934456929 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007986466665870644, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.156904407604072, 'dropout_rate_Layer_2': 0.3303506820421278, 'dropout_rate_Layer_3': 0.3324573652873626, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.475775310253532e-05, 'l1_Layer_2': 4.851693669014959e-05, 'l1_Layer_3': 0.00013144339949313765, 'n_units_Layer_1': 230, 'n_units_Layer_2': 140, 'n_units_Layer_3': 265}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.26 | sMAPE for Validation Set is: 46.14% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 34.90 | sMAPE for Test Set is: 42.76% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:53:03,143]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:53:16,053]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:53:19,956]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:53:23,792]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:53:27,971]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:53:34,018]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:54:05,832]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:54:13,047]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:54:25,107]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:54:31,332]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:54:35,543]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:54:49,314]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:55:16,011]\u001b[0m Trial 612 finished with value: 9.230261087225147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008109588514365343, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1741370079604692, 'dropout_rate_Layer_2': 0.32346846223353054, 'dropout_rate_Layer_3': 0.32331253279152655, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9042598192377473e-05, 'l1_Layer_2': 5.995116625677926e-05, 'l1_Layer_3': 0.00015474192500523873, 'n_units_Layer_1': 205, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.23 | sMAPE for Validation Set is: 44.68% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 36.06 | sMAPE for Test Set is: 44.15% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:55:44,894]\u001b[0m Trial 613 finished with value: 9.235270867565424 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009730811501563213, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17461892966027262, 'dropout_rate_Layer_2': 0.315502814415771, 'dropout_rate_Layer_3': 0.32190877670445606, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9149030028895355e-05, 'l1_Layer_2': 9.289182594574534e-05, 'l1_Layer_3': 0.00015200392069771544, 'n_units_Layer_1': 205, 'n_units_Layer_2': 145, 'n_units_Layer_3': 265}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.24 | sMAPE for Validation Set is: 44.52% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 37.18 | sMAPE for Test Set is: 45.95% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:56:13,868]\u001b[0m Trial 614 finished with value: 9.15833938662748 and parameters: {'n_hidden': 3, 'learning_rate': 0.000798390143119478, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19221133545154373, 'dropout_rate_Layer_2': 0.3202379654643549, 'dropout_rate_Layer_3': 0.32145878752029994, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8626905819844413e-05, 'l1_Layer_2': 9.578537467174374e-05, 'l1_Layer_3': 0.00013094842406645516, 'n_units_Layer_1': 210, 'n_units_Layer_2': 145, 'n_units_Layer_3': 265}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.16 | sMAPE for Validation Set is: 44.60% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 36.10 | sMAPE for Test Set is: 44.32% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:56:30,497]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:56:34,381]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:56:38,775]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:56:42,593]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:56:46,799]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:56:53,783]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:56:57,394]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:57:00,936]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:57:29,227]\u001b[0m Trial 623 finished with value: 9.388391945737457 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009949398500025274, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17737453600753453, 'dropout_rate_Layer_2': 0.3186005980345419, 'dropout_rate_Layer_3': 0.3100093581226545, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4597667207898883e-05, 'l1_Layer_2': 3.5205499269865196e-05, 'l1_Layer_3': 0.0001153714748705786, 'n_units_Layer_1': 210, 'n_units_Layer_2': 145, 'n_units_Layer_3': 265}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.39 | sMAPE for Validation Set is: 45.47% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 36.68 | sMAPE for Test Set is: 45.18% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:58:02,549]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:58:06,197]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:58:09,440]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:58:12,786]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:58:16,076]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:58:22,321]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:58:25,579]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:58:44,678]\u001b[0m Trial 631 finished with value: 9.402056819368623 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007201021310330989, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19977284760292285, 'dropout_rate_Layer_2': 0.29866090326303285, 'dropout_rate_Layer_3': 0.3067808266018157, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9395700041078457e-05, 'l1_Layer_2': 2.3560503334039356e-05, 'l1_Layer_3': 6.0274195565294366e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 155, 'n_units_Layer_3': 270}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.40 | sMAPE for Validation Set is: 45.30% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 36.33 | sMAPE for Test Set is: 44.81% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:59:05,586]\u001b[0m Trial 632 finished with value: 9.524699490763242 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008522488977401043, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17386082700751931, 'dropout_rate_Layer_2': 0.32788574419358324, 'dropout_rate_Layer_3': 0.32359128222640116, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.3270841404290065e-05, 'l1_Layer_2': 7.000089621593063e-05, 'l1_Layer_3': 0.00014453225745513905, 'n_units_Layer_1': 220, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 545 with value: 8.61020861161819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.52 | sMAPE for Validation Set is: 46.46% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 36.36 | sMAPE for Test Set is: 44.85% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 01:59:17,704]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:59:23,286]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:59:26,926]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:59:31,379]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:59:35,362]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:59:38,647]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:59:42,045]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:59:45,280]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 01:59:48,584]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:00:49,578]\u001b[0m Trial 642 finished with value: 8.54081638869953 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008055717408891219, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15648465691538604, 'dropout_rate_Layer_2': 0.09582986567290762, 'dropout_rate_Layer_3': 0.19851168553128284, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.426273143690804e-05, 'l1_Layer_2': 0.00026977835172874284, 'l1_Layer_3': 0.00013472118221037166, 'n_units_Layer_1': 270, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.54 | sMAPE for Validation Set is: 42.61% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.27 | sMAPE for Test Set is: 29.83% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:00:52,902]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:00:58,592]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:01:06,033]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:01:18,775]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:01:32,273]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:01:38,300]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:01:45,196]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:02:24,876]\u001b[0m Trial 650 finished with value: 8.95587267041912 and parameters: {'n_hidden': 3, 'learning_rate': 0.000981576808594897, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24259629176113146, 'dropout_rate_Layer_2': 0.32131933929981576, 'dropout_rate_Layer_3': 0.22637272557974253, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004703253279804289, 'l1_Layer_2': 1.3999913749118819e-05, 'l1_Layer_3': 4.126335377871712e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 225, 'n_units_Layer_3': 135}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.96 | sMAPE for Validation Set is: 44.35% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 35.03 | sMAPE for Test Set is: 42.79% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:02:28,523]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:02:32,526]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:02:36,276]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:03:14,092]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:03:17,420]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:03:29,368]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:04:04,776]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:04:22,004]\u001b[0m Trial 658 finished with value: 9.541418121747652 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015166305576107162, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1736417138173702, 'dropout_rate_Layer_2': 0.3416833517120848, 'dropout_rate_Layer_3': 0.35043961143658403, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.173002856280868e-05, 'l1_Layer_2': 7.830041523346075e-05, 'l1_Layer_3': 4.9537624236580555e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 140, 'n_units_Layer_3': 270}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.54 | sMAPE for Validation Set is: 45.96% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 38.31 | sMAPE for Test Set is: 47.79% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:04:25,621]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:04:29,014]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:04:40,647]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:04:43,754]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:04:47,964]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:04:51,338]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:04:54,599]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:05:28,520]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:05:32,441]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:05:35,598]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:05:38,720]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:05:41,948]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:05:47,365]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:06:22,826]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:06:26,619]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:06:30,315]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:06:43,519]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:06:56,084]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:06:59,280]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:07:03,674]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:07:07,428]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:07:10,691]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:07:50,080]\u001b[0m Trial 681 finished with value: 9.247687814872757 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008748546451380376, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21309090453558097, 'dropout_rate_Layer_2': 0.3675050073269774, 'dropout_rate_Layer_3': 0.1952092180948672, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013938529825545538, 'l1_Layer_2': 1.2967192837345579e-05, 'l1_Layer_3': 5.730247997533109e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 205, 'n_units_Layer_3': 170}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.25 | sMAPE for Validation Set is: 44.39% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 32.73 | sMAPE for Test Set is: 39.87% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:07:53,829]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:07:57,035]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:08:10,734]\u001b[0m Trial 684 finished with value: 10.04636435485152 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013437355353217917, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20176718470267718, 'dropout_rate_Layer_2': 0.3170921354475256, 'dropout_rate_Layer_3': 0.3411846476744632, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8935889797201195e-05, 'l1_Layer_2': 6.696636450808929e-05, 'l1_Layer_3': 5.592120890482515e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.05 | sMAPE for Validation Set is: 48.00% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 38.39 | sMAPE for Test Set is: 48.04% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:08:26,333]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:08:30,008]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:08:33,511]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:08:37,742]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:08:41,184]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:09:04,077]\u001b[0m Trial 690 finished with value: 9.594439636879533 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006722302498004064, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15458847272861087, 'dropout_rate_Layer_2': 0.3600645393251855, 'dropout_rate_Layer_3': 0.307556162166701, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7189527949775944e-05, 'l1_Layer_2': 9.609388813179397e-05, 'l1_Layer_3': 0.00016230635091351553, 'n_units_Layer_1': 220, 'n_units_Layer_2': 125, 'n_units_Layer_3': 295}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.59 | sMAPE for Validation Set is: 46.26% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 36.12 | sMAPE for Test Set is: 44.48% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:09:07,935]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:09:11,295]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:09:14,647]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:09:18,012]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:09:22,267]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:09:25,401]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:09:59,110]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:10:03,340]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:10:06,943]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:10:10,213]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:10:38,260]\u001b[0m Trial 701 finished with value: 9.36491493791764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009739088182187482, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13560217966932772, 'dropout_rate_Layer_2': 0.34573468211109293, 'dropout_rate_Layer_3': 0.3268034215872924, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1085457991585163e-05, 'l1_Layer_2': 5.222011887586586e-05, 'l1_Layer_3': 4.538931539314021e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.36 | sMAPE for Validation Set is: 45.30% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 35.14 | sMAPE for Test Set is: 42.95% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:10:42,407]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:10:46,247]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:11:20,535]\u001b[0m Trial 704 finished with value: 9.275116952560504 and parameters: {'n_hidden': 3, 'learning_rate': 0.000786661904464869, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15366560689126868, 'dropout_rate_Layer_2': 0.3274922004807706, 'dropout_rate_Layer_3': 0.31807487173584537, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.722906253180709e-05, 'l1_Layer_2': 0.0001667942001634646, 'l1_Layer_3': 0.00010797571660798601, 'n_units_Layer_1': 190, 'n_units_Layer_2': 140, 'n_units_Layer_3': 290}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.28 | sMAPE for Validation Set is: 44.89% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 35.72 | sMAPE for Test Set is: 43.78% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:11:23,895]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:11:27,535]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:11:31,369]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:11:44,113]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:11:47,474]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:11:51,835]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:11:55,021]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:11:58,403]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:12:05,918]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:12:09,296]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:12:22,828]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:12:37,598]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:12:43,853]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:12:47,201]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:12:50,532]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:12:54,555]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:13:01,210]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:13:04,176]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:13:08,659]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:13:12,253]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:14:02,094]\u001b[0m Trial 725 finished with value: 8.838064713442531 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006127893613177357, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23441787253173857, 'dropout_rate_Layer_2': 0.3201429923055687, 'dropout_rate_Layer_3': 0.2462581524666041, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004781106708472701, 'l1_Layer_2': 3.238687645834813e-05, 'l1_Layer_3': 0.00010285004553077512, 'n_units_Layer_1': 145, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.84 | sMAPE for Validation Set is: 43.55% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 32.19 | sMAPE for Test Set is: 39.04% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:14:07,486]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:14:10,512]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:14:13,802]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:14:20,422]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:14:23,613]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:14:27,196]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:14:36,539]\u001b[0m Trial 732 finished with value: 10.889563425432895 and parameters: {'n_hidden': 4, 'learning_rate': 0.00544601025049042, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22837031380127382, 'dropout_rate_Layer_2': 0.3472935558745246, 'dropout_rate_Layer_3': 0.0932813853216052, 'dropout_rate_Layer_4': 0.07250838741510869, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.750843004859011e-05, 'l1_Layer_2': 0.0002758717650299403, 'l1_Layer_3': 0.0005841074079253233, 'l1_Layer_4': 0.00015377918396628385, 'n_units_Layer_1': 70, 'n_units_Layer_2': 75, 'n_units_Layer_3': 275, 'n_units_Layer_4': 160}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.89 | sMAPE for Validation Set is: 51.15% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 38.52 | sMAPE for Test Set is: 48.50% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:14:40,096]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:14:43,154]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:14:46,419]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:14:50,294]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:14:54,724]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:15:07,198]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:15:36,635]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:15:40,285]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:15:45,821]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:15:55,821]\u001b[0m Trial 742 finished with value: 10.960801657952972 and parameters: {'n_hidden': 4, 'learning_rate': 0.0044661761860029315, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23562000780958295, 'dropout_rate_Layer_2': 0.39306946780342694, 'dropout_rate_Layer_3': 0.13901910731208109, 'dropout_rate_Layer_4': 0.004828660516919879, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.480191879042897e-05, 'l1_Layer_2': 5.220321535577573e-05, 'l1_Layer_3': 0.0003243335467065527, 'l1_Layer_4': 2.1897835552712005e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 85, 'n_units_Layer_3': 265, 'n_units_Layer_4': 220}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.96 | sMAPE for Validation Set is: 51.90% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 39.86 | sMAPE for Test Set is: 50.70% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:15:59,922]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:16:05,514]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:16:09,985]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:16:16,663]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:16:20,154]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:16:23,472]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:16:43,786]\u001b[0m Trial 749 finished with value: 9.409817216017784 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014369154917556696, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16861058120568065, 'dropout_rate_Layer_2': 0.3142472326812603, 'dropout_rate_Layer_3': 0.3097831612216596, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.935108696979702e-05, 'l1_Layer_2': 6.079674274530806e-05, 'l1_Layer_3': 8.962706008483706e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 135, 'n_units_Layer_3': 260}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.41 | sMAPE for Validation Set is: 45.08% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 37.74 | sMAPE for Test Set is: 47.12% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:16:47,192]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:17:03,283]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:17:07,553]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:17:13,795]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:17:17,592]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:17:21,249]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:17:25,866]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:17:57,179]\u001b[0m Trial 757 finished with value: 8.915739425343693 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013712107641613842, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031262930849490736, 'dropout_rate_Layer_2': 0.01560591682131316, 'dropout_rate_Layer_3': 0.19612970041716116, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.29603329940609e-05, 'l1_Layer_2': 0.00030638059317027215, 'l1_Layer_3': 6.663531775925741e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 300, 'n_units_Layer_3': 255}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.92 | sMAPE for Validation Set is: 45.05% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.18 | sMAPE for Test Set is: 30.95% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:18:03,810]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:18:56,005]\u001b[0m Trial 759 finished with value: 8.625899664755485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006379769159722884, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2086431481309792, 'dropout_rate_Layer_2': 0.3219374343950247, 'dropout_rate_Layer_3': 0.16627763592634653, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006083885402651806, 'l1_Layer_2': 1.498705584202783e-05, 'l1_Layer_3': 0.00010812255937746238, 'n_units_Layer_1': 165, 'n_units_Layer_2': 205, 'n_units_Layer_3': 135}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 41.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 32.84 | sMAPE for Test Set is: 39.81% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:18:59,950]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:19:12,895]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:19:27,087]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:19:31,250]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:19:35,110]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:20:04,186]\u001b[0m Trial 765 finished with value: 9.26758217215552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006331439932184463, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1506173128304139, 'dropout_rate_Layer_2': 0.33377359710368054, 'dropout_rate_Layer_3': 0.3407601802293868, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.146493088746328e-05, 'l1_Layer_2': 9.249556252312251e-05, 'l1_Layer_3': 0.0001805511572982867, 'n_units_Layer_1': 190, 'n_units_Layer_2': 165, 'n_units_Layer_3': 280}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.27 | sMAPE for Validation Set is: 44.63% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 36.89 | sMAPE for Test Set is: 45.54% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:20:11,387]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:20:14,505]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:20:21,006]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:20:34,474]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:20:37,836]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:20:41,647]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:21:13,379]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:21:40,754]\u001b[0m Trial 773 finished with value: 9.274993914736275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006208453474984754, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18126088322182404, 'dropout_rate_Layer_2': 0.34337261158945254, 'dropout_rate_Layer_3': 0.3352815425142545, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7345650389685553e-05, 'l1_Layer_2': 5.348034496100724e-05, 'l1_Layer_3': 0.00013640566891321375, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.27 | sMAPE for Validation Set is: 44.54% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 36.78 | sMAPE for Test Set is: 45.20% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:21:44,155]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:21:48,421]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:21:51,525]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:21:54,886]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:21:58,986]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:22:20,405]\u001b[0m Trial 779 finished with value: 11.082010068185037 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022238909909198367, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02584925412109578, 'dropout_rate_Layer_2': 0.007107491036670896, 'dropout_rate_Layer_3': 0.26706541397100747, 'dropout_rate_Layer_4': 0.12033631413934182, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.7017490580051563e-05, 'l1_Layer_2': 0.0005929785015420469, 'l1_Layer_3': 0.00012865447955938566, 'l1_Layer_4': 0.004348757274186469, 'n_units_Layer_1': 270, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260, 'n_units_Layer_4': 120}. Best is trial 642 with value: 8.54081638869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.08 | sMAPE for Validation Set is: 52.10% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 34.93 | sMAPE for Test Set is: 43.01% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:22:34,548]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:22:38,728]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:22:42,142]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:22:52,141]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:22:56,807]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:23:39,112]\u001b[0m Trial 785 finished with value: 8.47526021193495 and parameters: {'n_hidden': 3, 'learning_rate': 0.00156083287968542, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18923674814911123, 'dropout_rate_Layer_2': 0.05325561300729874, 'dropout_rate_Layer_3': 0.1299034619480324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.500678584790675e-05, 'l1_Layer_2': 0.00018343591032962626, 'l1_Layer_3': 0.00022569530546509453, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 300}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 42.36% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.01 | sMAPE for Test Set is: 29.77% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:23:42,396]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:23:45,816]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:24:39,958]\u001b[0m Trial 788 finished with value: 8.832912914406029 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005544628228256318, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22461558778555463, 'dropout_rate_Layer_2': 0.2749465020526101, 'dropout_rate_Layer_3': 0.16520709495507033, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010598633344401967, 'l1_Layer_2': 2.4963245542142325e-05, 'l1_Layer_3': 0.00016998082449802568, 'n_units_Layer_1': 130, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.83 | sMAPE for Validation Set is: 42.37% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 30.18 | sMAPE for Test Set is: 36.54% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:24:45,211]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:24:49,836]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:24:53,738]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:25:07,237]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:25:11,408]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:25:15,198]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:25:19,180]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:25:23,692]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:25:26,955]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:25:39,599]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:25:52,135]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:25:58,981]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:26:02,549]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:26:14,676]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:26:21,252]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:26:27,838]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:26:31,694]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:26:38,426]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:26:49,006]\u001b[0m Trial 807 finished with value: 25.578372532992244 and parameters: {'n_hidden': 3, 'learning_rate': 0.001735561003503712, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18216503958990776, 'dropout_rate_Layer_2': 0.0577907346497192, 'dropout_rate_Layer_3': 0.135604173509885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4243733488529086e-05, 'l1_Layer_2': 6.77701587139886e-05, 'l1_Layer_3': 0.00021527998240928147, 'n_units_Layer_1': 300, 'n_units_Layer_2': 265, 'n_units_Layer_3': 110}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.58 | sMAPE for Validation Set is: 166.92% | rMAE for Validation Set is: 1.95\n",
      "MAE for Test Set is: 81.45 | sMAPE for Test Set is: 185.52% | rMAE for Test Set is: 2.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:26:52,264]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:26:55,696]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:26:59,861]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:27:05,967]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:27:09,531]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:27:13,221]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:27:16,639]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:27:23,443]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:27:26,795]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:27:30,750]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:27:35,179]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:27:39,513]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:28:09,098]\u001b[0m Trial 820 finished with value: 9.160539536250889 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007976337806511046, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1936019988056114, 'dropout_rate_Layer_2': 0.22385815798922415, 'dropout_rate_Layer_3': 0.3293233720459222, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.173015084718715e-05, 'l1_Layer_2': 8.27849355159733e-05, 'l1_Layer_3': 8.414475715245045e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 155, 'n_units_Layer_3': 275}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.16 | sMAPE for Validation Set is: 44.36% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 36.37 | sMAPE for Test Set is: 44.62% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:28:58,267]\u001b[0m Trial 821 finished with value: 8.635407494893892 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013876443102013771, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21064465166147714, 'dropout_rate_Layer_2': 0.030002425659254095, 'dropout_rate_Layer_3': 0.197055349684985, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0203691117708429e-05, 'l1_Layer_2': 0.00024108630050760055, 'l1_Layer_3': 0.00012528873928523731, 'n_units_Layer_1': 290, 'n_units_Layer_2': 245, 'n_units_Layer_3': 300}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.64 | sMAPE for Validation Set is: 41.79% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.10 | sMAPE for Test Set is: 29.66% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:29:39,993]\u001b[0m Trial 822 finished with value: 9.164255583809004 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006649238788784623, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19477461985429198, 'dropout_rate_Layer_2': 0.3001162656406446, 'dropout_rate_Layer_3': 0.3167127280347843, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.389204733960362e-05, 'l1_Layer_2': 5.8666851542277816e-05, 'l1_Layer_3': 0.0002099071603733906, 'n_units_Layer_1': 215, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.16 | sMAPE for Validation Set is: 44.07% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 36.83 | sMAPE for Test Set is: 45.43% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:30:23,353]\u001b[0m Trial 823 finished with value: 8.70783955123528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015166536408874685, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21518482241297607, 'dropout_rate_Layer_2': 0.03490811817375249, 'dropout_rate_Layer_3': 0.1991629940257804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1351845025782804e-05, 'l1_Layer_2': 0.000171197916387316, 'l1_Layer_3': 0.0005022949548939551, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 300}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.71 | sMAPE for Validation Set is: 42.77% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.73 | sMAPE for Test Set is: 30.35% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:30:30,812]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:30:56,736]\u001b[0m Trial 825 finished with value: 9.261662302121534 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006434923044127421, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2065365229876941, 'dropout_rate_Layer_2': 0.2489917361404671, 'dropout_rate_Layer_3': 0.3164956244818259, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.806241194188833e-05, 'l1_Layer_2': 7.518000759607814e-05, 'l1_Layer_3': 0.0001806565957120861, 'n_units_Layer_1': 205, 'n_units_Layer_2': 160, 'n_units_Layer_3': 255}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.26 | sMAPE for Validation Set is: 44.33% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 36.94 | sMAPE for Test Set is: 45.63% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:31:18,275]\u001b[0m Trial 826 finished with value: 9.563347397029968 and parameters: {'n_hidden': 3, 'learning_rate': 0.000629411058314409, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20160033268361757, 'dropout_rate_Layer_2': 0.23412099367339737, 'dropout_rate_Layer_3': 0.31583978420904607, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.081182327378703e-05, 'l1_Layer_2': 7.22956509972885e-05, 'l1_Layer_3': 0.00016753057920028495, 'n_units_Layer_1': 205, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.56 | sMAPE for Validation Set is: 46.17% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 35.09 | sMAPE for Test Set is: 42.95% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:31:46,001]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:31:59,909]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:32:03,493]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:32:06,742]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:32:11,133]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:32:15,331]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:32:19,361]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:32:34,128]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:33:04,514]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:33:09,151]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:33:13,086]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:33:16,929]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:33:21,319]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:33:24,769]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:33:28,703]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:33:32,720]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:33:58,399]\u001b[0m Trial 843 finished with value: 9.442009380497419 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007624994719808395, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1203814406361512, 'dropout_rate_Layer_2': 0.35055610619641114, 'dropout_rate_Layer_3': 0.3260125350221597, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.622807182683086e-05, 'l1_Layer_2': 0.00018014549983821, 'l1_Layer_3': 0.00010021224020048818, 'n_units_Layer_1': 205, 'n_units_Layer_2': 175, 'n_units_Layer_3': 280}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.44 | sMAPE for Validation Set is: 45.28% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 36.94 | sMAPE for Test Set is: 45.62% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:34:03,049]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:34:16,894]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:34:21,448]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:34:24,628]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:34:36,882]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:34:51,765]\u001b[0m Trial 849 finished with value: 11.005724580489384 and parameters: {'n_hidden': 4, 'learning_rate': 0.002548285420165991, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038224847529877704, 'dropout_rate_Layer_2': 0.3872573529763629, 'dropout_rate_Layer_3': 0.22314204300420015, 'dropout_rate_Layer_4': 0.05899273160942141, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.8836970554944644e-05, 'l1_Layer_2': 0.00012501750463262418, 'l1_Layer_3': 0.0009646683601316827, 'l1_Layer_4': 1.8508757476277648e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 75, 'n_units_Layer_3': 290, 'n_units_Layer_4': 180}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.01 | sMAPE for Validation Set is: 51.98% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 38.73 | sMAPE for Test Set is: 48.71% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:35:21,368]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:35:24,700]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:35:28,609]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:35:32,802]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:36:00,517]\u001b[0m Trial 854 finished with value: 8.983338253444117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015386672322344212, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20941759200569132, 'dropout_rate_Layer_2': 0.029224704589559548, 'dropout_rate_Layer_3': 0.19646342865206048, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0935524549680149e-05, 'l1_Layer_2': 0.00018029590744246982, 'l1_Layer_3': 0.0005581146687777624, 'n_units_Layer_1': 285, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.98 | sMAPE for Validation Set is: 43.44% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.81 | sMAPE for Test Set is: 30.65% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:36:04,091]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:36:07,508]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:36:39,746]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:37:03,667]\u001b[0m Trial 858 finished with value: 9.550585892890878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008756696377277275, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17909725042330382, 'dropout_rate_Layer_2': 0.32032631057980765, 'dropout_rate_Layer_3': 0.33385525624884277, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7161543044654962e-05, 'l1_Layer_2': 4.483452715358389e-05, 'l1_Layer_3': 7.920638031926499e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.55 | sMAPE for Validation Set is: 46.12% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 38.16 | sMAPE for Test Set is: 47.49% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:37:10,316]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:37:13,892]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.15 | sMAPE for Validation Set is: 49.69% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 22.56 | sMAPE for Test Set is: 31.24% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:37:44,096]\u001b[0m Trial 861 finished with value: 9.154456596411176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020735132067747873, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21224632944447755, 'dropout_rate_Layer_2': 0.02899967086004858, 'dropout_rate_Layer_3': 0.19862996134543232, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1364277448591249e-05, 'l1_Layer_2': 0.0001690506499004702, 'l1_Layer_3': 0.000605735152564654, 'n_units_Layer_1': 270, 'n_units_Layer_2': 235, 'n_units_Layer_3': 300}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:37:48,056]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:37:52,045]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:37:55,500]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:38:05,521]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:38:19,109]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:38:48,401]\u001b[0m Trial 867 finished with value: 9.408431120220442 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009287952055397793, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1724702031136319, 'dropout_rate_Layer_2': 0.3623685380269382, 'dropout_rate_Layer_3': 0.3180712777641299, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.065971975543102e-05, 'l1_Layer_2': 9.052997445940259e-05, 'l1_Layer_3': 0.0001168252152821321, 'n_units_Layer_1': 200, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.41 | sMAPE for Validation Set is: 45.25% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 37.99 | sMAPE for Test Set is: 47.13% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:38:53,160]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:38:59,941]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:39:02,916]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:39:06,723]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:39:10,166]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:39:17,836]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:39:21,268]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:40:03,569]\u001b[0m Trial 875 finished with value: 8.6992565956507 and parameters: {'n_hidden': 3, 'learning_rate': 0.001061292526903857, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16313507842201874, 'dropout_rate_Layer_2': 0.32538456845694486, 'dropout_rate_Layer_3': 0.3126340634513268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4117011090894153e-05, 'l1_Layer_2': 3.2476620025109426e-05, 'l1_Layer_3': 0.00018709989268689219, 'n_units_Layer_1': 220, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.70 | sMAPE for Validation Set is: 44.88% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.35 | sMAPE for Test Set is: 30.40% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:40:24,791]\u001b[0m Trial 876 finished with value: 8.899228987216107 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010445046377183282, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13460537964868471, 'dropout_rate_Layer_2': 0.3002445537028395, 'dropout_rate_Layer_3': 0.3141071490605095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.464747242714212e-05, 'l1_Layer_2': 7.302346042243654e-05, 'l1_Layer_3': 0.00019133706939849173, 'n_units_Layer_1': 220, 'n_units_Layer_2': 145, 'n_units_Layer_3': 280}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.90 | sMAPE for Validation Set is: 44.42% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.18 | sMAPE for Test Set is: 31.47% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:40:52,717]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:40:57,070]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:41:06,670]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:41:37,135]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:41:53,360]\u001b[0m Trial 881 finished with value: 8.496785747515887 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027854769481127617, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1960956974824641, 'dropout_rate_Layer_2': 0.0007300322846078185, 'dropout_rate_Layer_3': 0.2266550683243725, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.023290226267708e-05, 'l1_Layer_2': 8.766833103635837e-05, 'l1_Layer_3': 0.0002843190567049477, 'n_units_Layer_1': 290, 'n_units_Layer_2': 210, 'n_units_Layer_3': 295}. Best is trial 785 with value: 8.47526021193495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.50 | sMAPE for Validation Set is: 43.92% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.83 | sMAPE for Test Set is: 30.19% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:41:57,245]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:42:11,607]\u001b[0m Trial 883 finished with value: 8.387230977266334 and parameters: {'n_hidden': 3, 'learning_rate': 0.002655927193549233, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19056236167518187, 'dropout_rate_Layer_2': 0.009549748915819709, 'dropout_rate_Layer_3': 0.2188708489916738, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6572724217990736e-05, 'l1_Layer_2': 8.508684155451626e-05, 'l1_Layer_3': 0.000298379847014947, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 270}. Best is trial 883 with value: 8.387230977266334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 42.26% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.35 | sMAPE for Test Set is: 28.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:42:21,238]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:42:25,029]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:42:28,459]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:42:50,754]\u001b[0m Trial 887 finished with value: 8.88876829917744 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015339897503819186, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14305148884330848, 'dropout_rate_Layer_2': 0.2887246764046427, 'dropout_rate_Layer_3': 0.312404818496441, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.627994621186149e-05, 'l1_Layer_2': 7.253080326587413e-05, 'l1_Layer_3': 0.00023422073835848247, 'n_units_Layer_1': 230, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 883 with value: 8.387230977266334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.89 | sMAPE for Validation Set is: 46.54% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.97 | sMAPE for Test Set is: 30.37% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:42:54,031]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:42:57,654]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:43:01,014]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:43:23,395]\u001b[0m Trial 891 finished with value: 8.963706358089668 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014233773258460073, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13795375567131576, 'dropout_rate_Layer_2': 0.29021967429628764, 'dropout_rate_Layer_3': 0.30897556309876983, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.8264752603789346e-05, 'l1_Layer_2': 6.976245413776223e-05, 'l1_Layer_3': 0.00019085882020110115, 'n_units_Layer_1': 230, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 883 with value: 8.387230977266334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.96 | sMAPE for Validation Set is: 45.40% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.07 | sMAPE for Test Set is: 30.53% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:43:29,197]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:43:32,604]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:44:28,663]\u001b[0m Trial 894 finished with value: 8.530181336528385 and parameters: {'n_hidden': 3, 'learning_rate': 0.001561555380861439, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13640812116195236, 'dropout_rate_Layer_2': 0.2816259556692481, 'dropout_rate_Layer_3': 0.3125518459633636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.055148913109139e-05, 'l1_Layer_2': 7.37767726670865e-05, 'l1_Layer_3': 0.00023096222738514598, 'n_units_Layer_1': 230, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 883 with value: 8.387230977266334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 42.36% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.81 | sMAPE for Test Set is: 30.15% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:44:32,594]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:44:51,691]\u001b[0m Trial 896 finished with value: 8.40226402439004 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025211437848087796, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1628374656589071, 'dropout_rate_Layer_2': 0.05855458484219199, 'dropout_rate_Layer_3': 0.2859248827654792, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0520437776653352e-05, 'l1_Layer_2': 7.56586119612627e-05, 'l1_Layer_3': 0.0003562968194143707, 'n_units_Layer_1': 170, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295}. Best is trial 883 with value: 8.387230977266334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 40.34% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.79 | sMAPE for Test Set is: 29.30% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:44:55,454]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:45:15,699]\u001b[0m Trial 898 finished with value: 8.877728958671174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014818524904047564, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1259850425812669, 'dropout_rate_Layer_2': 0.28479304144237044, 'dropout_rate_Layer_3': 0.3098105140708319, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.430684759062771e-05, 'l1_Layer_2': 7.370406944944742e-05, 'l1_Layer_3': 0.00020050041052522118, 'n_units_Layer_1': 230, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 883 with value: 8.387230977266334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 46.48% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.98 | sMAPE for Test Set is: 31.84% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:45:19,305]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:45:28,375]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:46:42,200]\u001b[0m Trial 901 finished with value: 8.365227526624167 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014888253020488504, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12589463641991816, 'dropout_rate_Layer_2': 0.28246256171249706, 'dropout_rate_Layer_3': 0.2966934989195528, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.557048279066796e-05, 'l1_Layer_2': 7.34000575465621e-05, 'l1_Layer_3': 0.00023583166685322394, 'n_units_Layer_1': 230, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 901 with value: 8.365227526624167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 41.63% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.71 | sMAPE for Test Set is: 28.21% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:47:25,822]\u001b[0m Trial 902 finished with value: 8.567442037119092 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015620279005959304, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11855649674919105, 'dropout_rate_Layer_2': 0.28145103797644005, 'dropout_rate_Layer_3': 0.30555660071852464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.784258544445749e-05, 'l1_Layer_2': 7.194628848814309e-05, 'l1_Layer_3': 0.00025292921492225495, 'n_units_Layer_1': 230, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 901 with value: 8.365227526624167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 42.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.62 | sMAPE for Test Set is: 29.09% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:47:29,205]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:47:32,695]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:47:36,037]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:47:48,263]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:48:38,634]\u001b[0m Trial 907 finished with value: 8.508995118120144 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016348862635808196, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11650474391879125, 'dropout_rate_Layer_2': 0.2841353923982978, 'dropout_rate_Layer_3': 0.30689755822517734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.161419652761512e-05, 'l1_Layer_2': 7.327481780254631e-05, 'l1_Layer_3': 0.0002302967164480763, 'n_units_Layer_1': 230, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 901 with value: 8.365227526624167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.51 | sMAPE for Validation Set is: 41.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.19 | sMAPE for Test Set is: 28.37% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:49:08,650]\u001b[0m Trial 908 finished with value: 8.390683266869162 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024428164520674334, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1696485710875595, 'dropout_rate_Layer_2': 0.05335149396481122, 'dropout_rate_Layer_3': 0.27859459079677157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8093257752692173e-05, 'l1_Layer_2': 6.707366467229439e-05, 'l1_Layer_3': 0.00033868430297196497, 'n_units_Layer_1': 170, 'n_units_Layer_2': 205, 'n_units_Layer_3': 290}. Best is trial 901 with value: 8.365227526624167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 41.04% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.27 | sMAPE for Test Set is: 28.61% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:49:12,935]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:49:19,120]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:49:23,592]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:49:27,059]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:49:32,651]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:49:49,359]\u001b[0m Trial 914 finished with value: 9.178531213087846 and parameters: {'n_hidden': 3, 'learning_rate': 0.00162020790228556, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11768808549890941, 'dropout_rate_Layer_2': 0.2857493990012646, 'dropout_rate_Layer_3': 0.2924054268423519, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.918107813274362e-05, 'l1_Layer_2': 7.991742906197448e-05, 'l1_Layer_3': 0.00024313531721463936, 'n_units_Layer_1': 230, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 901 with value: 8.365227526624167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.18 | sMAPE for Validation Set is: 47.50% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.96 | sMAPE for Test Set is: 33.34% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:49:53,118]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:49:56,743]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:50:00,078]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:50:42,425]\u001b[0m Trial 918 finished with value: 8.598594422490926 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015894352136420174, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1174833493613447, 'dropout_rate_Layer_2': 0.2810005368149774, 'dropout_rate_Layer_3': 0.2981000487660204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.0221705432558206e-05, 'l1_Layer_2': 8.170952139898455e-05, 'l1_Layer_3': 0.00024232888413785813, 'n_units_Layer_1': 230, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 901 with value: 8.365227526624167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.60 | sMAPE for Validation Set is: 45.19% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 21.68 | sMAPE for Test Set is: 29.17% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:50:47,525]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:50:51,276]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:50:54,514]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:50:59,985]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:51:04,097]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:51:07,792]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:51:11,793]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:51:16,014]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:51:19,767]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:51:23,826]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:51:27,526]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:51:30,825]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:51:34,807]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:51:37,776]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:51:57,378]\u001b[0m Trial 933 finished with value: 8.866741213463973 and parameters: {'n_hidden': 3, 'learning_rate': 0.001611324673340543, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11166891041521808, 'dropout_rate_Layer_2': 0.2746806212258308, 'dropout_rate_Layer_3': 0.29535483217441894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.420607098652765e-05, 'l1_Layer_2': 7.450115648161403e-05, 'l1_Layer_3': 0.00023058941171772609, 'n_units_Layer_1': 225, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 901 with value: 8.365227526624167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.87 | sMAPE for Validation Set is: 44.15% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.54 | sMAPE for Test Set is: 30.79% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:52:03,644]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:52:51,574]\u001b[0m Trial 935 finished with value: 8.613675587517498 and parameters: {'n_hidden': 3, 'learning_rate': 0.001587395305661596, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11386266256883665, 'dropout_rate_Layer_2': 0.2758982344361177, 'dropout_rate_Layer_3': 0.29390423906859026, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.442521241159874e-05, 'l1_Layer_2': 7.634605751228949e-05, 'l1_Layer_3': 0.00023493191120439332, 'n_units_Layer_1': 225, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 901 with value: 8.365227526624167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 43.29% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 21.18 | sMAPE for Test Set is: 29.11% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:52:55,798]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:52:59,078]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:53:08,500]\u001b[0m Trial 938 finished with value: 10.994250920029181 and parameters: {'n_hidden': 4, 'learning_rate': 0.002479935542990288, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25328295501730813, 'dropout_rate_Layer_2': 0.30619597672854654, 'dropout_rate_Layer_3': 0.29790422335295996, 'dropout_rate_Layer_4': 0.087645663758181, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005864678758556075, 'l1_Layer_2': 2.44742513316823e-05, 'l1_Layer_3': 0.00024396870693058108, 'l1_Layer_4': 2.0987966872459823e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 75, 'n_units_Layer_3': 280, 'n_units_Layer_4': 250}. Best is trial 901 with value: 8.365227526624167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.99 | sMAPE for Validation Set is: 51.81% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 37.32 | sMAPE for Test Set is: 46.60% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:53:12,320]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:53:15,539]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:53:18,904]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:53:22,952]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:53:26,039]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:53:29,572]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:53:33,408]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:53:36,984]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:53:41,191]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:53:44,915]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:53:57,452]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:54:00,722]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:54:20,795]\u001b[0m Trial 951 finished with value: 8.504013107367475 and parameters: {'n_hidden': 3, 'learning_rate': 0.002457626835613918, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16322231106270393, 'dropout_rate_Layer_2': 0.057600351636453134, 'dropout_rate_Layer_3': 0.2866833130670871, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0544051774037516e-05, 'l1_Layer_2': 7.296377191765843e-05, 'l1_Layer_3': 0.000359725103251253, 'n_units_Layer_1': 165, 'n_units_Layer_2': 205, 'n_units_Layer_3': 270}. Best is trial 901 with value: 8.365227526624167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.50 | sMAPE for Validation Set is: 41.63% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.97 | sMAPE for Test Set is: 30.04% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:54:26,842]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:54:46,207]\u001b[0m Trial 953 finished with value: 8.327045231787979 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025631308804495725, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15718926668637814, 'dropout_rate_Layer_2': 0.05620366532341849, 'dropout_rate_Layer_3': 0.27662161172311467, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.757056052327098e-05, 'l1_Layer_2': 7.14675112109041e-05, 'l1_Layer_3': 0.0003883749803886699, 'n_units_Layer_1': 165, 'n_units_Layer_2': 205, 'n_units_Layer_3': 270}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 41.12% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.87 | sMAPE for Test Set is: 29.61% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:55:01,146]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:55:19,216]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:55:22,563]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:55:53,903]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:55:58,635]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:56:02,708]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:56:25,646]\u001b[0m Trial 960 finished with value: 8.905682874379218 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015123317293522398, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11277652548859401, 'dropout_rate_Layer_2': 0.2923588045851191, 'dropout_rate_Layer_3': 0.29586933436252616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.76983938853314e-05, 'l1_Layer_2': 9.795440353128254e-05, 'l1_Layer_3': 0.000317179795362643, 'n_units_Layer_1': 230, 'n_units_Layer_2': 130, 'n_units_Layer_3': 270}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.91 | sMAPE for Validation Set is: 44.30% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.66 | sMAPE for Test Set is: 29.42% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:56:31,138]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:56:34,617]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:56:48,407]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:56:52,944]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:56:59,704]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:57:11,154]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:57:32,558]\u001b[0m Trial 967 finished with value: 8.849041404994402 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019553868784263277, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.100266247867589, 'dropout_rate_Layer_2': 0.29182752915012256, 'dropout_rate_Layer_3': 0.2910169318649924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.9773378419001816e-05, 'l1_Layer_2': 0.00012227684969521167, 'l1_Layer_3': 0.00020547610233687024, 'n_units_Layer_1': 220, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.85 | sMAPE for Validation Set is: 45.09% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.89 | sMAPE for Test Set is: 29.68% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:57:36,829]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:57:41,623]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:57:45,076]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:57:48,673]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:57:52,265]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:57:55,878]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:58:15,631]\u001b[0m Trial 974 finished with value: 8.3860162554177 and parameters: {'n_hidden': 3, 'learning_rate': 0.002510557999552176, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16890250792348777, 'dropout_rate_Layer_2': 0.0573064499641502, 'dropout_rate_Layer_3': 0.28868412157130985, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7205951854276272e-05, 'l1_Layer_2': 6.639650781576019e-05, 'l1_Layer_3': 0.0003555423787331573, 'n_units_Layer_1': 165, 'n_units_Layer_2': 205, 'n_units_Layer_3': 265}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 42.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.01 | sMAPE for Test Set is: 29.77% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:58:52,076]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:58:55,532]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:58:58,971]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:59:11,761]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:59:33,614]\u001b[0m Trial 979 finished with value: 8.910570650897442 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019540952120115523, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09974139105681062, 'dropout_rate_Layer_2': 0.2834842380574973, 'dropout_rate_Layer_3': 0.2925469086177929, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.374936396513534e-05, 'l1_Layer_2': 7.581452658848526e-05, 'l1_Layer_3': 0.0002958529633837365, 'n_units_Layer_1': 225, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.91 | sMAPE for Validation Set is: 43.70% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.42 | sMAPE for Test Set is: 28.91% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 02:59:37,222]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:59:40,965]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:59:44,931]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 02:59:49,483]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:00:20,139]\u001b[0m Trial 984 finished with value: 8.426170233841033 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027000544660211643, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19232484817881018, 'dropout_rate_Layer_2': 0.04532316049071605, 'dropout_rate_Layer_3': 0.28102292235710913, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5738407441484886e-05, 'l1_Layer_2': 2.0647262830934294e-05, 'l1_Layer_3': 0.0008099456763700461, 'n_units_Layer_1': 150, 'n_units_Layer_2': 215, 'n_units_Layer_3': 165}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.43 | sMAPE for Validation Set is: 42.00% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.49 | sMAPE for Test Set is: 28.96% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:00:24,524]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:00:28,349]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:00:32,873]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:00:36,426]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:00:41,544]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:01:12,944]\u001b[0m Trial 990 finished with value: 8.395692085497144 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021119011722292207, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17547965740684107, 'dropout_rate_Layer_2': 0.06028351244817283, 'dropout_rate_Layer_3': 0.28897781305915665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.58953153269101e-05, 'l1_Layer_2': 1.4795545776649702e-05, 'l1_Layer_3': 0.0007987584425031784, 'n_units_Layer_1': 140, 'n_units_Layer_2': 220, 'n_units_Layer_3': 165}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 42.19% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.14 | sMAPE for Test Set is: 29.38% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:01:16,412]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:01:23,167]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:01:27,033]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:01:30,464]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:01:34,524]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:01:55,845]\u001b[0m Trial 996 finished with value: 8.910642324546101 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014183720209906398, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12660756447107696, 'dropout_rate_Layer_2': 0.2723647636233334, 'dropout_rate_Layer_3': 0.30786941446003047, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.539940774872274e-05, 'l1_Layer_2': 7.558894400053213e-05, 'l1_Layer_3': 0.0002263975868297765, 'n_units_Layer_1': 220, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.91 | sMAPE for Validation Set is: 46.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.21 | sMAPE for Test Set is: 30.62% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:02:29,373]\u001b[0m Trial 997 finished with value: 8.719790807545476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014176562102952708, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12954037637365204, 'dropout_rate_Layer_2': 0.26924336026795664, 'dropout_rate_Layer_3': 0.2779059420151338, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.9560304771621264e-05, 'l1_Layer_2': 7.211589017018936e-05, 'l1_Layer_3': 0.00023322546616749322, 'n_units_Layer_1': 220, 'n_units_Layer_2': 125, 'n_units_Layer_3': 280}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.72 | sMAPE for Validation Set is: 43.16% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 21.90 | sMAPE for Test Set is: 30.24% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:02:33,080]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:02:37,744]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:02:40,938]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:03:07,210]\u001b[0m Trial 1001 finished with value: 8.831752408739169 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013977812618203723, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12481586360428559, 'dropout_rate_Layer_2': 0.2705629448173313, 'dropout_rate_Layer_3': 0.2951275540376158, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5590580304532756e-05, 'l1_Layer_2': 7.297842230883481e-05, 'l1_Layer_3': 0.0002449492674737158, 'n_units_Layer_1': 220, 'n_units_Layer_2': 120, 'n_units_Layer_3': 280}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.83 | sMAPE for Validation Set is: 47.58% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 21.45 | sMAPE for Test Set is: 29.72% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:03:40,049]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:04:13,637]\u001b[0m Trial 1003 finished with value: 9.218599285745272 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008694430103261467, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2325540401340989, 'dropout_rate_Layer_2': 0.2997296953504827, 'dropout_rate_Layer_3': 0.17810916935530197, 'dropout_rate_Layer_4': 0.19591984976934637, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.008783859168644324, 'l1_Layer_2': 1.3941347124602704e-05, 'l1_Layer_3': 1.8783749985606123e-05, 'l1_Layer_4': 0.0007371981867007384, 'n_units_Layer_1': 165, 'n_units_Layer_2': 205, 'n_units_Layer_3': 150, 'n_units_Layer_4': 55}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.22 | sMAPE for Validation Set is: 44.24% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 32.03 | sMAPE for Test Set is: 39.08% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:04:20,354]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:04:25,842]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:04:29,341]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:04:42,274]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:04:45,914]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:05:00,084]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:05:22,343]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:05:29,051]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:05:32,525]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:05:36,639]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:06:30,122]\u001b[0m Trial 1014 finished with value: 8.581384718069183 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016232445282662428, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13124284748669168, 'dropout_rate_Layer_2': 0.2802487782200838, 'dropout_rate_Layer_3': 0.29799478860892176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.818090265803714e-05, 'l1_Layer_2': 7.045465098546027e-05, 'l1_Layer_3': 0.0003768888373924735, 'n_units_Layer_1': 225, 'n_units_Layer_2': 110, 'n_units_Layer_3': 275}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.58 | sMAPE for Validation Set is: 42.07% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 21.63 | sMAPE for Test Set is: 29.20% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:06:42,800]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:06:58,586]\u001b[0m Trial 1016 finished with value: 8.436640338677199 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036086494871877977, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.141577183892556, 'dropout_rate_Layer_2': 0.043842245141724454, 'dropout_rate_Layer_3': 0.3125456325774432, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0034639432602636e-05, 'l1_Layer_2': 1.1234027810952002e-05, 'l1_Layer_3': 0.0003782543192710178, 'n_units_Layer_1': 135, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 42.56% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.35 | sMAPE for Test Set is: 28.87% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:07:20,642]\u001b[0m Trial 1017 finished with value: 8.878556984579925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015307140673353975, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12041169915069717, 'dropout_rate_Layer_2': 0.28542869334526433, 'dropout_rate_Layer_3': 0.2829764296704894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.902871190765906e-05, 'l1_Layer_2': 6.720872825039843e-05, 'l1_Layer_3': 0.00023876460971636142, 'n_units_Layer_1': 235, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 44.16% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 25.32 | sMAPE for Test Set is: 34.89% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:07:57,449]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:08:12,765]\u001b[0m Trial 1019 finished with value: 10.857008511083704 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022134272313776623, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013998203378057641, 'dropout_rate_Layer_2': 0.39302098468497915, 'dropout_rate_Layer_3': 0.2942216004445253, 'dropout_rate_Layer_4': 0.02707505466546329, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.2048545248745185e-05, 'l1_Layer_2': 0.00010707165754307631, 'l1_Layer_3': 0.0007855009428136591, 'l1_Layer_4': 2.5374349622098347e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 80, 'n_units_Layer_3': 285, 'n_units_Layer_4': 230}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.86 | sMAPE for Validation Set is: 51.11% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 40.02 | sMAPE for Test Set is: 51.17% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:08:33,318]\u001b[0m Trial 1020 finished with value: 8.93553789047571 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015337880240456933, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11976344343185588, 'dropout_rate_Layer_2': 0.28531789226577786, 'dropout_rate_Layer_3': 0.28324023209912635, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.866070034635592e-05, 'l1_Layer_2': 1.5536281693929188e-05, 'l1_Layer_3': 0.00021767101243012356, 'n_units_Layer_1': 235, 'n_units_Layer_2': 105, 'n_units_Layer_3': 275}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.94 | sMAPE for Validation Set is: 46.89% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.76 | sMAPE for Test Set is: 31.35% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:09:01,207]\u001b[0m Trial 1021 finished with value: 8.416145380380232 and parameters: {'n_hidden': 3, 'learning_rate': 0.002621113702980029, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16994831624876344, 'dropout_rate_Layer_2': 0.021623194694606426, 'dropout_rate_Layer_3': 0.2538904195770876, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5605347639944986e-05, 'l1_Layer_2': 2.319971388709278e-05, 'l1_Layer_3': 0.0010349331244164331, 'n_units_Layer_1': 190, 'n_units_Layer_2': 185, 'n_units_Layer_3': 165}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.42 | sMAPE for Validation Set is: 41.39% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.39 | sMAPE for Test Set is: 28.65% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:09:05,114]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:09:09,216]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:09:13,122]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:09:33,982]\u001b[0m Trial 1025 finished with value: 8.928992138086379 and parameters: {'n_hidden': 3, 'learning_rate': 0.001440087519435099, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12907748130198943, 'dropout_rate_Layer_2': 0.2938706925328396, 'dropout_rate_Layer_3': 0.2816198673643288, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.191311323008647e-05, 'l1_Layer_2': 2.2142145568624177e-05, 'l1_Layer_3': 0.000210411931105113, 'n_units_Layer_1': 235, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 45.03% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 26.07 | sMAPE for Test Set is: 36.10% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:09:37,466]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:09:48,621]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:10:03,569]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:10:07,032]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:10:10,506]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:10:18,869]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:10:24,208]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:10:29,842]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:10:33,581]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:10:37,380]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:10:40,710]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:10:59,194]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:11:46,686]\u001b[0m Trial 1038 finished with value: 8.545152088014916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014784032884769956, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12629964088371207, 'dropout_rate_Layer_2': 0.27326840411843095, 'dropout_rate_Layer_3': 0.2803911050273686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.99227241216358e-05, 'l1_Layer_2': 1.2126187345897963e-05, 'l1_Layer_3': 0.00033297254513119746, 'n_units_Layer_1': 235, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.55 | sMAPE for Validation Set is: 43.74% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.06 | sMAPE for Test Set is: 28.76% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:11:51,084]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:11:56,647]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:12:01,903]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:12:05,163]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:12:09,251]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:12:12,650]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:12:16,994]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:12:30,065]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:12:33,646]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:12:38,128]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:12:41,544]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:12:46,065]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:12:50,551]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:12:56,162]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:13:00,206]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:13:11,571]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:13:48,360]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:13:53,898]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:13:59,515]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:14:25,426]\u001b[0m Trial 1058 finished with value: 8.424203788300936 and parameters: {'n_hidden': 3, 'learning_rate': 0.002777802113013263, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14156152137564948, 'dropout_rate_Layer_2': 0.041138822532915696, 'dropout_rate_Layer_3': 0.2727067814880149, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5672180968460793e-05, 'l1_Layer_2': 2.4680787551326343e-05, 'l1_Layer_3': 0.0007040904371166293, 'n_units_Layer_1': 150, 'n_units_Layer_2': 220, 'n_units_Layer_3': 165}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.42 | sMAPE for Validation Set is: 40.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.41 | sMAPE for Test Set is: 28.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:14:42,847]\u001b[0m Trial 1059 finished with value: 8.931910703141957 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020977886660055716, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11437420015483124, 'dropout_rate_Layer_2': 0.2626606911777079, 'dropout_rate_Layer_3': 0.30053603751300584, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.25846099908713e-05, 'l1_Layer_2': 2.193124012599279e-05, 'l1_Layer_3': 0.0002671608305406697, 'n_units_Layer_1': 235, 'n_units_Layer_2': 105, 'n_units_Layer_3': 275}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 47.12% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.83 | sMAPE for Test Set is: 29.58% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:15:16,197]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:15:23,017]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:15:26,499]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:15:30,729]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:15:34,121]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:15:37,935]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:15:41,720]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:15:45,102]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:15:49,415]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:15:52,820]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:15:56,660]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:16:13,805]\u001b[0m Trial 1071 finished with value: 8.850526362116947 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015808239831063265, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12946903055081885, 'dropout_rate_Layer_2': 0.279739997521391, 'dropout_rate_Layer_3': 0.3043314482181938, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.166464489062421e-05, 'l1_Layer_2': 3.1097805498664545e-05, 'l1_Layer_3': 0.00035734284871334285, 'n_units_Layer_1': 225, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.85 | sMAPE for Validation Set is: 45.48% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.02 | sMAPE for Test Set is: 31.41% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:16:16,990]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:17:06,419]\u001b[0m Trial 1073 finished with value: 8.530740514951468 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015864080915748704, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13057714799865414, 'dropout_rate_Layer_2': 0.28031938499929526, 'dropout_rate_Layer_3': 0.3039805285462082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.416317968964564e-05, 'l1_Layer_2': 2.258691847607697e-05, 'l1_Layer_3': 0.00045895222016345777, 'n_units_Layer_1': 225, 'n_units_Layer_2': 110, 'n_units_Layer_3': 275}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 41.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.77 | sMAPE for Test Set is: 29.27% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:17:11,026]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:17:18,489]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:17:22,108]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:17:26,559]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:17:30,224]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:17:33,710]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:17:37,137]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:17:40,958]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:17:45,379]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:17:48,512]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:17:52,468]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:18:20,672]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:18:43,308]\u001b[0m Trial 1086 finished with value: 8.734798150972127 and parameters: {'n_hidden': 3, 'learning_rate': 0.002105215247015, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10905689002195576, 'dropout_rate_Layer_2': 0.27639637261507455, 'dropout_rate_Layer_3': 0.27548693830213433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.32330597687959e-05, 'l1_Layer_2': 1.946889446760638e-05, 'l1_Layer_3': 0.00034406301828475487, 'n_units_Layer_1': 230, 'n_units_Layer_2': 105, 'n_units_Layer_3': 275}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.73 | sMAPE for Validation Set is: 43.25% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.68 | sMAPE for Test Set is: 30.85% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:18:48,055]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:18:51,837]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:19:05,183]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:20:16,606]\u001b[0m Trial 1090 finished with value: 8.489029264662591 and parameters: {'n_hidden': 3, 'learning_rate': 0.002120621915242306, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10970316079833782, 'dropout_rate_Layer_2': 0.2723696005228016, 'dropout_rate_Layer_3': 0.2950499356669676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.233219449835567e-05, 'l1_Layer_2': 2.000046719943502e-05, 'l1_Layer_3': 0.0003629551601295477, 'n_units_Layer_1': 220, 'n_units_Layer_2': 100, 'n_units_Layer_3': 270}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 43.72% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.85 | sMAPE for Test Set is: 29.27% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:20:20,440]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:20:23,947]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:20:27,687]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:20:31,177]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:20:34,632]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:20:38,182]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:20:41,681]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:20:49,776]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:21:13,051]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:21:35,197]\u001b[0m Trial 1100 finished with value: 8.42246123350368 and parameters: {'n_hidden': 3, 'learning_rate': 0.003812349488898946, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15239152046329, 'dropout_rate_Layer_2': 0.018918119223655352, 'dropout_rate_Layer_3': 0.2540231684673788, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1708877092247013e-05, 'l1_Layer_2': 3.633320590395562e-05, 'l1_Layer_3': 0.0006398116235821451, 'n_units_Layer_1': 160, 'n_units_Layer_2': 225, 'n_units_Layer_3': 190}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.42 | sMAPE for Validation Set is: 41.40% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.77 | sMAPE for Test Set is: 29.33% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:21:45,088]\u001b[0m Trial 1101 finished with value: 11.199870101934025 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038787926817902482, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18086823394553758, 'dropout_rate_Layer_2': 0.021519515146506765, 'dropout_rate_Layer_3': 0.24524448387097036, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.192518522775154e-05, 'l1_Layer_2': 3.33676118128878e-05, 'l1_Layer_3': 0.00041962118992838255, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 180}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.20 | sMAPE for Validation Set is: 52.45% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 36.51 | sMAPE for Test Set is: 45.41% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:21:49,097]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:21:53,252]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:21:57,744]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:22:01,678]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:22:05,372]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:22:24,915]\u001b[0m Trial 1107 finished with value: 8.8072256542258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018433252082838162, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0994801167259046, 'dropout_rate_Layer_2': 0.27387396140528014, 'dropout_rate_Layer_3': 0.27712630057307536, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.403103845025369e-05, 'l1_Layer_2': 1.999739636209459e-05, 'l1_Layer_3': 0.00033104603293891493, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 270}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.81 | sMAPE for Validation Set is: 46.82% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.79 | sMAPE for Test Set is: 32.39% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:22:31,386]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:22:35,177]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:22:39,760]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:22:43,241]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:23:21,980]\u001b[0m Trial 1112 finished with value: 8.341500898121597 and parameters: {'n_hidden': 3, 'learning_rate': 0.004054155509630054, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1569692784829572, 'dropout_rate_Layer_2': 0.03801802749019384, 'dropout_rate_Layer_3': 0.25817715335550157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9647072359206557e-05, 'l1_Layer_2': 5.780575685873765e-05, 'l1_Layer_3': 0.0006611810647579938, 'n_units_Layer_1': 125, 'n_units_Layer_2': 190, 'n_units_Layer_3': 195}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 39.65% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.10 | sMAPE for Test Set is: 30.02% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:23:25,510]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:23:29,420]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:23:34,156]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:23:37,658]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:23:42,341]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:24:00,724]\u001b[0m Trial 1118 finished with value: 11.927127963422956 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018108260887924426, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16746465676866382, 'dropout_rate_Layer_2': 0.39284128931362805, 'dropout_rate_Layer_3': 0.2721838467187345, 'dropout_rate_Layer_4': 0.029206063711767125, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002774772010438575, 'l1_Layer_2': 0.009756563967264887, 'l1_Layer_3': 2.624586301435288e-05, 'l1_Layer_4': 3.4986089963179186e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 300, 'n_units_Layer_4': 210}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.93 | sMAPE for Validation Set is: 55.52% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 36.10 | sMAPE for Test Set is: 44.79% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:24:06,167]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:24:10,067]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:24:13,711]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:24:17,065]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:24:20,891]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:25:35,212]\u001b[0m Trial 1124 finished with value: 8.446375351912076 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017188715276869133, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10815985824294451, 'dropout_rate_Layer_2': 0.2567884002301724, 'dropout_rate_Layer_3': 0.27458219535825473, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.607077805508809e-05, 'l1_Layer_2': 1.802829379026412e-05, 'l1_Layer_3': 0.00045552422661410943, 'n_units_Layer_1': 225, 'n_units_Layer_2': 80, 'n_units_Layer_3': 270}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.45 | sMAPE for Validation Set is: 42.85% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 20.86 | sMAPE for Test Set is: 28.55% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:25:39,200]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:25:42,852]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:25:46,515]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:25:51,035]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:25:55,797]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:26:12,067]\u001b[0m Trial 1130 finished with value: 8.49573025510144 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031922064315818596, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16655125642526147, 'dropout_rate_Layer_2': 0.0703150125128528, 'dropout_rate_Layer_3': 0.2567156140802798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0469636704935573e-05, 'l1_Layer_2': 5.8317676389103206e-05, 'l1_Layer_3': 0.0003521730802684329, 'n_units_Layer_1': 110, 'n_units_Layer_2': 190, 'n_units_Layer_3': 230}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.50 | sMAPE for Validation Set is: 40.64% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.93 | sMAPE for Test Set is: 29.60% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:26:15,623]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:26:19,215]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:26:23,814]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:26:27,099]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:26:32,611]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:26:36,294]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:26:39,641]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:26:46,056]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:27:06,989]\u001b[0m Trial 1139 finished with value: 8.851089640657106 and parameters: {'n_hidden': 3, 'learning_rate': 0.001694929998542588, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09934936492540551, 'dropout_rate_Layer_2': 0.25474903520752473, 'dropout_rate_Layer_3': 0.2932437024046672, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.7463237566948355e-05, 'l1_Layer_2': 1.9469271996658564e-05, 'l1_Layer_3': 0.0003474770509059611, 'n_units_Layer_1': 225, 'n_units_Layer_2': 65, 'n_units_Layer_3': 270}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.85 | sMAPE for Validation Set is: 45.62% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 24.05 | sMAPE for Test Set is: 32.67% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:27:28,176]\u001b[0m Trial 1140 finished with value: 8.967995391067191 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016738543439617393, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09003192363062788, 'dropout_rate_Layer_2': 0.257539644141838, 'dropout_rate_Layer_3': 0.27511400575606954, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.826857773360246e-05, 'l1_Layer_2': 2.457825891888056e-05, 'l1_Layer_3': 0.0004600968192691279, 'n_units_Layer_1': 230, 'n_units_Layer_2': 65, 'n_units_Layer_3': 270}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.97 | sMAPE for Validation Set is: 46.50% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.89 | sMAPE for Test Set is: 32.28% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:27:32,691]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:27:39,349]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:27:45,126]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:27:49,216]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:28:34,338]\u001b[0m Trial 1145 finished with value: 8.536190940577368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017647716508829557, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11121955819837669, 'dropout_rate_Layer_2': 0.2553210615352014, 'dropout_rate_Layer_3': 0.2635297489311008, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.878802294480376e-05, 'l1_Layer_2': 1.8956144434664694e-05, 'l1_Layer_3': 0.00034070370629309593, 'n_units_Layer_1': 225, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.54 | sMAPE for Validation Set is: 42.08% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.20 | sMAPE for Test Set is: 28.55% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:28:37,755]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:28:42,040]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:28:46,548]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:28:50,233]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:28:53,548]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:28:57,177]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:29:02,854]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:29:06,201]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:29:24,821]\u001b[0m Trial 1154 finished with value: 8.990151482790418 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016298688081191324, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11932532012541014, 'dropout_rate_Layer_2': 0.25288052141189227, 'dropout_rate_Layer_3': 0.2768814657213051, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.310676577096239e-05, 'l1_Layer_2': 1.308305998738177e-05, 'l1_Layer_3': 0.00035656374110378024, 'n_units_Layer_1': 225, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.99 | sMAPE for Validation Set is: 44.45% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 25.58 | sMAPE for Test Set is: 35.89% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:29:38,565]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:30:21,901]\u001b[0m Trial 1156 finished with value: 8.3822452775712 and parameters: {'n_hidden': 3, 'learning_rate': 0.002440921362016051, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12874563979714082, 'dropout_rate_Layer_2': 0.03992671454828782, 'dropout_rate_Layer_3': 0.3012565643039448, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.266497470504663e-05, 'l1_Layer_2': 1.4877713295010812e-05, 'l1_Layer_3': 0.0010563155917764592, 'n_units_Layer_1': 125, 'n_units_Layer_2': 155, 'n_units_Layer_3': 120}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.38 | sMAPE for Validation Set is: 39.73% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.27 | sMAPE for Test Set is: 28.58% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:30:25,201]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:30:29,813]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:30:32,979]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:30:45,609]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:30:50,462]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:30:53,787]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:30:57,971]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:01,537]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:04,847]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:08,133]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:11,380]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:14,779]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:19,430]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:26,933]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:31,330]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:34,753]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:38,564]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:41,905]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:45,699]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:48,900]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:31:52,472]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:32:16,360]\u001b[0m Trial 1178 finished with value: 8.97812025141936 and parameters: {'n_hidden': 3, 'learning_rate': 0.001311464950132684, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1389624092623974, 'dropout_rate_Layer_2': 0.2595580885862418, 'dropout_rate_Layer_3': 0.29658166953903786, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.447853275915034e-05, 'l1_Layer_2': 2.394448993037992e-05, 'l1_Layer_3': 0.00040757731198555724, 'n_units_Layer_1': 285, 'n_units_Layer_2': 110, 'n_units_Layer_3': 275}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.98 | sMAPE for Validation Set is: 47.99% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.85 | sMAPE for Test Set is: 29.55% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:32:19,277]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:32:23,970]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:32:27,944]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:32:32,008]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:32:35,307]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:32:38,440]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:32:42,153]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:32:45,476]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:33:44,303]\u001b[0m Trial 1187 finished with value: 8.68558113141838 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005056459889035491, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21677390015252884, 'dropout_rate_Layer_2': 0.31465282015180723, 'dropout_rate_Layer_3': 0.18913992089270182, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005956854488933332, 'l1_Layer_2': 1.1478220269546447e-05, 'l1_Layer_3': 0.00010411595214290792, 'n_units_Layer_1': 135, 'n_units_Layer_2': 205, 'n_units_Layer_3': 215}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.69 | sMAPE for Validation Set is: 41.86% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 32.57 | sMAPE for Test Set is: 39.38% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:34:09,469]\u001b[0m Trial 1188 finished with value: 8.489375138192289 and parameters: {'n_hidden': 3, 'learning_rate': 0.001876959253788739, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13564771753849308, 'dropout_rate_Layer_2': 0.04984956453034124, 'dropout_rate_Layer_3': 0.301754966097343, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.392159792802432e-05, 'l1_Layer_2': 1.39635214364872e-05, 'l1_Layer_3': 0.0005061438628009079, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 85}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 40.58% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.73 | sMAPE for Test Set is: 29.59% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:34:12,625]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:34:16,776]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:34:19,903]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:34:42,011]\u001b[0m Trial 1192 finished with value: 8.860642470149747 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026273306600809007, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10352614118757501, 'dropout_rate_Layer_2': 0.2714485825907467, 'dropout_rate_Layer_3': 0.2774444366172059, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.470344482687749e-05, 'l1_Layer_2': 2.6753974569548214e-05, 'l1_Layer_3': 0.0005475961778987296, 'n_units_Layer_1': 220, 'n_units_Layer_2': 60, 'n_units_Layer_3': 100}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.86 | sMAPE for Validation Set is: 45.47% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 24.48 | sMAPE for Test Set is: 32.70% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:34:45,833]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:34:49,547]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:34:54,049]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:35:04,205]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:35:07,505]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:35:10,952]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:35:14,710]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:35:20,368]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:35:31,311]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:35:43,080]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:35:46,901]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:35:51,334]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:35:54,676]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:35:58,367]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:36:05,274]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:36:36,027]\u001b[0m Trial 1208 finished with value: 8.393505034147656 and parameters: {'n_hidden': 3, 'learning_rate': 0.002381006854704505, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18260059410081206, 'dropout_rate_Layer_2': 0.037380023213207346, 'dropout_rate_Layer_3': 0.2644368260357481, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4865048031227043e-05, 'l1_Layer_2': 1.550194228772242e-05, 'l1_Layer_3': 0.0008642788154420611, 'n_units_Layer_1': 190, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 41.47% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.43 | sMAPE for Test Set is: 28.94% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:36:39,616]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:36:43,688]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:36:47,040]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:36:57,355]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:37:20,435]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:37:46,897]\u001b[0m Trial 1214 finished with value: 8.347504946245996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030265849452598076, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1568313485610392, 'dropout_rate_Layer_2': 0.0640254136552994, 'dropout_rate_Layer_3': 0.28886995672714993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.299511067908131e-05, 'l1_Layer_2': 1.741043303221668e-05, 'l1_Layer_3': 0.0004262087569062691, 'n_units_Layer_1': 140, 'n_units_Layer_2': 170, 'n_units_Layer_3': 145}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 40.79% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.31 | sMAPE for Test Set is: 30.11% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:37:50,940]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:38:08,489]\u001b[0m Trial 1216 finished with value: 8.473385709658707 and parameters: {'n_hidden': 3, 'learning_rate': 0.003098321102910146, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18341041146958711, 'dropout_rate_Layer_2': 0.06623581150391691, 'dropout_rate_Layer_3': 0.29440792719562786, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.960444790000973e-05, 'l1_Layer_2': 1.4046071973495015e-05, 'l1_Layer_3': 0.0008581164990472639, 'n_units_Layer_1': 145, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.47 | sMAPE for Validation Set is: 42.48% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.94 | sMAPE for Test Set is: 29.28% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:38:12,057]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:39:19,296]\u001b[0m Trial 1218 finished with value: 8.720021852863644 and parameters: {'n_hidden': 3, 'learning_rate': 0.000510993901531741, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24783300603861572, 'dropout_rate_Layer_2': 0.31526374133684415, 'dropout_rate_Layer_3': 0.17314642889006668, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003466018840198197, 'l1_Layer_2': 1.1935427493122122e-05, 'l1_Layer_3': 7.476036184321455e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 205, 'n_units_Layer_3': 250}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.72 | sMAPE for Validation Set is: 42.43% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 33.26 | sMAPE for Test Set is: 40.14% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:39:22,645]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:39:26,058]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:39:29,254]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:39:33,569]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:40:58,659]\u001b[0m Trial 1223 finished with value: 8.804970264422085 and parameters: {'n_hidden': 3, 'learning_rate': 0.00051844457107361, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24806752423693582, 'dropout_rate_Layer_2': 0.31285479654124404, 'dropout_rate_Layer_3': 0.17413758593499665, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0035573294752898497, 'l1_Layer_2': 1.1326404327931302e-05, 'l1_Layer_3': 9.762508086347014e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 200, 'n_units_Layer_3': 230}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.80 | sMAPE for Validation Set is: 42.32% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 32.24 | sMAPE for Test Set is: 38.87% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:41:02,294]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:41:12,255]\u001b[0m Trial 1225 finished with value: 11.18514755297504 and parameters: {'n_hidden': 3, 'learning_rate': 0.002218010787639976, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1532305178869519, 'dropout_rate_Layer_2': 0.037558687055169696, 'dropout_rate_Layer_3': 0.27634757013651284, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5717549305952006e-05, 'l1_Layer_2': 1.0389265398680692e-05, 'l1_Layer_3': 0.00045662229148689035, 'n_units_Layer_1': 120, 'n_units_Layer_2': 110, 'n_units_Layer_3': 140}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.19 | sMAPE for Validation Set is: 52.00% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 38.66 | sMAPE for Test Set is: 48.50% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:42:47,222]\u001b[0m Trial 1226 finished with value: 8.77078397063215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005049611076746119, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2504033536804119, 'dropout_rate_Layer_2': 0.31066512883756703, 'dropout_rate_Layer_3': 0.17344180037855106, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032630182265176, 'l1_Layer_2': 1.735134504220893e-05, 'l1_Layer_3': 9.821622720797215e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.77 | sMAPE for Validation Set is: 41.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 32.56 | sMAPE for Test Set is: 39.23% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:43:32,048]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:43:35,815]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:43:44,075]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:44:05,942]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:44:09,701]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:44:13,905]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:44:17,223]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:44:21,319]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:44:24,857]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:44:53,779]\u001b[0m Trial 1236 finished with value: 8.873650051131222 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018837616490247832, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12046501475082316, 'dropout_rate_Layer_2': 0.28448762157653346, 'dropout_rate_Layer_3': 0.30319041745011405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.467754718044919e-05, 'l1_Layer_2': 1.3628787979513459e-05, 'l1_Layer_3': 0.0002502034310874971, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 275}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.87 | sMAPE for Validation Set is: 44.14% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.79 | sMAPE for Test Set is: 32.84% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:45:04,187]\u001b[0m Trial 1237 finished with value: 11.03564212198709 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023779052940599795, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3501695007146991, 'dropout_rate_Layer_2': 0.3998681044616742, 'dropout_rate_Layer_3': 0.20608580459017706, 'dropout_rate_Layer_4': 0.057962911019924436, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00022058367788423326, 'l1_Layer_2': 0.0005884730265074191, 'l1_Layer_3': 0.00026661791040288266, 'l1_Layer_4': 2.1696195733046237e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 70, 'n_units_Layer_3': 300, 'n_units_Layer_4': 160}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.04 | sMAPE for Validation Set is: 52.26% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 37.61 | sMAPE for Test Set is: 46.94% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:45:07,984]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:45:11,812]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:45:14,801]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:45:22,770]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:45:30,708]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:45:34,624]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:45:39,101]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:45:43,531]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:45:59,999]\u001b[0m Trial 1246 finished with value: 8.413587370808605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033684773133866555, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17720678700128728, 'dropout_rate_Layer_2': 0.05158193104598863, 'dropout_rate_Layer_3': 0.2406898633077726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5417862076359812e-05, 'l1_Layer_2': 1.880995170045831e-05, 'l1_Layer_3': 0.00023439795585558981, 'n_units_Layer_1': 140, 'n_units_Layer_2': 180, 'n_units_Layer_3': 130}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.41 | sMAPE for Validation Set is: 40.69% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.26 | sMAPE for Test Set is: 29.71% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:46:03,441]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:47:04,701]\u001b[0m Trial 1248 finished with value: 8.670315269558943 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005015557708853214, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25434231051343736, 'dropout_rate_Layer_2': 0.28168402126820713, 'dropout_rate_Layer_3': 0.17663458812448865, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006180652511789351, 'l1_Layer_2': 1.6059425227174232e-05, 'l1_Layer_3': 0.0001062936114538762, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 260}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.67 | sMAPE for Validation Set is: 42.42% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 31.78 | sMAPE for Test Set is: 38.33% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:47:09,248]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:47:14,232]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:47:17,759]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:47:46,212]\u001b[0m Trial 1252 finished with value: 8.96109435012635 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017452996991134799, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10403412018659136, 'dropout_rate_Layer_2': 0.2815380517041769, 'dropout_rate_Layer_3': 0.30383377120330346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.029754743330731e-05, 'l1_Layer_2': 1.5385388231019614e-05, 'l1_Layer_3': 0.0006232953019852056, 'n_units_Layer_1': 215, 'n_units_Layer_2': 85, 'n_units_Layer_3': 120}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.96 | sMAPE for Validation Set is: 47.08% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.13 | sMAPE for Test Set is: 29.75% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:47:51,208]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:47:55,551]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:48:59,003]\u001b[0m Trial 1255 finished with value: 8.719473299780304 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005094062232331684, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2538128391029504, 'dropout_rate_Layer_2': 0.2967614298015935, 'dropout_rate_Layer_3': 0.17578342769676186, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005815923267743032, 'l1_Layer_2': 1.0088734281308199e-05, 'l1_Layer_3': 0.0001968118253140158, 'n_units_Layer_1': 145, 'n_units_Layer_2': 195, 'n_units_Layer_3': 235}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.72 | sMAPE for Validation Set is: 42.32% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 30.95 | sMAPE for Test Set is: 37.26% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:49:05,086]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:49:09,515]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:49:25,011]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:49:28,536]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:49:31,848]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:49:35,552]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:49:39,042]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:49:44,249]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:50:15,524]\u001b[0m Trial 1264 finished with value: 8.583959478769684 and parameters: {'n_hidden': 3, 'learning_rate': 0.001545244394118429, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0975034252254195, 'dropout_rate_Layer_2': 0.2824499680427194, 'dropout_rate_Layer_3': 0.27621263453203176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.235162073339642e-05, 'l1_Layer_2': 3.1382110199586705e-05, 'l1_Layer_3': 0.0003924098973177882, 'n_units_Layer_1': 215, 'n_units_Layer_2': 120, 'n_units_Layer_3': 280}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.58 | sMAPE for Validation Set is: 44.41% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 21.67 | sMAPE for Test Set is: 29.14% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:50:52,171]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:50:56,627]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:51:00,518]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:51:03,737]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:51:07,676]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:51:29,319]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:51:32,734]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:51:36,506]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:52:31,371]\u001b[0m Trial 1273 finished with value: 8.726272650921963 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005016076466258075, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23658175895980268, 'dropout_rate_Layer_2': 0.27872982746139197, 'dropout_rate_Layer_3': 0.15837746997583002, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009998730114173075, 'l1_Layer_2': 2.038136311360954e-05, 'l1_Layer_3': 0.0002285598513503889, 'n_units_Layer_1': 120, 'n_units_Layer_2': 195, 'n_units_Layer_3': 230}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.73 | sMAPE for Validation Set is: 41.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 30.46 | sMAPE for Test Set is: 36.92% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:52:35,007]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:52:38,962]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:53:22,649]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:53:30,094]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:53:33,913]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:53:38,451]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:53:43,023]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:54:07,970]\u001b[0m Trial 1281 finished with value: 8.410586125185658 and parameters: {'n_hidden': 3, 'learning_rate': 0.001873429789361783, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11660403780483455, 'dropout_rate_Layer_2': 0.0785625027265226, 'dropout_rate_Layer_3': 0.270304149941886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.972074038846155e-05, 'l1_Layer_2': 2.7218575329579583e-05, 'l1_Layer_3': 0.001880719846054619, 'n_units_Layer_1': 130, 'n_units_Layer_2': 160, 'n_units_Layer_3': 145}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.41 | sMAPE for Validation Set is: 41.07% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.74 | sMAPE for Test Set is: 29.03% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:54:44,254]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:55:21,734]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:55:31,831]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:05,637]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:08,943]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:12,464]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:18,248]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:22,140]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:27,704]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:32,675]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:37,011]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:40,068]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:44,930]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:48,661]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:53,396]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:56:57,316]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:57:21,228]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:57:24,774]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:57:28,600]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:57:31,954]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:57:35,900]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:58:48,059]\u001b[0m Trial 1303 finished with value: 8.777815383394753 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005037600141831406, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23372532723889583, 'dropout_rate_Layer_2': 0.30537503321634507, 'dropout_rate_Layer_3': 0.1407621744555167, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006908426417111472, 'l1_Layer_2': 1.0013141175797581e-05, 'l1_Layer_3': 0.00013015527645754708, 'n_units_Layer_1': 115, 'n_units_Layer_2': 190, 'n_units_Layer_3': 265}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.78 | sMAPE for Validation Set is: 41.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 31.16 | sMAPE for Test Set is: 37.67% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 03:58:52,810]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:58:56,154]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:59:31,865]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:59:46,249]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:59:49,793]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:59:54,063]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 03:59:58,365]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:00:02,925]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:00:06,919]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:00:10,297]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:00:14,150]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:00:18,375]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:00:28,848]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:00:32,567]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:00:40,889]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:01:14,400]\u001b[0m Trial 1319 finished with value: 8.46028960811602 and parameters: {'n_hidden': 3, 'learning_rate': 0.002986325069347442, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.146058404399528, 'dropout_rate_Layer_2': 0.04845884409461844, 'dropout_rate_Layer_3': 0.29963321979343666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8184275024105548e-05, 'l1_Layer_2': 4.9883120977205585e-05, 'l1_Layer_3': 0.0010043362634574006, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 215}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 41.06% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.43 | sMAPE for Test Set is: 28.74% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:01:18,753]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:01:22,160]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:01:26,537]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:01:29,962]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:01:45,067]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:01:49,711]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:01:53,488]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:02:39,950]\u001b[0m Trial 1327 finished with value: 8.548792924688664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014843841433602207, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12254729488452143, 'dropout_rate_Layer_2': 0.2608606777662936, 'dropout_rate_Layer_3': 0.2839733078034948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.656441623340958e-05, 'l1_Layer_2': 1.4306430220225547e-05, 'l1_Layer_3': 0.000976780984462051, 'n_units_Layer_1': 225, 'n_units_Layer_2': 115, 'n_units_Layer_3': 275}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.55 | sMAPE for Validation Set is: 43.33% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.74 | sMAPE for Test Set is: 29.65% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:02:55,238]\u001b[0m Trial 1328 finished with value: 8.46034420499258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025344758695107117, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15820872660695257, 'dropout_rate_Layer_2': 0.06260026908631286, 'dropout_rate_Layer_3': 0.2828014213878086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3325851744913735e-05, 'l1_Layer_2': 6.20613671351198e-05, 'l1_Layer_3': 0.0003078481725542076, 'n_units_Layer_1': 175, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 43.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.99 | sMAPE for Test Set is: 31.05% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:03:16,233]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:03:19,963]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:03:24,560]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:03:32,236]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:03:39,659]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:04:02,751]\u001b[0m Trial 1334 finished with value: 8.878358204907348 and parameters: {'n_hidden': 3, 'learning_rate': 0.002224378347997354, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10657361322684525, 'dropout_rate_Layer_2': 0.24109283947781507, 'dropout_rate_Layer_3': 0.2809976638709517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.690049385109992e-05, 'l1_Layer_2': 1.7722001784509983e-05, 'l1_Layer_3': 0.0007302308541475266, 'n_units_Layer_1': 215, 'n_units_Layer_2': 115, 'n_units_Layer_3': 270}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 45.64% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.19 | sMAPE for Test Set is: 30.29% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:04:07,673]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:04:11,168]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:04:33,500]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:04:40,992]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:04:44,784]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:04:48,766]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:04:52,612]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:05:05,080]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:05:08,616]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:05:16,996]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:05:21,692]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:05:53,815]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:05:57,114]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:06:00,516]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:06:03,973]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:06:09,201]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:06:12,890]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:06:16,218]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:06:19,630]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:06:25,352]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:06:36,757]\u001b[0m Trial 1355 finished with value: 10.93251305121012 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026827637252646785, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3272774566900969, 'dropout_rate_Layer_2': 0.38527125315930716, 'dropout_rate_Layer_3': 0.3099258945587888, 'dropout_rate_Layer_4': 0.07579452456750425, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.0601010593214163e-05, 'l1_Layer_2': 0.001141257793313019, 'l1_Layer_3': 1.4612802190637091e-05, 'l1_Layer_4': 0.0002391689930076591, 'n_units_Layer_1': 110, 'n_units_Layer_2': 70, 'n_units_Layer_3': 235, 'n_units_Layer_4': 195}. Best is trial 953 with value: 8.327045231787979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.93 | sMAPE for Validation Set is: 51.52% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 39.99 | sMAPE for Test Set is: 50.99% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:06:40,505]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:06:48,373]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:06:55,973]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:07:24,988]\u001b[0m Trial 1359 finished with value: 8.30974347783109 and parameters: {'n_hidden': 3, 'learning_rate': 0.002133829077345962, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1599259217572255, 'dropout_rate_Layer_2': 0.07412902530317136, 'dropout_rate_Layer_3': 0.27568974821644865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2415411953767567e-05, 'l1_Layer_2': 2.1472224034222625e-05, 'l1_Layer_3': 0.00036153816594187196, 'n_units_Layer_1': 140, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.31 | sMAPE for Validation Set is: 39.89% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.63 | sMAPE for Test Set is: 29.28% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:07:28,438]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:07:35,460]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:07:40,638]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:07:45,078]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:07:48,537]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:08:55,322]\u001b[0m Trial 1365 finished with value: 8.736216079266386 and parameters: {'n_hidden': 3, 'learning_rate': 0.000501236157015482, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23790477124956802, 'dropout_rate_Layer_2': 0.2862810323245397, 'dropout_rate_Layer_3': 0.17454269001253336, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005437468427883903, 'l1_Layer_2': 2.737928882050835e-05, 'l1_Layer_3': 0.0005513323931048199, 'n_units_Layer_1': 140, 'n_units_Layer_2': 165, 'n_units_Layer_3': 210}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.74 | sMAPE for Validation Set is: 44.03% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 31.81 | sMAPE for Test Set is: 38.46% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:08:58,886]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:09:12,049]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:10:36,591]\u001b[0m Trial 1368 finished with value: 8.76338880975211 and parameters: {'n_hidden': 3, 'learning_rate': 0.000507368165333514, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23481954280805017, 'dropout_rate_Layer_2': 0.2864576264602089, 'dropout_rate_Layer_3': 0.1747019102689555, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005433015395995586, 'l1_Layer_2': 6.779847418075392e-05, 'l1_Layer_3': 0.000632399574159772, 'n_units_Layer_1': 140, 'n_units_Layer_2': 170, 'n_units_Layer_3': 210}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.76 | sMAPE for Validation Set is: 41.56% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 31.99 | sMAPE for Test Set is: 38.55% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:10:40,972]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:11:09,072]\u001b[0m Trial 1370 finished with value: 8.378236598340568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020869517357117004, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.174093389647045, 'dropout_rate_Layer_2': 0.08607460114598099, 'dropout_rate_Layer_3': 0.27464347141525275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.909144912131483e-05, 'l1_Layer_2': 2.0670277995433043e-05, 'l1_Layer_3': 0.0007614786581880334, 'n_units_Layer_1': 140, 'n_units_Layer_2': 150, 'n_units_Layer_3': 250}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.38 | sMAPE for Validation Set is: 40.82% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.82 | sMAPE for Test Set is: 29.72% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:11:12,749]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:11:16,158]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:11:21,006]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:11:49,207]\u001b[0m Trial 1374 finished with value: 8.313064959248392 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021359862859879355, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1577693666770846, 'dropout_rate_Layer_2': 0.0753643929639291, 'dropout_rate_Layer_3': 0.2744985665311698, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2749829005895492e-05, 'l1_Layer_2': 2.9014487809946656e-05, 'l1_Layer_3': 0.0004715583559347363, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 250}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.31 | sMAPE for Validation Set is: 40.55% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.77 | sMAPE for Test Set is: 29.59% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:12:00,102]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:12:03,546]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:12:26,586]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:12:42,942]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:12:47,443]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:12:51,664]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:13:27,455]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:13:37,273]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:13:50,570]\u001b[0m Trial 1383 finished with value: 10.722384471534687 and parameters: {'n_hidden': 4, 'learning_rate': 0.003800451164671576, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34133324391307823, 'dropout_rate_Layer_2': 0.04169504288504408, 'dropout_rate_Layer_3': 0.09363584368482183, 'dropout_rate_Layer_4': 0.007835192750662795, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.778081880923447e-05, 'l1_Layer_2': 0.00017874826836906645, 'l1_Layer_3': 0.001297404841167942, 'l1_Layer_4': 0.0002734400407286589, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230, 'n_units_Layer_4': 255}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.72 | sMAPE for Validation Set is: 51.30% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 38.55 | sMAPE for Test Set is: 48.36% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:13:54,066]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:14:04,736]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:14:29,562]\u001b[0m Trial 1386 finished with value: 8.416671674496312 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019007877708200175, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16151244507934392, 'dropout_rate_Layer_2': 0.0899671609536147, 'dropout_rate_Layer_3': 0.30751374552990135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.998790055290475e-05, 'l1_Layer_2': 3.8665525209878135e-05, 'l1_Layer_3': 0.00031381748818777626, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.42 | sMAPE for Validation Set is: 41.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.57 | sMAPE for Test Set is: 29.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:14:33,427]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:15:10,252]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:15:14,627]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:15:18,638]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:15:24,362]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:15:28,694]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:15:32,543]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:15:37,138]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:15:41,528]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:16:13,001]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:16:16,453]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:16:20,349]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:16:24,131]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:16:47,811]\u001b[0m Trial 1400 finished with value: 8.983898136518004 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022791775792329874, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11710434181488019, 'dropout_rate_Layer_2': 0.28219429254432077, 'dropout_rate_Layer_3': 0.26962747500905626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.361460102406028e-05, 'l1_Layer_2': 4.23703770115015e-05, 'l1_Layer_3': 0.00023519496108446541, 'n_units_Layer_1': 240, 'n_units_Layer_2': 115, 'n_units_Layer_3': 270}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.98 | sMAPE for Validation Set is: 47.06% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.05 | sMAPE for Test Set is: 29.84% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:16:51,256]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:16:55,795]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:16:59,310]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:17:02,857]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:17:07,404]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:17:12,376]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:17:16,291]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:17:20,883]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:17:25,275]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:17:28,757]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:17:33,614]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:17:37,835]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:17:42,042]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:18:18,324]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:18:22,450]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:18:55,849]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:18:59,283]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:19:02,870]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:19:06,627]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:19:12,076]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:19:40,375]\u001b[0m Trial 1421 finished with value: 9.876930852932517 and parameters: {'n_hidden': 4, 'learning_rate': 0.002142088732120767, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14388188146149478, 'dropout_rate_Layer_2': 0.16452866995788643, 'dropout_rate_Layer_3': 0.11828570923632263, 'dropout_rate_Layer_4': 0.016976140338258998, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000530697284270483, 'l1_Layer_2': 0.0006814048894525355, 'l1_Layer_3': 1.615144578073991e-05, 'l1_Layer_4': 0.0001994575370090518, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 235, 'n_units_Layer_4': 195}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.88 | sMAPE for Validation Set is: 48.25% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 35.05 | sMAPE for Test Set is: 43.16% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:19:58,119]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:20:24,340]\u001b[0m Trial 1423 finished with value: 8.35745662047826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021278300306712358, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15108001475663704, 'dropout_rate_Layer_2': 0.07533854338234344, 'dropout_rate_Layer_3': 0.24369472217831656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4949189840105998e-05, 'l1_Layer_2': 1.942098466889204e-05, 'l1_Layer_3': 0.0006510636211839878, 'n_units_Layer_1': 115, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.36 | sMAPE for Validation Set is: 41.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.79 | sMAPE for Test Set is: 29.12% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:20:30,041]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:20:34,343]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:21:17,132]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:21:20,656]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:22:37,515]\u001b[0m Trial 1428 finished with value: 8.740720390175213 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005068394015655781, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2631443961539642, 'dropout_rate_Layer_2': 0.25624441817749843, 'dropout_rate_Layer_3': 0.19595133683496715, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0041220900838856355, 'l1_Layer_2': 7.088302828752943e-05, 'l1_Layer_3': 0.0001031110483960473, 'n_units_Layer_1': 155, 'n_units_Layer_2': 170, 'n_units_Layer_3': 225}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.74 | sMAPE for Validation Set is: 41.62% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 31.98 | sMAPE for Test Set is: 38.55% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:23:46,117]\u001b[0m Trial 1429 finished with value: 8.70841515166569 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006242180082289214, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2617032340300615, 'dropout_rate_Layer_2': 0.2628899101112196, 'dropout_rate_Layer_3': 0.19664330800415672, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004353884617861495, 'l1_Layer_2': 6.680067535354404e-05, 'l1_Layer_3': 0.0004854119144874215, 'n_units_Layer_1': 150, 'n_units_Layer_2': 170, 'n_units_Layer_3': 225}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.71 | sMAPE for Validation Set is: 41.79% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 33.22 | sMAPE for Test Set is: 40.21% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:23:50,052]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:23:54,092]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:23:58,001]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:24:02,587]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:24:06,639]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:24:10,324]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:24:14,763]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:24:19,656]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:24:41,956]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:24:52,699]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:25:08,784]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:25:13,262]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:25:18,169]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:25:22,099]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:25:26,170]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:25:31,248]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:25:35,019]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:25:38,820]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:25:42,349]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:25:46,583]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:25:51,430]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:25:55,712]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:26:00,098]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:26:36,466]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:26:48,379]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:26:53,072]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:26:56,908]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:28:24,712]\u001b[0m Trial 1457 finished with value: 8.88333420980829 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006055921914432293, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2595912538606638, 'dropout_rate_Layer_2': 0.2810277406639813, 'dropout_rate_Layer_3': 0.2001297499425762, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004414109702880309, 'l1_Layer_2': 6.354538886129092e-05, 'l1_Layer_3': 0.0005441043130441263, 'n_units_Layer_1': 140, 'n_units_Layer_2': 170, 'n_units_Layer_3': 225}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 43.17% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 32.20 | sMAPE for Test Set is: 38.78% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:28:28,371]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:28:32,881]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:28:37,459]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:28:40,858]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:28:44,260]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:29:56,048]\u001b[0m Trial 1463 finished with value: 8.812966331002217 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005657320415265758, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22757832269841563, 'dropout_rate_Layer_2': 0.24807198962918656, 'dropout_rate_Layer_3': 0.18557694324896443, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006148796413378543, 'l1_Layer_2': 5.0374255900177516e-05, 'l1_Layer_3': 0.00031051471135798826, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 200}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.81 | sMAPE for Validation Set is: 42.03% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 32.27 | sMAPE for Test Set is: 38.88% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:30:56,505]\u001b[0m Trial 1464 finished with value: 8.716002290502896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005023194016209378, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25499037577090117, 'dropout_rate_Layer_2': 0.2581954649869298, 'dropout_rate_Layer_3': 0.19442722760306838, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007351438802801383, 'l1_Layer_2': 8.099914249808457e-05, 'l1_Layer_3': 0.00022103462570907168, 'n_units_Layer_1': 145, 'n_units_Layer_2': 170, 'n_units_Layer_3': 230}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.72 | sMAPE for Validation Set is: 42.07% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 31.42 | sMAPE for Test Set is: 37.82% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:31:11,710]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:31:17,243]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:31:32,426]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:31:36,165]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:31:40,108]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:31:44,169]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:31:48,454]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:31:57,242]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:32:25,298]\u001b[0m Trial 1473 finished with value: 8.394047657495422 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027365200050429687, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1474768826667444, 'dropout_rate_Layer_2': 0.051972128798195134, 'dropout_rate_Layer_3': 0.2738242509447715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.121138147482631e-05, 'l1_Layer_2': 3.268369207995092e-05, 'l1_Layer_3': 0.00042770651786084955, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 40.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.14 | sMAPE for Test Set is: 28.53% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:33:32,040]\u001b[0m Trial 1474 finished with value: 8.868750913364531 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005012937625498716, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27993669993868436, 'dropout_rate_Layer_2': 0.29117547055667364, 'dropout_rate_Layer_3': 0.19111664149206206, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0080552170840349, 'l1_Layer_2': 6.941794779822145e-05, 'l1_Layer_3': 0.0003490820109569034, 'n_units_Layer_1': 145, 'n_units_Layer_2': 170, 'n_units_Layer_3': 230}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.87 | sMAPE for Validation Set is: 42.72% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 31.32 | sMAPE for Test Set is: 37.84% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:33:42,787]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:34:28,784]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:34:32,145]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:34:36,215]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:34:40,744]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:34:45,339]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:34:48,992]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:34:53,519]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:34:59,162]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:35:02,728]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:35:06,182]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:35:09,583]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:35:29,812]\u001b[0m Trial 1487 finished with value: 8.418596264812109 and parameters: {'n_hidden': 3, 'learning_rate': 0.00362231058333704, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12212534186726043, 'dropout_rate_Layer_2': 0.07647394551385871, 'dropout_rate_Layer_3': 0.26044027509417955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2709134442031942e-05, 'l1_Layer_2': 1.2358663665800305e-05, 'l1_Layer_3': 0.000540952470442552, 'n_units_Layer_1': 130, 'n_units_Layer_2': 80, 'n_units_Layer_3': 255}. Best is trial 1359 with value: 8.30974347783109.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.42 | sMAPE for Validation Set is: 41.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.57 | sMAPE for Test Set is: 28.90% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 04:35:34,060]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:35:38,214]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:35:42,718]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:35:47,273]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:35:51,512]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:35:55,699]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:35:59,282]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:36:03,396]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:36:06,859]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:36:11,084]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:36:14,507]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 04:36:38,133]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-01-01, MAE is:7.71 & sMAPE is:19.85% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 19.85% & 0.90\n",
      "for 2021-01-02, MAE is:10.66 & sMAPE is:24.79% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :9.19 & 22.32% & 0.67\n",
      "for 2021-01-03, MAE is:12.11 & sMAPE is:36.06% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 26.90% & 0.64\n",
      "for 2021-01-04, MAE is:11.55 & sMAPE is:25.61% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 26.58% & 0.68\n",
      "for 2021-01-05, MAE is:8.94 & sMAPE is:17.63% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 24.79% & 0.76\n",
      "for 2021-01-06, MAE is:5.64 & sMAPE is:13.29% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 22.87% & 0.76\n",
      "for 2021-01-07, MAE is:21.84 & sMAPE is:35.81% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :11.21 & 24.72% & 0.77\n",
      "for 2021-01-08, MAE is:19.09 & sMAPE is:24.38% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :12.19 & 24.68% & 0.73\n",
      "for 2021-01-09, MAE is:3.43 & sMAPE is:6.51% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 22.66% & 0.68\n",
      "for 2021-01-10, MAE is:4.07 & sMAPE is:9.23% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 21.32% & 0.64\n",
      "for 2021-01-11, MAE is:7.72 & sMAPE is:17.94% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 21.01% & 0.64\n",
      "for 2021-01-12, MAE is:11.19 & sMAPE is:26.90% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 21.50% & 0.78\n",
      "for 2021-01-13, MAE is:4.52 & sMAPE is:10.40% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :9.88 & 20.65% & 0.78\n",
      "for 2021-01-14, MAE is:26.88 & sMAPE is:41.20% & rMAE is:4.88 ||| daily mean of MAE & sMAPE & rMAE till now are :11.10 & 22.11% & 1.07\n",
      "for 2021-01-15, MAE is:8.36 & sMAPE is:10.71% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 21.35% & 1.08\n",
      "for 2021-01-16, MAE is:4.75 & sMAPE is:8.21% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 20.53% & 1.08\n",
      "for 2021-01-17, MAE is:4.84 & sMAPE is:8.70% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :10.19 & 19.84% & 1.04\n",
      "for 2021-01-18, MAE is:5.44 & sMAPE is:9.54% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.93 & 19.26% & 1.01\n",
      "for 2021-01-19, MAE is:3.96 & sMAPE is:8.97% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 18.72% & 0.98\n",
      "for 2021-01-20, MAE is:4.55 & sMAPE is:12.26% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 18.40% & 0.97\n",
      "for 2021-01-21, MAE is:8.78 & sMAPE is:24.45% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 18.69% & 0.94\n",
      "for 2021-01-22, MAE is:5.75 & sMAPE is:22.11% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 18.84% & 0.90\n",
      "for 2021-01-23, MAE is:12.58 & sMAPE is:29.90% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 19.32% & 0.91\n",
      "for 2021-01-24, MAE is:6.94 & sMAPE is:15.04% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 19.14% & 0.92\n",
      "for 2021-01-25, MAE is:10.41 & sMAPE is:18.07% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :9.27 & 19.10% & 0.95\n",
      "for 2021-01-26, MAE is:9.58 & sMAPE is:16.25% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 18.99% & 0.94\n",
      "for 2021-01-27, MAE is:6.00 & sMAPE is:10.40% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.16 & 18.67% & 0.91\n",
      "for 2021-01-28, MAE is:6.11 & sMAPE is:10.31% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.05 & 18.38% & 0.89\n",
      "for 2021-01-29, MAE is:5.95 & sMAPE is:10.58% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.94 & 18.11% & 0.87\n",
      "for 2021-01-30, MAE is:5.63 & sMAPE is:11.65% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 17.89% & 0.87\n",
      "for 2021-01-31, MAE is:4.10 & sMAPE is:8.12% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 17.58% & 0.92\n",
      "for 2021-02-01, MAE is:36.28 & sMAPE is:39.17% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 18.25% & 0.93\n",
      "for 2021-02-02, MAE is:14.31 & sMAPE is:19.14% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 18.28% & 0.94\n",
      "for 2021-02-03, MAE is:7.13 & sMAPE is:12.54% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :9.61 & 18.11% & 0.93\n",
      "for 2021-02-04, MAE is:15.63 & sMAPE is:26.80% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.78 & 18.36% & 0.96\n",
      "for 2021-02-05, MAE is:24.93 & sMAPE is:24.17% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 18.52% & 0.97\n",
      "for 2021-02-06, MAE is:4.41 & sMAPE is:9.37% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.05 & 18.27% & 0.97\n",
      "for 2021-02-07, MAE is:2.19 & sMAPE is:5.08% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :9.84 & 17.92% & 0.95\n",
      "for 2021-02-08, MAE is:4.10 & sMAPE is:6.91% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 17.64% & 0.93\n",
      "for 2021-02-09, MAE is:15.68 & sMAPE is:23.32% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.84 & 17.78% & 0.94\n",
      "for 2021-02-10, MAE is:12.25 & sMAPE is:16.67% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.90 & 17.76% & 0.93\n",
      "for 2021-02-11, MAE is:31.82 & sMAPE is:27.20% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 17.98% & 0.93\n",
      "for 2021-02-12, MAE is:24.51 & sMAPE is:25.20% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.75 & 18.15% & 0.96\n",
      "for 2021-02-13, MAE is:9.83 & sMAPE is:19.70% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :10.73 & 18.18% & 0.97\n",
      "for 2021-02-14, MAE is:6.22 & sMAPE is:12.63% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :10.63 & 18.06% & 0.97\n",
      "for 2021-02-15, MAE is:13.77 & sMAPE is:17.16% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.70 & 18.04% & 0.98\n",
      "for 2021-02-16, MAE is:10.73 & sMAPE is:17.62% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :10.70 & 18.03% & 0.99\n",
      "for 2021-02-17, MAE is:8.59 & sMAPE is:15.81% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :10.66 & 17.99% & 0.97\n",
      "for 2021-02-18, MAE is:11.95 & sMAPE is:22.25% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.68 & 18.07% & 0.96\n",
      "for 2021-02-19, MAE is:5.54 & sMAPE is:11.37% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.58 & 17.94% & 0.94\n",
      "for 2021-02-20, MAE is:6.24 & sMAPE is:15.73% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 17.90% & 0.93\n",
      "for 2021-02-21, MAE is:5.72 & sMAPE is:14.58% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 17.83% & 0.92\n",
      "for 2021-02-22, MAE is:7.53 & sMAPE is:15.26% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 17.78% & 0.92\n",
      "for 2021-02-23, MAE is:7.28 & sMAPE is:15.19% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.29 & 17.74% & 0.91\n",
      "for 2021-02-24, MAE is:9.19 & sMAPE is:24.60% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 17.86% & 0.90\n",
      "for 2021-02-25, MAE is:3.99 & sMAPE is:11.21% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 17.74% & 0.89\n",
      "for 2021-02-26, MAE is:4.27 & sMAPE is:14.02% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 17.68% & 0.88\n",
      "for 2021-02-27, MAE is:11.36 & sMAPE is:30.29% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.08 & 17.89% & 0.88\n",
      "for 2021-02-28, MAE is:5.69 & sMAPE is:16.94% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 17.88% & 0.88\n",
      "for 2021-03-01, MAE is:8.75 & sMAPE is:21.61% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :9.98 & 17.94% & 0.88\n",
      "for 2021-03-02, MAE is:14.67 & sMAPE is:31.67% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 18.16% & 0.90\n",
      "for 2021-03-03, MAE is:7.35 & sMAPE is:14.20% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :10.02 & 18.10% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-04, MAE is:9.35 & sMAPE is:18.61% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.01 & 18.11% & 0.88\n",
      "for 2021-03-05, MAE is:4.60 & sMAPE is:8.47% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :9.92 & 17.96% & 0.87\n",
      "for 2021-03-06, MAE is:13.39 & sMAPE is:36.51% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :9.97 & 18.24% & 0.87\n",
      "for 2021-03-07, MAE is:14.12 & sMAPE is:43.33% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.04 & 18.62% & 0.89\n",
      "for 2021-03-08, MAE is:11.17 & sMAPE is:19.20% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :10.05 & 18.63% & 0.89\n",
      "for 2021-03-09, MAE is:6.39 & sMAPE is:9.76% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 18.50% & 0.88\n",
      "for 2021-03-10, MAE is:13.68 & sMAPE is:21.73% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.05 & 18.55% & 0.88\n",
      "for 2021-03-11, MAE is:9.43 & sMAPE is:33.31% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.04 & 18.76% & 0.87\n",
      "for 2021-03-12, MAE is:5.18 & sMAPE is:16.89% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :9.98 & 18.73% & 0.86\n",
      "for 2021-03-13, MAE is:2.25 & sMAPE is:7.02% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 18.57% & 0.86\n",
      "for 2021-03-14, MAE is:6.06 & sMAPE is:17.75% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.82 & 18.56% & 0.85\n",
      "for 2021-03-15, MAE is:7.75 & sMAPE is:16.48% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.79 & 18.53% & 0.85\n",
      "for 2021-03-16, MAE is:8.27 & sMAPE is:15.20% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.77 & 18.49% & 0.86\n",
      "for 2021-03-17, MAE is:7.33 & sMAPE is:12.72% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.74 & 18.41% & 0.85\n",
      "for 2021-03-18, MAE is:5.82 & sMAPE is:8.70% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 18.28% & 0.84\n",
      "for 2021-03-19, MAE is:9.38 & sMAPE is:17.05% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :9.68 & 18.27% & 0.84\n",
      "for 2021-03-20, MAE is:11.09 & sMAPE is:26.99% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.70 & 18.38% & 0.83\n",
      "for 2021-03-21, MAE is:14.05 & sMAPE is:46.93% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 18.74% & 0.84\n",
      "for 2021-03-22, MAE is:11.80 & sMAPE is:24.70% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :9.78 & 18.81% & 0.85\n",
      "for 2021-03-23, MAE is:10.85 & sMAPE is:20.81% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.79 & 18.83% & 0.86\n",
      "for 2021-03-24, MAE is:11.60 & sMAPE is:23.91% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 18.90% & 0.86\n",
      "for 2021-03-25, MAE is:9.89 & sMAPE is:20.30% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 18.91% & 0.86\n",
      "for 2021-03-26, MAE is:10.25 & sMAPE is:23.57% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :9.82 & 18.97% & 0.87\n",
      "for 2021-03-27, MAE is:14.27 & sMAPE is:52.71% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 19.36% & 0.86\n",
      "for 2021-03-28, MAE is:7.07 & sMAPE is:29.46% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.84 & 19.48% & 0.86\n",
      "for 2021-03-29, MAE is:7.14 & sMAPE is:26.75% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 19.56% & 0.85\n",
      "for 2021-03-30, MAE is:17.57 & sMAPE is:48.69% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :9.90 & 19.89% & 0.86\n",
      "for 2021-03-31, MAE is:11.52 & sMAPE is:27.31% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.91 & 19.97% & 0.86\n",
      "for 2021-04-01, MAE is:11.96 & sMAPE is:29.99% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 20.08% & 0.86\n",
      "for 2021-04-02, MAE is:12.72 & sMAPE is:45.62% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :9.97 & 20.36% & 0.86\n",
      "for 2021-04-03, MAE is:9.34 & sMAPE is:30.99% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :9.96 & 20.47% & 0.86\n",
      "for 2021-04-04, MAE is:22.10 & sMAPE is:104.43% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 21.36% & 0.87\n",
      "for 2021-04-05, MAE is:3.61 & sMAPE is:84.37% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.02 & 22.03% & 0.86\n",
      "for 2021-04-06, MAE is:14.45 & sMAPE is:72.38% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 22.55% & 0.87\n",
      "for 2021-04-07, MAE is:8.27 & sMAPE is:21.88% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :10.05 & 22.54% & 0.87\n",
      "for 2021-04-08, MAE is:11.91 & sMAPE is:26.73% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 22.59% & 0.86\n",
      "for 2021-04-09, MAE is:3.67 & sMAPE is:18.09% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 22.54% & 0.86\n",
      "for 2021-04-10, MAE is:24.76 & sMAPE is:70.23% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :10.15 & 23.02% & 0.87\n",
      "for 2021-04-11, MAE is:11.25 & sMAPE is:30.74% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 23.09% & 0.86\n",
      "for 2021-04-12, MAE is:14.16 & sMAPE is:35.22% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 23.21% & 0.86\n",
      "for 2021-04-13, MAE is:15.39 & sMAPE is:35.31% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 23.33% & 0.86\n",
      "for 2021-04-14, MAE is:16.98 & sMAPE is:29.25% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 23.39% & 0.86\n",
      "for 2021-04-15, MAE is:17.87 & sMAPE is:33.59% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :10.39 & 23.49% & 0.86\n",
      "for 2021-04-16, MAE is:12.89 & sMAPE is:27.85% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 23.53% & 0.86\n",
      "for 2021-04-17, MAE is:12.79 & sMAPE is:28.67% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 23.57% & 0.87\n",
      "for 2021-04-18, MAE is:14.95 & sMAPE is:32.15% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :10.48 & 23.65% & 0.87\n",
      "for 2021-04-19, MAE is:8.43 & sMAPE is:18.48% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 23.61% & 0.87\n",
      "for 2021-04-20, MAE is:11.21 & sMAPE is:19.76% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 23.57% & 0.86\n",
      "for 2021-04-21, MAE is:19.73 & sMAPE is:40.07% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :10.55 & 23.72% & 0.87\n",
      "for 2021-04-22, MAE is:12.77 & sMAPE is:48.74% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 23.94% & 0.86\n",
      "for 2021-04-23, MAE is:11.73 & sMAPE is:34.08% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.58 & 24.03% & 0.86\n",
      "for 2021-04-24, MAE is:11.88 & sMAPE is:38.48% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :10.59 & 24.16% & 0.86\n",
      "for 2021-04-25, MAE is:14.28 & sMAPE is:59.54% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.62 & 24.47% & 0.86\n",
      "for 2021-04-26, MAE is:12.61 & sMAPE is:25.56% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.64 & 24.48% & 0.87\n",
      "for 2021-04-27, MAE is:9.01 & sMAPE is:14.96% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.62 & 24.40% & 0.87\n",
      "for 2021-04-28, MAE is:7.78 & sMAPE is:12.80% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.60 & 24.30% & 0.87\n",
      "for 2021-04-29, MAE is:6.18 & sMAPE is:11.65% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.56 & 24.19% & 0.86\n",
      "for 2021-04-30, MAE is:19.18 & sMAPE is:34.32% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :10.63 & 24.28% & 0.86\n",
      "for 2021-05-01, MAE is:3.72 & sMAPE is:6.78% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :10.58 & 24.13% & 0.86\n",
      "for 2021-05-02, MAE is:5.78 & sMAPE is:12.84% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 24.04% & 0.85\n",
      "for 2021-05-03, MAE is:7.51 & sMAPE is:12.33% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 23.94% & 0.85\n",
      "for 2021-05-04, MAE is:8.61 & sMAPE is:20.40% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 23.91% & 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-05, MAE is:9.07 & sMAPE is:22.07% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 23.90% & 0.85\n",
      "for 2021-05-06, MAE is:17.18 & sMAPE is:31.71% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 23.96% & 0.85\n",
      "for 2021-05-07, MAE is:9.05 & sMAPE is:13.84% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 23.88% & 0.85\n",
      "for 2021-05-08, MAE is:6.26 & sMAPE is:14.62% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 23.81% & 0.85\n",
      "for 2021-05-09, MAE is:15.83 & sMAPE is:52.64% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 24.03% & 0.85\n",
      "for 2021-05-10, MAE is:10.95 & sMAPE is:27.03% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 24.06% & 0.85\n",
      "for 2021-05-11, MAE is:11.60 & sMAPE is:30.67% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :10.55 & 24.11% & 0.85\n",
      "for 2021-05-12, MAE is:17.40 & sMAPE is:36.90% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.60 & 24.20% & 0.85\n",
      "for 2021-05-13, MAE is:8.19 & sMAPE is:20.46% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :10.58 & 24.18% & 0.85\n",
      "for 2021-05-14, MAE is:25.29 & sMAPE is:52.60% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.69 & 24.39% & 0.85\n",
      "for 2021-05-15, MAE is:13.96 & sMAPE is:48.98% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.72 & 24.57% & 0.85\n",
      "for 2021-05-16, MAE is:11.04 & sMAPE is:36.22% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :10.72 & 24.66% & 0.85\n",
      "for 2021-05-17, MAE is:22.17 & sMAPE is:39.46% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.80 & 24.76% & 0.86\n",
      "for 2021-05-18, MAE is:21.97 & sMAPE is:39.27% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :10.88 & 24.87% & 0.86\n",
      "for 2021-05-19, MAE is:21.82 & sMAPE is:40.21% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.96 & 24.98% & 0.86\n",
      "for 2021-05-20, MAE is:14.04 & sMAPE is:38.39% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.98 & 25.07% & 0.87\n",
      "for 2021-05-21, MAE is:14.03 & sMAPE is:47.99% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.00 & 25.24% & 0.86\n",
      "for 2021-05-22, MAE is:11.44 & sMAPE is:92.42% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :11.01 & 25.71% & 0.86\n",
      "for 2021-05-23, MAE is:14.55 & sMAPE is:69.06% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :11.03 & 26.01% & 0.87\n",
      "for 2021-05-24, MAE is:7.31 & sMAPE is:17.52% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :11.01 & 25.95% & 0.86\n",
      "for 2021-05-25, MAE is:14.10 & sMAPE is:28.00% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :11.03 & 25.97% & 0.86\n",
      "for 2021-05-26, MAE is:9.44 & sMAPE is:15.23% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :11.02 & 25.90% & 0.86\n",
      "for 2021-05-27, MAE is:15.62 & sMAPE is:24.49% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.05 & 25.89% & 0.86\n",
      "for 2021-05-28, MAE is:9.37 & sMAPE is:13.38% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 25.80% & 0.86\n",
      "for 2021-05-29, MAE is:9.49 & sMAPE is:19.92% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :11.03 & 25.76% & 0.85\n",
      "for 2021-05-30, MAE is:15.77 & sMAPE is:40.52% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 25.86% & 0.85\n",
      "for 2021-05-31, MAE is:14.96 & sMAPE is:29.21% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 25.88% & 0.85\n",
      "for 2021-06-01, MAE is:10.36 & sMAPE is:16.16% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 25.82% & 0.86\n",
      "for 2021-06-02, MAE is:8.67 & sMAPE is:13.86% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 25.74% & 0.86\n",
      "for 2021-06-03, MAE is:5.59 & sMAPE is:9.40% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :11.03 & 25.63% & 0.86\n",
      "for 2021-06-04, MAE is:16.30 & sMAPE is:26.33% & rMAE is:3.56 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 25.64% & 0.87\n",
      "for 2021-06-05, MAE is:4.89 & sMAPE is:7.78% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :11.02 & 25.52% & 0.87\n",
      "for 2021-06-06, MAE is:6.83 & sMAPE is:11.67% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :11.00 & 25.44% & 0.87\n",
      "for 2021-06-07, MAE is:15.13 & sMAPE is:21.81% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :11.02 & 25.41% & 0.87\n",
      "for 2021-06-08, MAE is:7.75 & sMAPE is:10.08% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :11.00 & 25.32% & 0.87\n",
      "for 2021-06-09, MAE is:6.37 & sMAPE is:8.15% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :10.97 & 25.21% & 0.87\n",
      "for 2021-06-10, MAE is:7.85 & sMAPE is:10.14% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.95 & 25.12% & 0.86\n",
      "for 2021-06-11, MAE is:5.79 & sMAPE is:7.41% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 25.01% & 0.86\n",
      "for 2021-06-12, MAE is:37.08 & sMAPE is:85.02% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 25.37% & 0.86\n",
      "for 2021-06-13, MAE is:28.80 & sMAPE is:125.73% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 25.99% & 0.86\n",
      "for 2021-06-14, MAE is:20.69 & sMAPE is:34.05% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :11.25 & 26.04% & 0.87\n",
      "for 2021-06-15, MAE is:10.20 & sMAPE is:15.05% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 25.97% & 0.88\n",
      "for 2021-06-16, MAE is:8.60 & sMAPE is:9.80% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 25.87% & 0.88\n",
      "for 2021-06-17, MAE is:10.94 & sMAPE is:14.58% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 25.80% & 0.88\n",
      "for 2021-06-18, MAE is:12.84 & sMAPE is:17.24% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :11.23 & 25.75% & 0.88\n",
      "for 2021-06-19, MAE is:9.77 & sMAPE is:14.23% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 25.69% & 0.88\n",
      "for 2021-06-20, MAE is:14.00 & sMAPE is:25.53% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 25.69% & 0.88\n",
      "for 2021-06-21, MAE is:6.19 & sMAPE is:8.00% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :11.21 & 25.58% & 0.88\n",
      "for 2021-06-22, MAE is:8.38 & sMAPE is:10.40% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 25.49% & 0.88\n",
      "for 2021-06-23, MAE is:10.27 & sMAPE is:10.32% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 25.41% & 0.88\n",
      "for 2021-06-24, MAE is:11.43 & sMAPE is:12.31% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 25.33% & 0.88\n",
      "for 2021-06-25, MAE is:8.01 & sMAPE is:9.10% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 25.24% & 0.88\n",
      "for 2021-06-26, MAE is:8.24 & sMAPE is:10.42% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 25.16% & 0.88\n",
      "for 2021-06-27, MAE is:12.86 & sMAPE is:21.42% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 25.14% & 0.88\n",
      "for 2021-06-28, MAE is:16.58 & sMAPE is:19.87% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :11.20 & 25.11% & 0.89\n",
      "for 2021-06-29, MAE is:7.52 & sMAPE is:8.23% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 25.01% & 0.89\n",
      "for 2021-06-30, MAE is:5.30 & sMAPE is:5.79% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :11.14 & 24.91% & 0.88\n",
      "for 2021-07-01, MAE is:4.28 & sMAPE is:4.71% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 24.80% & 0.88\n",
      "for 2021-07-02, MAE is:7.82 & sMAPE is:8.17% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :11.09 & 24.70% & 0.89\n",
      "for 2021-07-03, MAE is:8.56 & sMAPE is:10.16% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.07 & 24.63% & 0.89\n",
      "for 2021-07-04, MAE is:5.26 & sMAPE is:6.25% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 24.53% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-05, MAE is:6.03 & sMAPE is:6.68% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :11.02 & 24.43% & 0.89\n",
      "for 2021-07-06, MAE is:18.58 & sMAPE is:26.72% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 24.44% & 0.88\n",
      "for 2021-07-07, MAE is:24.12 & sMAPE is:30.11% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 24.47% & 0.89\n",
      "for 2021-07-08, MAE is:26.77 & sMAPE is:28.78% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :11.21 & 24.50% & 0.89\n",
      "for 2021-07-09, MAE is:10.56 & sMAPE is:15.22% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :11.20 & 24.45% & 0.89\n",
      "for 2021-07-10, MAE is:4.27 & sMAPE is:7.60% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 24.36% & 0.88\n",
      "for 2021-07-11, MAE is:3.61 & sMAPE is:6.50% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 24.27% & 0.88\n",
      "for 2021-07-12, MAE is:17.73 & sMAPE is:22.16% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 24.25% & 0.88\n",
      "for 2021-07-13, MAE is:10.14 & sMAPE is:14.00% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 24.20% & 0.88\n",
      "for 2021-07-14, MAE is:11.29 & sMAPE is:15.04% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 24.15% & 0.88\n",
      "for 2021-07-15, MAE is:15.90 & sMAPE is:21.93% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 24.14% & 0.88\n",
      "for 2021-07-16, MAE is:8.83 & sMAPE is:12.73% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 24.09% & 0.88\n",
      "for 2021-07-17, MAE is:5.55 & sMAPE is:11.18% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :11.14 & 24.02% & 0.88\n",
      "for 2021-07-18, MAE is:12.80 & sMAPE is:44.32% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 24.12% & 0.88\n",
      "for 2021-07-19, MAE is:28.25 & sMAPE is:44.86% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 24.23% & 0.89\n",
      "for 2021-07-20, MAE is:7.47 & sMAPE is:12.51% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 24.17% & 0.89\n",
      "for 2021-07-21, MAE is:4.22 & sMAPE is:7.32% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 24.08% & 0.88\n",
      "for 2021-07-22, MAE is:5.09 & sMAPE is:10.55% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 24.02% & 0.88\n",
      "for 2021-07-23, MAE is:5.62 & sMAPE is:10.88% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 23.95% & 0.88\n",
      "for 2021-07-24, MAE is:3.55 & sMAPE is:6.60% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :11.09 & 23.87% & 0.88\n",
      "for 2021-07-25, MAE is:3.28 & sMAPE is:6.98% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :11.05 & 23.79% & 0.87\n",
      "for 2021-07-26, MAE is:26.88 & sMAPE is:38.53% & rMAE is:3.84 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 23.86% & 0.89\n",
      "for 2021-07-27, MAE is:15.57 & sMAPE is:20.01% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 23.84% & 0.89\n",
      "for 2021-07-28, MAE is:11.37 & sMAPE is:16.16% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 23.80% & 0.89\n",
      "for 2021-07-29, MAE is:10.68 & sMAPE is:20.50% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 23.79% & 0.89\n",
      "for 2021-07-30, MAE is:13.55 & sMAPE is:23.59% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 23.79% & 0.89\n",
      "for 2021-07-31, MAE is:11.90 & sMAPE is:24.42% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 23.79% & 0.89\n",
      "for 2021-08-01, MAE is:8.30 & sMAPE is:14.90% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 23.75% & 0.89\n",
      "for 2021-08-02, MAE is:14.18 & sMAPE is:18.42% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 23.72% & 0.89\n",
      "for 2021-08-03, MAE is:16.26 & sMAPE is:17.92% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 23.70% & 0.89\n",
      "for 2021-08-04, MAE is:12.61 & sMAPE is:13.07% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 23.65% & 0.89\n",
      "for 2021-08-05, MAE is:10.39 & sMAPE is:10.93% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 23.59% & 0.88\n",
      "for 2021-08-06, MAE is:7.13 & sMAPE is:10.04% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 23.53% & 0.88\n",
      "for 2021-08-07, MAE is:5.34 & sMAPE is:8.54% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :11.14 & 23.46% & 0.88\n",
      "for 2021-08-08, MAE is:30.42 & sMAPE is:99.13% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :11.23 & 23.80% & 0.88\n",
      "for 2021-08-09, MAE is:12.93 & sMAPE is:19.40% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 23.78% & 0.88\n",
      "for 2021-08-10, MAE is:13.29 & sMAPE is:15.02% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :11.25 & 23.74% & 0.89\n",
      "for 2021-08-11, MAE is:16.20 & sMAPE is:16.76% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 23.71% & 0.89\n",
      "for 2021-08-12, MAE is:11.30 & sMAPE is:10.25% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 23.65% & 0.89\n",
      "for 2021-08-13, MAE is:10.54 & sMAPE is:11.08% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 23.59% & 0.89\n",
      "for 2021-08-14, MAE is:11.81 & sMAPE is:17.34% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 23.57% & 0.89\n",
      "for 2021-08-15, MAE is:9.03 & sMAPE is:13.51% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 23.52% & 0.89\n",
      "for 2021-08-16, MAE is:10.59 & sMAPE is:13.40% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 23.48% & 0.88\n",
      "for 2021-08-17, MAE is:11.23 & sMAPE is:16.97% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 23.45% & 0.88\n",
      "for 2021-08-18, MAE is:9.16 & sMAPE is:12.44% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :11.25 & 23.40% & 0.88\n",
      "for 2021-08-19, MAE is:17.52 & sMAPE is:19.82% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :11.28 & 23.39% & 0.88\n",
      "for 2021-08-20, MAE is:8.91 & sMAPE is:8.87% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 23.32% & 0.88\n",
      "for 2021-08-21, MAE is:9.24 & sMAPE is:10.20% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 23.27% & 0.88\n",
      "for 2021-08-22, MAE is:12.46 & sMAPE is:15.17% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 23.23% & 0.88\n",
      "for 2021-08-23, MAE is:10.84 & sMAPE is:11.79% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 23.18% & 0.88\n",
      "for 2021-08-24, MAE is:20.18 & sMAPE is:21.21% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 23.18% & 0.88\n",
      "for 2021-08-25, MAE is:13.87 & sMAPE is:21.16% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :11.31 & 23.17% & 0.88\n",
      "for 2021-08-26, MAE is:19.10 & sMAPE is:23.08% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :11.34 & 23.17% & 0.88\n",
      "for 2021-08-27, MAE is:13.10 & sMAPE is:16.41% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :11.35 & 23.14% & 0.88\n",
      "for 2021-08-28, MAE is:5.97 & sMAPE is:7.21% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :11.33 & 23.07% & 0.88\n",
      "for 2021-08-29, MAE is:4.41 & sMAPE is:5.20% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 23.00% & 0.88\n",
      "for 2021-08-30, MAE is:19.77 & sMAPE is:19.51% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :11.33 & 22.98% & 0.89\n",
      "for 2021-08-31, MAE is:13.65 & sMAPE is:12.80% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :11.34 & 22.94% & 0.89\n",
      "for 2021-09-01, MAE is:22.59 & sMAPE is:21.71% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :11.39 & 22.94% & 0.89\n",
      "for 2021-09-02, MAE is:17.90 & sMAPE is:15.75% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :11.41 & 22.91% & 0.89\n",
      "for 2021-09-03, MAE is:13.62 & sMAPE is:12.42% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :11.42 & 22.86% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-04, MAE is:13.69 & sMAPE is:12.77% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :11.43 & 22.82% & 0.89\n",
      "for 2021-09-05, MAE is:13.28 & sMAPE is:13.71% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :11.44 & 22.79% & 0.89\n",
      "for 2021-09-06, MAE is:21.76 & sMAPE is:16.93% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :11.48 & 22.76% & 0.89\n",
      "for 2021-09-07, MAE is:14.55 & sMAPE is:11.17% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :11.49 & 22.72% & 0.89\n",
      "for 2021-09-08, MAE is:13.94 & sMAPE is:11.30% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :11.50 & 22.67% & 0.89\n",
      "for 2021-09-09, MAE is:18.54 & sMAPE is:14.58% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :11.53 & 22.64% & 0.89\n",
      "for 2021-09-10, MAE is:13.63 & sMAPE is:10.36% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :11.54 & 22.59% & 0.89\n",
      "for 2021-09-11, MAE is:11.41 & sMAPE is:8.93% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :11.54 & 22.54% & 0.89\n",
      "for 2021-09-12, MAE is:17.55 & sMAPE is:16.54% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :11.56 & 22.51% & 0.89\n",
      "for 2021-09-13, MAE is:29.63 & sMAPE is:21.81% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :11.63 & 22.51% & 0.90\n",
      "for 2021-09-14, MAE is:16.98 & sMAPE is:11.81% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :11.65 & 22.47% & 0.90\n",
      "for 2021-09-15, MAE is:37.58 & sMAPE is:25.38% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :11.76 & 22.48% & 0.90\n",
      "for 2021-09-16, MAE is:25.51 & sMAPE is:17.19% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :11.81 & 22.46% & 0.90\n",
      "for 2021-09-17, MAE is:21.65 & sMAPE is:15.38% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :11.85 & 22.43% & 0.90\n",
      "for 2021-09-18, MAE is:19.32 & sMAPE is:16.28% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :11.87 & 22.41% & 0.90\n",
      "for 2021-09-19, MAE is:22.39 & sMAPE is:21.50% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :11.91 & 22.41% & 0.91\n",
      "for 2021-09-20, MAE is:36.77 & sMAPE is:26.70% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :12.01 & 22.42% & 0.91\n",
      "for 2021-09-21, MAE is:18.44 & sMAPE is:13.45% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :12.03 & 22.39% & 0.91\n",
      "for 2021-09-22, MAE is:28.27 & sMAPE is:19.57% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :12.09 & 22.38% & 0.91\n",
      "for 2021-09-23, MAE is:45.96 & sMAPE is:53.35% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :12.22 & 22.49% & 0.91\n",
      "for 2021-09-24, MAE is:22.70 & sMAPE is:30.74% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :12.26 & 22.52% & 0.91\n",
      "for 2021-09-25, MAE is:36.61 & sMAPE is:33.47% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :12.35 & 22.57% & 0.91\n",
      "for 2021-09-26, MAE is:18.04 & sMAPE is:15.94% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :12.37 & 22.54% & 0.91\n",
      "for 2021-09-27, MAE is:28.85 & sMAPE is:21.88% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :12.43 & 22.54% & 0.91\n",
      "for 2021-09-28, MAE is:35.42 & sMAPE is:23.80% & rMAE is:2.86 ||| daily mean of MAE & sMAPE & rMAE till now are :12.52 & 22.54% & 0.92\n",
      "for 2021-09-29, MAE is:27.66 & sMAPE is:23.57% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :12.58 & 22.55% & 0.92\n",
      "for 2021-09-30, MAE is:23.44 & sMAPE is:26.20% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :12.61 & 22.56% & 0.92\n",
      "for 2021-10-01, MAE is:19.09 & sMAPE is:34.54% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :12.64 & 22.60% & 0.92\n",
      "for 2021-10-02, MAE is:23.89 & sMAPE is:37.68% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :12.68 & 22.66% & 0.92\n",
      "for 2021-10-03, MAE is:46.72 & sMAPE is:156.70% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :12.80 & 23.14% & 0.92\n",
      "for 2021-10-04, MAE is:110.02 & sMAPE is:132.12% & rMAE is:2.51 ||| daily mean of MAE & sMAPE & rMAE till now are :13.15 & 23.54% & 0.92\n",
      "for 2021-10-05, MAE is:38.96 & sMAPE is:32.98% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :13.25 & 23.57% & 0.92\n",
      "for 2021-10-06, MAE is:44.35 & sMAPE is:44.56% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :13.36 & 23.65% & 0.92\n",
      "for 2021-10-07, MAE is:126.31 & sMAPE is:73.26% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :13.76 & 23.82% & 0.92\n",
      "for 2021-10-08, MAE is:37.73 & sMAPE is:20.86% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :13.85 & 23.81% & 0.92\n",
      "for 2021-10-09, MAE is:38.81 & sMAPE is:40.48% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :13.94 & 23.87% & 0.92\n",
      "for 2021-10-10, MAE is:17.80 & sMAPE is:42.07% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :13.95 & 23.94% & 0.92\n",
      "for 2021-10-11, MAE is:37.33 & sMAPE is:42.12% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :14.03 & 24.00% & 0.92\n",
      "for 2021-10-12, MAE is:53.18 & sMAPE is:49.17% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :14.17 & 24.09% & 0.92\n",
      "for 2021-10-13, MAE is:59.21 & sMAPE is:42.77% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :14.33 & 24.15% & 0.92\n",
      "for 2021-10-14, MAE is:63.95 & sMAPE is:61.39% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :14.50 & 24.28% & 0.92\n",
      "for 2021-10-15, MAE is:27.34 & sMAPE is:87.26% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :14.54 & 24.50% & 0.92\n",
      "for 2021-10-16, MAE is:16.59 & sMAPE is:116.80% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :14.55 & 24.82% & 0.92\n",
      "for 2021-10-17, MAE is:53.88 & sMAPE is:100.77% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :14.69 & 25.08% & 0.92\n",
      "for 2021-10-18, MAE is:76.94 & sMAPE is:66.67% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :14.90 & 25.23% & 0.92\n",
      "for 2021-10-19, MAE is:34.70 & sMAPE is:27.98% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :14.97 & 25.24% & 0.92\n",
      "for 2021-10-20, MAE is:49.57 & sMAPE is:98.34% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :15.09 & 25.49% & 0.92\n",
      "for 2021-10-21, MAE is:19.84 & sMAPE is:47.29% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :15.10 & 25.56% & 0.91\n",
      "for 2021-10-22, MAE is:17.04 & sMAPE is:55.77% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :15.11 & 25.66% & 0.92\n",
      "for 2021-10-23, MAE is:59.70 & sMAPE is:106.88% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :15.26 & 25.94% & 0.92\n",
      "for 2021-10-24, MAE is:45.86 & sMAPE is:59.74% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :15.36 & 26.05% & 0.92\n",
      "for 2021-10-25, MAE is:37.75 & sMAPE is:52.46% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :15.44 & 26.14% & 0.92\n",
      "for 2021-10-26, MAE is:43.57 & sMAPE is:30.48% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :15.53 & 26.15% & 0.92\n",
      "for 2021-10-27, MAE is:47.01 & sMAPE is:102.06% & rMAE is:3.22 ||| daily mean of MAE & sMAPE & rMAE till now are :15.64 & 26.41% & 0.93\n",
      "for 2021-10-28, MAE is:30.21 & sMAPE is:62.93% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :15.69 & 26.53% & 0.93\n",
      "for 2021-10-29, MAE is:26.54 & sMAPE is:48.34% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :15.72 & 26.60% & 0.93\n",
      "for 2021-10-30, MAE is:24.49 & sMAPE is:45.83% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :15.75 & 26.66% & 0.93\n",
      "for 2021-10-31, MAE is:15.52 & sMAPE is:37.16% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :15.75 & 26.70% & 0.93\n",
      "for 2021-11-01, MAE is:15.92 & sMAPE is:29.70% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :15.75 & 26.71% & 0.93\n",
      "for 2021-11-02, MAE is:37.60 & sMAPE is:69.90% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :15.82 & 26.85% & 0.93\n",
      "for 2021-11-03, MAE is:52.21 & sMAPE is:64.06% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :15.94 & 26.97% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-04, MAE is:21.77 & sMAPE is:27.51% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :15.96 & 26.97% & 0.92\n",
      "for 2021-11-05, MAE is:20.33 & sMAPE is:52.29% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :15.97 & 27.05% & 0.93\n",
      "for 2021-11-06, MAE is:25.18 & sMAPE is:116.34% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :16.00 & 27.34% & 0.93\n",
      "for 2021-11-07, MAE is:17.44 & sMAPE is:71.32% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :16.01 & 27.48% & 0.93\n",
      "for 2021-11-08, MAE is:96.68 & sMAPE is:88.88% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :16.27 & 27.68% & 0.93\n",
      "for 2021-11-09, MAE is:82.34 & sMAPE is:73.49% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :16.48 & 27.83% & 0.93\n",
      "for 2021-11-10, MAE is:78.19 & sMAPE is:110.79% & rMAE is:2.81 ||| daily mean of MAE & sMAPE & rMAE till now are :16.67 & 28.09% & 0.94\n",
      "for 2021-11-11, MAE is:29.41 & sMAPE is:31.13% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :16.71 & 28.10% & 0.94\n",
      "for 2021-11-12, MAE is:45.92 & sMAPE is:35.73% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :16.81 & 28.13% & 0.94\n",
      "for 2021-11-13, MAE is:43.65 & sMAPE is:33.26% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :16.89 & 28.14% & 0.93\n",
      "for 2021-11-14, MAE is:16.21 & sMAPE is:14.27% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :16.89 & 28.10% & 0.93\n",
      "for 2021-11-15, MAE is:67.25 & sMAPE is:54.99% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :17.05 & 28.18% & 0.93\n",
      "for 2021-11-16, MAE is:98.79 & sMAPE is:55.10% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :17.30 & 28.27% & 0.93\n",
      "for 2021-11-17, MAE is:79.60 & sMAPE is:61.36% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :17.50 & 28.37% & 0.93\n",
      "for 2021-11-18, MAE is:35.81 & sMAPE is:78.02% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :17.55 & 28.52% & 0.93\n",
      "for 2021-11-19, MAE is:41.38 & sMAPE is:117.80% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :17.63 & 28.80% & 0.93\n",
      "for 2021-11-20, MAE is:22.62 & sMAPE is:67.56% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :17.64 & 28.92% & 0.93\n",
      "for 2021-11-21, MAE is:31.25 & sMAPE is:58.76% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :17.68 & 29.01% & 0.93\n",
      "for 2021-11-22, MAE is:48.82 & sMAPE is:40.07% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :17.78 & 29.05% & 0.93\n",
      "for 2021-11-23, MAE is:53.76 & sMAPE is:55.69% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :17.89 & 29.13% & 0.92\n",
      "for 2021-11-24, MAE is:32.74 & sMAPE is:53.65% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :17.93 & 29.20% & 0.92\n",
      "for 2021-11-25, MAE is:40.76 & sMAPE is:42.90% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :18.00 & 29.24% & 0.92\n",
      "for 2021-11-26, MAE is:67.42 & sMAPE is:48.66% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :18.15 & 29.30% & 0.92\n",
      "for 2021-11-27, MAE is:59.87 & sMAPE is:37.81% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :18.28 & 29.33% & 0.92\n",
      "for 2021-11-28, MAE is:35.43 & sMAPE is:21.20% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :18.33 & 29.30% & 0.92\n",
      "for 2021-11-29, MAE is:90.88 & sMAPE is:35.50% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :18.55 & 29.32% & 0.92\n",
      "for 2021-11-30, MAE is:55.97 & sMAPE is:31.43% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :18.66 & 29.33% & 0.92\n",
      "for 2021-12-01, MAE is:38.16 & sMAPE is:26.65% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :18.72 & 29.32% & 0.92\n",
      "for 2021-12-02, MAE is:89.50 & sMAPE is:59.50% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :18.93 & 29.41% & 0.92\n",
      "for 2021-12-03, MAE is:33.17 & sMAPE is:19.53% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :18.97 & 29.38% & 0.92\n",
      "for 2021-12-04, MAE is:38.67 & sMAPE is:22.77% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :19.03 & 29.36% & 0.92\n",
      "for 2021-12-05, MAE is:34.37 & sMAPE is:24.47% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :19.08 & 29.35% & 0.92\n",
      "for 2021-12-06, MAE is:102.47 & sMAPE is:35.41% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :19.32 & 29.36% & 0.93\n",
      "for 2021-12-07, MAE is:47.21 & sMAPE is:22.14% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :19.40 & 29.34% & 0.92\n",
      "for 2021-12-08, MAE is:35.26 & sMAPE is:22.44% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :19.45 & 29.32% & 0.92\n",
      "for 2021-12-09, MAE is:75.17 & sMAPE is:29.59% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :19.61 & 29.32% & 0.92\n",
      "for 2021-12-10, MAE is:37.28 & sMAPE is:16.41% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :19.66 & 29.29% & 0.92\n",
      "for 2021-12-11, MAE is:42.80 & sMAPE is:20.31% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :19.73 & 29.26% & 0.92\n",
      "for 2021-12-12, MAE is:39.66 & sMAPE is:22.23% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :19.79 & 29.24% & 0.92\n",
      "for 2021-12-13, MAE is:49.19 & sMAPE is:24.12% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :19.87 & 29.23% & 0.92\n",
      "for 2021-12-14, MAE is:91.17 & sMAPE is:53.19% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :20.08 & 29.29% & 0.92\n",
      "for 2021-12-15, MAE is:94.19 & sMAPE is:91.00% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :20.29 & 29.47% & 0.92\n",
      "for 2021-12-16, MAE is:36.04 & sMAPE is:48.45% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :20.34 & 29.53% & 0.92\n",
      "for 2021-12-17, MAE is:87.30 & sMAPE is:63.18% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :20.53 & 29.62% & 0.92\n",
      "for 2021-12-18, MAE is:74.70 & sMAPE is:69.84% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :20.68 & 29.74% & 0.92\n",
      "for 2021-12-19, MAE is:36.04 & sMAPE is:62.81% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :20.72 & 29.83% & 0.92\n",
      "for 2021-12-20, MAE is:203.68 & sMAPE is:90.03% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :21.24 & 30.00% & 0.92\n",
      "for 2021-12-21, MAE is:127.08 & sMAPE is:36.58% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :21.54 & 30.02% & 0.92\n",
      "for 2021-12-22, MAE is:75.66 & sMAPE is:20.47% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :21.69 & 29.99% & 0.92\n",
      "for 2021-12-23, MAE is:52.52 & sMAPE is:21.11% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :21.78 & 29.97% & 0.92\n",
      "for 2021-12-24, MAE is:61.11 & sMAPE is:38.58% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :21.89 & 29.99% & 0.92\n",
      "for 2021-12-25, MAE is:14.08 & sMAPE is:11.44% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :21.86 & 29.94% & 0.92\n",
      "for 2021-12-26, MAE is:43.25 & sMAPE is:29.75% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :21.92 & 29.94% & 0.92\n",
      "for 2021-12-27, MAE is:37.09 & sMAPE is:22.71% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :21.97 & 29.92% & 0.91\n",
      "for 2021-12-28, MAE is:62.18 & sMAPE is:47.10% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :22.08 & 29.97% & 0.91\n",
      "for 2021-12-29, MAE is:24.56 & sMAPE is:16.68% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :22.08 & 29.93% & 0.91\n",
      "for 2021-12-30, MAE is:67.16 & sMAPE is:68.07% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :22.21 & 30.03% & 0.91\n",
      "for 2021-12-31, MAE is:25.21 & sMAPE is:49.13% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :22.22 & 30.09% & 0.91\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 06:49:44,938]\u001b[0m A new study created in RDB with name: SE_4_2022\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:49:56,965]\u001b[0m Trial 0 finished with value: 41.12452063790025 and parameters: {'n_hidden': 4, 'learning_rate': 0.01964219392381131, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2631298459593683, 'dropout_rate_Layer_2': 0.37217768275567337, 'dropout_rate_Layer_3': 0.23356429238410611, 'dropout_rate_Layer_4': 0.2895177235751562, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012792200211888852, 'l1_Layer_2': 0.012110013329057133, 'l1_Layer_3': 0.0032357461094841447, 'l1_Layer_4': 2.5278958822460455e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 235, 'n_units_Layer_3': 195, 'n_units_Layer_4': 195}. Best is trial 0 with value: 41.12452063790025.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.12 | sMAPE for Validation Set is: 52.59% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 118.81 | sMAPE for Test Set is: 99.90% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 06:50:28,412]\u001b[0m Trial 1 finished with value: 34.37633434731645 and parameters: {'n_hidden': 4, 'learning_rate': 0.06565668274609418, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04935183554893055, 'dropout_rate_Layer_2': 0.3489223544960258, 'dropout_rate_Layer_3': 0.3973398508480647, 'dropout_rate_Layer_4': 0.35895232416739825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.721154410662058e-05, 'l1_Layer_2': 0.011397007896641838, 'l1_Layer_3': 1.1482993363518403e-05, 'l1_Layer_4': 0.034348763313160335, 'n_units_Layer_1': 75, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270, 'n_units_Layer_4': 55}. Best is trial 1 with value: 34.37633434731645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.38 | sMAPE for Validation Set is: 43.13% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 106.96 | sMAPE for Test Set is: 86.99% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 06:50:51,482]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:51:51,618]\u001b[0m Trial 3 finished with value: 37.96321535990981 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007149284812719697, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12608447112948556, 'dropout_rate_Layer_2': 0.3696527011867759, 'dropout_rate_Layer_3': 0.07280864135905066, 'dropout_rate_Layer_4': 0.11190531815242527, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 8.264392365524795e-05, 'l1_Layer_2': 1.9345671280203125e-05, 'l1_Layer_3': 0.0007290800848895018, 'l1_Layer_4': 0.0009435505099533775, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180, 'n_units_Layer_4': 125}. Best is trial 1 with value: 34.37633434731645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.96 | sMAPE for Validation Set is: 47.59% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 113.98 | sMAPE for Test Set is: 93.73% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 06:53:24,859]\u001b[0m Trial 4 finished with value: 23.80981260627342 and parameters: {'n_hidden': 4, 'learning_rate': 0.0044768196495760726, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01813082704135005, 'dropout_rate_Layer_2': 0.3956950463695265, 'dropout_rate_Layer_3': 0.2827276319967715, 'dropout_rate_Layer_4': 0.36034107667384696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017941955197833077, 'l1_Layer_2': 7.691587829351679e-05, 'l1_Layer_3': 0.0005540614709872965, 'l1_Layer_4': 5.644504058283056e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 280, 'n_units_Layer_3': 100, 'n_units_Layer_4': 230}. Best is trial 4 with value: 23.80981260627342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.81 | sMAPE for Validation Set is: 32.43% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 63.42 | sMAPE for Test Set is: 59.72% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 06:53:27,980]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:54:26,456]\u001b[0m Trial 6 finished with value: 34.89554758023505 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018587276846634376, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13438212346518613, 'dropout_rate_Layer_2': 0.34303608373935657, 'dropout_rate_Layer_3': 0.2869303017026118, 'dropout_rate_Layer_4': 0.07404787993368181, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032985313997028823, 'l1_Layer_2': 0.0006837745913772087, 'l1_Layer_3': 0.019025392329337712, 'l1_Layer_4': 3.733517467726048e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145, 'n_units_Layer_4': 60}. Best is trial 4 with value: 23.80981260627342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.90 | sMAPE for Validation Set is: 43.20% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 110.30 | sMAPE for Test Set is: 90.01% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 06:54:33,898]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:55:31,877]\u001b[0m Trial 8 finished with value: 34.20275028578507 and parameters: {'n_hidden': 4, 'learning_rate': 0.004173660796937017, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12502254715619876, 'dropout_rate_Layer_2': 0.3507047191569168, 'dropout_rate_Layer_3': 0.0742395847728644, 'dropout_rate_Layer_4': 0.1555727965869839, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004149825295680265, 'l1_Layer_2': 5.7743772398847734e-05, 'l1_Layer_3': 0.000124010863661017, 'l1_Layer_4': 0.00027108563561846754, 'n_units_Layer_1': 135, 'n_units_Layer_2': 235, 'n_units_Layer_3': 170, 'n_units_Layer_4': 150}. Best is trial 4 with value: 23.80981260627342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.20 | sMAPE for Validation Set is: 41.99% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 108.85 | sMAPE for Test Set is: 87.99% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 06:55:35,542]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:55:39,769]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:55:43,024]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:56:11,103]\u001b[0m Trial 12 finished with value: 35.94944240643104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005803798669617899, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2712327827555407, 'dropout_rate_Layer_2': 0.10178962983560447, 'dropout_rate_Layer_3': 0.006047974741380413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.844131124922532e-05, 'l1_Layer_2': 4.019412803572293e-05, 'l1_Layer_3': 1.2034156181304909e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280}. Best is trial 4 with value: 23.80981260627342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.95 | sMAPE for Validation Set is: 44.35% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 110.89 | sMAPE for Test Set is: 90.21% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 06:56:15,557]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:56:18,718]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:56:45,073]\u001b[0m Trial 15 finished with value: 36.01118238958566 and parameters: {'n_hidden': 4, 'learning_rate': 0.002816013722804464, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06879116050918777, 'dropout_rate_Layer_2': 0.020396173096873405, 'dropout_rate_Layer_3': 0.27653892698128274, 'dropout_rate_Layer_4': 0.10118685176102966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004113725221191465, 'l1_Layer_2': 2.8761275594900712e-05, 'l1_Layer_3': 1.9974082366612576e-05, 'l1_Layer_4': 0.00025658353071728447, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 270, 'n_units_Layer_4': 175}. Best is trial 4 with value: 23.80981260627342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.01 | sMAPE for Validation Set is: 44.67% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 111.05 | sMAPE for Test Set is: 89.97% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 06:56:49,422]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:56:56,929]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:57:02,196]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:57:14,783]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:57:24,630]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:57:30,082]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:57:42,242]\u001b[0m Trial 22 finished with value: 23.41318712514872 and parameters: {'n_hidden': 3, 'learning_rate': 0.04864874416041234, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17291970814365856, 'dropout_rate_Layer_2': 0.1972901932053578, 'dropout_rate_Layer_3': 0.28125542014760513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00047668562153192014, 'l1_Layer_2': 0.0004330431422639284, 'l1_Layer_3': 0.00882711393387765, 'n_units_Layer_1': 295, 'n_units_Layer_2': 115, 'n_units_Layer_3': 185}. Best is trial 22 with value: 23.41318712514872.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.41 | sMAPE for Validation Set is: 32.45% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 59.48 | sMAPE for Test Set is: 57.36% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 06:57:51,273]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:57:58,243]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:58:03,821]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:58:09,850]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:58:48,619]\u001b[0m Trial 27 finished with value: 22.776392697537634 and parameters: {'n_hidden': 3, 'learning_rate': 0.06883697211605946, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.043271519703518106, 'dropout_rate_Layer_2': 0.14844636279864518, 'dropout_rate_Layer_3': 0.1515657827694628, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.850470479172522e-05, 'l1_Layer_2': 0.011397449662476956, 'l1_Layer_3': 2.312548179405708e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 90, 'n_units_Layer_3': 180}. Best is trial 27 with value: 22.776392697537634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.78 | sMAPE for Validation Set is: 30.58% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 62.11 | sMAPE for Test Set is: 59.45% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 06:58:56,081]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:59:00,815]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:59:07,408]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:59:12,699]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:59:19,830]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:59:24,174]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:59:38,906]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:59:42,741]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 06:59:56,827]\u001b[0m Trial 36 finished with value: 23.34048682490763 and parameters: {'n_hidden': 4, 'learning_rate': 0.0074273722483823145, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11779252108909413, 'dropout_rate_Layer_2': 0.04017260546293327, 'dropout_rate_Layer_3': 0.23358613957734256, 'dropout_rate_Layer_4': 0.07096542962104198, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0047358105669837135, 'l1_Layer_2': 0.00032114525864295363, 'l1_Layer_3': 0.024745105946765298, 'l1_Layer_4': 0.0006681638321674815, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295, 'n_units_Layer_4': 180}. Best is trial 27 with value: 22.776392697537634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.34 | sMAPE for Validation Set is: 31.58% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 61.45 | sMAPE for Test Set is: 59.10% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:00:04,024]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:00:08,047]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:00:12,246]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:00:16,142]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:00:20,498]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:00:26,849]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:00:30,669]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:00:50,879]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:00:56,203]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:01:02,570]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:01:06,113]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:01:09,990]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:01:40,655]\u001b[0m Trial 49 finished with value: 26.555157756456897 and parameters: {'n_hidden': 4, 'learning_rate': 0.09018425634730709, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14111350231543068, 'dropout_rate_Layer_2': 0.3028156400415726, 'dropout_rate_Layer_3': 0.3230586969561561, 'dropout_rate_Layer_4': 0.26434707149230846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002480801579801917, 'l1_Layer_2': 0.0029793138592734076, 'l1_Layer_3': 0.0014238739716017266, 'l1_Layer_4': 2.282719030630159e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 275, 'n_units_Layer_4': 200}. Best is trial 27 with value: 22.776392697537634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.56 | sMAPE for Validation Set is: 35.73% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 71.95 | sMAPE for Test Set is: 64.84% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:01:46,278]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:01:52,965]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:02:05,221]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:02:14,543]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:02:20,314]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:02:39,473]\u001b[0m Trial 55 finished with value: 27.67507443000706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011161343791676228, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2181212731682113, 'dropout_rate_Layer_2': 0.27990635476851694, 'dropout_rate_Layer_3': 0.15320478836802667, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03750612144388683, 'l1_Layer_2': 1.83239653721051e-05, 'l1_Layer_3': 6.493671377200548e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 80}. Best is trial 27 with value: 22.776392697537634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.68 | sMAPE for Validation Set is: 34.24% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 96.75 | sMAPE for Test Set is: 77.59% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:02:54,331]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:02:59,627]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:03:04,142]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:03:25,232]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:03:30,964]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:03:38,136]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:04:19,008]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:04:24,938]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:04:31,765]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:04:37,243]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:04:41,544]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:04:45,848]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:04:55,124]\u001b[0m Trial 68 finished with value: 27.211186337564243 and parameters: {'n_hidden': 3, 'learning_rate': 0.07998494796830997, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23986502358119258, 'dropout_rate_Layer_2': 0.19340964723608756, 'dropout_rate_Layer_3': 0.1791081786478647, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05195635222772336, 'l1_Layer_2': 0.05691553428936152, 'l1_Layer_3': 0.08098084577539483, 'n_units_Layer_1': 290, 'n_units_Layer_2': 70, 'n_units_Layer_3': 295}. Best is trial 27 with value: 22.776392697537634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.21 | sMAPE for Validation Set is: 34.93% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 73.80 | sMAPE for Test Set is: 65.12% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:05:09,181]\u001b[0m Trial 69 finished with value: 22.696809562728834 and parameters: {'n_hidden': 4, 'learning_rate': 0.008194146981702703, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15345045691109616, 'dropout_rate_Layer_2': 0.009651515152839338, 'dropout_rate_Layer_3': 0.1862782270783322, 'dropout_rate_Layer_4': 0.025142764342854666, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0021391315818717516, 'l1_Layer_2': 0.0008721854625388563, 'l1_Layer_3': 0.000116966757704208, 'l1_Layer_4': 0.004552566330141977, 'n_units_Layer_1': 55, 'n_units_Layer_2': 145, 'n_units_Layer_3': 130, 'n_units_Layer_4': 90}. Best is trial 69 with value: 22.696809562728834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.70 | sMAPE for Validation Set is: 30.96% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 61.53 | sMAPE for Test Set is: 58.66% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:05:17,277]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:05:21,247]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:05:38,844]\u001b[0m Trial 72 finished with value: 21.40974896668833 and parameters: {'n_hidden': 3, 'learning_rate': 0.010459506084456564, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1670108059108549, 'dropout_rate_Layer_2': 0.008734945389972382, 'dropout_rate_Layer_3': 0.145572407081835, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00156372737978575, 'l1_Layer_2': 0.0012931148777232595, 'l1_Layer_3': 8.467169543487378e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 130, 'n_units_Layer_3': 130}. Best is trial 72 with value: 21.40974896668833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.41 | sMAPE for Validation Set is: 28.87% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.91 | sMAPE for Test Set is: 56.81% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:05:42,540]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:05:46,503]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:06:00,139]\u001b[0m Trial 75 finished with value: 21.604003530747395 and parameters: {'n_hidden': 3, 'learning_rate': 0.013483779161601055, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17757597670168898, 'dropout_rate_Layer_2': 0.011033592120173179, 'dropout_rate_Layer_3': 0.19176998833108955, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011544902488383171, 'l1_Layer_2': 0.0003867587383086597, 'l1_Layer_3': 0.00012191196774762015, 'n_units_Layer_1': 205, 'n_units_Layer_2': 140, 'n_units_Layer_3': 120}. Best is trial 72 with value: 21.40974896668833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.60 | sMAPE for Validation Set is: 28.92% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 61.57 | sMAPE for Test Set is: 57.86% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:06:16,229]\u001b[0m Trial 76 finished with value: 21.727173562718065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0112018806599026, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2941303798083933, 'dropout_rate_Layer_2': 0.20269877092109087, 'dropout_rate_Layer_3': 0.37139927579147225, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004135012821584939, 'l1_Layer_2': 0.0008764057927425794, 'l1_Layer_3': 0.007261686888137834, 'n_units_Layer_1': 250, 'n_units_Layer_2': 120, 'n_units_Layer_3': 300}. Best is trial 72 with value: 21.40974896668833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.73 | sMAPE for Validation Set is: 29.42% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.67 | sMAPE for Test Set is: 57.55% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:06:23,724]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:06:27,584]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:06:32,851]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:06:38,767]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:06:54,753]\u001b[0m Trial 81 finished with value: 21.709605418015233 and parameters: {'n_hidden': 3, 'learning_rate': 0.011034766123567862, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3008917989002686, 'dropout_rate_Layer_2': 0.14861820069648313, 'dropout_rate_Layer_3': 0.3989888348097827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00037926760495942085, 'l1_Layer_2': 0.0009298654832349777, 'l1_Layer_3': 0.004903123684998866, 'n_units_Layer_1': 240, 'n_units_Layer_2': 125, 'n_units_Layer_3': 235}. Best is trial 72 with value: 21.40974896668833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.71 | sMAPE for Validation Set is: 29.49% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.49 | sMAPE for Test Set is: 56.17% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:06:59,283]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:07:03,717]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:07:09,371]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:07:14,596]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:07:20,264]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:07:34,511]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:07:46,078]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:07:58,401]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:08:06,752]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:08:11,941]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:08:16,637]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:08:30,161]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:08:35,824]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:08:52,589]\u001b[0m Trial 95 finished with value: 22.62282482835612 and parameters: {'n_hidden': 3, 'learning_rate': 0.011096133256678829, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31142864342132837, 'dropout_rate_Layer_2': 0.1393211991138855, 'dropout_rate_Layer_3': 0.3982738256112003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002428931771710873, 'l1_Layer_2': 0.0017667397148718104, 'l1_Layer_3': 0.0026144189864332327, 'n_units_Layer_1': 225, 'n_units_Layer_2': 125, 'n_units_Layer_3': 250}. Best is trial 72 with value: 21.40974896668833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.62 | sMAPE for Validation Set is: 30.71% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 62.85 | sMAPE for Test Set is: 58.11% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:08:56,663]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:09:08,569]\u001b[0m Trial 97 finished with value: 22.452616525033775 and parameters: {'n_hidden': 3, 'learning_rate': 0.007858618702300835, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31880878950089714, 'dropout_rate_Layer_2': 0.273762925223249, 'dropout_rate_Layer_3': 0.3985875810686297, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000778092473453464, 'l1_Layer_2': 0.001238083609730046, 'l1_Layer_3': 0.004189911531667663, 'n_units_Layer_1': 250, 'n_units_Layer_2': 120, 'n_units_Layer_3': 250}. Best is trial 72 with value: 21.40974896668833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.45 | sMAPE for Validation Set is: 30.59% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 61.44 | sMAPE for Test Set is: 59.02% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:09:12,510]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:09:21,524]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:09:27,653]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:09:32,149]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:09:38,572]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:09:45,856]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:10:00,766]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:10:09,186]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:10:14,576]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:10:26,332]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:10:32,307]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:10:36,381]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:10:42,448]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:10:48,033]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:10:53,406]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:10:58,996]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:11:04,142]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:11:17,729]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:11:27,955]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:11:33,058]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:11:41,334]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:11:49,690]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:12:01,604]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:12:13,863]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:12:25,782]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:12:37,458]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:12:42,429]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:13:00,782]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:13:23,089]\u001b[0m Trial 126 finished with value: 21.45750737991746 and parameters: {'n_hidden': 4, 'learning_rate': 0.007093980746546261, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.155691181451584, 'dropout_rate_Layer_2': 0.00488068097193575, 'dropout_rate_Layer_3': 0.19049652494463945, 'dropout_rate_Layer_4': 0.006215319545127385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0017384125722262277, 'l1_Layer_2': 0.000806491839899904, 'l1_Layer_3': 9.572444939316391e-05, 'l1_Layer_4': 0.006175949309212714, 'n_units_Layer_1': 90, 'n_units_Layer_2': 150, 'n_units_Layer_3': 50, 'n_units_Layer_4': 55}. Best is trial 72 with value: 21.40974896668833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.46 | sMAPE for Validation Set is: 28.97% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.60 | sMAPE for Test Set is: 56.48% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:13:27,744]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:13:33,758]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:13:47,661]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:13:53,379]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:14:04,923]\u001b[0m Trial 131 finished with value: 21.581579226467422 and parameters: {'n_hidden': 3, 'learning_rate': 0.009392240260366152, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19110498606300225, 'dropout_rate_Layer_2': 0.0017365555044724281, 'dropout_rate_Layer_3': 0.17646705182029948, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046535513808108013, 'l1_Layer_2': 0.00028791181536382964, 'l1_Layer_3': 0.00019642131392319956, 'n_units_Layer_1': 230, 'n_units_Layer_2': 145, 'n_units_Layer_3': 55}. Best is trial 72 with value: 21.40974896668833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.58 | sMAPE for Validation Set is: 29.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.63 | sMAPE for Test Set is: 57.74% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:14:12,580]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:14:21,191]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:14:25,914]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:14:29,870]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:14:39,823]\u001b[0m Trial 136 finished with value: 21.79227258729313 and parameters: {'n_hidden': 3, 'learning_rate': 0.020572852595891478, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34698806378078517, 'dropout_rate_Layer_2': 0.12538457491762592, 'dropout_rate_Layer_3': 0.23443370046125575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.953776123385129e-05, 'l1_Layer_2': 0.0007869432209092324, 'l1_Layer_3': 0.011305917952957815, 'n_units_Layer_1': 260, 'n_units_Layer_2': 100, 'n_units_Layer_3': 220}. Best is trial 72 with value: 21.40974896668833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.79 | sMAPE for Validation Set is: 29.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.91 | sMAPE for Test Set is: 57.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:14:55,788]\u001b[0m Trial 137 finished with value: 51.01668634903054 and parameters: {'n_hidden': 4, 'learning_rate': 0.09993199261486992, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13595502485754948, 'dropout_rate_Layer_2': 0.32014603623501847, 'dropout_rate_Layer_3': 0.28942734296022343, 'dropout_rate_Layer_4': 0.0014272792843973703, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0013216688039229207, 'l1_Layer_2': 0.00024003978999492248, 'l1_Layer_3': 0.00046523744377050284, 'l1_Layer_4': 1.5236883543193018e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 115, 'n_units_Layer_3': 125, 'n_units_Layer_4': 50}. Best is trial 72 with value: 21.40974896668833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.02 | sMAPE for Validation Set is: 73.66% | rMAE for Validation Set is: 1.56\n",
      "MAE for Test Set is: 127.07 | sMAPE for Test Set is: 111.28% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:15:04,351]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:15:15,208]\u001b[0m Trial 139 finished with value: 21.776362100595424 and parameters: {'n_hidden': 3, 'learning_rate': 0.007447523261645203, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34088821512544976, 'dropout_rate_Layer_2': 0.15767526361077874, 'dropout_rate_Layer_3': 0.3727605439042901, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014440996080046872, 'l1_Layer_2': 0.0001552344371377405, 'l1_Layer_3': 0.01917924364793368, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 280}. Best is trial 72 with value: 21.40974896668833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.78 | sMAPE for Validation Set is: 30.30% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.11 | sMAPE for Test Set is: 57.65% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:15:20,489]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:15:26,941]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:15:32,668]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:15:37,179]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:15:41,389]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:15:46,401]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:15:52,408]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:15:57,833]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:16:01,667]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:16:05,782]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:16:11,120]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:16:19,093]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:16:24,043]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:16:30,514]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:16:39,613]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:16:52,228]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:16:57,244]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:17:03,317]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:17:16,864]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:17:20,934]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:17:32,849]\u001b[0m Trial 160 finished with value: 21.401671682700407 and parameters: {'n_hidden': 3, 'learning_rate': 0.004106457299134157, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39973871166282793, 'dropout_rate_Layer_2': 0.15581254250215887, 'dropout_rate_Layer_3': 0.33274338764226785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004606000251471127, 'l1_Layer_2': 0.0003296133665248023, 'l1_Layer_3': 0.010792462870680194, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 280}. Best is trial 160 with value: 21.401671682700407.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.40 | sMAPE for Validation Set is: 29.76% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 58.93 | sMAPE for Test Set is: 57.10% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:17:36,642]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:17:41,181]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:17:45,146]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:17:53,629]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:18:08,518]\u001b[0m Trial 165 finished with value: 21.805921437325207 and parameters: {'n_hidden': 3, 'learning_rate': 0.004044911355428717, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38851858673238987, 'dropout_rate_Layer_2': 0.07553766047221684, 'dropout_rate_Layer_3': 0.3277913676891135, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004251266179529318, 'l1_Layer_2': 0.00028753597142856753, 'l1_Layer_3': 0.003929481910151451, 'n_units_Layer_1': 240, 'n_units_Layer_2': 190, 'n_units_Layer_3': 240}. Best is trial 160 with value: 21.401671682700407.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.81 | sMAPE for Validation Set is: 29.28% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 63.23 | sMAPE for Test Set is: 59.41% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:18:12,754]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:18:16,966]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:18:21,712]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:18:27,120]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:18:58,616]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:19:06,943]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:19:12,816]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:19:17,050]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:19:30,377]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:20:16,595]\u001b[0m Trial 175 finished with value: 35.20083438857197 and parameters: {'n_hidden': 4, 'learning_rate': 0.08766879998842861, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05259262908096241, 'dropout_rate_Layer_2': 0.3095710560162081, 'dropout_rate_Layer_3': 0.36944367866390065, 'dropout_rate_Layer_4': 0.2761155530359655, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.1883885849717736e-05, 'l1_Layer_2': 0.0010986316835721287, 'l1_Layer_3': 0.0003258499826831346, 'l1_Layer_4': 5.8249233907980066e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 290, 'n_units_Layer_3': 200, 'n_units_Layer_4': 240}. Best is trial 160 with value: 21.401671682700407.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.20 | sMAPE for Validation Set is: 43.90% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 111.24 | sMAPE for Test Set is: 91.14% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:20:31,699]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:20:37,907]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:20:45,848]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:21:06,396]\u001b[0m Trial 179 finished with value: 35.549838428488435 and parameters: {'n_hidden': 4, 'learning_rate': 0.004604218466089502, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06437060918225765, 'dropout_rate_Layer_2': 0.330099408914759, 'dropout_rate_Layer_3': 0.14999083722799011, 'dropout_rate_Layer_4': 0.11151176575068711, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003849167012216031, 'l1_Layer_2': 8.655735156594372e-05, 'l1_Layer_3': 0.00024511683474481583, 'l1_Layer_4': 1.0260540711470153e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 160, 'n_units_Layer_3': 130, 'n_units_Layer_4': 140}. Best is trial 160 with value: 21.401671682700407.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.55 | sMAPE for Validation Set is: 43.82% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 111.09 | sMAPE for Test Set is: 90.48% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:21:21,703]\u001b[0m Trial 180 finished with value: 21.56286798300135 and parameters: {'n_hidden': 3, 'learning_rate': 0.020404853291786998, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3669740407934644, 'dropout_rate_Layer_2': 0.12676224232345681, 'dropout_rate_Layer_3': 0.320607399087416, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006026970179622326, 'l1_Layer_2': 0.0008030817947785338, 'l1_Layer_3': 0.004136235749627168, 'n_units_Layer_1': 155, 'n_units_Layer_2': 90, 'n_units_Layer_3': 265}. Best is trial 160 with value: 21.401671682700407.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.56 | sMAPE for Validation Set is: 28.99% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.96 | sMAPE for Test Set is: 57.78% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:21:27,194]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:21:35,045]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:21:40,096]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:21:44,124]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:22:03,409]\u001b[0m Trial 185 finished with value: 20.803607578845888 and parameters: {'n_hidden': 3, 'learning_rate': 0.004541959628756565, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09952955790724029, 'dropout_rate_Layer_2': 0.029823563305037312, 'dropout_rate_Layer_3': 0.18676195821719263, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014205017289484123, 'l1_Layer_2': 0.003344479095298987, 'l1_Layer_3': 3.0369258777287725e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 130, 'n_units_Layer_3': 160}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.80 | sMAPE for Validation Set is: 27.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.17 | sMAPE for Test Set is: 56.29% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:22:23,903]\u001b[0m Trial 186 finished with value: 36.59818246522651 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008827197585385203, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17668960961497795, 'dropout_rate_Layer_2': 0.1805640854331982, 'dropout_rate_Layer_3': 0.2551152397125341, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09769581233171294, 'l1_Layer_2': 0.0008461537258679838, 'l1_Layer_3': 0.0016183240827287416, 'n_units_Layer_1': 115, 'n_units_Layer_2': 200, 'n_units_Layer_3': 55}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.60 | sMAPE for Validation Set is: 45.31% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 112.90 | sMAPE for Test Set is: 92.94% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:22:30,195]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:22:41,671]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:22:48,814]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:22:53,965]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:22:59,183]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:23:07,475]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:23:11,068]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:23:15,831]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:23:21,446]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:23:30,111]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:23:35,012]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:23:40,513]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:23:52,938]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:24:08,154]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:24:12,090]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:24:17,435]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:24:24,618]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:24:29,737]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:24:35,473]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:24:51,436]\u001b[0m Trial 206 finished with value: 21.868855754276893 and parameters: {'n_hidden': 3, 'learning_rate': 0.02630639247151382, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36796762696346363, 'dropout_rate_Layer_2': 0.05551820568570061, 'dropout_rate_Layer_3': 0.3461191148072104, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.295643431059489e-05, 'l1_Layer_2': 0.0014997740609607743, 'l1_Layer_3': 0.0010065232456588106, 'n_units_Layer_1': 105, 'n_units_Layer_2': 70, 'n_units_Layer_3': 200}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.87 | sMAPE for Validation Set is: 29.70% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 58.50 | sMAPE for Test Set is: 56.54% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:24:59,413]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:25:05,541]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:25:09,944]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:25:16,497]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:25:22,968]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:25:48,067]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:25:59,728]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:26:07,715]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:26:16,558]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:26:25,042]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:26:42,466]\u001b[0m Trial 217 finished with value: 21.638769142735658 and parameters: {'n_hidden': 3, 'learning_rate': 0.011644036503245844, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.363452376161081, 'dropout_rate_Layer_2': 0.10660081250436021, 'dropout_rate_Layer_3': 0.321155791766422, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012233058210687872, 'l1_Layer_2': 0.0009339653291938973, 'l1_Layer_3': 0.009849454294727389, 'n_units_Layer_1': 190, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.64 | sMAPE for Validation Set is: 29.45% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 58.69 | sMAPE for Test Set is: 56.95% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:26:50,503]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:27:04,345]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:27:33,534]\u001b[0m Trial 220 finished with value: 32.36753246404161 and parameters: {'n_hidden': 3, 'learning_rate': 0.06144904077551487, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15301386965086253, 'dropout_rate_Layer_2': 0.32212999323589764, 'dropout_rate_Layer_3': 0.19306346774285066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014385315115803275, 'l1_Layer_2': 0.014291082707073886, 'l1_Layer_3': 0.0003154944322167502, 'n_units_Layer_1': 265, 'n_units_Layer_2': 275, 'n_units_Layer_3': 165}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.37 | sMAPE for Validation Set is: 39.80% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 106.21 | sMAPE for Test Set is: 85.54% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:27:39,008]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:27:46,687]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:27:56,900]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:28:02,410]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:28:07,581]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:28:12,401]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:28:27,905]\u001b[0m Trial 227 finished with value: 21.724443549654783 and parameters: {'n_hidden': 3, 'learning_rate': 0.01776426381678626, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18819607894033066, 'dropout_rate_Layer_2': 0.02687414026775649, 'dropout_rate_Layer_3': 0.18651693834917088, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002094800270609871, 'l1_Layer_2': 0.00011988802580932428, 'l1_Layer_3': 3.570091643425333e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 130, 'n_units_Layer_3': 80}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.72 | sMAPE for Validation Set is: 29.24% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.89 | sMAPE for Test Set is: 57.70% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:28:32,694]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:28:36,953]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:29:16,182]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:29:25,984]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:29:40,005]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:29:43,824]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:29:47,759]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:29:55,401]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:30:06,220]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:30:13,105]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:30:23,405]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:30:37,780]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:31:06,958]\u001b[0m Trial 240 finished with value: 33.99404418409093 and parameters: {'n_hidden': 3, 'learning_rate': 0.058309411000566885, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18369360917669655, 'dropout_rate_Layer_2': 0.2720415004523595, 'dropout_rate_Layer_3': 0.2483260022887161, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001391934590033603, 'l1_Layer_2': 0.013659632160627655, 'l1_Layer_3': 0.00012469811826989726, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 80}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.99 | sMAPE for Validation Set is: 41.74% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 109.11 | sMAPE for Test Set is: 88.28% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:31:14,540]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:31:19,288]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:31:27,068]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:31:34,661]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:31:42,737]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:31:49,888]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:31:55,694]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:32:02,870]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:32:06,976]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:32:12,325]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:32:16,500]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:32:25,885]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:32:33,381]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:32:38,007]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:32:59,276]\u001b[0m Trial 255 finished with value: 32.90101714166266 and parameters: {'n_hidden': 3, 'learning_rate': 0.04086305806436075, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17370210871267283, 'dropout_rate_Layer_2': 0.23072392992607238, 'dropout_rate_Layer_3': 0.2305003723581387, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00033720395691621863, 'l1_Layer_2': 0.007227652498382463, 'l1_Layer_3': 0.0001320701358797312, 'n_units_Layer_1': 300, 'n_units_Layer_2': 230, 'n_units_Layer_3': 70}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.90 | sMAPE for Validation Set is: 40.59% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 106.81 | sMAPE for Test Set is: 86.00% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:33:03,727]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:33:07,939]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:33:14,092]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:33:19,076]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:33:22,994]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:33:37,272]\u001b[0m Trial 261 finished with value: 21.816369322150862 and parameters: {'n_hidden': 3, 'learning_rate': 0.01391314042451077, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17497672540370654, 'dropout_rate_Layer_2': 0.06665668750898776, 'dropout_rate_Layer_3': 0.18232362771486452, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003654210996467887, 'l1_Layer_2': 7.275285554552867e-05, 'l1_Layer_3': 3.053842620434522e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 140, 'n_units_Layer_3': 80}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.82 | sMAPE for Validation Set is: 29.50% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 59.62 | sMAPE for Test Set is: 56.91% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:33:41,989]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:33:49,704]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:34:02,018]\u001b[0m Trial 264 finished with value: 21.435667257173545 and parameters: {'n_hidden': 3, 'learning_rate': 0.00891362282764505, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18681895101017848, 'dropout_rate_Layer_2': 0.019780102101392957, 'dropout_rate_Layer_3': 0.13096125198612102, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014669828407380286, 'l1_Layer_2': 0.00015935771913471778, 'l1_Layer_3': 0.0001031831695408808, 'n_units_Layer_1': 200, 'n_units_Layer_2': 155, 'n_units_Layer_3': 95}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.44 | sMAPE for Validation Set is: 29.11% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.13 | sMAPE for Test Set is: 56.67% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:34:10,402]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:34:15,718]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:34:23,206]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:34:36,744]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:34:55,542]\u001b[0m Trial 269 finished with value: 21.359438626969325 and parameters: {'n_hidden': 3, 'learning_rate': 0.00865919184831721, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23543702188279003, 'dropout_rate_Layer_2': 0.015054251121336931, 'dropout_rate_Layer_3': 0.13065238228227513, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013999845746618014, 'l1_Layer_2': 0.0003945123989001579, 'l1_Layer_3': 6.437444813399388e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 155, 'n_units_Layer_3': 95}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.36 | sMAPE for Validation Set is: 28.72% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.36 | sMAPE for Test Set is: 56.47% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:35:00,219]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:35:04,307]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:35:08,231]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:35:12,531]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:35:18,125]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:35:21,753]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:35:35,194]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:35:42,354]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:35:47,258]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:36:00,472]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:36:11,670]\u001b[0m Trial 280 finished with value: 34.12463994521419 and parameters: {'n_hidden': 3, 'learning_rate': 0.05419653605528571, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16372230448294203, 'dropout_rate_Layer_2': 0.18618595270122773, 'dropout_rate_Layer_3': 0.003417362204933272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016503341847910825, 'l1_Layer_2': 0.0035550226043384657, 'l1_Layer_3': 0.00013706583743785343, 'n_units_Layer_1': 290, 'n_units_Layer_2': 250, 'n_units_Layer_3': 95}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.12 | sMAPE for Validation Set is: 44.95% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 107.95 | sMAPE for Test Set is: 89.96% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:36:22,135]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:36:35,057]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:36:38,859]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:36:44,221]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:36:48,305]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:37:14,689]\u001b[0m Trial 286 finished with value: 22.564843753030186 and parameters: {'n_hidden': 4, 'learning_rate': 0.01092098026962936, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33171728304578074, 'dropout_rate_Layer_2': 0.13643675877930872, 'dropout_rate_Layer_3': 0.2585516514925245, 'dropout_rate_Layer_4': 0.3877712886640843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001008640098072033, 'l1_Layer_2': 0.000549865252247073, 'l1_Layer_3': 0.004055958665927485, 'l1_Layer_4': 6.861777191908491e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 60, 'n_units_Layer_3': 150, 'n_units_Layer_4': 195}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.56 | sMAPE for Validation Set is: 30.98% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 61.64 | sMAPE for Test Set is: 58.53% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:37:35,731]\u001b[0m Trial 287 finished with value: 34.528731353427226 and parameters: {'n_hidden': 4, 'learning_rate': 0.00349122395831293, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07927272372188013, 'dropout_rate_Layer_2': 0.3183056668180946, 'dropout_rate_Layer_3': 0.16232089490707435, 'dropout_rate_Layer_4': 0.1052713089871764, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003141421595173183, 'l1_Layer_2': 8.54834162755625e-05, 'l1_Layer_3': 0.0001892309158661177, 'l1_Layer_4': 1.3238098727287483e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 165, 'n_units_Layer_3': 135, 'n_units_Layer_4': 120}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.53 | sMAPE for Validation Set is: 42.74% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 109.20 | sMAPE for Test Set is: 88.40% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:37:44,873]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:37:50,652]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:37:56,275]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:38:00,981]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:38:06,269]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:38:11,375]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:38:16,573]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:38:19,920]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:38:24,515]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:38:30,132]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:38:46,787]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:38:52,711]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:39:06,290]\u001b[0m Trial 300 finished with value: 21.76879217158927 and parameters: {'n_hidden': 3, 'learning_rate': 0.01223114841327279, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35114630601840136, 'dropout_rate_Layer_2': 0.18873556796998917, 'dropout_rate_Layer_3': 0.3338346527049513, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029542234873060157, 'l1_Layer_2': 0.003911775374552133, 'l1_Layer_3': 0.005223354259429929, 'n_units_Layer_1': 240, 'n_units_Layer_2': 230, 'n_units_Layer_3': 300}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.77 | sMAPE for Validation Set is: 29.39% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.31 | sMAPE for Test Set is: 56.94% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:39:11,532]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:39:16,236]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:39:28,589]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:39:33,104]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:39:38,543]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:39:50,230]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:39:55,293]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:40:02,367]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:40:31,186]\u001b[0m Trial 309 finished with value: 35.9550026132985 and parameters: {'n_hidden': 4, 'learning_rate': 0.003077545875377894, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1582603387020729, 'dropout_rate_Layer_2': 0.34995773155580956, 'dropout_rate_Layer_3': 0.09910709707958583, 'dropout_rate_Layer_4': 0.15053950399043947, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004109197561035743, 'l1_Layer_2': 9.391938097269326e-05, 'l1_Layer_3': 0.0007295283129016926, 'l1_Layer_4': 1.2087119229717058e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 105, 'n_units_Layer_3': 75, 'n_units_Layer_4': 90}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.96 | sMAPE for Validation Set is: 44.24% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 112.10 | sMAPE for Test Set is: 91.19% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:40:36,831]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:40:41,404]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:40:44,937]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:40:50,602]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:40:55,334]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:40:59,887]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:41:04,841]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:41:09,975]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:41:15,543]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:41:20,045]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:41:23,320]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:41:27,389]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:41:38,261]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:41:42,551]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:41:47,674]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:42:02,802]\u001b[0m Trial 325 finished with value: 35.32707858676046 and parameters: {'n_hidden': 3, 'learning_rate': 0.0743165533483362, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19563758273840626, 'dropout_rate_Layer_2': 0.17367844421780995, 'dropout_rate_Layer_3': 0.029222953242263178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00033154463090112, 'l1_Layer_2': 0.011067647647103062, 'l1_Layer_3': 1.5922213605411504e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 250, 'n_units_Layer_3': 95}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.33 | sMAPE for Validation Set is: 44.98% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 109.49 | sMAPE for Test Set is: 90.01% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:42:07,289]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:42:12,491]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:42:18,304]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:42:23,123]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:42:28,138]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:42:49,633]\u001b[0m Trial 331 finished with value: 33.09753961310262 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012636488637260293, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1044397801504209, 'dropout_rate_Layer_2': 0.29054094376473877, 'dropout_rate_Layer_3': 0.11480870828220294, 'dropout_rate_Layer_4': 0.06944163227807901, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.025158433133274496, 'l1_Layer_2': 2.529134144144494e-05, 'l1_Layer_3': 6.666911685498635e-05, 'l1_Layer_4': 0.00010291188654630175, 'n_units_Layer_1': 100, 'n_units_Layer_2': 50, 'n_units_Layer_3': 115, 'n_units_Layer_4': 145}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.10 | sMAPE for Validation Set is: 40.56% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 105.44 | sMAPE for Test Set is: 84.95% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:43:14,882]\u001b[0m Trial 332 finished with value: 31.70357656082405 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008586895480267592, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05857782948537671, 'dropout_rate_Layer_2': 0.25029114623625565, 'dropout_rate_Layer_3': 0.11877072769077737, 'dropout_rate_Layer_4': 0.16643651039682186, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.027443382842034653, 'l1_Layer_2': 1.0638886524432556e-05, 'l1_Layer_3': 4.916114837207578e-05, 'l1_Layer_4': 0.00012080614156237115, 'n_units_Layer_1': 95, 'n_units_Layer_2': 60, 'n_units_Layer_3': 105, 'n_units_Layer_4': 165}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.70 | sMAPE for Validation Set is: 38.59% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 102.93 | sMAPE for Test Set is: 82.04% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:43:18,857]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:43:30,637]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:43:43,699]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:43:47,819]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:43:52,312]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:43:56,916]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:44:01,537]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:44:05,630]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:44:10,873]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:44:16,486]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:44:23,272]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:44:41,109]\u001b[0m Trial 344 finished with value: 21.56385913480483 and parameters: {'n_hidden': 3, 'learning_rate': 0.009852899792010488, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2117321903486224, 'dropout_rate_Layer_2': 0.03819464667473599, 'dropout_rate_Layer_3': 0.17173618329453116, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019120826184995496, 'l1_Layer_2': 0.000233984483217567, 'l1_Layer_3': 6.384212007333316e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 145, 'n_units_Layer_3': 70}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.56 | sMAPE for Validation Set is: 29.16% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.66 | sMAPE for Test Set is: 56.31% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:44:46,855]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:44:52,766]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:45:10,333]\u001b[0m Trial 347 finished with value: 35.17891366907005 and parameters: {'n_hidden': 3, 'learning_rate': 0.05869941934533704, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22348051901909521, 'dropout_rate_Layer_2': 0.22501757122453891, 'dropout_rate_Layer_3': 0.02246148265952521, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002445667695014916, 'l1_Layer_2': 0.0048613936443607205, 'l1_Layer_3': 1.9320727213805333e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 240, 'n_units_Layer_3': 100}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.18 | sMAPE for Validation Set is: 43.22% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 110.75 | sMAPE for Test Set is: 90.15% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:45:14,440]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:45:20,013]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:45:25,043]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:45:30,703]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:45:42,467]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:46:10,958]\u001b[0m Trial 353 finished with value: 34.56794219441253 and parameters: {'n_hidden': 4, 'learning_rate': 0.000869716781726028, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05542608123947495, 'dropout_rate_Layer_2': 0.24647268281633797, 'dropout_rate_Layer_3': 0.11502527151249034, 'dropout_rate_Layer_4': 0.16573698953661867, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03153644275858626, 'l1_Layer_2': 2.0223914776052484e-05, 'l1_Layer_3': 4.817437656220528e-05, 'l1_Layer_4': 0.00015797081923213808, 'n_units_Layer_1': 65, 'n_units_Layer_2': 50, 'n_units_Layer_3': 110, 'n_units_Layer_4': 175}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.57 | sMAPE for Validation Set is: 42.54% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 110.17 | sMAPE for Test Set is: 90.07% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:46:24,845]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:46:28,784]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:46:34,741]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:46:39,202]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:46:51,455]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:46:55,762]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:47:00,660]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:47:05,460]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:47:10,843]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:47:18,462]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:47:23,015]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:47:33,900]\u001b[0m Trial 365 finished with value: 22.055791501601533 and parameters: {'n_hidden': 3, 'learning_rate': 0.01297356747450937, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3550997230514935, 'dropout_rate_Layer_2': 0.19314136665910164, 'dropout_rate_Layer_3': 0.33167200895481785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000244419466499002, 'l1_Layer_2': 0.003738239244823459, 'l1_Layer_3': 0.005604865397121423, 'n_units_Layer_1': 245, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.06 | sMAPE for Validation Set is: 29.99% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.36 | sMAPE for Test Set is: 58.90% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:47:41,061]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:47:46,484]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:47:59,507]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:48:03,844]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:48:12,505]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:48:25,496]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:48:42,290]\u001b[0m Trial 372 finished with value: 33.024081812148815 and parameters: {'n_hidden': 3, 'learning_rate': 0.07601624351866872, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2199598152009672, 'dropout_rate_Layer_2': 0.3769086953959281, 'dropout_rate_Layer_3': 0.11371218212937227, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005856814673586345, 'l1_Layer_2': 0.003265548423454387, 'l1_Layer_3': 2.422136874405246e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 230, 'n_units_Layer_3': 70}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.02 | sMAPE for Validation Set is: 41.48% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 106.62 | sMAPE for Test Set is: 87.10% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:49:07,640]\u001b[0m Trial 373 finished with value: 21.73515551486273 and parameters: {'n_hidden': 3, 'learning_rate': 0.007100695477453681, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2942233191177852, 'dropout_rate_Layer_2': 0.13255599983995298, 'dropout_rate_Layer_3': 0.33294788998437524, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00038993489149244484, 'l1_Layer_2': 0.001444238364344527, 'l1_Layer_3': 0.00937902531495907, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 70}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.74 | sMAPE for Validation Set is: 29.30% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.40 | sMAPE for Test Set is: 57.21% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:49:30,118]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:49:35,745]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:49:40,748]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:49:46,054]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:50:13,123]\u001b[0m Trial 378 finished with value: 27.55347236524747 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008033366372876567, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1117261402365901, 'dropout_rate_Layer_2': 0.1939202281799829, 'dropout_rate_Layer_3': 0.11910619438891928, 'dropout_rate_Layer_4': 0.17415153037779524, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04723043066718044, 'l1_Layer_2': 4.77357727008803e-05, 'l1_Layer_3': 2.0719956008781453e-05, 'l1_Layer_4': 0.00026467183597717037, 'n_units_Layer_1': 165, 'n_units_Layer_2': 65, 'n_units_Layer_3': 50, 'n_units_Layer_4': 200}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.55 | sMAPE for Validation Set is: 34.20% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 95.35 | sMAPE for Test Set is: 76.48% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:50:25,719]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:50:48,569]\u001b[0m Trial 380 finished with value: 28.713569069390406 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007737932510779173, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02614546614955269, 'dropout_rate_Layer_2': 0.18999515945357365, 'dropout_rate_Layer_3': 0.06915937894211313, 'dropout_rate_Layer_4': 0.18595607987740553, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.044165331167828184, 'l1_Layer_2': 4.998952387819573e-05, 'l1_Layer_3': 2.1916547625264846e-05, 'l1_Layer_4': 0.0003862689575572737, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 50, 'n_units_Layer_4': 240}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.71 | sMAPE for Validation Set is: 35.51% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 97.32 | sMAPE for Test Set is: 77.83% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:50:58,254]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:51:03,502]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:51:10,885]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:51:18,103]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:51:41,319]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:51:45,914]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:52:14,233]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:52:18,825]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:52:30,196]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:52:34,848]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:52:39,429]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:52:43,406]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:52:55,515]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:52:59,908]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:53:18,876]\u001b[0m Trial 395 finished with value: 21.767532418928283 and parameters: {'n_hidden': 3, 'learning_rate': 0.007993354899660845, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1566147776674121, 'dropout_rate_Layer_2': 0.03829709383224757, 'dropout_rate_Layer_3': 0.21252592540856255, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013889019678362635, 'l1_Layer_2': 9.264601598189819e-05, 'l1_Layer_3': 0.00010660812065990647, 'n_units_Layer_1': 190, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.77 | sMAPE for Validation Set is: 29.33% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.97 | sMAPE for Test Set is: 57.33% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:53:24,633]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:53:29,878]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:53:33,734]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:53:53,938]\u001b[0m Trial 399 finished with value: 21.870961273469078 and parameters: {'n_hidden': 3, 'learning_rate': 0.006956752500865025, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18165556470315047, 'dropout_rate_Layer_2': 0.032220625763755104, 'dropout_rate_Layer_3': 0.1771343440195302, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006525104722219641, 'l1_Layer_2': 0.0005258889297563068, 'l1_Layer_3': 6.203092204305406e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 150, 'n_units_Layer_3': 95}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.87 | sMAPE for Validation Set is: 29.52% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 61.84 | sMAPE for Test Set is: 57.90% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:54:15,652]\u001b[0m Trial 400 finished with value: 33.56711379488615 and parameters: {'n_hidden': 3, 'learning_rate': 0.05606258681160131, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2160612817602883, 'dropout_rate_Layer_2': 0.38221893770663495, 'dropout_rate_Layer_3': 0.1066432010888892, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041873593360756836, 'l1_Layer_2': 0.0021751221418593964, 'l1_Layer_3': 2.150865198354552e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 235, 'n_units_Layer_3': 50}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.57 | sMAPE for Validation Set is: 43.12% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 106.14 | sMAPE for Test Set is: 86.63% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:54:34,340]\u001b[0m Trial 401 finished with value: 28.48403195334102 and parameters: {'n_hidden': 4, 'learning_rate': 0.000756326856230111, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028903872411272298, 'dropout_rate_Layer_2': 0.18722066984713437, 'dropout_rate_Layer_3': 0.06639559320516257, 'dropout_rate_Layer_4': 0.18174152340355212, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.052553900395584406, 'l1_Layer_2': 5.169749442800218e-05, 'l1_Layer_3': 2.8006835159072655e-05, 'l1_Layer_4': 0.00033578864121936667, 'n_units_Layer_1': 205, 'n_units_Layer_2': 70, 'n_units_Layer_3': 50, 'n_units_Layer_4': 255}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.48 | sMAPE for Validation Set is: 35.75% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 95.84 | sMAPE for Test Set is: 77.65% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:54:51,891]\u001b[0m Trial 402 finished with value: 21.554117571066655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0051676697339140204, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3097521124043785, 'dropout_rate_Layer_2': 0.11176576819336678, 'dropout_rate_Layer_3': 0.36761411702146685, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018927737357213146, 'l1_Layer_2': 0.00034245657922163635, 'l1_Layer_3': 0.021520106747270815, 'n_units_Layer_1': 185, 'n_units_Layer_2': 150, 'n_units_Layer_3': 160}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.55 | sMAPE for Validation Set is: 29.50% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 58.20 | sMAPE for Test Set is: 56.29% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:54:57,120]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:55:01,897]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:55:06,213]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:55:12,389]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:55:16,662]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:55:22,345]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:55:27,870]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:55:33,192]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:55:55,183]\u001b[0m Trial 411 finished with value: 29.824447663221054 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006199952679140788, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0015556393274523544, 'dropout_rate_Layer_2': 0.18396392027044217, 'dropout_rate_Layer_3': 0.042402865764850375, 'dropout_rate_Layer_4': 0.20045254391112624, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.05266725751845641, 'l1_Layer_2': 4.9303473955729066e-05, 'l1_Layer_3': 2.4535728832020094e-05, 'l1_Layer_4': 0.0004215995659241028, 'n_units_Layer_1': 200, 'n_units_Layer_2': 80, 'n_units_Layer_3': 50, 'n_units_Layer_4': 255}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.82 | sMAPE for Validation Set is: 36.83% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 98.50 | sMAPE for Test Set is: 79.36% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:55:58,937]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:56:03,897]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:56:33,878]\u001b[0m Trial 414 finished with value: 28.26825219658278 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007668025980061148, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030698683942708256, 'dropout_rate_Layer_2': 0.19700991963010392, 'dropout_rate_Layer_3': 0.08005366382882212, 'dropout_rate_Layer_4': 0.2479910598774921, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04944683244143525, 'l1_Layer_2': 5.2415338069196476e-05, 'l1_Layer_3': 2.6729298603980424e-05, 'l1_Layer_4': 0.0011428418598956516, 'n_units_Layer_1': 170, 'n_units_Layer_2': 110, 'n_units_Layer_3': 50, 'n_units_Layer_4': 240}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.27 | sMAPE for Validation Set is: 34.48% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 98.43 | sMAPE for Test Set is: 78.38% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:56:48,225]\u001b[0m Trial 415 finished with value: 22.266420175265562 and parameters: {'n_hidden': 3, 'learning_rate': 0.00622729085244972, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15658771714628694, 'dropout_rate_Layer_2': 0.006802986996151481, 'dropout_rate_Layer_3': 0.22946954140078404, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010775801593733497, 'l1_Layer_2': 0.00015405261698832527, 'l1_Layer_3': 0.00014991625768726193, 'n_units_Layer_1': 195, 'n_units_Layer_2': 135, 'n_units_Layer_3': 55}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.27 | sMAPE for Validation Set is: 29.79% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 60.51 | sMAPE for Test Set is: 57.84% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 07:56:53,347]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:57:02,768]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:57:07,273]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:57:12,408]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:57:19,016]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:57:24,982]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:57:29,938]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:57:34,102]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:57:47,288]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:57:52,494]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:57:57,057]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:58:02,725]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:58:08,786]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:58:14,240]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:58:18,868]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:58:30,070]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:58:33,877]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:58:38,734]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:58:44,144]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:58:49,193]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:58:57,863]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:59:02,541]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:59:07,834]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:59:13,501]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:59:18,706]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:59:27,848]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:59:32,444]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:59:41,735]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 07:59:56,221]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:00:00,716]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:00:04,641]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:00:18,759]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:00:41,913]\u001b[0m Trial 448 finished with value: 34.71091591492212 and parameters: {'n_hidden': 3, 'learning_rate': 0.06065580237602974, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23039672117387716, 'dropout_rate_Layer_2': 0.24297481301880297, 'dropout_rate_Layer_3': 0.2974009570537008, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009069723313529453, 'l1_Layer_2': 0.003714292749679147, 'l1_Layer_3': 3.819926903882263e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 105}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.71 | sMAPE for Validation Set is: 42.85% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 111.03 | sMAPE for Test Set is: 90.57% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:00:46,200]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:00:50,769]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:01:07,601]\u001b[0m Trial 451 finished with value: 31.271475748252158 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016224124882724144, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06756426522571651, 'dropout_rate_Layer_2': 0.19640945951090397, 'dropout_rate_Layer_3': 0.046544071827238666, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016020573010681032, 'l1_Layer_2': 0.00016602487457629829, 'l1_Layer_3': 9.244169075446288e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 135, 'n_units_Layer_3': 90}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.27 | sMAPE for Validation Set is: 37.98% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 104.25 | sMAPE for Test Set is: 83.85% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:01:27,577]\u001b[0m Trial 452 finished with value: 21.25989787855184 and parameters: {'n_hidden': 3, 'learning_rate': 0.003914138701556323, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2827169923304736, 'dropout_rate_Layer_2': 0.13450086430541303, 'dropout_rate_Layer_3': 0.3367084224285645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004014858737564392, 'l1_Layer_2': 0.0012640363406196894, 'l1_Layer_3': 0.0031132333412459056, 'n_units_Layer_1': 200, 'n_units_Layer_2': 120, 'n_units_Layer_3': 270}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.26 | sMAPE for Validation Set is: 28.83% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.66 | sMAPE for Test Set is: 56.71% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:01:31,736]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:01:36,107]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:01:41,137]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:01:57,887]\u001b[0m Trial 456 finished with value: 21.211029787447643 and parameters: {'n_hidden': 3, 'learning_rate': 0.002408596837380241, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3404111089642615, 'dropout_rate_Layer_2': 0.1540863529028848, 'dropout_rate_Layer_3': 0.3991910533389733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001276100554298428, 'l1_Layer_2': 0.0005682101299561633, 'l1_Layer_3': 0.0031503568699373947, 'n_units_Layer_1': 200, 'n_units_Layer_2': 120, 'n_units_Layer_3': 265}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.21 | sMAPE for Validation Set is: 28.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.39 | sMAPE for Test Set is: 56.37% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:02:53,593]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:03:05,687]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:03:10,840]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:03:15,649]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:03:20,760]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:03:25,517]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:03:29,376]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:03:34,980]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:03:39,627]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:03:44,357]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:03:48,464]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:03:53,565]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:04:16,669]\u001b[0m Trial 469 finished with value: 21.49446864540684 and parameters: {'n_hidden': 3, 'learning_rate': 0.004171522932379903, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3631186617932318, 'dropout_rate_Layer_2': 0.09788740040826041, 'dropout_rate_Layer_3': 0.385199141517639, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.515637601835888e-05, 'l1_Layer_2': 0.0003609474626526455, 'l1_Layer_3': 0.004337594490715521, 'n_units_Layer_1': 195, 'n_units_Layer_2': 120, 'n_units_Layer_3': 230}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.49 | sMAPE for Validation Set is: 29.24% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.00 | sMAPE for Test Set is: 56.43% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:04:21,280]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:04:26,591]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:04:32,031]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:04:36,522]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:04:41,217]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:05:16,231]\u001b[0m Trial 475 finished with value: 28.62631692910438 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006629177417476385, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22344038276953074, 'dropout_rate_Layer_2': 0.26342644646556834, 'dropout_rate_Layer_3': 0.026946531825911016, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013749231654015271, 'l1_Layer_2': 0.0003743550131734165, 'l1_Layer_3': 3.552825979253292e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 180, 'n_units_Layer_3': 65}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.63 | sMAPE for Validation Set is: 34.97% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 98.55 | sMAPE for Test Set is: 78.99% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:05:34,443]\u001b[0m Trial 476 finished with value: 21.466759767434677 and parameters: {'n_hidden': 3, 'learning_rate': 0.003871555202069624, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3597055539272904, 'dropout_rate_Layer_2': 0.09376518942739592, 'dropout_rate_Layer_3': 0.38334543067982757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.97671691518974e-05, 'l1_Layer_2': 0.00033034357432311156, 'l1_Layer_3': 0.0020083702790911237, 'n_units_Layer_1': 195, 'n_units_Layer_2': 100, 'n_units_Layer_3': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.47 | sMAPE for Validation Set is: 29.17% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.33 | sMAPE for Test Set is: 57.00% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:05:38,430]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:05:44,230]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:05:54,079]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:06:03,850]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:06:08,264]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:06:13,902]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:06:29,662]\u001b[0m Trial 483 finished with value: 21.71565850239698 and parameters: {'n_hidden': 3, 'learning_rate': 0.005293140434635675, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18294048559747692, 'dropout_rate_Layer_2': 0.03951180467815415, 'dropout_rate_Layer_3': 0.15442686979677442, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004736206875723975, 'l1_Layer_2': 0.000344826003536149, 'l1_Layer_3': 8.229946331317682e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 155, 'n_units_Layer_3': 155}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.72 | sMAPE for Validation Set is: 29.09% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.48 | sMAPE for Test Set is: 57.25% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:06:34,198]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:06:38,253]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:06:52,974]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:06:59,009]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:07:02,962]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:07:09,549]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:07:15,289]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:07:19,982]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:07:25,055]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:07:48,084]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:07:52,373]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:07:57,074]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:08:01,734]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:08:09,609]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:08:29,658]\u001b[0m Trial 498 finished with value: 21.25090404245441 and parameters: {'n_hidden': 3, 'learning_rate': 0.008972520685703167, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18794242891202598, 'dropout_rate_Layer_2': 0.0028025639702430535, 'dropout_rate_Layer_3': 0.12838896667410796, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023171773842063947, 'l1_Layer_2': 0.00019356641664944284, 'l1_Layer_3': 3.868714820575797e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 165, 'n_units_Layer_3': 175}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.25 | sMAPE for Validation Set is: 28.61% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.29 | sMAPE for Test Set is: 56.83% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:08:34,370]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:08:39,354]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:08:43,395]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:08:48,610]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:08:52,088]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:08:57,165]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:09:17,953]\u001b[0m Trial 505 finished with value: 21.349809980463565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025157166954635265, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3562818273929229, 'dropout_rate_Layer_2': 0.10377325509419431, 'dropout_rate_Layer_3': 0.34872196368593, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4767838203501703e-05, 'l1_Layer_2': 0.00044140060114073457, 'l1_Layer_3': 0.0036410232277027644, 'n_units_Layer_1': 190, 'n_units_Layer_2': 115, 'n_units_Layer_3': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.35 | sMAPE for Validation Set is: 29.17% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.06 | sMAPE for Test Set is: 56.32% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:09:22,094]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:09:27,358]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:09:32,032]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:09:41,392]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:09:46,926]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:10:18,930]\u001b[0m Trial 511 finished with value: 27.733256413595857 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006601743434112838, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23167074619664432, 'dropout_rate_Layer_2': 0.265465740385299, 'dropout_rate_Layer_3': 0.02366877967348119, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014535479363314724, 'l1_Layer_2': 0.0003332834625831234, 'l1_Layer_3': 3.620006151618988e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 185, 'n_units_Layer_3': 70}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.73 | sMAPE for Validation Set is: 33.86% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 96.72 | sMAPE for Test Set is: 77.01% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:10:23,849]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:10:49,669]\u001b[0m Trial 513 finished with value: 21.81356394173491 and parameters: {'n_hidden': 3, 'learning_rate': 0.002640896697010204, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34629031775687324, 'dropout_rate_Layer_2': 0.11435682487878134, 'dropout_rate_Layer_3': 0.34711559348078874, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3172858819531808e-05, 'l1_Layer_2': 0.00041426244681378013, 'l1_Layer_3': 0.003927517139112379, 'n_units_Layer_1': 175, 'n_units_Layer_2': 120, 'n_units_Layer_3': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.81 | sMAPE for Validation Set is: 29.69% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 59.94 | sMAPE for Test Set is: 57.23% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:10:54,119]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:10:58,901]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:11:04,025]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:11:08,558]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:11:12,531]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:11:16,324]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:11:27,241]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:11:32,261]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:11:39,719]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:11:44,834]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:12:05,074]\u001b[0m Trial 524 finished with value: 21.25588780436325 and parameters: {'n_hidden': 3, 'learning_rate': 0.004495928487488801, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3605050910094883, 'dropout_rate_Layer_2': 0.07427786453892024, 'dropout_rate_Layer_3': 0.37828744749637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.684057158680117e-05, 'l1_Layer_2': 0.0003411029534802252, 'l1_Layer_3': 0.002046156818475478, 'n_units_Layer_1': 190, 'n_units_Layer_2': 85, 'n_units_Layer_3': 195}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.26 | sMAPE for Validation Set is: 29.28% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.57 | sMAPE for Test Set is: 56.20% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:12:24,225]\u001b[0m Trial 525 finished with value: 21.47776238281745 and parameters: {'n_hidden': 3, 'learning_rate': 0.004642082943045895, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3549658243061384, 'dropout_rate_Layer_2': 0.06319111037178263, 'dropout_rate_Layer_3': 0.3798146004955005, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.027066415951229e-05, 'l1_Layer_2': 0.0003194637369315333, 'l1_Layer_3': 0.0021600629569194624, 'n_units_Layer_1': 190, 'n_units_Layer_2': 100, 'n_units_Layer_3': 190}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.48 | sMAPE for Validation Set is: 29.21% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.63 | sMAPE for Test Set is: 56.42% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:12:28,543]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:12:49,268]\u001b[0m Trial 527 finished with value: 21.65111420099518 and parameters: {'n_hidden': 3, 'learning_rate': 0.004204793621177544, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35776079662998644, 'dropout_rate_Layer_2': 0.06503877359320039, 'dropout_rate_Layer_3': 0.38150068627354505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.16361701215063e-05, 'l1_Layer_2': 0.00018985614396768315, 'l1_Layer_3': 0.00206698759078332, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 195}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.65 | sMAPE for Validation Set is: 29.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.18 | sMAPE for Test Set is: 57.32% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:12:54,234]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:12:58,557]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:13:04,331]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:13:09,125]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:13:13,883]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:13:18,019]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:13:23,364]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:13:31,215]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:13:36,442]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:13:40,690]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:13:53,626]\u001b[0m Trial 538 finished with value: 21.732438126538273 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028721743971559135, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37815726139209155, 'dropout_rate_Layer_2': 0.07501799577345138, 'dropout_rate_Layer_3': 0.38740098407880863, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.4806639221081e-05, 'l1_Layer_2': 0.0004682504890420104, 'l1_Layer_3': 0.0011558016246770572, 'n_units_Layer_1': 215, 'n_units_Layer_2': 100, 'n_units_Layer_3': 185}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.73 | sMAPE for Validation Set is: 29.41% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 59.66 | sMAPE for Test Set is: 56.79% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:14:04,173]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:14:16,253]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:14:22,303]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:14:33,151]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:14:38,277]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:14:42,835]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:14:46,882]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:15:11,106]\u001b[0m Trial 546 finished with value: 26.778215658131927 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006990392273195289, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23988711549295413, 'dropout_rate_Layer_2': 0.20661764895974644, 'dropout_rate_Layer_3': 0.06506728789249405, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018952440219876278, 'l1_Layer_2': 0.00011598598841770624, 'l1_Layer_3': 3.982574791940667e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 195, 'n_units_Layer_3': 75}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.78 | sMAPE for Validation Set is: 33.45% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 94.52 | sMAPE for Test Set is: 76.49% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:15:16,331]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:15:26,517]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:15:33,212]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:15:36,457]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:16:07,822]\u001b[0m Trial 551 finished with value: 27.348893895341252 and parameters: {'n_hidden': 3, 'learning_rate': 0.000661971406200199, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24569010590837242, 'dropout_rate_Layer_2': 0.20946531610833563, 'dropout_rate_Layer_3': 0.0370418497390856, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01661131138589946, 'l1_Layer_2': 0.00012261284347843258, 'l1_Layer_3': 3.574707005889288e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 195, 'n_units_Layer_3': 80}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.35 | sMAPE for Validation Set is: 33.55% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 95.07 | sMAPE for Test Set is: 75.98% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:16:12,412]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:16:17,660]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:16:23,608]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:16:27,927]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:16:32,554]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:16:46,024]\u001b[0m Trial 557 finished with value: 30.40526715594297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018304517071856046, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24441637606808087, 'dropout_rate_Layer_2': 0.23640769456851632, 'dropout_rate_Layer_3': 0.030188323188782992, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01078966244772061, 'l1_Layer_2': 0.00010978389138092827, 'l1_Layer_3': 3.938240106479783e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 190, 'n_units_Layer_3': 80}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.41 | sMAPE for Validation Set is: 36.97% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 102.79 | sMAPE for Test Set is: 82.85% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:17:12,917]\u001b[0m Trial 558 finished with value: 27.85469453727067 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006525919514264872, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2111494201261504, 'dropout_rate_Layer_2': 0.2593989445140482, 'dropout_rate_Layer_3': 0.008353467363268856, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018062254601517874, 'l1_Layer_2': 0.0003612497347537904, 'l1_Layer_3': 0.00012116586309208421, 'n_units_Layer_1': 270, 'n_units_Layer_2': 215, 'n_units_Layer_3': 90}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.85 | sMAPE for Validation Set is: 34.59% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 95.84 | sMAPE for Test Set is: 77.04% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:17:38,836]\u001b[0m Trial 559 finished with value: 29.856423433512948 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009760678045933958, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24104609578357647, 'dropout_rate_Layer_2': 0.21900230555563432, 'dropout_rate_Layer_3': 0.020786744048241032, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009718648220221025, 'l1_Layer_2': 0.00013468586473168182, 'l1_Layer_3': 1.6087218558622826e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 205, 'n_units_Layer_3': 120}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.86 | sMAPE for Validation Set is: 36.50% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 102.38 | sMAPE for Test Set is: 82.61% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:18:01,319]\u001b[0m Trial 560 finished with value: 29.220399505300673 and parameters: {'n_hidden': 3, 'learning_rate': 0.001258510783926687, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19198160864203834, 'dropout_rate_Layer_2': 0.1693067523116224, 'dropout_rate_Layer_3': 0.05143527407243315, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02068104613918847, 'l1_Layer_2': 0.00027297821535922915, 'l1_Layer_3': 6.946397132518596e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 230, 'n_units_Layer_3': 70}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.22 | sMAPE for Validation Set is: 35.57% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 100.21 | sMAPE for Test Set is: 80.34% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:18:06,566]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:18:11,673]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:18:16,559]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:18:28,304]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:18:32,292]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:18:37,474]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:18:47,482]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:18:52,757]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:18:57,325]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:19:03,304]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:19:08,155]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:19:12,298]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:19:23,179]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:19:27,479]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:19:32,134]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:19:39,518]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:19:43,107]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:19:46,862]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:19:51,877]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:19:56,707]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:20:00,596]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:20:05,295]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:20:31,552]\u001b[0m Trial 583 finished with value: 23.428638854675015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014983109052930388, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22585957935091, 'dropout_rate_Layer_2': 0.23728799040248277, 'dropout_rate_Layer_3': 0.038898509469266276, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03173512970297378, 'l1_Layer_2': 0.0014054773359736534, 'l1_Layer_3': 1.5958816004413632e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 170, 'n_units_Layer_3': 190}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.43 | sMAPE for Validation Set is: 31.10% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 65.26 | sMAPE for Test Set is: 60.18% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:20:36,973]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:20:41,789]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:20:47,672]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:20:52,867]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:20:57,306]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:21:21,202]\u001b[0m Trial 589 finished with value: 21.139110688088355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025545612902297034, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3513071482101855, 'dropout_rate_Layer_2': 0.04047836051089688, 'dropout_rate_Layer_3': 0.3698293445683899, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.580683045712695e-05, 'l1_Layer_2': 0.0005597496244628987, 'l1_Layer_3': 0.0025260900948181537, 'n_units_Layer_1': 210, 'n_units_Layer_2': 130, 'n_units_Layer_3': 170}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.14 | sMAPE for Validation Set is: 28.79% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.85 | sMAPE for Test Set is: 56.03% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:21:26,479]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:21:30,326]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:21:34,163]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:21:44,622]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:21:49,590]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:21:54,120]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:21:59,432]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:22:12,061]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:22:16,484]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:22:21,866]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:22:29,477]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:22:34,355]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:22:40,112]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:22:45,800]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:23:00,920]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:23:05,211]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:23:13,334]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:23:18,105]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:23:22,703]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:23:27,907]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:23:31,496]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:23:58,518]\u001b[0m Trial 611 finished with value: 22.60393880736451 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010167638042076733, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.191961145080978, 'dropout_rate_Layer_2': 0.26833591062135187, 'dropout_rate_Layer_3': 0.036724184424996774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07166668426561301, 'l1_Layer_2': 0.0001676222642700656, 'l1_Layer_3': 3.9071929904636724e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 255, 'n_units_Layer_3': 175}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.60 | sMAPE for Validation Set is: 30.35% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 62.39 | sMAPE for Test Set is: 58.58% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:24:03,172]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:24:07,851]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:24:13,091]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:24:43,487]\u001b[0m Trial 615 finished with value: 23.455455286633818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010585556529897496, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19100626906678503, 'dropout_rate_Layer_2': 0.20911242547292896, 'dropout_rate_Layer_3': 0.039713061611680846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07809619601549987, 'l1_Layer_2': 0.00016157531594134281, 'l1_Layer_3': 6.518542299700855e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 185}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.46 | sMAPE for Validation Set is: 31.25% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 64.59 | sMAPE for Test Set is: 60.14% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:24:48,514]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:24:52,714]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:24:57,715]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:25:03,117]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:25:07,181]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:25:27,962]\u001b[0m Trial 621 finished with value: 21.30142437566037 and parameters: {'n_hidden': 3, 'learning_rate': 0.003768390260852196, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3694243658437144, 'dropout_rate_Layer_2': 0.09783953388977577, 'dropout_rate_Layer_3': 0.38220353236434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.79641156093738e-05, 'l1_Layer_2': 0.0005831685063492609, 'l1_Layer_3': 0.006097624660372156, 'n_units_Layer_1': 210, 'n_units_Layer_2': 75, 'n_units_Layer_3': 220}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.30 | sMAPE for Validation Set is: 29.26% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.35 | sMAPE for Test Set is: 57.02% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:25:54,277]\u001b[0m Trial 622 finished with value: 22.901605133504177 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015698607587587266, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1994602086090586, 'dropout_rate_Layer_2': 0.20482977756592194, 'dropout_rate_Layer_3': 0.03728350483763829, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07499468826562408, 'l1_Layer_2': 0.00017136576311687528, 'l1_Layer_3': 1.8078235339205282e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 255, 'n_units_Layer_3': 170}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.90 | sMAPE for Validation Set is: 30.76% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 63.30 | sMAPE for Test Set is: 59.11% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:26:10,621]\u001b[0m Trial 623 finished with value: 21.188782074936913 and parameters: {'n_hidden': 3, 'learning_rate': 0.008277888402419949, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19644188404462543, 'dropout_rate_Layer_2': 0.019168320858306574, 'dropout_rate_Layer_3': 0.1803785224722257, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007991377817863182, 'l1_Layer_2': 0.0004979183203455774, 'l1_Layer_3': 6.05958996617986e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 125, 'n_units_Layer_3': 70}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.19 | sMAPE for Validation Set is: 28.66% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 60.21 | sMAPE for Test Set is: 57.30% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:26:14,650]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:26:44,158]\u001b[0m Trial 625 finished with value: 23.442281814953475 and parameters: {'n_hidden': 3, 'learning_rate': 0.001462994153217222, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19053077275520688, 'dropout_rate_Layer_2': 0.20669695982697656, 'dropout_rate_Layer_3': 0.039023835429921536, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09690110562088015, 'l1_Layer_2': 0.00020354087404620503, 'l1_Layer_3': 1.0121642721582673e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 270, 'n_units_Layer_3': 180}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.44 | sMAPE for Validation Set is: 31.20% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 65.61 | sMAPE for Test Set is: 60.62% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:26:59,326]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:27:23,734]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:27:28,650]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:27:34,018]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:27:56,239]\u001b[0m Trial 630 finished with value: 23.110536895790585 and parameters: {'n_hidden': 3, 'learning_rate': 0.001453280534662452, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19857746846306187, 'dropout_rate_Layer_2': 0.22919349631622254, 'dropout_rate_Layer_3': 0.011753672248657459, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07407434586726706, 'l1_Layer_2': 0.0002120470580470907, 'l1_Layer_3': 1.1466029011795624e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 265, 'n_units_Layer_3': 175}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.11 | sMAPE for Validation Set is: 30.59% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 64.41 | sMAPE for Test Set is: 59.56% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:28:01,088]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:28:05,934]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:28:27,656]\u001b[0m Trial 633 finished with value: 21.81056637341889 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030934605717468817, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38088800738280637, 'dropout_rate_Layer_2': 0.09422067220208821, 'dropout_rate_Layer_3': 0.3615377005863357, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011506154439728447, 'l1_Layer_2': 0.000413637330676179, 'l1_Layer_3': 0.0036062231928333656, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.81 | sMAPE for Validation Set is: 29.85% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 58.82 | sMAPE for Test Set is: 56.84% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:28:58,593]\u001b[0m Trial 634 finished with value: 23.79600183778635 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014220876062873563, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19312751328100594, 'dropout_rate_Layer_2': 0.23174597785683312, 'dropout_rate_Layer_3': 0.009663003416469515, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07385888700804089, 'l1_Layer_2': 0.0005280555838201496, 'l1_Layer_3': 1.0816847354889125e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 270, 'n_units_Layer_3': 175}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.80 | sMAPE for Validation Set is: 31.50% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 66.20 | sMAPE for Test Set is: 60.55% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:29:03,428]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:29:07,695]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:29:11,930]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:29:22,325]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:29:26,757]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:29:32,126]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:29:37,159]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:29:42,015]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:29:56,167]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:30:00,879]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:30:05,198]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:30:09,692]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:30:15,596]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:30:20,315]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:32:01,443]\u001b[0m Trial 649 finished with value: 22.53925853301693 and parameters: {'n_hidden': 3, 'learning_rate': 0.08357892265806395, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01756392830739655, 'dropout_rate_Layer_2': 0.2576254898652389, 'dropout_rate_Layer_3': 0.2626477767282938, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001267230107471417, 'l1_Layer_2': 0.006981623797470879, 'l1_Layer_3': 1.0129209213106938e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.54 | sMAPE for Validation Set is: 30.65% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 60.47 | sMAPE for Test Set is: 57.65% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:32:05,447]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:32:14,199]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:32:25,600]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:32:30,878]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:32:35,158]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:32:56,995]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:33:24,962]\u001b[0m Trial 656 finished with value: 23.794099339499823 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026426981430207096, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20684157404079032, 'dropout_rate_Layer_2': 0.22721357495973823, 'dropout_rate_Layer_3': 0.017357516434043933, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09708535710527985, 'l1_Layer_2': 0.00020460998972686055, 'l1_Layer_3': 1.2493993260204749e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 160}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.79 | sMAPE for Validation Set is: 31.31% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 66.67 | sMAPE for Test Set is: 60.64% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:33:35,955]\u001b[0m Trial 657 finished with value: 21.735898810575478 and parameters: {'n_hidden': 3, 'learning_rate': 0.006113025701064343, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3485307631825747, 'dropout_rate_Layer_2': 0.11831037999744287, 'dropout_rate_Layer_3': 0.38426574790976586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.049302093338884e-05, 'l1_Layer_2': 0.0012124478752163525, 'l1_Layer_3': 0.004750829896669479, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.74 | sMAPE for Validation Set is: 29.70% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.81 | sMAPE for Test Set is: 58.31% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:33:41,565]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:33:47,501]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:33:53,113]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:33:57,025]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:34:08,543]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:34:13,868]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:34:19,096]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:34:52,001]\u001b[0m Trial 665 finished with value: 23.90600669534291 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019727677439497168, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16461227909501372, 'dropout_rate_Layer_2': 0.2992835077243205, 'dropout_rate_Layer_3': 0.0020663499712016142, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06991967811487136, 'l1_Layer_2': 0.0002609190929797762, 'l1_Layer_3': 1.6961624116747472e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 250, 'n_units_Layer_3': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.91 | sMAPE for Validation Set is: 31.32% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 67.04 | sMAPE for Test Set is: 60.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:35:02,594]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:35:09,118]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:35:13,372]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:35:24,663]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:35:30,190]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:35:35,362]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:35:39,186]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:35:43,313]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:35:47,407]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:35:53,572]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:36:21,418]\u001b[0m Trial 676 finished with value: 23.081770660242338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014500215550707918, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20346715977004118, 'dropout_rate_Layer_2': 0.2747925875029663, 'dropout_rate_Layer_3': 0.038064725828529426, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0701952481367934, 'l1_Layer_2': 0.0011069370206451025, 'l1_Layer_3': 1.11777276312482e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.08 | sMAPE for Validation Set is: 30.87% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 62.55 | sMAPE for Test Set is: 58.66% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:36:26,886]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:36:31,764]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:36:37,864]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:36:41,832]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:36:52,881]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:37:17,233]\u001b[0m Trial 682 finished with value: 21.674148904091407 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025019168876163965, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36686229000514486, 'dropout_rate_Layer_2': 0.13649115664733139, 'dropout_rate_Layer_3': 0.37172609435745807, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013235773610978678, 'l1_Layer_2': 0.0007367186236738728, 'l1_Layer_3': 0.005576767328123418, 'n_units_Layer_1': 180, 'n_units_Layer_2': 60, 'n_units_Layer_3': 220}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.67 | sMAPE for Validation Set is: 29.76% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.62 | sMAPE for Test Set is: 57.15% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:37:24,857]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:37:31,113]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:37:35,951]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:38:31,310]\u001b[0m Trial 686 finished with value: 22.711064202490245 and parameters: {'n_hidden': 3, 'learning_rate': 0.07009263052209885, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2079271973229945, 'dropout_rate_Layer_2': 0.23294900831867588, 'dropout_rate_Layer_3': 0.21757225901739352, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021231592081937602, 'l1_Layer_2': 0.0007907194830470577, 'l1_Layer_3': 2.9209635908173017e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 225, 'n_units_Layer_3': 65}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.71 | sMAPE for Validation Set is: 30.44% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 62.91 | sMAPE for Test Set is: 58.87% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:38:37,973]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:39:44,962]\u001b[0m Trial 688 finished with value: 25.759640427969913 and parameters: {'n_hidden': 4, 'learning_rate': 0.05484484172806502, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26049543740411196, 'dropout_rate_Layer_2': 0.23031718345748378, 'dropout_rate_Layer_3': 0.22925287142663994, 'dropout_rate_Layer_4': 0.34453712322651187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001575422574508364, 'l1_Layer_2': 0.0007137455789120937, 'l1_Layer_3': 3.057913646501117e-05, 'l1_Layer_4': 0.01696255493707956, 'n_units_Layer_1': 280, 'n_units_Layer_2': 220, 'n_units_Layer_3': 65, 'n_units_Layer_4': 205}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.76 | sMAPE for Validation Set is: 33.77% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 70.16 | sMAPE for Test Set is: 63.51% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:39:51,016]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:39:59,419]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:40:05,886]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:41:06,671]\u001b[0m Trial 692 finished with value: 23.546489435396605 and parameters: {'n_hidden': 4, 'learning_rate': 0.005771377284068834, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2555463620857499, 'dropout_rate_Layer_2': 0.21871471471952628, 'dropout_rate_Layer_3': 0.22155737344104748, 'dropout_rate_Layer_4': 0.3326787835177573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00016694903912127363, 'l1_Layer_2': 0.0005038142852204639, 'l1_Layer_3': 2.3039985971304887e-05, 'l1_Layer_4': 0.014683880889237532, 'n_units_Layer_1': 65, 'n_units_Layer_2': 220, 'n_units_Layer_3': 110, 'n_units_Layer_4': 225}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.55 | sMAPE for Validation Set is: 31.56% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 64.31 | sMAPE for Test Set is: 59.91% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:42:05,764]\u001b[0m Trial 693 finished with value: 24.131096936164624 and parameters: {'n_hidden': 4, 'learning_rate': 0.0051464047884397625, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2493317403907421, 'dropout_rate_Layer_2': 0.2280220487366427, 'dropout_rate_Layer_3': 0.21494871394740248, 'dropout_rate_Layer_4': 0.32702743394917155, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017047867156988412, 'l1_Layer_2': 0.000544158446970278, 'l1_Layer_3': 2.3240852409713782e-05, 'l1_Layer_4': 0.01581861987645694, 'n_units_Layer_1': 70, 'n_units_Layer_2': 210, 'n_units_Layer_3': 110, 'n_units_Layer_4': 225}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.13 | sMAPE for Validation Set is: 31.90% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 66.88 | sMAPE for Test Set is: 60.83% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:42:11,485]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:42:17,215]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:43:16,776]\u001b[0m Trial 696 finished with value: 22.638671840555844 and parameters: {'n_hidden': 4, 'learning_rate': 0.0062386378007254824, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25149394050548374, 'dropout_rate_Layer_2': 0.22695909305966833, 'dropout_rate_Layer_3': 0.2069584750142229, 'dropout_rate_Layer_4': 0.32817580055614626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017032190703824982, 'l1_Layer_2': 0.00045355283984469246, 'l1_Layer_3': 2.577504955260691e-05, 'l1_Layer_4': 0.01623374863814073, 'n_units_Layer_1': 70, 'n_units_Layer_2': 210, 'n_units_Layer_3': 115, 'n_units_Layer_4': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.64 | sMAPE for Validation Set is: 30.87% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 62.10 | sMAPE for Test Set is: 58.84% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:43:23,397]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:43:48,024]\u001b[0m Trial 698 finished with value: 21.13607347160134 and parameters: {'n_hidden': 3, 'learning_rate': 0.005242494222972277, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2056786871895352, 'dropout_rate_Layer_2': 0.03385298931436384, 'dropout_rate_Layer_3': 0.14327424587573484, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002390135952501521, 'l1_Layer_2': 0.0005368723807984632, 'l1_Layer_3': 0.000929733945505324, 'n_units_Layer_1': 235, 'n_units_Layer_2': 135, 'n_units_Layer_3': 95}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.14 | sMAPE for Validation Set is: 28.38% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 63.02 | sMAPE for Test Set is: 58.03% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:45:42,437]\u001b[0m Trial 699 finished with value: 24.28082703465856 and parameters: {'n_hidden': 4, 'learning_rate': 0.005346819757209166, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25152141406830986, 'dropout_rate_Layer_2': 0.22560404540222315, 'dropout_rate_Layer_3': 0.2111387203902434, 'dropout_rate_Layer_4': 0.31537088572912303, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00015828201803175506, 'l1_Layer_2': 0.0007305165182344013, 'l1_Layer_3': 2.5382261380457106e-05, 'l1_Layer_4': 0.01693861707247185, 'n_units_Layer_1': 70, 'n_units_Layer_2': 200, 'n_units_Layer_3': 120, 'n_units_Layer_4': 205}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.28 | sMAPE for Validation Set is: 32.85% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 66.02 | sMAPE for Test Set is: 61.31% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:45:48,649]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:45:58,429]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:46:22,828]\u001b[0m Trial 702 finished with value: 23.69324153786931 and parameters: {'n_hidden': 4, 'learning_rate': 0.004728854298119452, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25209093810534144, 'dropout_rate_Layer_2': 0.22253644839081677, 'dropout_rate_Layer_3': 0.21731991975582698, 'dropout_rate_Layer_4': 0.3393036757952368, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001285211199988286, 'l1_Layer_2': 0.0007061331709073191, 'l1_Layer_3': 2.3282015102934757e-05, 'l1_Layer_4': 0.011779570943163916, 'n_units_Layer_1': 65, 'n_units_Layer_2': 205, 'n_units_Layer_3': 120, 'n_units_Layer_4': 195}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.69 | sMAPE for Validation Set is: 31.85% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 63.47 | sMAPE for Test Set is: 60.08% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:46:27,574]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:46:33,035]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:46:37,111]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:47:05,922]\u001b[0m Trial 706 finished with value: 24.14098690469616 and parameters: {'n_hidden': 4, 'learning_rate': 0.005977219159034976, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24851376933998529, 'dropout_rate_Layer_2': 0.22641756603046476, 'dropout_rate_Layer_3': 0.2044494505507096, 'dropout_rate_Layer_4': 0.34759328338104595, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014087761571382967, 'l1_Layer_2': 0.0003939381170473861, 'l1_Layer_3': 3.08384962799955e-05, 'l1_Layer_4': 0.020521972352418406, 'n_units_Layer_1': 70, 'n_units_Layer_2': 205, 'n_units_Layer_3': 120, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.14 | sMAPE for Validation Set is: 32.33% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 64.56 | sMAPE for Test Set is: 60.96% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:47:28,483]\u001b[0m Trial 707 finished with value: 24.21385551259948 and parameters: {'n_hidden': 4, 'learning_rate': 0.006052786937014757, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2460162631385066, 'dropout_rate_Layer_2': 0.22771100476350242, 'dropout_rate_Layer_3': 0.20593465496350907, 'dropout_rate_Layer_4': 0.35923113851709026, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001154459544984944, 'l1_Layer_2': 0.000737597723640685, 'l1_Layer_3': 2.911953470436064e-05, 'l1_Layer_4': 0.021227856374545603, 'n_units_Layer_1': 70, 'n_units_Layer_2': 205, 'n_units_Layer_3': 125, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.21 | sMAPE for Validation Set is: 32.39% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 65.14 | sMAPE for Test Set is: 61.04% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:47:49,336]\u001b[0m Trial 708 finished with value: 24.543994179020604 and parameters: {'n_hidden': 4, 'learning_rate': 0.005973071622804556, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2449704028697264, 'dropout_rate_Layer_2': 0.22768229597778933, 'dropout_rate_Layer_3': 0.20636141866039748, 'dropout_rate_Layer_4': 0.3567882325850578, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010970637030578581, 'l1_Layer_2': 0.0007183085732506962, 'l1_Layer_3': 2.7490093048050323e-05, 'l1_Layer_4': 0.02023372387261151, 'n_units_Layer_1': 70, 'n_units_Layer_2': 200, 'n_units_Layer_3': 125, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.54 | sMAPE for Validation Set is: 33.25% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 66.96 | sMAPE for Test Set is: 61.94% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:47:53,825]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:48:15,537]\u001b[0m Trial 710 finished with value: 24.156203268875185 and parameters: {'n_hidden': 4, 'learning_rate': 0.005857950651242206, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.251090361894021, 'dropout_rate_Layer_2': 0.23414269144722968, 'dropout_rate_Layer_3': 0.20607287722415202, 'dropout_rate_Layer_4': 0.35978498944104426, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00011332468637446353, 'l1_Layer_2': 0.0007273224872645533, 'l1_Layer_3': 2.6646551641373516e-05, 'l1_Layer_4': 0.021703706304315947, 'n_units_Layer_1': 70, 'n_units_Layer_2': 205, 'n_units_Layer_3': 130, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.16 | sMAPE for Validation Set is: 33.69% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 63.56 | sMAPE for Test Set is: 60.17% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:48:19,757]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:48:51,417]\u001b[0m Trial 712 finished with value: 23.49012717316271 and parameters: {'n_hidden': 4, 'learning_rate': 0.005988831705225333, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2541693429053413, 'dropout_rate_Layer_2': 0.2302962391465942, 'dropout_rate_Layer_3': 0.20692222081238731, 'dropout_rate_Layer_4': 0.3634547884418959, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010508240845481863, 'l1_Layer_2': 0.0007534509030779845, 'l1_Layer_3': 2.8669064862260077e-05, 'l1_Layer_4': 0.02302463153609967, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.49 | sMAPE for Validation Set is: 31.59% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 63.79 | sMAPE for Test Set is: 60.33% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:49:21,613]\u001b[0m Trial 713 finished with value: 23.39034602961283 and parameters: {'n_hidden': 4, 'learning_rate': 0.0059669075176652766, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24734003366377827, 'dropout_rate_Layer_2': 0.23156048854217845, 'dropout_rate_Layer_3': 0.20693429332542126, 'dropout_rate_Layer_4': 0.35925202556150115, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00011956652033097686, 'l1_Layer_2': 0.0007091157383002052, 'l1_Layer_3': 2.9099402087096803e-05, 'l1_Layer_4': 0.02380237729804009, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.39 | sMAPE for Validation Set is: 32.07% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 63.40 | sMAPE for Test Set is: 60.00% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:49:47,114]\u001b[0m Trial 714 finished with value: 22.72686453046302 and parameters: {'n_hidden': 3, 'learning_rate': 0.001549988335473689, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2009708593544761, 'dropout_rate_Layer_2': 0.2761659308689688, 'dropout_rate_Layer_3': 0.03796202033679598, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07377221706663431, 'l1_Layer_2': 0.001009115569814893, 'l1_Layer_3': 1.293598430148041e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 180}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.73 | sMAPE for Validation Set is: 30.42% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 62.05 | sMAPE for Test Set is: 58.65% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:50:16,643]\u001b[0m Trial 715 finished with value: 24.266572126591893 and parameters: {'n_hidden': 4, 'learning_rate': 0.005952686840956804, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.246768521081176, 'dropout_rate_Layer_2': 0.23080237908868492, 'dropout_rate_Layer_3': 0.2081608429207163, 'dropout_rate_Layer_4': 0.3580100422437816, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010031401564633823, 'l1_Layer_2': 0.0007478927438771359, 'l1_Layer_3': 2.9470211388541617e-05, 'l1_Layer_4': 0.022442033840722717, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.27 | sMAPE for Validation Set is: 32.41% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 66.17 | sMAPE for Test Set is: 61.46% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:50:20,646]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:50:40,791]\u001b[0m Trial 717 finished with value: 23.938257216426024 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015501849360022937, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21318532784266525, 'dropout_rate_Layer_2': 0.27427918146341773, 'dropout_rate_Layer_3': 0.05075279558534997, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09714479983799999, 'l1_Layer_2': 0.0014254688660377778, 'l1_Layer_3': 1.0735237855886105e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 170}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.94 | sMAPE for Validation Set is: 32.25% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 63.30 | sMAPE for Test Set is: 60.40% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:51:22,238]\u001b[0m Trial 718 finished with value: 23.575630079114905 and parameters: {'n_hidden': 4, 'learning_rate': 0.005944798589583935, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24794065920496247, 'dropout_rate_Layer_2': 0.23037100156974552, 'dropout_rate_Layer_3': 0.20686004782939546, 'dropout_rate_Layer_4': 0.3584525841079182, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.883031629798685e-05, 'l1_Layer_2': 0.0007622300250455891, 'l1_Layer_3': 2.8250043015894363e-05, 'l1_Layer_4': 0.020580339136945475, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.58 | sMAPE for Validation Set is: 32.65% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 63.29 | sMAPE for Test Set is: 60.36% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:51:51,645]\u001b[0m Trial 719 finished with value: 24.116741472302866 and parameters: {'n_hidden': 4, 'learning_rate': 0.005874189978779, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.246868980392752, 'dropout_rate_Layer_2': 0.23244055913742243, 'dropout_rate_Layer_3': 0.20297797376213797, 'dropout_rate_Layer_4': 0.35939984885212184, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010104217022597393, 'l1_Layer_2': 0.0007678317783081839, 'l1_Layer_3': 2.5733012523105294e-05, 'l1_Layer_4': 0.021820795915317867, 'n_units_Layer_1': 70, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130, 'n_units_Layer_4': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.12 | sMAPE for Validation Set is: 32.62% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 66.10 | sMAPE for Test Set is: 61.10% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:52:28,360]\u001b[0m Trial 720 finished with value: 24.191836838808808 and parameters: {'n_hidden': 4, 'learning_rate': 0.005875698117291366, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2489566928161175, 'dropout_rate_Layer_2': 0.23266347131241713, 'dropout_rate_Layer_3': 0.20673595040471868, 'dropout_rate_Layer_4': 0.3617110418083096, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010650162612308996, 'l1_Layer_2': 0.000748291259240136, 'l1_Layer_3': 2.961178286178147e-05, 'l1_Layer_4': 0.020940694925950215, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.19 | sMAPE for Validation Set is: 32.28% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 67.20 | sMAPE for Test Set is: 61.43% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:52:33,493]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:53:17,119]\u001b[0m Trial 722 finished with value: 23.189755161810854 and parameters: {'n_hidden': 4, 'learning_rate': 0.0058379681332211076, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.250191258652767, 'dropout_rate_Layer_2': 0.23275613552828248, 'dropout_rate_Layer_3': 0.20776803906885646, 'dropout_rate_Layer_4': 0.36000944131760576, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010122744178726806, 'l1_Layer_2': 0.0007585886419432169, 'l1_Layer_3': 2.7040947308231474e-05, 'l1_Layer_4': 0.022283511172941806, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.19 | sMAPE for Validation Set is: 31.24% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 63.91 | sMAPE for Test Set is: 59.85% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:53:33,920]\u001b[0m Trial 723 finished with value: 23.0797267599834 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027236509703771755, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20063708060554128, 'dropout_rate_Layer_2': 0.2897065651741015, 'dropout_rate_Layer_3': 0.019327723730750757, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.035904644625617176, 'l1_Layer_2': 0.0007155335047466971, 'l1_Layer_3': 1.8627704328299632e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 280, 'n_units_Layer_3': 200}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.08 | sMAPE for Validation Set is: 30.61% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 64.22 | sMAPE for Test Set is: 60.02% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:54:02,077]\u001b[0m Trial 724 finished with value: 24.72377839020511 and parameters: {'n_hidden': 4, 'learning_rate': 0.005539676409120911, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24872430973424428, 'dropout_rate_Layer_2': 0.22924576440610445, 'dropout_rate_Layer_3': 0.2064517617937277, 'dropout_rate_Layer_4': 0.35554960576618433, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.595415865864053e-05, 'l1_Layer_2': 0.0007501784574972641, 'l1_Layer_3': 2.882017464741053e-05, 'l1_Layer_4': 0.023158068372852128, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.72 | sMAPE for Validation Set is: 33.09% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 66.05 | sMAPE for Test Set is: 61.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:54:30,132]\u001b[0m Trial 725 finished with value: 24.142418884187663 and parameters: {'n_hidden': 4, 'learning_rate': 0.005866379006138104, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2484595996571598, 'dropout_rate_Layer_2': 0.23181893636723752, 'dropout_rate_Layer_3': 0.20532956109001368, 'dropout_rate_Layer_4': 0.35910951190032897, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010017611001539034, 'l1_Layer_2': 0.000765937840507153, 'l1_Layer_3': 2.8839846673731382e-05, 'l1_Layer_4': 0.022414681768866795, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.14 | sMAPE for Validation Set is: 32.65% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 64.54 | sMAPE for Test Set is: 61.04% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:55:13,963]\u001b[0m Trial 726 finished with value: 23.382988822557852 and parameters: {'n_hidden': 4, 'learning_rate': 0.005828251508837526, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24895845576161435, 'dropout_rate_Layer_2': 0.23416683571887079, 'dropout_rate_Layer_3': 0.20671315166756282, 'dropout_rate_Layer_4': 0.36005545432901864, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.966686991148348e-05, 'l1_Layer_2': 0.0007451106149062847, 'l1_Layer_3': 2.967009692261091e-05, 'l1_Layer_4': 0.022557739116848444, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.38 | sMAPE for Validation Set is: 31.90% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 62.37 | sMAPE for Test Set is: 59.94% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:55:42,162]\u001b[0m Trial 727 finished with value: 23.90593699588456 and parameters: {'n_hidden': 4, 'learning_rate': 0.005873967756032718, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24964733250841367, 'dropout_rate_Layer_2': 0.23238644918062057, 'dropout_rate_Layer_3': 0.2045099059711813, 'dropout_rate_Layer_4': 0.35703848208289946, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.961237518787383e-05, 'l1_Layer_2': 0.000753312849628989, 'l1_Layer_3': 2.9635327727693402e-05, 'l1_Layer_4': 0.021887059867151972, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.91 | sMAPE for Validation Set is: 32.33% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 63.64 | sMAPE for Test Set is: 60.36% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:55:48,942]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:56:09,581]\u001b[0m Trial 729 finished with value: 22.77234603914691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025379163067526, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1665063609260985, 'dropout_rate_Layer_2': 0.2913697602730439, 'dropout_rate_Layer_3': 0.018252491848814358, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03414195233125345, 'l1_Layer_2': 0.0019693932668929685, 'l1_Layer_3': 1.948082857991721e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 300, 'n_units_Layer_3': 235}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.77 | sMAPE for Validation Set is: 30.48% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 63.67 | sMAPE for Test Set is: 59.51% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:56:13,549]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:56:34,031]\u001b[0m Trial 731 finished with value: 24.392945948954623 and parameters: {'n_hidden': 4, 'learning_rate': 0.005788752674092885, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24904914479525972, 'dropout_rate_Layer_2': 0.23245340007018944, 'dropout_rate_Layer_3': 0.20519584919614445, 'dropout_rate_Layer_4': 0.3597442478328158, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.131842335725108e-05, 'l1_Layer_2': 0.0007423556161643088, 'l1_Layer_3': 2.9486513580549974e-05, 'l1_Layer_4': 0.023251369660891048, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.39 | sMAPE for Validation Set is: 33.57% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 63.57 | sMAPE for Test Set is: 60.21% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:56:59,429]\u001b[0m Trial 732 finished with value: 24.14420953609424 and parameters: {'n_hidden': 4, 'learning_rate': 0.005836451766814635, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2550410193889511, 'dropout_rate_Layer_2': 0.2315621582151871, 'dropout_rate_Layer_3': 0.20678425275585635, 'dropout_rate_Layer_4': 0.3591343264139659, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.156405134125527e-05, 'l1_Layer_2': 0.0007788803001621185, 'l1_Layer_3': 3.0326986976020125e-05, 'l1_Layer_4': 0.022288847005689495, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 210}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.14 | sMAPE for Validation Set is: 32.45% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 66.89 | sMAPE for Test Set is: 61.35% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:57:04,750]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:57:16,425]\u001b[0m Trial 734 finished with value: 21.835072209828393 and parameters: {'n_hidden': 3, 'learning_rate': 0.005140514268224759, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34266806598319116, 'dropout_rate_Layer_2': 0.12017661689919729, 'dropout_rate_Layer_3': 0.36878648207483883, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022656959488976874, 'l1_Layer_2': 0.000317523611979298, 'l1_Layer_3': 0.0032475061489607854, 'n_units_Layer_1': 200, 'n_units_Layer_2': 115, 'n_units_Layer_3': 155}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.84 | sMAPE for Validation Set is: 29.81% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.20 | sMAPE for Test Set is: 57.68% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:57:21,800]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:57:25,883]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:57:30,013]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 08:58:25,944]\u001b[0m Trial 738 finished with value: 23.730699774824927 and parameters: {'n_hidden': 4, 'learning_rate': 0.0058460684401476426, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2502085498205893, 'dropout_rate_Layer_2': 0.2341166893696168, 'dropout_rate_Layer_3': 0.20623604347426108, 'dropout_rate_Layer_4': 0.35884493757380853, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.385769131860247e-05, 'l1_Layer_2': 0.0008119830842833977, 'l1_Layer_3': 2.9044609648395357e-05, 'l1_Layer_4': 0.021871526880267424, 'n_units_Layer_1': 65, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.73 | sMAPE for Validation Set is: 32.06% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 67.03 | sMAPE for Test Set is: 61.36% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:59:11,187]\u001b[0m Trial 739 finished with value: 22.999355231108392 and parameters: {'n_hidden': 4, 'learning_rate': 0.005868704457636716, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25311443435266384, 'dropout_rate_Layer_2': 0.23653007902221726, 'dropout_rate_Layer_3': 0.20015174162876512, 'dropout_rate_Layer_4': 0.3625599866411053, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.772582865444246e-05, 'l1_Layer_2': 0.0008612306436093951, 'l1_Layer_3': 2.854672950763201e-05, 'l1_Layer_4': 0.02077199724028613, 'n_units_Layer_1': 65, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.00 | sMAPE for Validation Set is: 31.47% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 63.67 | sMAPE for Test Set is: 60.18% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 08:59:39,030]\u001b[0m Trial 740 finished with value: 24.105736800212437 and parameters: {'n_hidden': 4, 'learning_rate': 0.005929855186921612, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2538233099465885, 'dropout_rate_Layer_2': 0.2363408530613643, 'dropout_rate_Layer_3': 0.19618045755089183, 'dropout_rate_Layer_4': 0.36439057699191657, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.87575320158172e-05, 'l1_Layer_2': 0.0008760518366415385, 'l1_Layer_3': 3.2142676343786246e-05, 'l1_Layer_4': 0.02534253053476136, 'n_units_Layer_1': 80, 'n_units_Layer_2': 190, 'n_units_Layer_3': 135, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.11 | sMAPE for Validation Set is: 32.45% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 64.97 | sMAPE for Test Set is: 60.56% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:00:01,548]\u001b[0m Trial 741 finished with value: 23.434160246342923 and parameters: {'n_hidden': 3, 'learning_rate': 0.00275772175171508, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16154934477345098, 'dropout_rate_Layer_2': 0.28344822723648627, 'dropout_rate_Layer_3': 0.015322175838143362, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06322755508908741, 'l1_Layer_2': 0.0007414388040494376, 'l1_Layer_3': 2.1421609970158164e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 290, 'n_units_Layer_3': 250}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.43 | sMAPE for Validation Set is: 31.15% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 64.85 | sMAPE for Test Set is: 60.02% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:00:19,202]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:00:29,563]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:00:34,322]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:00:57,492]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:01:02,111]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:01:20,990]\u001b[0m Trial 747 finished with value: 21.421591364016525 and parameters: {'n_hidden': 3, 'learning_rate': 0.005534903314280321, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36226862007246774, 'dropout_rate_Layer_2': 0.1287230600354442, 'dropout_rate_Layer_3': 0.380195737426589, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016006519738460013, 'l1_Layer_2': 0.00035131208819623986, 'l1_Layer_3': 0.0014232445114955488, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 175}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.42 | sMAPE for Validation Set is: 29.17% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.08 | sMAPE for Test Set is: 56.34% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:02:03,876]\u001b[0m Trial 748 finished with value: 22.844406339873597 and parameters: {'n_hidden': 4, 'learning_rate': 0.0059707708877327235, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24494864662453708, 'dropout_rate_Layer_2': 0.22322621261758904, 'dropout_rate_Layer_3': 0.193549780612319, 'dropout_rate_Layer_4': 0.3639893465233643, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.221473304835524e-05, 'l1_Layer_2': 0.0008780050615662813, 'l1_Layer_3': 3.232499429739795e-05, 'l1_Layer_4': 0.01537672334984079, 'n_units_Layer_1': 80, 'n_units_Layer_2': 195, 'n_units_Layer_3': 130, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.84 | sMAPE for Validation Set is: 31.09% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 63.79 | sMAPE for Test Set is: 59.75% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:02:50,219]\u001b[0m Trial 749 finished with value: 23.662208533053956 and parameters: {'n_hidden': 4, 'learning_rate': 0.006986734815766458, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24611787836106588, 'dropout_rate_Layer_2': 0.2419270887818274, 'dropout_rate_Layer_3': 0.19121344816424424, 'dropout_rate_Layer_4': 0.36594678567758704, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.871064936345221e-05, 'l1_Layer_2': 0.0008633082565719636, 'l1_Layer_3': 3.2982450303791864e-05, 'l1_Layer_4': 0.023732035263654083, 'n_units_Layer_1': 85, 'n_units_Layer_2': 185, 'n_units_Layer_3': 135, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.66 | sMAPE for Validation Set is: 32.14% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 65.76 | sMAPE for Test Set is: 61.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:03:14,594]\u001b[0m Trial 750 finished with value: 23.822803997152125 and parameters: {'n_hidden': 4, 'learning_rate': 0.006792481386465839, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2662059522570679, 'dropout_rate_Layer_2': 0.2422347663218882, 'dropout_rate_Layer_3': 0.19080104983422516, 'dropout_rate_Layer_4': 0.36800999884264063, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.707521034397458e-05, 'l1_Layer_2': 0.0009325817740291341, 'l1_Layer_3': 3.554451453749266e-05, 'l1_Layer_4': 0.013498738328413624, 'n_units_Layer_1': 80, 'n_units_Layer_2': 195, 'n_units_Layer_3': 125, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.82 | sMAPE for Validation Set is: 31.86% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 65.00 | sMAPE for Test Set is: 60.74% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:03:36,312]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:04:00,411]\u001b[0m Trial 752 finished with value: 24.821479168222385 and parameters: {'n_hidden': 4, 'learning_rate': 0.0048905319457506185, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26646793349363124, 'dropout_rate_Layer_2': 0.24125051562545358, 'dropout_rate_Layer_3': 0.1952333833572515, 'dropout_rate_Layer_4': 0.3722567598219417, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.508341931244524e-05, 'l1_Layer_2': 0.0010319175714284558, 'l1_Layer_3': 3.555188414014269e-05, 'l1_Layer_4': 0.02604077812858198, 'n_units_Layer_1': 80, 'n_units_Layer_2': 185, 'n_units_Layer_3': 135, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.82 | sMAPE for Validation Set is: 33.31% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 67.07 | sMAPE for Test Set is: 61.29% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:04:05,204]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:04:09,048]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:04:26,852]\u001b[0m Trial 755 finished with value: 23.754416891329782 and parameters: {'n_hidden': 4, 'learning_rate': 0.007168590602199446, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24199152288633088, 'dropout_rate_Layer_2': 0.21866682166880005, 'dropout_rate_Layer_3': 0.19780274063488137, 'dropout_rate_Layer_4': 0.35079404420776206, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.898881139430079e-05, 'l1_Layer_2': 0.0008607923668945916, 'l1_Layer_3': 2.1166729352862804e-05, 'l1_Layer_4': 0.016082285850435647, 'n_units_Layer_1': 75, 'n_units_Layer_2': 195, 'n_units_Layer_3': 130, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.75 | sMAPE for Validation Set is: 32.16% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 64.20 | sMAPE for Test Set is: 60.82% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:05:06,577]\u001b[0m Trial 756 finished with value: 23.30186529166428 and parameters: {'n_hidden': 4, 'learning_rate': 0.007080888530039899, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2413440394877764, 'dropout_rate_Layer_2': 0.21627583682107007, 'dropout_rate_Layer_3': 0.19525988911987358, 'dropout_rate_Layer_4': 0.35083425698213533, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.930021508073254e-05, 'l1_Layer_2': 0.0008626217575257582, 'l1_Layer_3': 2.0882812552989094e-05, 'l1_Layer_4': 0.014955559301882772, 'n_units_Layer_1': 85, 'n_units_Layer_2': 195, 'n_units_Layer_3': 125, 'n_units_Layer_4': 225}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.30 | sMAPE for Validation Set is: 31.79% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 64.48 | sMAPE for Test Set is: 61.14% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:05:38,437]\u001b[0m Trial 757 finished with value: 23.350047001490157 and parameters: {'n_hidden': 4, 'learning_rate': 0.007221890566301777, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24247981914936992, 'dropout_rate_Layer_2': 0.21576859830142509, 'dropout_rate_Layer_3': 0.19572810891580902, 'dropout_rate_Layer_4': 0.3451545182427759, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.5245443116238076e-05, 'l1_Layer_2': 0.0009199297057082403, 'l1_Layer_3': 2.0808572902323425e-05, 'l1_Layer_4': 0.014079262574889584, 'n_units_Layer_1': 85, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120, 'n_units_Layer_4': 225}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.35 | sMAPE for Validation Set is: 31.66% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 65.45 | sMAPE for Test Set is: 60.41% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:05:49,142]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:05:53,826]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:05:58,317]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:06:02,814]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:06:06,880]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:06:32,259]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:06:59,609]\u001b[0m Trial 764 finished with value: 24.25822289216452 and parameters: {'n_hidden': 4, 'learning_rate': 0.005008841912060438, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26775332774125676, 'dropout_rate_Layer_2': 0.2215027188737202, 'dropout_rate_Layer_3': 0.19747037081482577, 'dropout_rate_Layer_4': 0.37789386281558185, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.741003423744585e-05, 'l1_Layer_2': 0.0010722249144064998, 'l1_Layer_3': 4.2510837333742576e-05, 'l1_Layer_4': 0.02816593103736316, 'n_units_Layer_1': 65, 'n_units_Layer_2': 200, 'n_units_Layer_3': 115, 'n_units_Layer_4': 205}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.26 | sMAPE for Validation Set is: 32.63% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 66.17 | sMAPE for Test Set is: 61.09% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:07:20,397]\u001b[0m Trial 765 finished with value: 24.574827891499414 and parameters: {'n_hidden': 4, 'learning_rate': 0.008358192021715038, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24119811612929382, 'dropout_rate_Layer_2': 0.2449953999045588, 'dropout_rate_Layer_3': 0.18350808662751994, 'dropout_rate_Layer_4': 0.3681802937248682, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.7451889173863095e-05, 'l1_Layer_2': 0.0005954982753211374, 'l1_Layer_3': 3.509365327038368e-05, 'l1_Layer_4': 0.018335083115598914, 'n_units_Layer_1': 75, 'n_units_Layer_2': 185, 'n_units_Layer_3': 120, 'n_units_Layer_4': 225}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.57 | sMAPE for Validation Set is: 33.17% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 65.52 | sMAPE for Test Set is: 61.56% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:07:26,181]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:07:31,506]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:07:41,309]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:07:45,901]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:08:10,227]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:08:14,956]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:08:39,313]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:09:06,501]\u001b[0m Trial 773 finished with value: 22.298072366499145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030511388355806386, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17805664308065156, 'dropout_rate_Layer_2': 0.3085222968822444, 'dropout_rate_Layer_3': 0.0010862956788014397, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02499169234605602, 'l1_Layer_2': 0.00047957405513509704, 'l1_Layer_3': 1.2681058562165794e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 300, 'n_units_Layer_3': 200}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.30 | sMAPE for Validation Set is: 29.81% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 63.07 | sMAPE for Test Set is: 58.77% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:09:40,226]\u001b[0m Trial 774 finished with value: 22.985017865890672 and parameters: {'n_hidden': 4, 'learning_rate': 0.004338564864861469, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23873311935927893, 'dropout_rate_Layer_2': 0.217228794300071, 'dropout_rate_Layer_3': 0.20037879891794236, 'dropout_rate_Layer_4': 0.344153892737734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.595859457990544e-05, 'l1_Layer_2': 0.0011797988406046537, 'l1_Layer_3': 2.5315298124554002e-05, 'l1_Layer_4': 0.014879513393151196, 'n_units_Layer_1': 90, 'n_units_Layer_2': 200, 'n_units_Layer_3': 145, 'n_units_Layer_4': 220}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.99 | sMAPE for Validation Set is: 31.18% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 62.98 | sMAPE for Test Set is: 59.34% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:09:44,397]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:09:53,582]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:10:09,813]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:10:16,296]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:11:03,298]\u001b[0m Trial 779 finished with value: 22.96602186188129 and parameters: {'n_hidden': 4, 'learning_rate': 0.00487052391652998, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2653404710385783, 'dropout_rate_Layer_2': 0.21728433755812265, 'dropout_rate_Layer_3': 0.21572294069406223, 'dropout_rate_Layer_4': 0.33229340890733194, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.201079778013218e-05, 'l1_Layer_2': 0.0009810971670647442, 'l1_Layer_3': 4.491513235990751e-05, 'l1_Layer_4': 0.010930199776443408, 'n_units_Layer_1': 80, 'n_units_Layer_2': 205, 'n_units_Layer_3': 140, 'n_units_Layer_4': 220}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.97 | sMAPE for Validation Set is: 31.05% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 64.26 | sMAPE for Test Set is: 59.79% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:11:39,343]\u001b[0m Trial 780 finished with value: 23.17190242418808 and parameters: {'n_hidden': 4, 'learning_rate': 0.004389284251707817, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26546734015966494, 'dropout_rate_Layer_2': 0.21635594286138246, 'dropout_rate_Layer_3': 0.2178726919800604, 'dropout_rate_Layer_4': 0.33291724371355363, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.0532919616880444e-05, 'l1_Layer_2': 0.0010704307085574573, 'l1_Layer_3': 4.180939094364652e-05, 'l1_Layer_4': 0.01031957047246189, 'n_units_Layer_1': 85, 'n_units_Layer_2': 185, 'n_units_Layer_3': 140, 'n_units_Layer_4': 220}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.17 | sMAPE for Validation Set is: 30.86% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 67.31 | sMAPE for Test Set is: 60.75% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:11:43,268]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:11:47,538]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:11:57,733]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:12:38,459]\u001b[0m Trial 784 finished with value: 22.906473993575776 and parameters: {'n_hidden': 4, 'learning_rate': 0.004756181676336027, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2724541022488059, 'dropout_rate_Layer_2': 0.20844780302458085, 'dropout_rate_Layer_3': 0.18328756984768776, 'dropout_rate_Layer_4': 0.33617993457703854, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.68773049714743e-05, 'l1_Layer_2': 0.0009515319746284261, 'l1_Layer_3': 4.700958434168711e-05, 'l1_Layer_4': 0.011080614473741745, 'n_units_Layer_1': 85, 'n_units_Layer_2': 195, 'n_units_Layer_3': 140, 'n_units_Layer_4': 220}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.91 | sMAPE for Validation Set is: 31.10% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 62.81 | sMAPE for Test Set is: 59.35% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:12:48,533]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:12:58,700]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:13:08,510]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:13:35,512]\u001b[0m Trial 788 finished with value: 23.080229660936354 and parameters: {'n_hidden': 3, 'learning_rate': 0.004490208433497933, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1725603631622688, 'dropout_rate_Layer_2': 0.3112189112873082, 'dropout_rate_Layer_3': 0.05695972896272131, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02611753091403545, 'l1_Layer_2': 0.0009715833645859961, 'l1_Layer_3': 2.795461581881565e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 300, 'n_units_Layer_3': 200}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.08 | sMAPE for Validation Set is: 31.28% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 63.44 | sMAPE for Test Set is: 59.57% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:13:43,984]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:14:04,356]\u001b[0m Trial 790 finished with value: 24.10488612225824 and parameters: {'n_hidden': 4, 'learning_rate': 0.007234858116533012, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2680672335278927, 'dropout_rate_Layer_2': 0.2122883845682806, 'dropout_rate_Layer_3': 0.1895379309762178, 'dropout_rate_Layer_4': 0.37238332627228404, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.578306618110971e-05, 'l1_Layer_2': 0.0006361121498561217, 'l1_Layer_3': 3.447754114205109e-05, 'l1_Layer_4': 0.010675893217764548, 'n_units_Layer_1': 90, 'n_units_Layer_2': 200, 'n_units_Layer_3': 145, 'n_units_Layer_4': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.10 | sMAPE for Validation Set is: 32.53% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 65.99 | sMAPE for Test Set is: 60.67% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:14:25,460]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:14:40,384]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:15:01,740]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:15:22,503]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:15:43,055]\u001b[0m Trial 795 finished with value: 23.07021708401 and parameters: {'n_hidden': 3, 'learning_rate': 0.003164816818096612, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15235915980820455, 'dropout_rate_Layer_2': 0.32382245512386987, 'dropout_rate_Layer_3': 0.006150921054310993, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.027829129771214767, 'l1_Layer_2': 0.0008632817572653132, 'l1_Layer_3': 5.27809867872052e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 295, 'n_units_Layer_3': 220}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.07 | sMAPE for Validation Set is: 31.49% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 61.92 | sMAPE for Test Set is: 58.69% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:16:18,449]\u001b[0m Trial 796 finished with value: 22.88458384255235 and parameters: {'n_hidden': 4, 'learning_rate': 0.004242761814156282, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2733066094173019, 'dropout_rate_Layer_2': 0.21683456858919992, 'dropout_rate_Layer_3': 0.17661046642974026, 'dropout_rate_Layer_4': 0.35189446978459443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.727615590343198e-05, 'l1_Layer_2': 0.0006494574210237131, 'l1_Layer_3': 1.6428678905589382e-05, 'l1_Layer_4': 0.016786637656624304, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 125, 'n_units_Layer_4': 230}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.88 | sMAPE for Validation Set is: 30.76% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 63.99 | sMAPE for Test Set is: 59.58% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:16:22,569]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:16:57,265]\u001b[0m Trial 798 finished with value: 22.38002133897785 and parameters: {'n_hidden': 4, 'learning_rate': 0.0041064504702978035, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2748591994532183, 'dropout_rate_Layer_2': 0.24837416729003114, 'dropout_rate_Layer_3': 0.1745134214868062, 'dropout_rate_Layer_4': 0.3476746136692353, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.242645364993526e-05, 'l1_Layer_2': 0.0010499219711820225, 'l1_Layer_3': 1.5398347672309725e-05, 'l1_Layer_4': 0.017922533990334624, 'n_units_Layer_1': 60, 'n_units_Layer_2': 170, 'n_units_Layer_3': 125, 'n_units_Layer_4': 230}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.38 | sMAPE for Validation Set is: 30.51% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 61.94 | sMAPE for Test Set is: 59.07% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:17:15,750]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:17:26,049]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:18:00,118]\u001b[0m Trial 801 finished with value: 23.904825796885643 and parameters: {'n_hidden': 3, 'learning_rate': 0.003093733820768748, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17530092168735562, 'dropout_rate_Layer_2': 0.3253696756281885, 'dropout_rate_Layer_3': 0.002516550611571812, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028226643982548774, 'l1_Layer_2': 0.0008842157548499404, 'l1_Layer_3': 5.0185543329276564e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 295, 'n_units_Layer_3': 220}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.90 | sMAPE for Validation Set is: 32.13% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 65.93 | sMAPE for Test Set is: 60.68% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:18:31,703]\u001b[0m Trial 802 finished with value: 23.34687263454805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0040290173533309905, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1520872403892709, 'dropout_rate_Layer_2': 0.3125499840488433, 'dropout_rate_Layer_3': 0.02487059148796885, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03852232253755058, 'l1_Layer_2': 0.00043393347887647326, 'l1_Layer_3': 1.8032489269962567e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 280, 'n_units_Layer_3': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.35 | sMAPE for Validation Set is: 31.02% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 65.21 | sMAPE for Test Set is: 60.67% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:18:45,921]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:19:03,498]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:19:09,151]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:19:14,627]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:20:14,331]\u001b[0m Trial 807 finished with value: 22.41148471943271 and parameters: {'n_hidden': 4, 'learning_rate': 0.003574996959372747, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2950435948825665, 'dropout_rate_Layer_2': 0.22295152078402083, 'dropout_rate_Layer_3': 0.21319512150100361, 'dropout_rate_Layer_4': 0.3501126441706317, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.207036067866587e-05, 'l1_Layer_2': 0.00047178529150759314, 'l1_Layer_3': 1.6579512931951645e-05, 'l1_Layer_4': 0.007988785635514598, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 135, 'n_units_Layer_4': 225}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.41 | sMAPE for Validation Set is: 30.55% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 62.44 | sMAPE for Test Set is: 59.54% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:20:39,291]\u001b[0m Trial 808 finished with value: 23.412555745871156 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032200965323444315, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30182440690782775, 'dropout_rate_Layer_2': 0.22285903634030163, 'dropout_rate_Layer_3': 0.21305807593964218, 'dropout_rate_Layer_4': 0.35231827234581325, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.817550311063898e-05, 'l1_Layer_2': 0.00048289096783069317, 'l1_Layer_3': 1.6298197354022514e-05, 'l1_Layer_4': 0.007670948451243125, 'n_units_Layer_1': 75, 'n_units_Layer_2': 165, 'n_units_Layer_3': 135, 'n_units_Layer_4': 220}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.41 | sMAPE for Validation Set is: 31.59% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 63.51 | sMAPE for Test Set is: 59.73% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:21:07,604]\u001b[0m Trial 809 finished with value: 23.44385894435078 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029739728406313424, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14069298482311668, 'dropout_rate_Layer_2': 0.33052114568567154, 'dropout_rate_Layer_3': 0.013485063216398845, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028949549507434953, 'l1_Layer_2': 0.0006852359318236761, 'l1_Layer_3': 2.6378457098012145e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 300, 'n_units_Layer_3': 230}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.44 | sMAPE for Validation Set is: 31.16% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 64.07 | sMAPE for Test Set is: 59.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:21:17,278]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:21:21,709]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:21:30,249]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:21:38,573]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:21:57,289]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:22:38,472]\u001b[0m Trial 815 finished with value: 22.865131774130703 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036588548809500508, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23615820371330454, 'dropout_rate_Layer_2': 0.22359004338670652, 'dropout_rate_Layer_3': 0.2016394410430787, 'dropout_rate_Layer_4': 0.3446998774656476, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.012473272499773e-05, 'l1_Layer_2': 0.0006616251163888388, 'l1_Layer_3': 1.986825430680071e-05, 'l1_Layer_4': 0.009602261628615936, 'n_units_Layer_1': 65, 'n_units_Layer_2': 180, 'n_units_Layer_3': 140, 'n_units_Layer_4': 220}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.87 | sMAPE for Validation Set is: 31.03% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 63.79 | sMAPE for Test Set is: 59.88% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:23:17,151]\u001b[0m Trial 816 finished with value: 22.83468123882177 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035312846680124444, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23495358454852505, 'dropout_rate_Layer_2': 0.22500053931048522, 'dropout_rate_Layer_3': 0.22564110980930657, 'dropout_rate_Layer_4': 0.3221769871676773, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.769801917097404e-05, 'l1_Layer_2': 0.00036837469959666, 'l1_Layer_3': 1.400015749528447e-05, 'l1_Layer_4': 0.010074186318535653, 'n_units_Layer_1': 65, 'n_units_Layer_2': 180, 'n_units_Layer_3': 140, 'n_units_Layer_4': 230}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.83 | sMAPE for Validation Set is: 30.88% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 63.57 | sMAPE for Test Set is: 59.63% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:23:57,262]\u001b[0m Trial 817 finished with value: 22.112612221409716 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035742657706610797, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23426964636759257, 'dropout_rate_Layer_2': 0.2241572849797443, 'dropout_rate_Layer_3': 0.22173906617048936, 'dropout_rate_Layer_4': 0.3261160381208976, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.629562910343534e-05, 'l1_Layer_2': 0.00034401328060707604, 'l1_Layer_3': 1.3657458665857019e-05, 'l1_Layer_4': 0.008523611931706792, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145, 'n_units_Layer_4': 230}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.11 | sMAPE for Validation Set is: 30.30% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 62.73 | sMAPE for Test Set is: 59.18% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:24:24,153]\u001b[0m Trial 818 finished with value: 23.25324268226073 and parameters: {'n_hidden': 4, 'learning_rate': 0.00403661083874294, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23797668620557086, 'dropout_rate_Layer_2': 0.20836499033824796, 'dropout_rate_Layer_3': 0.22175537986997662, 'dropout_rate_Layer_4': 0.3321881944930673, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.87008108373469e-05, 'l1_Layer_2': 0.000338810971599271, 'l1_Layer_3': 1.2894997043817537e-05, 'l1_Layer_4': 0.009271655473060718, 'n_units_Layer_1': 85, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140, 'n_units_Layer_4': 235}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.25 | sMAPE for Validation Set is: 31.42% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 64.08 | sMAPE for Test Set is: 59.87% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:24:30,079]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:25:05,036]\u001b[0m Trial 820 finished with value: 22.939855173042588 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036410898734845452, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23706088224542582, 'dropout_rate_Layer_2': 0.20139143777202062, 'dropout_rate_Layer_3': 0.22647212258912103, 'dropout_rate_Layer_4': 0.3215449749622568, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.8591073102403386e-05, 'l1_Layer_2': 0.00031638561490130845, 'l1_Layer_3': 1.3234244748916659e-05, 'l1_Layer_4': 0.009493766983590283, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145, 'n_units_Layer_4': 230}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.94 | sMAPE for Validation Set is: 30.82% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 64.37 | sMAPE for Test Set is: 59.72% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:25:10,515]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:25:53,512]\u001b[0m Trial 822 finished with value: 24.099325612843373 and parameters: {'n_hidden': 3, 'learning_rate': 0.002506216362417217, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12625449248805543, 'dropout_rate_Layer_2': 0.2905692539511262, 'dropout_rate_Layer_3': 0.05164465589770229, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02410911507193811, 'l1_Layer_2': 0.0004725410800256236, 'l1_Layer_3': 2.2376308825975667e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.10 | sMAPE for Validation Set is: 32.08% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 65.26 | sMAPE for Test Set is: 60.84% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:26:12,610]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:26:17,916]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:26:26,705]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:26:37,895]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:26:43,603]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:27:13,435]\u001b[0m Trial 828 finished with value: 22.425498276862356 and parameters: {'n_hidden': 4, 'learning_rate': 0.003732854297041211, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3058295947450858, 'dropout_rate_Layer_2': 0.19872941133417105, 'dropout_rate_Layer_3': 0.22234867165182806, 'dropout_rate_Layer_4': 0.32789199158512866, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.861212886619022e-05, 'l1_Layer_2': 0.00029149467920362894, 'l1_Layer_3': 1.410512940554411e-05, 'l1_Layer_4': 0.007445927562792111, 'n_units_Layer_1': 95, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140, 'n_units_Layer_4': 230}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.43 | sMAPE for Validation Set is: 30.48% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 62.10 | sMAPE for Test Set is: 58.83% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:27:48,024]\u001b[0m Trial 829 finished with value: 22.15669439790857 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034619618044594088, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23252819107201614, 'dropout_rate_Layer_2': 0.1999718192143414, 'dropout_rate_Layer_3': 0.22623400555211198, 'dropout_rate_Layer_4': 0.32513194422005565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.764932800395888e-05, 'l1_Layer_2': 0.0002935314111177911, 'l1_Layer_3': 1.359449221086515e-05, 'l1_Layer_4': 0.007718782502734184, 'n_units_Layer_1': 95, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150, 'n_units_Layer_4': 235}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.16 | sMAPE for Validation Set is: 30.08% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 62.26 | sMAPE for Test Set is: 58.67% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:27:53,838]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:28:02,243]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:28:11,371]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:28:21,380]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:28:28,413]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:28:32,896]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:29:09,506]\u001b[0m Trial 836 finished with value: 22.443767276141013 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031465527586980267, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29320014282253715, 'dropout_rate_Layer_2': 0.19957635095640966, 'dropout_rate_Layer_3': 0.22937625269729275, 'dropout_rate_Layer_4': 0.3330980591545084, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.324529386964072e-05, 'l1_Layer_2': 0.0003733431713106101, 'l1_Layer_3': 1.0002511509412675e-05, 'l1_Layer_4': 0.007440864530836051, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 150, 'n_units_Layer_4': 235}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.44 | sMAPE for Validation Set is: 30.24% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 62.67 | sMAPE for Test Set is: 58.56% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:29:17,679]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:29:23,059]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:29:27,790]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:29:56,443]\u001b[0m Trial 840 finished with value: 23.616376339423592 and parameters: {'n_hidden': 3, 'learning_rate': 0.003372158660711228, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16654323135390758, 'dropout_rate_Layer_2': 0.3055785799210144, 'dropout_rate_Layer_3': 0.06841705614699159, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04719681595939502, 'l1_Layer_2': 0.0009038523176319728, 'l1_Layer_3': 1.3180555131756975e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.62 | sMAPE for Validation Set is: 31.20% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 66.40 | sMAPE for Test Set is: 61.17% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:30:32,434]\u001b[0m Trial 841 finished with value: 22.630913284464256 and parameters: {'n_hidden': 4, 'learning_rate': 0.002656934171244457, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31306552506910507, 'dropout_rate_Layer_2': 0.1930412240837511, 'dropout_rate_Layer_3': 0.23076617231293325, 'dropout_rate_Layer_4': 0.3296294848236627, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.047611504761022e-05, 'l1_Layer_2': 0.00038195264620089045, 'l1_Layer_3': 1.1077699730866522e-05, 'l1_Layer_4': 0.009719117370581941, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155, 'n_units_Layer_4': 235}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.63 | sMAPE for Validation Set is: 30.51% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 63.53 | sMAPE for Test Set is: 59.65% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:30:40,774]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:30:58,428]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:31:07,527]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:31:12,910]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:31:22,969]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:32:06,321]\u001b[0m Trial 847 finished with value: 21.76011638382738 and parameters: {'n_hidden': 4, 'learning_rate': 0.003170933608279162, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29213759850409193, 'dropout_rate_Layer_2': 0.19216622903288738, 'dropout_rate_Layer_3': 0.22500169379081136, 'dropout_rate_Layer_4': 0.33157689774634347, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.1324923723592624e-05, 'l1_Layer_2': 0.000318188155147258, 'l1_Layer_3': 1.3630950669373006e-05, 'l1_Layer_4': 0.0071905068771672236, 'n_units_Layer_1': 100, 'n_units_Layer_2': 180, 'n_units_Layer_3': 140, 'n_units_Layer_4': 235}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.76 | sMAPE for Validation Set is: 29.88% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.82 | sMAPE for Test Set is: 58.41% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:32:11,481]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:32:15,751]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:32:24,157]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:32:50,081]\u001b[0m Trial 851 finished with value: 22.86557391149816 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032424795082100686, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28583156010304933, 'dropout_rate_Layer_2': 0.19183995668610043, 'dropout_rate_Layer_3': 0.24317863453525718, 'dropout_rate_Layer_4': 0.33492699223964184, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.961671683101755e-05, 'l1_Layer_2': 0.00031704322933876004, 'l1_Layer_3': 1.419817598204317e-05, 'l1_Layer_4': 0.007177366044054788, 'n_units_Layer_1': 95, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155, 'n_units_Layer_4': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.87 | sMAPE for Validation Set is: 30.89% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 63.04 | sMAPE for Test Set is: 59.44% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:32:54,560]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:33:27,869]\u001b[0m Trial 853 finished with value: 22.508491707530766 and parameters: {'n_hidden': 4, 'learning_rate': 0.003143816282137977, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2903908339084476, 'dropout_rate_Layer_2': 0.19213652273786438, 'dropout_rate_Layer_3': 0.2425629450753764, 'dropout_rate_Layer_4': 0.3299172085162429, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.192707692852242e-05, 'l1_Layer_2': 0.00031415359839225584, 'l1_Layer_3': 1.0407663242416568e-05, 'l1_Layer_4': 0.0072492618469522825, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155, 'n_units_Layer_4': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.51 | sMAPE for Validation Set is: 30.49% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 64.72 | sMAPE for Test Set is: 59.79% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:33:57,578]\u001b[0m Trial 854 finished with value: 22.61491509137207 and parameters: {'n_hidden': 4, 'learning_rate': 0.003160583178741741, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28325605520746655, 'dropout_rate_Layer_2': 0.1904810516135211, 'dropout_rate_Layer_3': 0.24208797477547234, 'dropout_rate_Layer_4': 0.3295848126548165, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.7796303484633426e-05, 'l1_Layer_2': 0.00023390704596390588, 'l1_Layer_3': 1.0147080332068911e-05, 'l1_Layer_4': 0.007171252802816341, 'n_units_Layer_1': 105, 'n_units_Layer_2': 175, 'n_units_Layer_3': 150, 'n_units_Layer_4': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.61 | sMAPE for Validation Set is: 30.55% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 64.60 | sMAPE for Test Set is: 59.70% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:34:01,201]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:34:08,322]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:34:38,508]\u001b[0m Trial 857 finished with value: 21.835644242406115 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030324561890376638, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2905999926975607, 'dropout_rate_Layer_2': 0.18476044569067585, 'dropout_rate_Layer_3': 0.24045477538603305, 'dropout_rate_Layer_4': 0.3300025039808381, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.1613249631772675e-05, 'l1_Layer_2': 0.0002910001800326681, 'l1_Layer_3': 1.0141320836283945e-05, 'l1_Layer_4': 0.005471536957452986, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155, 'n_units_Layer_4': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.84 | sMAPE for Validation Set is: 29.70% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 61.07 | sMAPE for Test Set is: 58.54% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:34:43,735]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:34:59,524]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:35:04,697]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:35:46,193]\u001b[0m Trial 861 finished with value: 22.21366880088101 and parameters: {'n_hidden': 4, 'learning_rate': 0.002661590981359977, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2920316865479272, 'dropout_rate_Layer_2': 0.19102864545700893, 'dropout_rate_Layer_3': 0.2317366331335595, 'dropout_rate_Layer_4': 0.33105384128186066, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.2881796179405892e-05, 'l1_Layer_2': 0.00031334612746347943, 'l1_Layer_3': 1.06296015175339e-05, 'l1_Layer_4': 0.00746868212762756, 'n_units_Layer_1': 110, 'n_units_Layer_2': 170, 'n_units_Layer_3': 160, 'n_units_Layer_4': 255}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.21 | sMAPE for Validation Set is: 29.93% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.65 | sMAPE for Test Set is: 58.28% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:35:51,381]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:36:15,613]\u001b[0m Trial 863 finished with value: 22.422548906776495 and parameters: {'n_hidden': 4, 'learning_rate': 0.002587629951405289, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2871123748965347, 'dropout_rate_Layer_2': 0.1875376319542806, 'dropout_rate_Layer_3': 0.2317343171529663, 'dropout_rate_Layer_4': 0.32300021258586553, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.2200331772509193e-05, 'l1_Layer_2': 0.00034588116589205685, 'l1_Layer_3': 1.0126274797648872e-05, 'l1_Layer_4': 0.006989005973202301, 'n_units_Layer_1': 115, 'n_units_Layer_2': 165, 'n_units_Layer_3': 155, 'n_units_Layer_4': 255}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.42 | sMAPE for Validation Set is: 30.49% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 61.64 | sMAPE for Test Set is: 58.64% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:36:24,366]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:36:31,679]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:36:51,128]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:36:59,440]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:37:32,662]\u001b[0m Trial 868 finished with value: 22.433797638662707 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030911765022145926, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2865936271036144, 'dropout_rate_Layer_2': 0.18037182172955152, 'dropout_rate_Layer_3': 0.22990310255907964, 'dropout_rate_Layer_4': 0.3281504490018285, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.1201271057158123e-05, 'l1_Layer_2': 0.0002330142820767181, 'l1_Layer_3': 1.020083573816212e-05, 'l1_Layer_4': 0.007227996607779969, 'n_units_Layer_1': 105, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155, 'n_units_Layer_4': 260}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.43 | sMAPE for Validation Set is: 30.34% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 63.08 | sMAPE for Test Set is: 58.93% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:37:49,065]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:37:57,803]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:38:06,477]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:38:15,170]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:38:20,498]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:38:25,234]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:38:49,687]\u001b[0m Trial 875 finished with value: 22.527720226340232 and parameters: {'n_hidden': 4, 'learning_rate': 0.002781391177848744, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28010794316407367, 'dropout_rate_Layer_2': 0.19247177056306305, 'dropout_rate_Layer_3': 0.23153466041740478, 'dropout_rate_Layer_4': 0.31668925405624115, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.264101235167476e-05, 'l1_Layer_2': 0.0003425927444037717, 'l1_Layer_3': 1.1812860079488044e-05, 'l1_Layer_4': 0.004391316890995784, 'n_units_Layer_1': 115, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150, 'n_units_Layer_4': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.53 | sMAPE for Validation Set is: 30.43% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 62.27 | sMAPE for Test Set is: 58.72% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:39:30,271]\u001b[0m Trial 876 finished with value: 21.87044140311149 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027623918753114127, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28224705389282856, 'dropout_rate_Layer_2': 0.19323444003643858, 'dropout_rate_Layer_3': 0.2310100779654019, 'dropout_rate_Layer_4': 0.31526758245420194, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.8601211813709695e-05, 'l1_Layer_2': 0.00032669137321842415, 'l1_Layer_3': 1.2305199666524288e-05, 'l1_Layer_4': 0.004800079487356683, 'n_units_Layer_1': 120, 'n_units_Layer_2': 165, 'n_units_Layer_3': 165, 'n_units_Layer_4': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.87 | sMAPE for Validation Set is: 29.84% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 63.04 | sMAPE for Test Set is: 59.06% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:39:51,695]\u001b[0m Trial 877 finished with value: 21.38656371791936 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026074468962006803, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30393193813875263, 'dropout_rate_Layer_2': 0.15266724741408833, 'dropout_rate_Layer_3': 0.3311974767663897, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.998748948467685e-05, 'l1_Layer_2': 0.0007144644947564773, 'l1_Layer_3': 0.0028012284279737656, 'n_units_Layer_1': 180, 'n_units_Layer_2': 160, 'n_units_Layer_3': 135}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.39 | sMAPE for Validation Set is: 29.37% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.63 | sMAPE for Test Set is: 56.64% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:39:57,079]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:40:37,123]\u001b[0m Trial 879 finished with value: 22.00681272493894 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027639243632684722, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2804795553499427, 'dropout_rate_Layer_2': 0.19045586590006913, 'dropout_rate_Layer_3': 0.2458633975995776, 'dropout_rate_Layer_4': 0.30056893808616447, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.2441936724260425e-05, 'l1_Layer_2': 0.00038145200056218784, 'l1_Layer_3': 1.1641286805315465e-05, 'l1_Layer_4': 0.0045230295613706275, 'n_units_Layer_1': 105, 'n_units_Layer_2': 165, 'n_units_Layer_3': 165, 'n_units_Layer_4': 250}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.01 | sMAPE for Validation Set is: 30.04% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 62.86 | sMAPE for Test Set is: 58.97% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:41:13,615]\u001b[0m Trial 880 finished with value: 22.23269561067529 and parameters: {'n_hidden': 4, 'learning_rate': 0.002771338460288745, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2810993050488136, 'dropout_rate_Layer_2': 0.1770122587281684, 'dropout_rate_Layer_3': 0.2455479475468742, 'dropout_rate_Layer_4': 0.3036751559304123, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.0889824634849414e-05, 'l1_Layer_2': 0.0003692407205838928, 'l1_Layer_3': 1.1876449764186277e-05, 'l1_Layer_4': 0.004616018833305744, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165, 'n_units_Layer_4': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.23 | sMAPE for Validation Set is: 29.88% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 64.48 | sMAPE for Test Set is: 59.63% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:41:58,196]\u001b[0m Trial 881 finished with value: 22.055724085912363 and parameters: {'n_hidden': 4, 'learning_rate': 0.002772356255620744, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28279162004535063, 'dropout_rate_Layer_2': 0.17951342175572804, 'dropout_rate_Layer_3': 0.2525492814385148, 'dropout_rate_Layer_4': 0.3005811631669637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.06815473165995e-05, 'l1_Layer_2': 0.00036460599462775624, 'l1_Layer_3': 1.0102814894362664e-05, 'l1_Layer_4': 0.00436875034235849, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 170, 'n_units_Layer_4': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.06 | sMAPE for Validation Set is: 30.20% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 62.72 | sMAPE for Test Set is: 59.37% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:42:03,375]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:42:29,166]\u001b[0m Trial 883 finished with value: 22.586809386072655 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028283704808018937, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2937776175632118, 'dropout_rate_Layer_2': 0.17496301217023888, 'dropout_rate_Layer_3': 0.2533562775696898, 'dropout_rate_Layer_4': 0.3099315616637489, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.0521343777541456e-05, 'l1_Layer_2': 0.000405797221031671, 'l1_Layer_3': 1.0279502729852584e-05, 'l1_Layer_4': 0.0043876686856081926, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 170, 'n_units_Layer_4': 250}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.59 | sMAPE for Validation Set is: 30.72% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 62.36 | sMAPE for Test Set is: 58.75% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:42:35,205]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:43:22,266]\u001b[0m Trial 885 finished with value: 22.197841083628287 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027866796081512835, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.293963230079469, 'dropout_rate_Layer_2': 0.18070080788786214, 'dropout_rate_Layer_3': 0.25435346378817136, 'dropout_rate_Layer_4': 0.3003703460746273, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.9532757667169945e-05, 'l1_Layer_2': 0.000377888405889778, 'l1_Layer_3': 1.0071914480000086e-05, 'l1_Layer_4': 0.004150642000636618, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 170, 'n_units_Layer_4': 250}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.20 | sMAPE for Validation Set is: 30.30% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.63 | sMAPE for Test Set is: 58.69% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:43:50,499]\u001b[0m Trial 886 finished with value: 22.116779919452068 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027665799801203147, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2952108185006651, 'dropout_rate_Layer_2': 0.17515279242472256, 'dropout_rate_Layer_3': 0.25583539814837, 'dropout_rate_Layer_4': 0.29850598771696135, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.013165457419272e-05, 'l1_Layer_2': 0.00037760618513642524, 'l1_Layer_3': 1.0044840847227709e-05, 'l1_Layer_4': 0.004187391670623832, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 165, 'n_units_Layer_4': 250}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.12 | sMAPE for Validation Set is: 30.62% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 60.83 | sMAPE for Test Set is: 58.64% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:43:58,370]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:44:06,830]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:44:22,857]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:45:01,782]\u001b[0m Trial 890 finished with value: 22.03577808364699 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027970964535788748, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29426727413379494, 'dropout_rate_Layer_2': 0.18147673014372398, 'dropout_rate_Layer_3': 0.2488712993575865, 'dropout_rate_Layer_4': 0.3088241432144637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.130039211808931e-05, 'l1_Layer_2': 0.00021719741021897774, 'l1_Layer_3': 1.1449525088579474e-05, 'l1_Layer_4': 0.004870133505097008, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 170, 'n_units_Layer_4': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.04 | sMAPE for Validation Set is: 30.18% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 61.37 | sMAPE for Test Set is: 58.46% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:45:10,021]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:45:38,710]\u001b[0m Trial 892 finished with value: 23.204087868953327 and parameters: {'n_hidden': 3, 'learning_rate': 0.002443486560877621, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1563122709689578, 'dropout_rate_Layer_2': 0.29757393569937324, 'dropout_rate_Layer_3': 0.07515842644493313, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02197219923773891, 'l1_Layer_2': 0.0006482845472339226, 'l1_Layer_3': 1.8037449441925452e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 275, 'n_units_Layer_3': 165}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.20 | sMAPE for Validation Set is: 31.16% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 63.46 | sMAPE for Test Set is: 59.10% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:45:44,617]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:45:51,597]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:46:00,246]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:46:04,947]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:46:20,678]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:46:25,884]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:46:41,531]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:46:46,823]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:46:50,939]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:47:19,247]\u001b[0m Trial 902 finished with value: 21.81960797730549 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027209511225061494, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30876447506647625, 'dropout_rate_Layer_2': 0.18896629187815178, 'dropout_rate_Layer_3': 0.2563981872942002, 'dropout_rate_Layer_4': 0.3146803068188336, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.3771536561704254e-05, 'l1_Layer_2': 0.00022019078708053146, 'l1_Layer_3': 1.2270680063856268e-05, 'l1_Layer_4': 0.0054925499296161326, 'n_units_Layer_1': 110, 'n_units_Layer_2': 165, 'n_units_Layer_3': 165, 'n_units_Layer_4': 240}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.82 | sMAPE for Validation Set is: 30.06% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.10 | sMAPE for Test Set is: 57.21% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:47:27,546]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:47:41,662]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:48:01,631]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:48:05,854]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:48:30,666]\u001b[0m Trial 907 finished with value: 22.648121668142537 and parameters: {'n_hidden': 4, 'learning_rate': 0.002632552509226365, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29675775987659864, 'dropout_rate_Layer_2': 0.19170782932154878, 'dropout_rate_Layer_3': 0.24381666063305857, 'dropout_rate_Layer_4': 0.3147270063134952, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.513475914388469e-05, 'l1_Layer_2': 0.00024838923240460273, 'l1_Layer_3': 1.02034213873252e-05, 'l1_Layer_4': 0.005364225519413794, 'n_units_Layer_1': 105, 'n_units_Layer_2': 165, 'n_units_Layer_3': 160, 'n_units_Layer_4': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.65 | sMAPE for Validation Set is: 30.52% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 63.93 | sMAPE for Test Set is: 59.59% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:49:02,587]\u001b[0m Trial 908 finished with value: 21.587342463246717 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023548291077266385, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3086606411035109, 'dropout_rate_Layer_2': 0.1833452383031747, 'dropout_rate_Layer_3': 0.23538649796951175, 'dropout_rate_Layer_4': 0.28621873434944767, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.4774907178168222e-05, 'l1_Layer_2': 0.00018098997705440724, 'l1_Layer_3': 1.2345494200853053e-05, 'l1_Layer_4': 0.003244444684989957, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165, 'n_units_Layer_4': 240}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.59 | sMAPE for Validation Set is: 29.54% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 61.39 | sMAPE for Test Set is: 58.53% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:49:39,428]\u001b[0m Trial 909 finished with value: 21.72126210646978 and parameters: {'n_hidden': 4, 'learning_rate': 0.002286616669488559, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28616726771473866, 'dropout_rate_Layer_2': 0.1748376314517765, 'dropout_rate_Layer_3': 0.2535343471916769, 'dropout_rate_Layer_4': 0.28694848295273756, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.3604758776287342e-05, 'l1_Layer_2': 0.00018269834934894546, 'l1_Layer_3': 1.4284071041927402e-05, 'l1_Layer_4': 0.0035869073901961942, 'n_units_Layer_1': 130, 'n_units_Layer_2': 160, 'n_units_Layer_3': 165, 'n_units_Layer_4': 255}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.72 | sMAPE for Validation Set is: 29.73% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 61.75 | sMAPE for Test Set is: 58.41% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:49:58,694]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:50:02,648]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:50:10,999]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:50:28,545]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:50:55,235]\u001b[0m Trial 914 finished with value: 22.67614467439039 and parameters: {'n_hidden': 4, 'learning_rate': 0.002858066969896075, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27986176552336905, 'dropout_rate_Layer_2': 0.1822336500375719, 'dropout_rate_Layer_3': 0.23260234296243187, 'dropout_rate_Layer_4': 0.3097289448259343, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.4214681170615243e-05, 'l1_Layer_2': 0.0001493805080559496, 'l1_Layer_3': 1.2329938971325142e-05, 'l1_Layer_4': 0.0037833061097986283, 'n_units_Layer_1': 110, 'n_units_Layer_2': 155, 'n_units_Layer_3': 160, 'n_units_Layer_4': 255}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.68 | sMAPE for Validation Set is: 30.81% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 62.65 | sMAPE for Test Set is: 58.79% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:51:00,279]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:51:05,936]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:51:13,715]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:51:22,235]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:51:29,154]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:51:33,108]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:51:37,246]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:51:46,173]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:52:02,858]\u001b[0m Trial 923 finished with value: 24.41635424250775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028627453617730493, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20248246622306615, 'dropout_rate_Layer_2': 0.27722909682483216, 'dropout_rate_Layer_3': 0.030756814507370216, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06617427883911914, 'l1_Layer_2': 0.001045834620399033, 'l1_Layer_3': 2.053632546298713e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 275, 'n_units_Layer_3': 225}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.42 | sMAPE for Validation Set is: 32.32% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 65.80 | sMAPE for Test Set is: 60.84% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:52:08,224]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:52:13,912]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:53:09,502]\u001b[0m Trial 926 finished with value: 22.141031092693908 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018107802014520743, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3264884552830064, 'dropout_rate_Layer_2': 0.17853212446604794, 'dropout_rate_Layer_3': 0.23434305194968383, 'dropout_rate_Layer_4': 0.29156439637577924, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.1532837815004808e-05, 'l1_Layer_2': 0.00028225310465992173, 'l1_Layer_3': 1.1712865039713774e-05, 'l1_Layer_4': 0.004433620373127613, 'n_units_Layer_1': 115, 'n_units_Layer_2': 170, 'n_units_Layer_3': 165, 'n_units_Layer_4': 250}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.14 | sMAPE for Validation Set is: 30.04% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 65.00 | sMAPE for Test Set is: 59.69% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:53:28,117]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:53:55,999]\u001b[0m Trial 928 finished with value: 22.035975333216914 and parameters: {'n_hidden': 4, 'learning_rate': 0.001686708390803942, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32595214583063864, 'dropout_rate_Layer_2': 0.18023954907234394, 'dropout_rate_Layer_3': 0.23596652685543534, 'dropout_rate_Layer_4': 0.2941173989654129, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.505270195579795e-05, 'l1_Layer_2': 0.00022326260379826405, 'l1_Layer_3': 1.2105756214011808e-05, 'l1_Layer_4': 0.005071596566864388, 'n_units_Layer_1': 115, 'n_units_Layer_2': 170, 'n_units_Layer_3': 160, 'n_units_Layer_4': 255}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.04 | sMAPE for Validation Set is: 29.99% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 61.80 | sMAPE for Test Set is: 58.62% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:54:01,165]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:54:20,320]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:54:57,340]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:55:05,802]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:55:23,862]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:55:48,772]\u001b[0m Trial 934 finished with value: 22.76179434667309 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032603661115311404, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2784830695870733, 'dropout_rate_Layer_2': 0.19628631399024024, 'dropout_rate_Layer_3': 0.22935542474097334, 'dropout_rate_Layer_4': 0.2792028214955061, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.4432684179025587e-05, 'l1_Layer_2': 0.00034186242003723363, 'l1_Layer_3': 1.6660740903920348e-05, 'l1_Layer_4': 0.0066939992060482, 'n_units_Layer_1': 115, 'n_units_Layer_2': 160, 'n_units_Layer_3': 170, 'n_units_Layer_4': 255}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.76 | sMAPE for Validation Set is: 31.24% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 62.64 | sMAPE for Test Set is: 59.11% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:56:14,404]\u001b[0m Trial 935 finished with value: 23.18221441349726 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025761742377515217, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30441787771400064, 'dropout_rate_Layer_2': 0.18752960810541944, 'dropout_rate_Layer_3': 0.23795445602930018, 'dropout_rate_Layer_4': 0.3050913509322952, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.7983795469838226e-05, 'l1_Layer_2': 0.0002856957555506169, 'l1_Layer_3': 1.1742538638974895e-05, 'l1_Layer_4': 0.005032945799114003, 'n_units_Layer_1': 105, 'n_units_Layer_2': 165, 'n_units_Layer_3': 165, 'n_units_Layer_4': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.18 | sMAPE for Validation Set is: 31.43% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 64.35 | sMAPE for Test Set is: 59.93% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:56:34,856]\u001b[0m Trial 936 finished with value: 23.37741560433608 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023212663554291663, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2012362649605625, 'dropout_rate_Layer_2': 0.2724243032561002, 'dropout_rate_Layer_3': 0.03102457948726689, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05327034468698152, 'l1_Layer_2': 0.0011008298568584735, 'l1_Layer_3': 1.2729312456817047e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 280, 'n_units_Layer_3': 185}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.38 | sMAPE for Validation Set is: 31.65% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 63.43 | sMAPE for Test Set is: 59.80% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:56:40,892]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:56:46,828]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:56:52,180]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:57:16,723]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:57:25,511]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:57:51,492]\u001b[0m Trial 942 finished with value: 23.479643845671387 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012089228997128713, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18443034763619165, 'dropout_rate_Layer_2': 0.2826791114316996, 'dropout_rate_Layer_3': 0.04400668208784978, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06299146864138, 'l1_Layer_2': 0.000733887181546011, 'l1_Layer_3': 1.3488141765114667e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 260, 'n_units_Layer_3': 205}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.48 | sMAPE for Validation Set is: 31.30% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 64.22 | sMAPE for Test Set is: 59.60% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:57:56,898]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:58:01,246]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:58:06,663]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:58:14,538]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:58:23,040]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:58:27,210]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:59:06,439]\u001b[0m Trial 949 finished with value: 22.85697971962018 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016681002703137263, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1684907254225547, 'dropout_rate_Layer_2': 0.2642453316081001, 'dropout_rate_Layer_3': 0.05927981900068201, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.037107453403559004, 'l1_Layer_2': 0.0008985148315639535, 'l1_Layer_3': 2.3557987223531685e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 295, 'n_units_Layer_3': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.86 | sMAPE for Validation Set is: 30.45% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 63.10 | sMAPE for Test Set is: 58.70% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 09:59:15,769]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:59:21,263]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 09:59:53,517]\u001b[0m Trial 952 finished with value: 22.912590221421905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018102033320911075, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1300271542044204, 'dropout_rate_Layer_2': 0.25552823013963677, 'dropout_rate_Layer_3': 0.057508945978180764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.037008352011033814, 'l1_Layer_2': 0.0004214488636163363, 'l1_Layer_3': 2.4315208382022087e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 295, 'n_units_Layer_3': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.91 | sMAPE for Validation Set is: 30.22% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 64.57 | sMAPE for Test Set is: 59.06% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:00:02,575]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:00:18,077]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:00:25,863]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:00:31,266]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:01:00,038]\u001b[0m Trial 957 finished with value: 22.15225917853013 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023299650812718194, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2779612554351393, 'dropout_rate_Layer_2': 0.19742927176509686, 'dropout_rate_Layer_3': 0.2266841287926223, 'dropout_rate_Layer_4': 0.3069575217416898, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.5646702039776056e-05, 'l1_Layer_2': 0.00030057264252062105, 'l1_Layer_3': 1.4258564926683026e-05, 'l1_Layer_4': 0.004856324401370358, 'n_units_Layer_1': 110, 'n_units_Layer_2': 165, 'n_units_Layer_3': 170, 'n_units_Layer_4': 235}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.15 | sMAPE for Validation Set is: 30.11% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.87 | sMAPE for Test Set is: 58.83% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:01:03,814]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:01:10,563]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:01:35,251]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:01:42,533]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:01:46,399]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:02:01,168]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:02:47,519]\u001b[0m Trial 964 finished with value: 23.512571467451988 and parameters: {'n_hidden': 3, 'learning_rate': 0.001667418426741961, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13301637176262962, 'dropout_rate_Layer_2': 0.25994494390229766, 'dropout_rate_Layer_3': 0.020828578638029352, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03951001575443575, 'l1_Layer_2': 0.0003221825652635115, 'l1_Layer_3': 2.2785698350178696e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 290, 'n_units_Layer_3': 245}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.51 | sMAPE for Validation Set is: 31.47% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 64.78 | sMAPE for Test Set is: 59.88% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:02:52,041]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:03:21,434]\u001b[0m Trial 966 finished with value: 21.99512381585617 and parameters: {'n_hidden': 3, 'learning_rate': 0.002081578388956373, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12300646421315656, 'dropout_rate_Layer_2': 0.2667027574382001, 'dropout_rate_Layer_3': 0.009233693444800689, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.032411478786189385, 'l1_Layer_2': 0.000360194697269536, 'l1_Layer_3': 3.75602692127345e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 245, 'n_units_Layer_3': 215}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.00 | sMAPE for Validation Set is: 29.62% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 62.10 | sMAPE for Test Set is: 58.42% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:03:39,963]\u001b[0m Trial 967 finished with value: 21.320517250027237 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035330188476368463, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.345362037001281, 'dropout_rate_Layer_2': 0.12101107057602015, 'dropout_rate_Layer_3': 0.37120504538305465, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.599350604363926e-05, 'l1_Layer_2': 0.0004689475267157497, 'l1_Layer_3': 0.0008848385838662612, 'n_units_Layer_1': 205, 'n_units_Layer_2': 155, 'n_units_Layer_3': 140}. Best is trial 185 with value: 20.803607578845888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.32 | sMAPE for Validation Set is: 29.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 60.17 | sMAPE for Test Set is: 56.80% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:03:44,389]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:03:49,790]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:04:12,198]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:05:07,271]\u001b[0m Trial 971 finished with value: 20.53692540401798 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017865769518480032, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1410853779184451, 'dropout_rate_Layer_2': 0.25254703189746475, 'dropout_rate_Layer_3': 0.0006127877409004695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011693570104104378, 'l1_Layer_2': 0.00042632040371478886, 'l1_Layer_3': 3.300041863265437e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.54 | sMAPE for Validation Set is: 27.80% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.08 | sMAPE for Test Set is: 55.59% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:05:16,141]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:05:31,512]\u001b[0m Trial 973 finished with value: 21.14979456743708 and parameters: {'n_hidden': 3, 'learning_rate': 0.003405024063119061, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3431136893128529, 'dropout_rate_Layer_2': 0.11905868351326984, 'dropout_rate_Layer_3': 0.3308244910552904, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.5429839212385126e-05, 'l1_Layer_2': 0.0010294628119150834, 'l1_Layer_3': 0.0008683755110065374, 'n_units_Layer_1': 205, 'n_units_Layer_2': 125, 'n_units_Layer_3': 145}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.15 | sMAPE for Validation Set is: 28.96% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.61 | sMAPE for Test Set is: 56.11% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:05:38,492]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:05:56,101]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:06:00,418]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:06:09,442]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:06:28,695]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:06:33,372]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:07:22,216]\u001b[0m Trial 980 finished with value: 20.961105952724065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012595918013964475, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14133894421155088, 'dropout_rate_Layer_2': 0.2513943764735316, 'dropout_rate_Layer_3': 0.08577806341781494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08263686171114976, 'l1_Layer_2': 0.0003791713649779977, 'l1_Layer_3': 3.4669214576672765e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 230, 'n_units_Layer_3': 265}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.96 | sMAPE for Validation Set is: 28.37% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.14 | sMAPE for Test Set is: 55.99% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:07:27,919]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:07:33,334]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:07:41,636]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:08:08,535]\u001b[0m Trial 984 finished with value: 22.303851397528106 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036627758368096147, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3091000428350727, 'dropout_rate_Layer_2': 0.1688340932786254, 'dropout_rate_Layer_3': 0.26375524142380335, 'dropout_rate_Layer_4': 0.32167296196622186, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.2931414552680296e-05, 'l1_Layer_2': 0.0002500534614896692, 'l1_Layer_3': 1.1714531183353488e-05, 'l1_Layer_4': 0.0070324541438608595, 'n_units_Layer_1': 125, 'n_units_Layer_2': 170, 'n_units_Layer_3': 165, 'n_units_Layer_4': 255}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.30 | sMAPE for Validation Set is: 30.53% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.81 | sMAPE for Test Set is: 58.61% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:08:16,498]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:08:25,058]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:08:29,130]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:08:33,365]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:08:41,740]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:08:50,938]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:08:59,739]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:09:50,219]\u001b[0m Trial 992 finished with value: 22.368079557434367 and parameters: {'n_hidden': 4, 'learning_rate': 0.003382488244803364, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2848027755503745, 'dropout_rate_Layer_2': 0.18494743035725883, 'dropout_rate_Layer_3': 0.2801679924208642, 'dropout_rate_Layer_4': 0.3127728315111405, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.0166069995306493e-05, 'l1_Layer_2': 0.0003783774159220072, 'l1_Layer_3': 0.022089115689966406, 'l1_Layer_4': 0.00394552629118395, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165, 'n_units_Layer_4': 250}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.37 | sMAPE for Validation Set is: 30.40% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 62.18 | sMAPE for Test Set is: 58.45% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:09:57,462]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:10:13,460]\u001b[0m Trial 994 finished with value: 21.477063395637163 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055326624482575125, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20430795909765928, 'dropout_rate_Layer_2': 0.026471832290827307, 'dropout_rate_Layer_3': 0.1386527465507579, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026898772247816973, 'l1_Layer_2': 0.0003079820623523444, 'l1_Layer_3': 0.0013553453339941659, 'n_units_Layer_1': 235, 'n_units_Layer_2': 120, 'n_units_Layer_3': 80}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.48 | sMAPE for Validation Set is: 29.34% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 61.12 | sMAPE for Test Set is: 57.94% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:10:20,668]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:10:24,771]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:11:03,075]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:11:10,627]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:11:14,931]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:11:20,439]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:11:52,293]\u001b[0m Trial 1001 finished with value: 21.97820946288287 and parameters: {'n_hidden': 4, 'learning_rate': 0.003420506553890874, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.274359831117441, 'dropout_rate_Layer_2': 0.17500515031850122, 'dropout_rate_Layer_3': 0.28059911980090935, 'dropout_rate_Layer_4': 0.28148036869299353, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.9805737374055512e-05, 'l1_Layer_2': 0.00032669766809769965, 'l1_Layer_3': 1.436541304946434e-05, 'l1_Layer_4': 0.002887882578305849, 'n_units_Layer_1': 110, 'n_units_Layer_2': 165, 'n_units_Layer_3': 180, 'n_units_Layer_4': 245}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.98 | sMAPE for Validation Set is: 29.72% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 61.06 | sMAPE for Test Set is: 58.31% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:11:57,964]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:12:02,576]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:12:06,720]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:12:26,636]\u001b[0m Trial 1005 finished with value: 22.47129942110575 and parameters: {'n_hidden': 4, 'learning_rate': 0.00393565407753337, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2720276348082772, 'dropout_rate_Layer_2': 0.16737369278396266, 'dropout_rate_Layer_3': 0.286797266984922, 'dropout_rate_Layer_4': 0.2841111737534232, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.1793053555342844e-05, 'l1_Layer_2': 0.00034371719850829406, 'l1_Layer_3': 0.008035102935742252, 'l1_Layer_4': 0.001720260241546102, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 185, 'n_units_Layer_4': 245}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.47 | sMAPE for Validation Set is: 30.45% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 61.84 | sMAPE for Test Set is: 58.50% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:12:30,641]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:12:45,001]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:12:51,874]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:12:59,043]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:13:11,313]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:13:16,096]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:13:20,259]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:13:24,518]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:13:28,391]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:13:53,524]\u001b[0m Trial 1015 finished with value: 23.828478112584833 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027987798422993157, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3857928983266625, 'dropout_rate_Layer_2': 0.17620643096116073, 'dropout_rate_Layer_3': 0.28047233150243084, 'dropout_rate_Layer_4': 0.29708519229614044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.839567341567839e-05, 'l1_Layer_2': 0.000332779496398401, 'l1_Layer_3': 0.023815518248569957, 'l1_Layer_4': 0.00537987717695737, 'n_units_Layer_1': 110, 'n_units_Layer_2': 170, 'n_units_Layer_3': 165, 'n_units_Layer_4': 230}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.83 | sMAPE for Validation Set is: 31.99% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 63.67 | sMAPE for Test Set is: 60.27% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:14:08,910]\u001b[0m Trial 1016 finished with value: 21.405561198415153 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025698883951308783, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.338979662742456, 'dropout_rate_Layer_2': 0.13447998401332945, 'dropout_rate_Layer_3': 0.29566090219683544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7334342747625362e-05, 'l1_Layer_2': 0.0009156619000990291, 'l1_Layer_3': 0.001112900419392011, 'n_units_Layer_1': 210, 'n_units_Layer_2': 205, 'n_units_Layer_3': 115}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.41 | sMAPE for Validation Set is: 29.21% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 58.63 | sMAPE for Test Set is: 56.48% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:14:14,603]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:14:20,087]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:14:39,367]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:14:55,163]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:15:02,587]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:15:08,077]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:15:12,611]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:15:17,920]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:15:22,220]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:15:37,527]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:16:17,892]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:16:22,141]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:17:06,950]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:17:29,066]\u001b[0m Trial 1030 finished with value: 21.444551361365246 and parameters: {'n_hidden': 3, 'learning_rate': 0.006937361995968768, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07353151101963695, 'dropout_rate_Layer_2': 0.021986753787350252, 'dropout_rate_Layer_3': 0.07055166439954076, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024623140017231075, 'l1_Layer_2': 0.007776735663308348, 'l1_Layer_3': 0.0005466272852540624, 'n_units_Layer_1': 210, 'n_units_Layer_2': 155, 'n_units_Layer_3': 70}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.44 | sMAPE for Validation Set is: 29.09% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 58.81 | sMAPE for Test Set is: 56.21% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:17:34,433]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:18:19,764]\u001b[0m Trial 1032 finished with value: 20.868680765545566 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020744783791201973, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14355040780339584, 'dropout_rate_Layer_2': 0.26604081234049587, 'dropout_rate_Layer_3': 0.047319298582387495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012209657891466202, 'l1_Layer_2': 0.0003403198676932881, 'l1_Layer_3': 2.472096830131564e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 255}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.87 | sMAPE for Validation Set is: 28.17% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.37 | sMAPE for Test Set is: 56.31% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:18:23,373]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:18:28,884]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:18:37,175]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:18:40,975]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:18:45,140]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:18:50,466]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:18:54,220]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:19:15,472]\u001b[0m Trial 1040 finished with value: 23.944929717732546 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030383354060718975, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3112339698380069, 'dropout_rate_Layer_2': 0.13665403720109326, 'dropout_rate_Layer_3': 0.2960011257198407, 'dropout_rate_Layer_4': 0.3094606220881069, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.054644080132517e-05, 'l1_Layer_2': 0.00022182080022501154, 'l1_Layer_3': 0.07555162930950178, 'l1_Layer_4': 0.006204166782770924, 'n_units_Layer_1': 130, 'n_units_Layer_2': 180, 'n_units_Layer_3': 165, 'n_units_Layer_4': 240}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.94 | sMAPE for Validation Set is: 32.47% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 64.05 | sMAPE for Test Set is: 60.86% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:20:33,061]\u001b[0m Trial 1041 finished with value: 20.55684018805262 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009111463049837005, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14415021810683754, 'dropout_rate_Layer_2': 0.26897832476361994, 'dropout_rate_Layer_3': 0.030926045592286268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012648543645592286, 'l1_Layer_2': 0.00034047618472318996, 'l1_Layer_3': 3.506158939522946e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 220, 'n_units_Layer_3': 275}. Best is trial 971 with value: 20.53692540401798.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.56 | sMAPE for Validation Set is: 27.84% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.04 | sMAPE for Test Set is: 55.42% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:20:37,455]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:20:46,686]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:20:54,251]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:21:02,276]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:21:11,114]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:21:30,591]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:21:34,868]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:21:39,423]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:21:45,303]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:21:49,354]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:21:54,851]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:22:00,443]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:22:43,580]\u001b[0m Trial 1054 finished with value: 20.496299671869263 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009026286614915164, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14238362359268183, 'dropout_rate_Layer_2': 0.27149449415359367, 'dropout_rate_Layer_3': 0.04452261295537883, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011556626480686791, 'l1_Layer_2': 0.00023508090804562904, 'l1_Layer_3': 3.8972354519302185e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 225, 'n_units_Layer_3': 275}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.50 | sMAPE for Validation Set is: 27.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.72 | sMAPE for Test Set is: 55.70% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:22:47,770]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:23:05,335]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:23:10,172]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:23:35,368]\u001b[0m Trial 1058 finished with value: 23.380129705363373 and parameters: {'n_hidden': 4, 'learning_rate': 0.002227379728720834, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2981626374151455, 'dropout_rate_Layer_2': 0.18290990455386835, 'dropout_rate_Layer_3': 0.2534914065686093, 'dropout_rate_Layer_4': 0.17779416699645045, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.020751809236346782, 'l1_Layer_2': 0.00037083512030686, 'l1_Layer_3': 0.0004093115044215544, 'l1_Layer_4': 0.006051155636154714, 'n_units_Layer_1': 125, 'n_units_Layer_2': 180, 'n_units_Layer_3': 165, 'n_units_Layer_4': 245}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.38 | sMAPE for Validation Set is: 31.73% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 61.96 | sMAPE for Test Set is: 59.44% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:23:39,522]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:23:47,220]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:24:05,609]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:24:37,857]\u001b[0m Trial 1062 finished with value: 22.216301669563887 and parameters: {'n_hidden': 4, 'learning_rate': 0.001594451700044925, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3098981280328824, 'dropout_rate_Layer_2': 0.17615447550279126, 'dropout_rate_Layer_3': 0.24447267306244994, 'dropout_rate_Layer_4': 0.29754379233950373, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.5476233097066845e-05, 'l1_Layer_2': 0.00021657533651065888, 'l1_Layer_3': 0.0014181605379990304, 'l1_Layer_4': 0.004464706736714823, 'n_units_Layer_1': 95, 'n_units_Layer_2': 170, 'n_units_Layer_3': 160, 'n_units_Layer_4': 260}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.22 | sMAPE for Validation Set is: 30.07% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 63.35 | sMAPE for Test Set is: 59.01% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:25:07,730]\u001b[0m Trial 1063 finished with value: 23.478633982327178 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024257813027155723, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3216623439817784, 'dropout_rate_Layer_2': 0.11941763081092255, 'dropout_rate_Layer_3': 0.24635256805966035, 'dropout_rate_Layer_4': 0.29281598361674815, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00294503545694422, 'l1_Layer_2': 0.00019962225466921654, 'l1_Layer_3': 0.010779422580512987, 'l1_Layer_4': 0.004177494208544933, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 160, 'n_units_Layer_4': 265}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.48 | sMAPE for Validation Set is: 31.62% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 62.83 | sMAPE for Test Set is: 59.89% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:25:42,173]\u001b[0m Trial 1064 finished with value: 22.642374725381757 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015531005346250985, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2705990870377083, 'dropout_rate_Layer_2': 0.17441409827064758, 'dropout_rate_Layer_3': 0.15881845421334534, 'dropout_rate_Layer_4': 0.3006460494516332, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.537028435413169e-05, 'l1_Layer_2': 0.00014447040392172178, 'l1_Layer_3': 0.01867529483960226, 'l1_Layer_4': 0.003563897223368116, 'n_units_Layer_1': 105, 'n_units_Layer_2': 150, 'n_units_Layer_3': 165, 'n_units_Layer_4': 255}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.64 | sMAPE for Validation Set is: 30.59% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 62.20 | sMAPE for Test Set is: 58.35% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:25:47,566]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:25:51,720]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:26:11,453]\u001b[0m Trial 1067 finished with value: 21.344278683709035 and parameters: {'n_hidden': 3, 'learning_rate': 0.002231056035173793, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34480985491056393, 'dropout_rate_Layer_2': 0.16434398250475174, 'dropout_rate_Layer_3': 0.3110983487204263, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.46530106233719e-05, 'l1_Layer_2': 0.000674343218687552, 'l1_Layer_3': 0.0008224693629096825, 'n_units_Layer_1': 210, 'n_units_Layer_2': 115, 'n_units_Layer_3': 110}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.34 | sMAPE for Validation Set is: 29.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.25 | sMAPE for Test Set is: 56.63% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:26:18,399]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:26:27,842]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:26:32,078]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:26:37,783]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:26:44,780]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:27:38,743]\u001b[0m Trial 1073 finished with value: 20.539050858760014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009598831256097969, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11756198766559924, 'dropout_rate_Layer_2': 0.24525593429550835, 'dropout_rate_Layer_3': 0.030449261004315054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013880475521905336, 'l1_Layer_2': 0.00025149882455433666, 'l1_Layer_3': 3.5075964660036894e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 215, 'n_units_Layer_3': 275}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.54 | sMAPE for Validation Set is: 27.74% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.71 | sMAPE for Test Set is: 55.98% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:27:43,873]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:27:49,028]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:28:08,903]\u001b[0m Trial 1076 finished with value: 21.085729236561715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016528732051861975, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33942706334335226, 'dropout_rate_Layer_2': 0.1554230160663714, 'dropout_rate_Layer_3': 0.3184161027775686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.013874979521955e-05, 'l1_Layer_2': 0.0009324103601908699, 'l1_Layer_3': 0.0012966234188538826, 'n_units_Layer_1': 210, 'n_units_Layer_2': 245, 'n_units_Layer_3': 105}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.09 | sMAPE for Validation Set is: 28.92% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.45 | sMAPE for Test Set is: 56.23% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:28:17,193]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:28:44,235]\u001b[0m Trial 1078 finished with value: 22.540564610682832 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015150822137935587, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3409006727771218, 'dropout_rate_Layer_2': 0.17684271455935988, 'dropout_rate_Layer_3': 0.288726413506097, 'dropout_rate_Layer_4': 0.2954267413615031, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.2155180494094745e-05, 'l1_Layer_2': 0.00043225466083613145, 'l1_Layer_3': 0.004629525861799713, 'l1_Layer_4': 0.0021509624169867196, 'n_units_Layer_1': 115, 'n_units_Layer_2': 175, 'n_units_Layer_3': 160, 'n_units_Layer_4': 275}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.54 | sMAPE for Validation Set is: 30.54% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 63.81 | sMAPE for Test Set is: 59.86% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:29:07,897]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:29:11,933]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:29:20,635]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:29:25,494]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:29:34,503]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:30:15,481]\u001b[0m Trial 1084 finished with value: 21.743648764437804 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016380550850166847, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2694038358773277, 'dropout_rate_Layer_2': 0.19077732113027623, 'dropout_rate_Layer_3': 0.1628621314560624, 'dropout_rate_Layer_4': 0.2988225226672099, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.9499925191392744e-05, 'l1_Layer_2': 0.0005131173450469826, 'l1_Layer_3': 1.8165298282483585e-05, 'l1_Layer_4': 0.0032525629245525995, 'n_units_Layer_1': 125, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165, 'n_units_Layer_4': 255}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.74 | sMAPE for Validation Set is: 29.92% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 62.44 | sMAPE for Test Set is: 58.05% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:30:20,776]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:30:24,730]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:30:30,301]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:30:38,375]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:30:42,845]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:30:47,813]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:30:54,820]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:31:08,549]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:31:12,521]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:31:20,600]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:31:31,131]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:31:46,540]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:32:00,830]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:32:05,895]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:32:10,651]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:32:16,548]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:32:20,142]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:32:38,849]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:32:47,759]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:33:56,270]\u001b[0m Trial 1104 finished with value: 20.76823953415207 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009251576582311689, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1404351646690797, 'dropout_rate_Layer_2': 0.27134616426685787, 'dropout_rate_Layer_3': 0.04445144852404242, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01181540714004339, 'l1_Layer_2': 0.00024358469238735435, 'l1_Layer_3': 4.1366334826348806e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 215, 'n_units_Layer_3': 295}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.77 | sMAPE for Validation Set is: 27.99% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.57 | sMAPE for Test Set is: 55.74% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:34:14,419]\u001b[0m Trial 1105 finished with value: 21.139481747063154 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029603385525145127, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36453292856732206, 'dropout_rate_Layer_2': 0.1384609006737932, 'dropout_rate_Layer_3': 0.2947259055425776, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.225546372351765e-05, 'l1_Layer_2': 0.0007405508617040566, 'l1_Layer_3': 0.0017350484355343658, 'n_units_Layer_1': 210, 'n_units_Layer_2': 245, 'n_units_Layer_3': 95}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.14 | sMAPE for Validation Set is: 28.96% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.26 | sMAPE for Test Set is: 56.35% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:34:22,925]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:34:27,021]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:34:31,286]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:34:55,699]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:35:04,486]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:35:20,483]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:35:28,883]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:35:47,171]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:36:30,701]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:36:34,588]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:36:39,984]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:36:44,402]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:37:19,838]\u001b[0m Trial 1118 finished with value: 22.85054813921563 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010812692861062857, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26236087867805685, 'dropout_rate_Layer_2': 0.18600116410978684, 'dropout_rate_Layer_3': 0.23447522381672195, 'dropout_rate_Layer_4': 0.30213248888334143, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.0396167588894785e-05, 'l1_Layer_2': 0.0001907581453137081, 'l1_Layer_3': 0.01654736077618079, 'l1_Layer_4': 0.006958056658372353, 'n_units_Layer_1': 95, 'n_units_Layer_2': 170, 'n_units_Layer_3': 180, 'n_units_Layer_4': 265}. Best is trial 1054 with value: 20.496299671869263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.85 | sMAPE for Validation Set is: 30.82% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 62.22 | sMAPE for Test Set is: 58.96% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:37:23,701]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:37:32,317]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:37:40,917]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:37:46,037]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:37:50,140]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:37:54,631]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:39:02,793]\u001b[0m Trial 1125 finished with value: 20.49545631043405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009492218109333955, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14279713479111344, 'dropout_rate_Layer_2': 0.28239805480532854, 'dropout_rate_Layer_3': 0.08091965922909974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011783917933791032, 'l1_Layer_2': 0.000297737830423653, 'l1_Layer_3': 8.556212785336007e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 210, 'n_units_Layer_3': 275}. Best is trial 1125 with value: 20.49545631043405.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.50 | sMAPE for Validation Set is: 27.55% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.25 | sMAPE for Test Set is: 54.38% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:39:07,740]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:39:28,663]\u001b[0m Trial 1127 finished with value: 21.301076661400096 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024195151532912826, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38170093515569076, 'dropout_rate_Layer_2': 0.14099173418765842, 'dropout_rate_Layer_3': 0.30279901982182433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.558628649176775e-05, 'l1_Layer_2': 0.0007063714398353979, 'l1_Layer_3': 0.0014444353625464395, 'n_units_Layer_1': 230, 'n_units_Layer_2': 240, 'n_units_Layer_3': 110}. Best is trial 1125 with value: 20.49545631043405.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.30 | sMAPE for Validation Set is: 29.17% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.06 | sMAPE for Test Set is: 56.41% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:39:32,908]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:39:38,273]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:39:43,835]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:39:49,199]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:39:54,773]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:39:59,844]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:40:03,939]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:40:08,524]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:40:12,797]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:40:16,651]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:40:21,182]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:40:26,402]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:40:30,848]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:41:56,659]\u001b[0m Trial 1141 finished with value: 20.375540080517254 and parameters: {'n_hidden': 3, 'learning_rate': 0.000957082742778113, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14112798220438647, 'dropout_rate_Layer_2': 0.24271078967420134, 'dropout_rate_Layer_3': 0.08461323793832007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011552502964717841, 'l1_Layer_2': 0.00030941903015301606, 'l1_Layer_3': 8.585976076751721e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 205, 'n_units_Layer_3': 255}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.38 | sMAPE for Validation Set is: 27.52% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.39 | sMAPE for Test Set is: 55.78% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:42:05,499]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:42:09,802]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:42:13,875]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:42:19,245]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:42:54,254]\u001b[0m Trial 1146 finished with value: 23.910865471194356 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015513941083423021, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2834597155129429, 'dropout_rate_Layer_2': 0.18523683413891998, 'dropout_rate_Layer_3': 0.3278803409009128, 'dropout_rate_Layer_4': 0.33245698073253627, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.2405348769202077e-05, 'l1_Layer_2': 0.0003164063997899902, 'l1_Layer_3': 0.032055256837150284, 'l1_Layer_4': 0.004497768394836716, 'n_units_Layer_1': 130, 'n_units_Layer_2': 160, 'n_units_Layer_3': 165, 'n_units_Layer_4': 230}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.91 | sMAPE for Validation Set is: 32.13% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 63.74 | sMAPE for Test Set is: 60.42% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:44:35,931]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:44:40,245]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:44:57,311]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:45:01,356]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:45:05,822]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:45:14,050]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:45:18,280]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:45:23,051]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:45:44,940]\u001b[0m Trial 1155 finished with value: 23.34765972742599 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026955451975044635, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3384095837116137, 'dropout_rate_Layer_2': 0.04374295231789205, 'dropout_rate_Layer_3': 0.2353242612532579, 'dropout_rate_Layer_4': 0.2567443324588196, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.01992506121742459, 'l1_Layer_2': 0.00022215818298894116, 'l1_Layer_3': 0.018411499266518347, 'l1_Layer_4': 0.0014073954537761116, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 150, 'n_units_Layer_4': 260}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.35 | sMAPE for Validation Set is: 31.47% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 62.62 | sMAPE for Test Set is: 59.74% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:45:50,360]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:45:55,894]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:46:01,651]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:46:05,937]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:46:10,985]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:46:49,548]\u001b[0m Trial 1161 finished with value: 20.72418683756885 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007788310640040193, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11943573645282946, 'dropout_rate_Layer_2': 0.24106754867499433, 'dropout_rate_Layer_3': 0.07981229290767083, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007228951052759836, 'l1_Layer_2': 0.0002343124585330133, 'l1_Layer_3': 6.930000874365855e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 220, 'n_units_Layer_3': 290}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.72 | sMAPE for Validation Set is: 28.01% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.52 | sMAPE for Test Set is: 55.81% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:46:54,362]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:46:58,473]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:47:03,366]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:47:08,885]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:47:16,022]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:47:21,415]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:47:30,272]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:47:36,256]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:47:40,337]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:47:44,795]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:47:53,482]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:47:57,711]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:48:02,599]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:48:06,882]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:48:22,860]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:48:40,414]\u001b[0m Trial 1177 finished with value: 21.33381105632367 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022260401937262337, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30320657503907017, 'dropout_rate_Layer_2': 0.18890060791933172, 'dropout_rate_Layer_3': 0.317932226309323, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.250546481469353e-05, 'l1_Layer_2': 0.0009631709387064739, 'l1_Layer_3': 0.0014611118839926134, 'n_units_Layer_1': 235, 'n_units_Layer_2': 250, 'n_units_Layer_3': 80}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.33 | sMAPE for Validation Set is: 29.47% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 57.80 | sMAPE for Test Set is: 56.22% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:49:22,788]\u001b[0m Trial 1178 finished with value: 20.65844254237092 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009805173832704876, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17598259603172647, 'dropout_rate_Layer_2': 0.10317570097032533, 'dropout_rate_Layer_3': 0.04073386189737502, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.023896622173284e-05, 'l1_Layer_2': 0.0023002713957261675, 'l1_Layer_3': 5.7869048357543736e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.66 | sMAPE for Validation Set is: 27.96% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.44 | sMAPE for Test Set is: 56.76% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:49:32,515]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:49:58,059]\u001b[0m Trial 1180 finished with value: 23.721661522814685 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029681256467042802, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3603964814538245, 'dropout_rate_Layer_2': 0.17328554180485187, 'dropout_rate_Layer_3': 0.05219778934764552, 'dropout_rate_Layer_4': 0.313777297433896, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.3180655907089286e-05, 'l1_Layer_2': 0.03608393748527444, 'l1_Layer_3': 0.00976525339946879, 'l1_Layer_4': 0.003975027620774304, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 150, 'n_units_Layer_4': 225}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.72 | sMAPE for Validation Set is: 31.84% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 63.75 | sMAPE for Test Set is: 60.36% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:50:03,340]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:50:08,833]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:50:12,968]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:50:17,315]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:50:22,230]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:50:38,334]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:50:55,790]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:51:09,146]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:51:53,679]\u001b[0m Trial 1189 finished with value: 20.748321907566915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008011423287002039, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16456994652676107, 'dropout_rate_Layer_2': 0.13907307241978278, 'dropout_rate_Layer_3': 0.06708866263090564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.7226682861898596e-05, 'l1_Layer_2': 0.0019124250238695432, 'l1_Layer_3': 5.1663088609676843e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 155, 'n_units_Layer_3': 135}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.75 | sMAPE for Validation Set is: 28.29% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.67 | sMAPE for Test Set is: 55.82% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:52:24,800]\u001b[0m Trial 1190 finished with value: 22.122786479078417 and parameters: {'n_hidden': 4, 'learning_rate': 0.002772641772418382, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3261550068534249, 'dropout_rate_Layer_2': 0.1880222680185752, 'dropout_rate_Layer_3': 0.32698986742504904, 'dropout_rate_Layer_4': 0.38778253804372764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.349554965502948e-05, 'l1_Layer_2': 0.0005372737127568934, 'l1_Layer_3': 1.0018817972828591e-05, 'l1_Layer_4': 0.0019289140652175053, 'n_units_Layer_1': 130, 'n_units_Layer_2': 175, 'n_units_Layer_3': 175, 'n_units_Layer_4': 250}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.12 | sMAPE for Validation Set is: 30.13% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.14 | sMAPE for Test Set is: 58.06% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:52:33,054]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:52:41,927]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:52:46,083]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:52:51,252]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:53:32,347]\u001b[0m Trial 1195 finished with value: 20.385394236833914 and parameters: {'n_hidden': 3, 'learning_rate': 0.000651237562486375, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15366178963488072, 'dropout_rate_Layer_2': 0.1397720678600741, 'dropout_rate_Layer_3': 0.023303986117238808, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.431797236762931e-05, 'l1_Layer_2': 0.0014724282561065193, 'l1_Layer_3': 5.7188295559682694e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 240, 'n_units_Layer_3': 140}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.39 | sMAPE for Validation Set is: 27.71% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.21 | sMAPE for Test Set is: 55.29% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:53:38,375]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:53:42,773]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:53:46,789]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:53:50,694]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:54:48,821]\u001b[0m Trial 1200 finished with value: 20.392719341836163 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009296734596325108, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10925509581966032, 'dropout_rate_Layer_2': 0.25971250608393626, 'dropout_rate_Layer_3': 0.1056611438071772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006452526097435628, 'l1_Layer_2': 0.0002563617450429667, 'l1_Layer_3': 6.209722321241692e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 220, 'n_units_Layer_3': 275}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.39 | sMAPE for Validation Set is: 27.74% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.78 | sMAPE for Test Set is: 55.63% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:54:52,932]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:01,427]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:53,091]\u001b[0m Trial 1203 finished with value: 20.851176639679867 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006518036953695436, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15125102086034264, 'dropout_rate_Layer_2': 0.13271095743989134, 'dropout_rate_Layer_3': 0.0626729118287061, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.751644999352786e-05, 'l1_Layer_2': 0.0019160274920883651, 'l1_Layer_3': 5.066613884602221e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 155, 'n_units_Layer_3': 120}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.85 | sMAPE for Validation Set is: 28.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.92 | sMAPE for Test Set is: 55.96% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:55:57,288]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:02,750]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:08,401]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:59,871]\u001b[0m Trial 1207 finished with value: 20.73672558276014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005889398646430903, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15371260585110144, 'dropout_rate_Layer_2': 0.1361989524302097, 'dropout_rate_Layer_3': 0.04594796397004501, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.038539348742297e-05, 'l1_Layer_2': 0.001940611747759233, 'l1_Layer_3': 5.7015303859801384e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 155, 'n_units_Layer_3': 140}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.74 | sMAPE for Validation Set is: 28.27% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.68 | sMAPE for Test Set is: 55.87% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:57:48,938]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:00,098]\u001b[0m Trial 1209 finished with value: 20.68908549819579 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006472347053041258, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15123799330204615, 'dropout_rate_Layer_2': 0.13797436980850075, 'dropout_rate_Layer_3': 0.05759326788154359, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.2662412791726595e-05, 'l1_Layer_2': 0.002083356259719281, 'l1_Layer_3': 5.5410264306306875e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 155, 'n_units_Layer_3': 135}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.69 | sMAPE for Validation Set is: 28.04% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.92 | sMAPE for Test Set is: 55.78% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:59:32,467]\u001b[0m Trial 1210 finished with value: 22.34820187305827 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017297626615629723, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3116972234860589, 'dropout_rate_Layer_2': 0.19750153879034413, 'dropout_rate_Layer_3': 0.33485583486894704, 'dropout_rate_Layer_4': 0.3273260476014683, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004516056387104967, 'l1_Layer_2': 0.0002715872048952291, 'l1_Layer_3': 1.0078057417077275e-05, 'l1_Layer_4': 0.0045284275602239035, 'n_units_Layer_1': 130, 'n_units_Layer_2': 155, 'n_units_Layer_3': 185, 'n_units_Layer_4': 250}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.35 | sMAPE for Validation Set is: 30.08% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.36 | sMAPE for Test Set is: 58.55% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:01:05,517]\u001b[0m Trial 1211 finished with value: 20.688593764604803 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009323508621783819, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09349974805741956, 'dropout_rate_Layer_2': 0.24062945859698148, 'dropout_rate_Layer_3': 0.10156840369646519, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006058197670114217, 'l1_Layer_2': 0.0002281728021570046, 'l1_Layer_3': 9.082924210154684e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 220, 'n_units_Layer_3': 275}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.69 | sMAPE for Validation Set is: 27.99% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.15 | sMAPE for Test Set is: 55.51% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:01:14,357]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:18,468]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:32,159]\u001b[0m Trial 1214 finished with value: 21.853400329659994 and parameters: {'n_hidden': 3, 'learning_rate': 0.000807522272508513, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09528781488004699, 'dropout_rate_Layer_2': 0.2250969609344053, 'dropout_rate_Layer_3': 0.10581053839471921, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006712112999687897, 'l1_Layer_2': 0.0002349013222636832, 'l1_Layer_3': 6.0863180841925124e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 220, 'n_units_Layer_3': 290}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.85 | sMAPE for Validation Set is: 29.15% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.64 | sMAPE for Test Set is: 57.38% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:04:50,950]\u001b[0m Trial 1215 finished with value: 20.7869452184583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006249894323861082, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15419226295155997, 'dropout_rate_Layer_2': 0.12719171479738126, 'dropout_rate_Layer_3': 0.0530173235836951, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.608492915253972e-05, 'l1_Layer_2': 0.0018981810308033042, 'l1_Layer_3': 5.0510521605416536e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 240, 'n_units_Layer_3': 135}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.79 | sMAPE for Validation Set is: 28.31% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.56 | sMAPE for Test Set is: 55.66% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:05:06,265]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:05:15,352]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:06:08,107]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:06:26,585]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:06:30,732]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:07:00,705]\u001b[0m Trial 1221 finished with value: 23.711155597395518 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012235518053759931, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33026930619961314, 'dropout_rate_Layer_2': 0.12429648039532329, 'dropout_rate_Layer_3': 0.3067928830749316, 'dropout_rate_Layer_4': 0.39452053306595436, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.035810610401075485, 'l1_Layer_2': 0.00040666742704152285, 'l1_Layer_3': 0.038528570913310106, 'l1_Layer_4': 0.003257840035713133, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 185, 'n_units_Layer_4': 255}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.71 | sMAPE for Validation Set is: 31.85% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 63.31 | sMAPE for Test Set is: 60.05% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:07:41,055]\u001b[0m Trial 1222 finished with value: 22.10264230733921 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024416237136118033, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09766380486017351, 'dropout_rate_Layer_2': 0.20555228617160592, 'dropout_rate_Layer_3': 0.31934896985376376, 'dropout_rate_Layer_4': 0.21640136954183015, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.1586061017770764e-05, 'l1_Layer_2': 0.028113059905571197, 'l1_Layer_3': 1.3254487595554296e-05, 'l1_Layer_4': 0.00458705358935631, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 170, 'n_units_Layer_4': 245}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.10 | sMAPE for Validation Set is: 29.94% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.94 | sMAPE for Test Set is: 58.65% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:08:16,945]\u001b[0m Trial 1223 finished with value: 21.74527069493268 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023183813836033435, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12389708739752144, 'dropout_rate_Layer_2': 0.2020210067589808, 'dropout_rate_Layer_3': 0.31704801187037984, 'dropout_rate_Layer_4': 0.2626461315096295, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0016083874030799032, 'l1_Layer_2': 0.00013371211988336715, 'l1_Layer_3': 1.0100041436738851e-05, 'l1_Layer_4': 0.005129314497907666, 'n_units_Layer_1': 125, 'n_units_Layer_2': 160, 'n_units_Layer_3': 180, 'n_units_Layer_4': 240}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.75 | sMAPE for Validation Set is: 29.47% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 60.48 | sMAPE for Test Set is: 57.48% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:08:56,309]\u001b[0m Trial 1224 finished with value: 20.814812444875805 and parameters: {'n_hidden': 3, 'learning_rate': 0.000640277766271192, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14645835819776987, 'dropout_rate_Layer_2': 0.13825342516173073, 'dropout_rate_Layer_3': 0.06562896758467254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.0666364431150067e-05, 'l1_Layer_2': 0.0017690819368353441, 'l1_Layer_3': 5.773745995799296e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.81 | sMAPE for Validation Set is: 28.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.73 | sMAPE for Test Set is: 55.58% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:10:04,656]\u001b[0m Trial 1225 finished with value: 20.8305790518671 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006297675334959522, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1472690402103679, 'dropout_rate_Layer_2': 0.14002701876314597, 'dropout_rate_Layer_3': 0.062484445656517444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.3355085134888195e-05, 'l1_Layer_2': 0.001884749572698619, 'l1_Layer_3': 5.44448548892487e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 250, 'n_units_Layer_3': 145}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.83 | sMAPE for Validation Set is: 28.54% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.53 | sMAPE for Test Set is: 55.54% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:10:09,140]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:17,575]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:21,807]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:39,484]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:35,927]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:31,854]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:49,846]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:55,023]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:59,185]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:13:03,323]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:13:57,481]\u001b[0m Trial 1236 finished with value: 20.6711427449392 and parameters: {'n_hidden': 3, 'learning_rate': 0.000574783464710957, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1357444134907016, 'dropout_rate_Layer_2': 0.12459474376086344, 'dropout_rate_Layer_3': 0.04795890470373369, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.1585425272871276e-05, 'l1_Layer_2': 0.0015738283167829748, 'l1_Layer_3': 6.432071089961188e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 245, 'n_units_Layer_3': 135}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.67 | sMAPE for Validation Set is: 28.19% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.57 | sMAPE for Test Set is: 55.99% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:14:05,870]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:14:30,056]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:14:34,374]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:23,223]\u001b[0m Trial 1240 finished with value: 20.69626748371502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005250374386612687, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.136761158882697, 'dropout_rate_Layer_2': 0.12619660372670044, 'dropout_rate_Layer_3': 0.05100157580894393, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.965533626363322e-05, 'l1_Layer_2': 0.001548375507439117, 'l1_Layer_3': 6.41164301987221e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.70 | sMAPE for Validation Set is: 28.14% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.88 | sMAPE for Test Set is: 55.90% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:15:27,412]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:35,450]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:39,381]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:43,898]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:38,517]\u001b[0m Trial 1245 finished with value: 20.731181031006013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005043259685162109, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13219579757996464, 'dropout_rate_Layer_2': 0.13229494302382763, 'dropout_rate_Layer_3': 0.047238832138385776, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.1897021868780816e-05, 'l1_Layer_2': 0.0015536405585025303, 'l1_Layer_3': 6.535480521039573e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.73 | sMAPE for Validation Set is: 28.28% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.62 | sMAPE for Test Set is: 55.97% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:16:43,807]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:47,500]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:17:42,250]\u001b[0m Trial 1248 finished with value: 20.748639105317537 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005518984203783363, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13271699346764348, 'dropout_rate_Layer_2': 0.12411014624925572, 'dropout_rate_Layer_3': 0.047554872462618344, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.5510071955381144e-05, 'l1_Layer_2': 0.0016658106363600551, 'l1_Layer_3': 6.451769122558384e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.75 | sMAPE for Validation Set is: 28.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.71 | sMAPE for Test Set is: 55.84% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:17:46,477]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:17:52,199]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:17:56,333]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:18,602]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:19:18,221]\u001b[0m Trial 1253 finished with value: 20.960564129220487 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005405713511169949, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12873781314614244, 'dropout_rate_Layer_2': 0.12579317585690997, 'dropout_rate_Layer_3': 0.04475481725343759, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.701757825851895e-05, 'l1_Layer_2': 0.0015234966953225106, 'l1_Layer_3': 5.864099454471861e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.96 | sMAPE for Validation Set is: 28.45% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.98 | sMAPE for Test Set is: 55.78% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:19:36,620]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:20:26,196]\u001b[0m Trial 1255 finished with value: 20.63151638586095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005445514409548901, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13873053779805844, 'dropout_rate_Layer_2': 0.12561970026749592, 'dropout_rate_Layer_3': 0.05894623784728612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.222671481813966e-05, 'l1_Layer_2': 0.0014638784943426459, 'l1_Layer_3': 5.728516753083718e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 270, 'n_units_Layer_3': 145}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.63 | sMAPE for Validation Set is: 28.15% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.52 | sMAPE for Test Set is: 55.77% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:20:51,917]\u001b[0m Trial 1256 finished with value: 23.676998516623097 and parameters: {'n_hidden': 4, 'learning_rate': 0.002498478977332489, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08810096528295669, 'dropout_rate_Layer_2': 0.17221668927742276, 'dropout_rate_Layer_3': 0.3409118843966144, 'dropout_rate_Layer_4': 0.272435654418928, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004095846439084922, 'l1_Layer_2': 0.020168349966377216, 'l1_Layer_3': 1.9748991858470967e-05, 'l1_Layer_4': 0.0031134583148735625, 'n_units_Layer_1': 130, 'n_units_Layer_2': 140, 'n_units_Layer_3': 155, 'n_units_Layer_4': 240}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.68 | sMAPE for Validation Set is: 31.85% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 62.55 | sMAPE for Test Set is: 59.28% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:21:01,637]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:05,804]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:06,438]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:10,600]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:14,809]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:37,821]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:23:33,843]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:23:42,181]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:39,441]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:48,359]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:28,262]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:23,764]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:16,980]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:32,815]\u001b[0m Trial 1270 finished with value: 21.866689906287906 and parameters: {'n_hidden': 3, 'learning_rate': 0.002545263497011705, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3426462309511349, 'dropout_rate_Layer_2': 0.1989994925174378, 'dropout_rate_Layer_3': 0.33868168535253107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.680679363661721e-05, 'l1_Layer_2': 0.0005265798889550965, 'l1_Layer_3': 0.0016669469004320981, 'n_units_Layer_1': 210, 'n_units_Layer_2': 230, 'n_units_Layer_3': 110}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.87 | sMAPE for Validation Set is: 29.61% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 59.87 | sMAPE for Test Set is: 57.04% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:29:28,120]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:29:36,643]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:29:40,946]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:31:16,260]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:31:20,883]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:31:25,098]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:32:20,793]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:07,646]\u001b[0m Trial 1278 finished with value: 20.65469004193276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005998804127895347, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1352307551030265, 'dropout_rate_Layer_2': 0.14061758295753227, 'dropout_rate_Layer_3': 0.0452838387223547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.640942261731435e-05, 'l1_Layer_2': 0.0022999260317937203, 'l1_Layer_3': 5.630795715390026e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 260, 'n_units_Layer_3': 140}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.65 | sMAPE for Validation Set is: 28.17% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.37 | sMAPE for Test Set is: 55.66% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:33:12,828]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:34:01,079]\u001b[0m Trial 1280 finished with value: 20.676479085328637 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005891488782998444, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13302435304067278, 'dropout_rate_Layer_2': 0.14187843362434366, 'dropout_rate_Layer_3': 0.04695304076802122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.958483295965955e-05, 'l1_Layer_2': 0.0013835598750525976, 'l1_Layer_3': 5.127778743598597e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.68 | sMAPE for Validation Set is: 28.06% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.41 | sMAPE for Test Set is: 55.71% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:34:06,152]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:34:14,996]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:34:20,310]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:35:11,480]\u001b[0m Trial 1284 finished with value: 20.78274967661783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005891601091148907, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13775242248763664, 'dropout_rate_Layer_2': 0.1431209966610174, 'dropout_rate_Layer_3': 0.04105579544298783, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.5951554476579256e-05, 'l1_Layer_2': 0.001450643234923637, 'l1_Layer_3': 5.070626978616801e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 260, 'n_units_Layer_3': 140}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.78 | sMAPE for Validation Set is: 28.33% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.00 | sMAPE for Test Set is: 56.32% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:35:15,777]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:35:51,950]\u001b[0m Trial 1286 finished with value: 21.6965757208885 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027005126458283075, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14245425597077158, 'dropout_rate_Layer_2': 0.10730640742071054, 'dropout_rate_Layer_3': 0.09482677706669813, 'dropout_rate_Layer_4': 0.22769051197133144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012745281742967411, 'l1_Layer_2': 0.0001731697365075271, 'l1_Layer_3': 1.184724897595995e-05, 'l1_Layer_4': 0.0025787539760094426, 'n_units_Layer_1': 110, 'n_units_Layer_2': 170, 'n_units_Layer_3': 170, 'n_units_Layer_4': 150}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.70 | sMAPE for Validation Set is: 29.19% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 62.10 | sMAPE for Test Set is: 58.41% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:36:36,920]\u001b[0m Trial 1287 finished with value: 20.81893259000401 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005811383588964953, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13228357832865306, 'dropout_rate_Layer_2': 0.14149016823865518, 'dropout_rate_Layer_3': 0.047645211480408164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.704555048033252e-05, 'l1_Layer_2': 0.0014280664799106032, 'l1_Layer_3': 5.21979701664916e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.82 | sMAPE for Validation Set is: 28.37% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.48 | sMAPE for Test Set is: 55.96% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:37:50,331]\u001b[0m Trial 1288 finished with value: 20.613053562655576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005840108452734055, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13136535147400177, 'dropout_rate_Layer_2': 0.14538809540793418, 'dropout_rate_Layer_3': 0.04354379923633372, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.8784669513797034e-05, 'l1_Layer_2': 0.00131187850606517, 'l1_Layer_3': 5.122574390749266e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.61 | sMAPE for Validation Set is: 28.13% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.62 | sMAPE for Test Set is: 55.84% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:38:40,151]\u001b[0m Trial 1289 finished with value: 20.572099220265446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006143028168444042, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13455169340524814, 'dropout_rate_Layer_2': 0.14187333099783328, 'dropout_rate_Layer_3': 0.04231508019728109, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6091804360235334e-05, 'l1_Layer_2': 0.0014122664934824545, 'l1_Layer_3': 4.956362580153735e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.57 | sMAPE for Validation Set is: 28.10% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.71 | sMAPE for Test Set is: 55.94% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:38:49,034]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:39:08,475]\u001b[0m Trial 1291 finished with value: 21.254974542605087 and parameters: {'n_hidden': 3, 'learning_rate': 0.002269681649993068, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3174635285403744, 'dropout_rate_Layer_2': 0.12131629303738062, 'dropout_rate_Layer_3': 0.3023623088624648, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.7718190484392013e-05, 'l1_Layer_2': 0.0012805168191462391, 'l1_Layer_3': 0.002276410607441167, 'n_units_Layer_1': 245, 'n_units_Layer_2': 265, 'n_units_Layer_3': 80}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.25 | sMAPE for Validation Set is: 29.05% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.56 | sMAPE for Test Set is: 56.15% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:40:05,709]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:40:10,365]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:41:05,188]\u001b[0m Trial 1294 finished with value: 20.8529803893686 and parameters: {'n_hidden': 3, 'learning_rate': 0.000648494083754901, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1358215446316178, 'dropout_rate_Layer_2': 0.15048763774715834, 'dropout_rate_Layer_3': 0.047645637340994924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.509891618135013e-05, 'l1_Layer_2': 0.0016192090097189866, 'l1_Layer_3': 4.228691492326823e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.85 | sMAPE for Validation Set is: 28.36% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.13 | sMAPE for Test Set is: 56.15% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:41:37,976]\u001b[0m Trial 1295 finished with value: 22.319402432896794 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018166419000720717, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09286162065825912, 'dropout_rate_Layer_2': 0.12596843113801107, 'dropout_rate_Layer_3': 0.04460889225833782, 'dropout_rate_Layer_4': 0.24606329020984796, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007598493008092083, 'l1_Layer_2': 0.0404621066694675, 'l1_Layer_3': 1.0051817386404886e-05, 'l1_Layer_4': 0.002230782086781335, 'n_units_Layer_1': 105, 'n_units_Layer_2': 180, 'n_units_Layer_3': 170, 'n_units_Layer_4': 120}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.32 | sMAPE for Validation Set is: 30.31% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.43 | sMAPE for Test Set is: 58.65% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:42:11,977]\u001b[0m Trial 1296 finished with value: 21.344587274452383 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026066546774999692, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15534776705989267, 'dropout_rate_Layer_2': 0.1301808011557781, 'dropout_rate_Layer_3': 0.09659119308741887, 'dropout_rate_Layer_4': 0.37627359968981555, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008679130149554355, 'l1_Layer_2': 0.0001312872569616176, 'l1_Layer_3': 0.0023559259826131736, 'l1_Layer_4': 0.0017360870702502562, 'n_units_Layer_1': 110, 'n_units_Layer_2': 145, 'n_units_Layer_3': 190, 'n_units_Layer_4': 245}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.34 | sMAPE for Validation Set is: 28.93% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.98 | sMAPE for Test Set is: 57.44% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:42:59,985]\u001b[0m Trial 1297 finished with value: 20.473412679107497 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006499156820839274, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13582236143687137, 'dropout_rate_Layer_2': 0.14279787904900348, 'dropout_rate_Layer_3': 0.046195752917669225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5417842304536175e-05, 'l1_Layer_2': 0.0015479209641810906, 'l1_Layer_3': 4.63858841272804e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.47 | sMAPE for Validation Set is: 27.89% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.29 | sMAPE for Test Set is: 55.32% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:43:09,917]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:43:41,126]\u001b[0m Trial 1299 finished with value: 22.34462505876019 and parameters: {'n_hidden': 4, 'learning_rate': 0.002526883884173794, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.087176414459042, 'dropout_rate_Layer_2': 0.08592939536386009, 'dropout_rate_Layer_3': 0.10150857539430463, 'dropout_rate_Layer_4': 0.3807120627868946, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008734963766407504, 'l1_Layer_2': 0.06717270894327515, 'l1_Layer_3': 0.0018536232300679965, 'l1_Layer_4': 0.0021472151490526336, 'n_units_Layer_1': 100, 'n_units_Layer_2': 90, 'n_units_Layer_3': 190, 'n_units_Layer_4': 230}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.34 | sMAPE for Validation Set is: 30.20% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.51 | sMAPE for Test Set is: 58.57% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:44:30,030]\u001b[0m Trial 1300 finished with value: 21.314643539307948 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020693178760683327, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1128965529668165, 'dropout_rate_Layer_2': 0.10233977825436011, 'dropout_rate_Layer_3': 0.0953534210084047, 'dropout_rate_Layer_4': 0.20225774214276812, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001142818704343255, 'l1_Layer_2': 0.00012017594505627211, 'l1_Layer_3': 0.0021244310734447134, 'l1_Layer_4': 0.001685674506290169, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 190, 'n_units_Layer_4': 140}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.31 | sMAPE for Validation Set is: 28.91% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.66 | sMAPE for Test Set is: 56.64% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:44:35,152]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:43,904]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:48,177]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:52,842]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:45:22,424]\u001b[0m Trial 1305 finished with value: 21.153802758677823 and parameters: {'n_hidden': 3, 'learning_rate': 0.001441493384262689, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30710018593918054, 'dropout_rate_Layer_2': 0.11842377641631514, 'dropout_rate_Layer_3': 0.30027796382625915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00048442735319644594, 'l1_Layer_2': 0.0012966825220139082, 'l1_Layer_3': 0.0019143226887049368, 'n_units_Layer_1': 250, 'n_units_Layer_2': 260, 'n_units_Layer_3': 70}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.15 | sMAPE for Validation Set is: 28.65% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.04 | sMAPE for Test Set is: 55.99% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:45:27,492]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:46:17,431]\u001b[0m Trial 1307 finished with value: 20.616891642124074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006762204228186339, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.134776538403104, 'dropout_rate_Layer_2': 0.14179711185398305, 'dropout_rate_Layer_3': 0.046275463945501576, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3332917079949923e-05, 'l1_Layer_2': 0.0016404728776200056, 'l1_Layer_3': 4.3635763279534844e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.62 | sMAPE for Validation Set is: 28.11% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.51 | sMAPE for Test Set is: 55.52% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:47:19,563]\u001b[0m Trial 1308 finished with value: 20.516737529903207 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009204560040759667, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08947213825054207, 'dropout_rate_Layer_2': 0.22244559793799604, 'dropout_rate_Layer_3': 0.06598221709762435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005769897867038623, 'l1_Layer_2': 0.00028559068282659096, 'l1_Layer_3': 4.8563355584426286e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 235, 'n_units_Layer_3': 260}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.52 | sMAPE for Validation Set is: 27.70% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.76 | sMAPE for Test Set is: 55.07% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:48:11,252]\u001b[0m Trial 1309 finished with value: 20.442518243068204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006673342294941248, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13548903484741429, 'dropout_rate_Layer_2': 0.14557114442713462, 'dropout_rate_Layer_3': 0.046080949919927956, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6669727158160716e-05, 'l1_Layer_2': 0.0015706442988656423, 'l1_Layer_3': 4.265183871075468e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.44 | sMAPE for Validation Set is: 27.87% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.26 | sMAPE for Test Set is: 55.35% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:48:15,922]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:48:20,091]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:48:24,396]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:48:33,197]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:49:08,126]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:49:13,618]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:49:48,389]\u001b[0m Trial 1316 finished with value: 21.510288672575957 and parameters: {'n_hidden': 4, 'learning_rate': 0.002231968650851352, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1379904412395949, 'dropout_rate_Layer_2': 0.14813995355480725, 'dropout_rate_Layer_3': 0.06730628950378453, 'dropout_rate_Layer_4': 0.219745751855173, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0016669152603512127, 'l1_Layer_2': 0.00013482748152753954, 'l1_Layer_3': 1.1762398414578903e-05, 'l1_Layer_4': 4.72029749301386e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 190, 'n_units_Layer_4': 125}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.51 | sMAPE for Validation Set is: 29.02% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.49 | sMAPE for Test Set is: 57.21% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:50:40,190]\u001b[0m Trial 1317 finished with value: 20.694436812549554 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007053896114442173, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12216003806062861, 'dropout_rate_Layer_2': 0.14112586300080965, 'dropout_rate_Layer_3': 0.050555121602553495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1965008825437e-05, 'l1_Layer_2': 0.0019184573563552259, 'l1_Layer_3': 3.6950293488558675e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.69 | sMAPE for Validation Set is: 28.16% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.63 | sMAPE for Test Set is: 55.98% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:51:11,277]\u001b[0m Trial 1318 finished with value: 23.232158560857204 and parameters: {'n_hidden': 4, 'learning_rate': 0.002227532663370141, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15245854964004876, 'dropout_rate_Layer_2': 0.11264232336004572, 'dropout_rate_Layer_3': 0.15122012107844388, 'dropout_rate_Layer_4': 0.2097190391774334, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0022156500878734897, 'l1_Layer_2': 8.593320580436408e-05, 'l1_Layer_3': 6.0499017306454614e-05, 'l1_Layer_4': 0.07184330733856033, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 200, 'n_units_Layer_4': 130}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.23 | sMAPE for Validation Set is: 31.58% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 61.42 | sMAPE for Test Set is: 59.08% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:51:32,237]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:17,427]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:34,166]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:53:13,954]\u001b[0m Trial 1322 finished with value: 20.731169832667383 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006862192539398529, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12201027284037803, 'dropout_rate_Layer_2': 0.14371392087549797, 'dropout_rate_Layer_3': 0.05744443402650488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.780958456844399e-05, 'l1_Layer_2': 0.002463607477363573, 'l1_Layer_3': 5.174121779646041e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 270, 'n_units_Layer_3': 140}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.73 | sMAPE for Validation Set is: 28.20% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.89 | sMAPE for Test Set is: 55.93% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:53:56,332]\u001b[0m Trial 1323 finished with value: 21.328028040629516 and parameters: {'n_hidden': 4, 'learning_rate': 0.002015933677116923, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12796858708900474, 'dropout_rate_Layer_2': 0.11959846385488437, 'dropout_rate_Layer_3': 0.10508493617893563, 'dropout_rate_Layer_4': 0.0020465113224164, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00177539201711045, 'l1_Layer_2': 0.0001552977616279713, 'l1_Layer_3': 0.002825127614312948, 'l1_Layer_4': 7.289818000996357e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 190, 'n_units_Layer_4': 115}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.33 | sMAPE for Validation Set is: 28.80% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.47 | sMAPE for Test Set is: 57.19% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:54:12,103]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:16,348]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:21,771]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:45,290]\u001b[0m Trial 1327 finished with value: 22.351584386596908 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020599629999520194, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1298437847794005, 'dropout_rate_Layer_2': 0.12102560173378238, 'dropout_rate_Layer_3': 0.07547015999026603, 'dropout_rate_Layer_4': 0.2131419945468464, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0017348106311216496, 'l1_Layer_2': 0.00015922006604774053, 'l1_Layer_3': 2.1061074602522118e-05, 'l1_Layer_4': 0.0013458315369988337, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 190, 'n_units_Layer_4': 110}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.35 | sMAPE for Validation Set is: 30.27% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.39 | sMAPE for Test Set is: 58.37% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:55:22,040]\u001b[0m Trial 1328 finished with value: 20.915381830549993 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021484272758412804, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11897825329784002, 'dropout_rate_Layer_2': 0.13077974611505253, 'dropout_rate_Layer_3': 0.09706072571201453, 'dropout_rate_Layer_4': 0.0656205335162687, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012557101326099254, 'l1_Layer_2': 8.772418015755804e-05, 'l1_Layer_3': 0.0024632006007820548, 'l1_Layer_4': 6.096615321830551e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205, 'n_units_Layer_4': 125}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.92 | sMAPE for Validation Set is: 28.40% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.55 | sMAPE for Test Set is: 56.76% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:56:00,139]\u001b[0m Trial 1329 finished with value: 21.426837136186037 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017708620134087982, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12785323120771983, 'dropout_rate_Layer_2': 0.13374766468901975, 'dropout_rate_Layer_3': 0.09509959414445218, 'dropout_rate_Layer_4': 0.09868666809857066, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015978847074283988, 'l1_Layer_2': 8.313264592760954e-05, 'l1_Layer_3': 0.0024263604569774635, 'l1_Layer_4': 7.437795916638143e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 135, 'n_units_Layer_3': 200, 'n_units_Layer_4': 125}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.43 | sMAPE for Validation Set is: 28.95% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.89 | sMAPE for Test Set is: 56.99% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:56:04,792]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:57:09,804]\u001b[0m Trial 1331 finished with value: 21.017881836389474 and parameters: {'n_hidden': 4, 'learning_rate': 0.001661510273231938, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12201769150672243, 'dropout_rate_Layer_2': 0.12861197103422883, 'dropout_rate_Layer_3': 0.10611917322464473, 'dropout_rate_Layer_4': 0.05209936502504574, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0016058550129157516, 'l1_Layer_2': 7.891336669414093e-05, 'l1_Layer_3': 0.0025923521304163193, 'l1_Layer_4': 6.774291326749283e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205, 'n_units_Layer_4': 125}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.02 | sMAPE for Validation Set is: 28.29% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.76 | sMAPE for Test Set is: 56.60% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:57:27,476]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:57:33,799]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:58:09,934]\u001b[0m Trial 1334 finished with value: 21.515556616243703 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018227140382597758, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11787198263235797, 'dropout_rate_Layer_2': 0.13396319470008958, 'dropout_rate_Layer_3': 0.09563725383212597, 'dropout_rate_Layer_4': 0.001404485510597131, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012500618407364059, 'l1_Layer_2': 7.329092685483385e-05, 'l1_Layer_3': 0.002822405259931456, 'l1_Layer_4': 5.995910681231531e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 135, 'n_units_Layer_3': 200, 'n_units_Layer_4': 125}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.52 | sMAPE for Validation Set is: 28.94% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.09 | sMAPE for Test Set is: 57.11% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:58:14,259]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:59:05,858]\u001b[0m Trial 1336 finished with value: 21.23775891888283 and parameters: {'n_hidden': 4, 'learning_rate': 0.001892883945216346, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1355724449032953, 'dropout_rate_Layer_2': 0.12582857994545577, 'dropout_rate_Layer_3': 0.10364683393232473, 'dropout_rate_Layer_4': 0.0699083546326453, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0019391410550989837, 'l1_Layer_2': 7.088495455043648e-05, 'l1_Layer_3': 0.0024090420975937106, 'l1_Layer_4': 5.771376369151097e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 120, 'n_units_Layer_3': 215, 'n_units_Layer_4': 120}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.24 | sMAPE for Validation Set is: 28.65% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 61.01 | sMAPE for Test Set is: 57.83% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:59:15,119]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:40,263]\u001b[0m Trial 1338 finished with value: 20.46508028046157 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007412590730160669, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13642598211091586, 'dropout_rate_Layer_2': 0.1433833975490616, 'dropout_rate_Layer_3': 0.05516995440693079, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0154674174754597e-05, 'l1_Layer_2': 0.0014666153602743096, 'l1_Layer_3': 3.652550204661463e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 255, 'n_units_Layer_3': 150}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.47 | sMAPE for Validation Set is: 27.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.23 | sMAPE for Test Set is: 55.33% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:01:41,153]\u001b[0m Trial 1339 finished with value: 20.45647214020653 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007041237441892907, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1180043406878751, 'dropout_rate_Layer_2': 0.26039744730628245, 'dropout_rate_Layer_3': 0.06720911052261365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0044906962785993135, 'l1_Layer_2': 0.0001479670645271429, 'l1_Layer_3': 6.579974784087981e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 235, 'n_units_Layer_3': 280}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.46 | sMAPE for Validation Set is: 27.59% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.39 | sMAPE for Test Set is: 55.29% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:02:48,867]\u001b[0m Trial 1340 finished with value: 21.010659055976785 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015124458886503814, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13511836533649277, 'dropout_rate_Layer_2': 0.13208638900320677, 'dropout_rate_Layer_3': 0.10232793561796497, 'dropout_rate_Layer_4': 0.001814391385554337, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0018408475224195486, 'l1_Layer_2': 9.54387601132098e-05, 'l1_Layer_3': 0.0023512623856136415, 'l1_Layer_4': 5.0793408898293974e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 115, 'n_units_Layer_3': 215, 'n_units_Layer_4': 125}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.01 | sMAPE for Validation Set is: 28.52% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.97 | sMAPE for Test Set is: 56.63% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:03:05,605]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:03:23,086]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:04:12,353]\u001b[0m Trial 1343 finished with value: 21.070442755094675 and parameters: {'n_hidden': 4, 'learning_rate': 0.001640846378617892, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11881139780311774, 'dropout_rate_Layer_2': 0.11827908905746343, 'dropout_rate_Layer_3': 0.09383306207752601, 'dropout_rate_Layer_4': 0.0031655351309366475, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020186287768470456, 'l1_Layer_2': 8.541735931986553e-05, 'l1_Layer_3': 0.0032557499035808114, 'l1_Layer_4': 5.09058128435764e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 115, 'n_units_Layer_3': 215, 'n_units_Layer_4': 125}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.07 | sMAPE for Validation Set is: 28.49% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.80 | sMAPE for Test Set is: 56.54% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:04:27,948]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:05:03,810]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:05:44,467]\u001b[0m Trial 1346 finished with value: 20.617404243969386 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005655826311306234, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11959183386773069, 'dropout_rate_Layer_2': 0.1400514014681196, 'dropout_rate_Layer_3': 0.03376678963826612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.843013313770079e-05, 'l1_Layer_2': 0.001597464479179429, 'l1_Layer_3': 4.654958357393949e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 140}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.62 | sMAPE for Validation Set is: 28.13% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.81 | sMAPE for Test Set is: 56.02% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:05:50,471]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:05:55,113]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:06:17,531]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:06:56,252]\u001b[0m Trial 1350 finished with value: 20.909782205199345 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015638011588168096, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12360489929446765, 'dropout_rate_Layer_2': 0.13982013853224248, 'dropout_rate_Layer_3': 0.08063054426622535, 'dropout_rate_Layer_4': 0.007757118329823786, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002231375006910147, 'l1_Layer_2': 8.145030685456117e-05, 'l1_Layer_3': 0.002859582852763668, 'l1_Layer_4': 4.262917096122184e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 125, 'n_units_Layer_3': 215, 'n_units_Layer_4': 120}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.91 | sMAPE for Validation Set is: 28.17% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.24 | sMAPE for Test Set is: 56.10% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:08:11,657]\u001b[0m Trial 1351 finished with value: 20.583442056085815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007315823700080913, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09416771757940778, 'dropout_rate_Layer_2': 0.2151688097700573, 'dropout_rate_Layer_3': 0.06610472716512597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004088756944877239, 'l1_Layer_2': 0.00010363084031554871, 'l1_Layer_3': 0.00011058347933812833, 'n_units_Layer_1': 220, 'n_units_Layer_2': 200, 'n_units_Layer_3': 275}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.58 | sMAPE for Validation Set is: 27.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.86 | sMAPE for Test Set is: 55.31% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:08:15,965]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:08:49,746]\u001b[0m Trial 1353 finished with value: 21.03945264740918 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013177244128844176, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11931457755449394, 'dropout_rate_Layer_2': 0.1219045996373931, 'dropout_rate_Layer_3': 0.08960325513314021, 'dropout_rate_Layer_4': 0.018256794731494854, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020315851055531667, 'l1_Layer_2': 6.356605990209124e-05, 'l1_Layer_3': 0.0028849515157100686, 'l1_Layer_4': 5.9250401690809694e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 120, 'n_units_Layer_3': 215, 'n_units_Layer_4': 130}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.04 | sMAPE for Validation Set is: 28.22% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.79 | sMAPE for Test Set is: 56.50% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:09:30,985]\u001b[0m Trial 1354 finished with value: 21.23265604075995 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013022010937541332, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11914681821865342, 'dropout_rate_Layer_2': 0.11813026568283197, 'dropout_rate_Layer_3': 0.09749312827068793, 'dropout_rate_Layer_4': 0.0031924543639078326, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020751671457202346, 'l1_Layer_2': 6.652647155349321e-05, 'l1_Layer_3': 0.002864941759585564, 'l1_Layer_4': 5.9115780475272714e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 115, 'n_units_Layer_3': 205, 'n_units_Layer_4': 130}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.23 | sMAPE for Validation Set is: 28.39% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 60.18 | sMAPE for Test Set is: 56.93% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:09:37,263]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:10:17,398]\u001b[0m Trial 1356 finished with value: 20.883639166080975 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013664153856087445, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1288585835973166, 'dropout_rate_Layer_2': 0.1210221846040885, 'dropout_rate_Layer_3': 0.09199432309900563, 'dropout_rate_Layer_4': 0.010511719875556992, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0021154810208828105, 'l1_Layer_2': 6.408865518774377e-05, 'l1_Layer_3': 0.003390249217800794, 'l1_Layer_4': 5.37034305746646e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215, 'n_units_Layer_4': 115}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.88 | sMAPE for Validation Set is: 28.07% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.04 | sMAPE for Test Set is: 56.11% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:10:40,458]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:10:58,469]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:07,242]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:59,115]\u001b[0m Trial 1360 finished with value: 20.804675095536414 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005861122573368389, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12526284227064574, 'dropout_rate_Layer_2': 0.14626589415909644, 'dropout_rate_Layer_3': 0.04048472002723079, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.069381237716817e-05, 'l1_Layer_2': 0.00122287922495347, 'l1_Layer_3': 6.826111968296551e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.80 | sMAPE for Validation Set is: 28.37% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.96 | sMAPE for Test Set is: 56.07% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:13:16,220]\u001b[0m Trial 1361 finished with value: 20.63742745713815 and parameters: {'n_hidden': 3, 'learning_rate': 0.000832674351452851, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10264249687035931, 'dropout_rate_Layer_2': 0.22343767913949386, 'dropout_rate_Layer_3': 0.06502963527466352, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029072551715381006, 'l1_Layer_2': 9.743615101150383e-05, 'l1_Layer_3': 8.9532585528315e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 190, 'n_units_Layer_3': 275}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.64 | sMAPE for Validation Set is: 27.84% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.28 | sMAPE for Test Set is: 55.65% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:13:21,804]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:09,989]\u001b[0m Trial 1363 finished with value: 20.722265770242203 and parameters: {'n_hidden': 3, 'learning_rate': 0.000574017325339123, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11920939727730279, 'dropout_rate_Layer_2': 0.14878686779413028, 'dropout_rate_Layer_3': 0.04072528084586829, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9480545218163392e-05, 'l1_Layer_2': 0.001308095221027387, 'l1_Layer_3': 6.879628102499396e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.72 | sMAPE for Validation Set is: 28.16% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.41 | sMAPE for Test Set is: 55.73% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:14:24,247]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:34,249]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:38,529]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:44,425]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:48,762]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:14:59,477]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:30,188]\u001b[0m Trial 1370 finished with value: 21.184234110492124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019071759940246643, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3267638260722233, 'dropout_rate_Layer_2': 0.11469270581567553, 'dropout_rate_Layer_3': 0.2811633123973641, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.218959483396631e-05, 'l1_Layer_2': 0.0006857383829828911, 'l1_Layer_3': 0.0018753808628161224, 'n_units_Layer_1': 240, 'n_units_Layer_2': 260, 'n_units_Layer_3': 80}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.18 | sMAPE for Validation Set is: 28.80% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.03 | sMAPE for Test Set is: 56.16% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:15:45,122]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:16:33,416]\u001b[0m Trial 1372 finished with value: 21.106983543756787 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014402942449317114, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12836003073485858, 'dropout_rate_Layer_2': 0.12640154039363524, 'dropout_rate_Layer_3': 0.10759015880313014, 'dropout_rate_Layer_4': 0.01238260128839676, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0016593281611261682, 'l1_Layer_2': 6.696414521396781e-05, 'l1_Layer_3': 0.0024995119903030347, 'l1_Layer_4': 9.143321220204365e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 125, 'n_units_Layer_3': 205, 'n_units_Layer_4': 135}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.11 | sMAPE for Validation Set is: 28.73% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.69 | sMAPE for Test Set is: 57.11% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:17:09,279]\u001b[0m Trial 1373 finished with value: 21.463509846419594 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013677857028423508, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12930691529716778, 'dropout_rate_Layer_2': 0.11582990839440677, 'dropout_rate_Layer_3': 0.10762672993378132, 'dropout_rate_Layer_4': 0.014145334857161148, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0017027881296860184, 'l1_Layer_2': 6.98725069540491e-05, 'l1_Layer_3': 0.0025119027941829077, 'l1_Layer_4': 0.00010075565301643305, 'n_units_Layer_1': 145, 'n_units_Layer_2': 105, 'n_units_Layer_3': 205, 'n_units_Layer_4': 135}. Best is trial 1141 with value: 20.375540080517254.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.46 | sMAPE for Validation Set is: 28.92% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.49 | sMAPE for Test Set is: 57.25% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:19:38,453]\u001b[0m Trial 1374 finished with value: 20.292632773287142 and parameters: {'n_hidden': 3, 'learning_rate': 0.000599290148009351, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10502165358836486, 'dropout_rate_Layer_2': 0.23414835416613208, 'dropout_rate_Layer_3': 0.0676288285787463, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0028231948466624734, 'l1_Layer_2': 0.00010106403818409982, 'l1_Layer_3': 8.383533941503347e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 190, 'n_units_Layer_3': 275}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.29 | sMAPE for Validation Set is: 27.35% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.32 | sMAPE for Test Set is: 55.78% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:19:44,112]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:21:20,462]\u001b[0m Trial 1376 finished with value: 20.591409106183544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005465217546515652, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09928481949639416, 'dropout_rate_Layer_2': 0.22138185102353605, 'dropout_rate_Layer_3': 0.06341325854700545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034570654003787276, 'l1_Layer_2': 9.494811631061805e-05, 'l1_Layer_3': 0.00014048158872809397, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 270}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.59 | sMAPE for Validation Set is: 27.95% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.89 | sMAPE for Test Set is: 55.41% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:21:25,799]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:23:51,131]\u001b[0m Trial 1378 finished with value: 20.549310646371804 and parameters: {'n_hidden': 3, 'learning_rate': 0.00055309084599425, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10826833180955744, 'dropout_rate_Layer_2': 0.22050821953834504, 'dropout_rate_Layer_3': 0.06330373946801592, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034120577067757924, 'l1_Layer_2': 0.00011174356757179783, 'l1_Layer_3': 0.00014229832248842283, 'n_units_Layer_1': 220, 'n_units_Layer_2': 185, 'n_units_Layer_3': 265}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.55 | sMAPE for Validation Set is: 27.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.22 | sMAPE for Test Set is: 55.86% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:24:09,123]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:24:15,122]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:17,127]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:26:52,285]\u001b[0m Trial 1382 finished with value: 20.70184186072767 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005793555978231838, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11153698883826321, 'dropout_rate_Layer_2': 0.23031728670946278, 'dropout_rate_Layer_3': 0.07000097227276542, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003977138931053394, 'l1_Layer_2': 7.610853822521219e-05, 'l1_Layer_3': 0.00014245728152871055, 'n_units_Layer_1': 225, 'n_units_Layer_2': 200, 'n_units_Layer_3': 265}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.70 | sMAPE for Validation Set is: 28.07% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.46 | sMAPE for Test Set is: 55.54% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:27:33,315]\u001b[0m Trial 1383 finished with value: 21.357569248181818 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013792822244843384, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10849231883332719, 'dropout_rate_Layer_2': 0.12691917027409666, 'dropout_rate_Layer_3': 0.11297643099796247, 'dropout_rate_Layer_4': 0.01839875495077191, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002725528483158975, 'l1_Layer_2': 4.5738116004736715e-05, 'l1_Layer_3': 0.004105741644042782, 'l1_Layer_4': 5.4561103498592903e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210, 'n_units_Layer_4': 125}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.36 | sMAPE for Validation Set is: 28.40% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.99 | sMAPE for Test Set is: 56.34% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:27:55,168]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:28:53,715]\u001b[0m Trial 1385 finished with value: 20.989985960088188 and parameters: {'n_hidden': 4, 'learning_rate': 0.001441960469385373, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1102795792985179, 'dropout_rate_Layer_2': 0.12956628326865902, 'dropout_rate_Layer_3': 0.1083813992666485, 'dropout_rate_Layer_4': 0.018216221536255232, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0028245501366560167, 'l1_Layer_2': 4.9760214841579536e-05, 'l1_Layer_3': 0.003444184417287448, 'l1_Layer_4': 5.231691095703639e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210, 'n_units_Layer_4': 125}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.99 | sMAPE for Validation Set is: 28.33% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.34 | sMAPE for Test Set is: 56.14% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:29:35,457]\u001b[0m Trial 1386 finished with value: 21.425921949451197 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013963072365229987, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10932843853893817, 'dropout_rate_Layer_2': 0.13008814378671535, 'dropout_rate_Layer_3': 0.11429703719779755, 'dropout_rate_Layer_4': 0.01941679660748866, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0028597183999211676, 'l1_Layer_2': 4.828194120516198e-05, 'l1_Layer_3': 0.003950632064483117, 'l1_Layer_4': 4.856528603446378e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 105, 'n_units_Layer_3': 210, 'n_units_Layer_4': 125}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.43 | sMAPE for Validation Set is: 28.66% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.51 | sMAPE for Test Set is: 56.67% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:29:57,612]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:30:54,248]\u001b[0m Trial 1388 finished with value: 21.215885971574185 and parameters: {'n_hidden': 4, 'learning_rate': 0.00134685767940008, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10808308458317979, 'dropout_rate_Layer_2': 0.1319346582408977, 'dropout_rate_Layer_3': 0.11202621956185124, 'dropout_rate_Layer_4': 0.019286698383762044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0028904894698767907, 'l1_Layer_2': 4.892639228917724e-05, 'l1_Layer_3': 0.0042894244917887625, 'l1_Layer_4': 5.0901787882728575e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 100, 'n_units_Layer_3': 210, 'n_units_Layer_4': 120}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.22 | sMAPE for Validation Set is: 28.52% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 60.61 | sMAPE for Test Set is: 56.49% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:31:26,668]\u001b[0m Trial 1389 finished with value: 22.15271652149089 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013479044087421484, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11009438520997133, 'dropout_rate_Layer_2': 0.12857992122336193, 'dropout_rate_Layer_3': 0.11158524562623567, 'dropout_rate_Layer_4': 0.02265780407565172, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003507380101402144, 'l1_Layer_2': 4.829197597980722e-05, 'l1_Layer_3': 0.0041743884973770165, 'l1_Layer_4': 5.535897764504188e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 210, 'n_units_Layer_4': 125}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.15 | sMAPE for Validation Set is: 29.51% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.18 | sMAPE for Test Set is: 57.13% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:31:31,467]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:31:49,237]\u001b[0m Trial 1391 finished with value: 20.926565762744936 and parameters: {'n_hidden': 3, 'learning_rate': 0.002003884625943201, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3170001383717732, 'dropout_rate_Layer_2': 0.1148487821403823, 'dropout_rate_Layer_3': 0.30080150365750624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.375767462997837e-05, 'l1_Layer_2': 0.0007202097627314243, 'l1_Layer_3': 0.0019449851785088342, 'n_units_Layer_1': 240, 'n_units_Layer_2': 260, 'n_units_Layer_3': 80}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.93 | sMAPE for Validation Set is: 28.55% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.50 | sMAPE for Test Set is: 56.39% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:33:34,512]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:33:40,780]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:34:15,226]\u001b[0m Trial 1394 finished with value: 21.322903872379822 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014626677180300791, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11717411898488438, 'dropout_rate_Layer_2': 0.14089454404041343, 'dropout_rate_Layer_3': 0.10055507854513478, 'dropout_rate_Layer_4': 0.013192744275416585, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003510688954097106, 'l1_Layer_2': 5.249290924674057e-05, 'l1_Layer_3': 0.004409704068005858, 'l1_Layer_4': 5.892172720899175e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210, 'n_units_Layer_4': 130}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.32 | sMAPE for Validation Set is: 28.56% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.77 | sMAPE for Test Set is: 56.90% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:34:38,406]\u001b[0m Trial 1395 finished with value: 20.938029290336697 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019510030862307773, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32288908153584545, 'dropout_rate_Layer_2': 0.11502005881918763, 'dropout_rate_Layer_3': 0.27459046274816773, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.125575178867768e-05, 'l1_Layer_2': 0.0005929477569405082, 'l1_Layer_3': 0.0017936220535846974, 'n_units_Layer_1': 245, 'n_units_Layer_2': 260, 'n_units_Layer_3': 80}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.94 | sMAPE for Validation Set is: 28.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.81 | sMAPE for Test Set is: 55.96% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:35:30,229]\u001b[0m Trial 1396 finished with value: 21.64928293228371 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011916246689262628, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11909638148137772, 'dropout_rate_Layer_2': 0.13643308245789143, 'dropout_rate_Layer_3': 0.10281901329526878, 'dropout_rate_Layer_4': 0.00029140447576039754, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002805152812014252, 'l1_Layer_2': 5.1558897699074225e-05, 'l1_Layer_3': 0.004809405473382819, 'l1_Layer_4': 7.363130328776861e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210, 'n_units_Layer_4': 130}. Best is trial 1374 with value: 20.292632773287142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.65 | sMAPE for Validation Set is: 28.87% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.51 | sMAPE for Test Set is: 56.68% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:36:06,064]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:28,723]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:55,431]\u001b[0m Trial 1399 finished with value: 20.26036708024017 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006161819534264368, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0776688220824484, 'dropout_rate_Layer_2': 0.21387747019835504, 'dropout_rate_Layer_3': 0.05195308272420091, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024760629006594093, 'l1_Layer_2': 0.00013720430712548516, 'l1_Layer_3': 0.00010969769432273459, 'n_units_Layer_1': 230, 'n_units_Layer_2': 185, 'n_units_Layer_3': 280}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.26 | sMAPE for Validation Set is: 27.72% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.42 | sMAPE for Test Set is: 55.36% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:37:59,860]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:04,717]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:44,411]\u001b[0m Trial 1402 finished with value: 21.484971177939823 and parameters: {'n_hidden': 4, 'learning_rate': 0.001466919287714312, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12012286186890121, 'dropout_rate_Layer_2': 0.1264101312826735, 'dropout_rate_Layer_3': 0.0975725810173366, 'dropout_rate_Layer_4': 0.013219249894037315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002581666954947306, 'l1_Layer_2': 4.5424513059723975e-05, 'l1_Layer_3': 0.003735363297692697, 'l1_Layer_4': 5.019423845512455e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 105, 'n_units_Layer_3': 205, 'n_units_Layer_4': 110}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.48 | sMAPE for Validation Set is: 29.07% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.84 | sMAPE for Test Set is: 56.95% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:39:21,903]\u001b[0m Trial 1403 finished with value: 21.26288890110159 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014570539896439072, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11966128310964827, 'dropout_rate_Layer_2': 0.13950813900385917, 'dropout_rate_Layer_3': 0.11177996414171747, 'dropout_rate_Layer_4': 0.01141858539860132, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0027225883024725017, 'l1_Layer_2': 3.4733333603474504e-05, 'l1_Layer_3': 0.0039064481896089465, 'l1_Layer_4': 4.020176644839126e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200, 'n_units_Layer_4': 110}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.26 | sMAPE for Validation Set is: 28.54% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.66 | sMAPE for Test Set is: 56.64% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:39:55,046]\u001b[0m Trial 1404 finished with value: 20.979985467362283 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018225549504512304, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3229123969732456, 'dropout_rate_Layer_2': 0.1143964676406258, 'dropout_rate_Layer_3': 0.27599878274525663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.103159675521923e-05, 'l1_Layer_2': 0.0006040698328339837, 'l1_Layer_3': 0.0017848291438394943, 'n_units_Layer_1': 240, 'n_units_Layer_2': 260, 'n_units_Layer_3': 80}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.98 | sMAPE for Validation Set is: 28.75% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.85 | sMAPE for Test Set is: 56.13% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:40:51,910]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:42,772]\u001b[0m Trial 1406 finished with value: 21.4142614642607 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014718368729792577, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10803253701970955, 'dropout_rate_Layer_2': 0.1430418191684743, 'dropout_rate_Layer_3': 0.1148320014308976, 'dropout_rate_Layer_4': 0.012915924406897485, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0022110714655546202, 'l1_Layer_2': 3.5959902279566436e-05, 'l1_Layer_3': 0.004005943408330708, 'l1_Layer_4': 3.812661124175661e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 100, 'n_units_Layer_3': 200, 'n_units_Layer_4': 115}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.41 | sMAPE for Validation Set is: 28.94% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.66 | sMAPE for Test Set is: 57.26% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:42:21,100]\u001b[0m Trial 1407 finished with value: 21.32663713372065 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014809833147662822, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10954067486775941, 'dropout_rate_Layer_2': 0.14236811544266562, 'dropout_rate_Layer_3': 0.11650074028365834, 'dropout_rate_Layer_4': 0.0314809474327733, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002251266791337654, 'l1_Layer_2': 4.1810774808935186e-05, 'l1_Layer_3': 0.0038584327274895592, 'l1_Layer_4': 3.69392578464184e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 200, 'n_units_Layer_4': 110}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.33 | sMAPE for Validation Set is: 28.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.99 | sMAPE for Test Set is: 56.74% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:42:42,859]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:51,646]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:43:45,793]\u001b[0m Trial 1410 finished with value: 21.348723025405832 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014390521955370535, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10662015307145964, 'dropout_rate_Layer_2': 0.14162701702146696, 'dropout_rate_Layer_3': 0.11386188895169641, 'dropout_rate_Layer_4': 0.03257560321836068, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0026358500006751057, 'l1_Layer_2': 3.657235366139664e-05, 'l1_Layer_3': 0.003704823765586486, 'l1_Layer_4': 3.569566703323903e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 205, 'n_units_Layer_4': 95}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.35 | sMAPE for Validation Set is: 28.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 60.20 | sMAPE for Test Set is: 57.55% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:44:28,635]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:44:32,889]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:44:37,101]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:44:54,317]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:45:17,054]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:46:02,939]\u001b[0m Trial 1416 finished with value: 21.509259946708127 and parameters: {'n_hidden': 4, 'learning_rate': 0.001486736332936885, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11693691202798581, 'dropout_rate_Layer_2': 0.1170776687343355, 'dropout_rate_Layer_3': 0.11454564789496795, 'dropout_rate_Layer_4': 0.010844705514968134, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0028420304934070094, 'l1_Layer_2': 3.14943586014549e-05, 'l1_Layer_3': 0.004368724972007444, 'l1_Layer_4': 3.9520179267616276e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 105, 'n_units_Layer_3': 205, 'n_units_Layer_4': 110}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.51 | sMAPE for Validation Set is: 28.98% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.04 | sMAPE for Test Set is: 56.72% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:46:08,502]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:46:55,022]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:47:30,752]\u001b[0m Trial 1419 finished with value: 20.95416131812323 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011625929612955792, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1000005252441371, 'dropout_rate_Layer_2': 0.14369894201423145, 'dropout_rate_Layer_3': 0.12795333501381845, 'dropout_rate_Layer_4': 0.02856021040205292, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003408629034436647, 'l1_Layer_2': 4.319140375019763e-05, 'l1_Layer_3': 0.005253977662241461, 'l1_Layer_4': 4.578993592783878e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 215, 'n_units_Layer_4': 100}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.95 | sMAPE for Validation Set is: 28.17% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.84 | sMAPE for Test Set is: 56.04% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:47:49,147]\u001b[0m Trial 1420 finished with value: 21.005000711829307 and parameters: {'n_hidden': 3, 'learning_rate': 0.001816983954972627, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31565003959251753, 'dropout_rate_Layer_2': 0.11256913128159926, 'dropout_rate_Layer_3': 0.27788726067708025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.895228475754706e-05, 'l1_Layer_2': 0.001033045688544611, 'l1_Layer_3': 0.001868015226502629, 'n_units_Layer_1': 240, 'n_units_Layer_2': 265, 'n_units_Layer_3': 80}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.01 | sMAPE for Validation Set is: 28.62% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.30 | sMAPE for Test Set is: 56.31% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:48:33,018]\u001b[0m Trial 1421 finished with value: 21.63264253664727 and parameters: {'n_hidden': 4, 'learning_rate': 0.00112755216056174, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10013131102808026, 'dropout_rate_Layer_2': 0.1440329163956752, 'dropout_rate_Layer_3': 0.1269086768192447, 'dropout_rate_Layer_4': 0.030269324842804323, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003537825447270628, 'l1_Layer_2': 3.0286625932805066e-05, 'l1_Layer_3': 0.005541353170178636, 'l1_Layer_4': 9.402616984024088e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 85, 'n_units_Layer_3': 215, 'n_units_Layer_4': 90}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.63 | sMAPE for Validation Set is: 29.21% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.93 | sMAPE for Test Set is: 57.04% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:49:11,312]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:19,715]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:25,077]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:30,881]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:50,904]\u001b[0m Trial 1426 finished with value: 21.198935800023808 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017918871578111212, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32358737060348114, 'dropout_rate_Layer_2': 0.1121203433191743, 'dropout_rate_Layer_3': 0.27875846320256364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.655805541226979e-05, 'l1_Layer_2': 0.0017258098530912045, 'l1_Layer_3': 0.0019307262873230256, 'n_units_Layer_1': 245, 'n_units_Layer_2': 260, 'n_units_Layer_3': 60}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.20 | sMAPE for Validation Set is: 28.97% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.40 | sMAPE for Test Set is: 56.40% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:51:04,708]\u001b[0m Trial 1427 finished with value: 20.49846138251228 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006421722198670675, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07221520919286306, 'dropout_rate_Layer_2': 0.21527411422727666, 'dropout_rate_Layer_3': 0.054342407250677675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027460836358796825, 'l1_Layer_2': 0.0001308781515020336, 'l1_Layer_3': 5.657752357708456e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 190, 'n_units_Layer_3': 280}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.50 | sMAPE for Validation Set is: 27.71% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.77 | sMAPE for Test Set is: 56.02% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:51:45,333]\u001b[0m Trial 1428 finished with value: 20.874442020003134 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013031401112739746, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12719265844661662, 'dropout_rate_Layer_2': 0.1063652689901286, 'dropout_rate_Layer_3': 0.11631255318556394, 'dropout_rate_Layer_4': 0.014118458224654473, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0029156370399216454, 'l1_Layer_2': 5.971915932907659e-05, 'l1_Layer_3': 0.0030473084078201013, 'l1_Layer_4': 4.079758762523039e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 110, 'n_units_Layer_3': 225, 'n_units_Layer_4': 120}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.87 | sMAPE for Validation Set is: 28.09% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.08 | sMAPE for Test Set is: 56.08% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:52:07,775]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:52:46,498]\u001b[0m Trial 1430 finished with value: 21.03578049000304 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011868716288380714, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10534714770246893, 'dropout_rate_Layer_2': 0.10385102671881236, 'dropout_rate_Layer_3': 0.13151615826018165, 'dropout_rate_Layer_4': 0.0282208337706601, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0029275127295261922, 'l1_Layer_2': 5.302450853062276e-05, 'l1_Layer_3': 0.0030895944920838457, 'l1_Layer_4': 4.11074156848431e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 235, 'n_units_Layer_4': 115}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.04 | sMAPE for Validation Set is: 28.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.89 | sMAPE for Test Set is: 55.97% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:52:52,381]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:04,081]\u001b[0m Trial 1432 finished with value: 21.231909878803922 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009817873976779364, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10003470498665948, 'dropout_rate_Layer_2': 0.10265039289554802, 'dropout_rate_Layer_3': 0.13508861083189655, 'dropout_rate_Layer_4': 0.026504954652343635, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002947525817085612, 'l1_Layer_2': 5.293106100128967e-05, 'l1_Layer_3': 0.004210199635198455, 'l1_Layer_4': 3.780835323424594e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 230, 'n_units_Layer_4': 120}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.23 | sMAPE for Validation Set is: 28.56% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 60.50 | sMAPE for Test Set is: 56.86% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:54:59,939]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:55:05,053]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:04,393]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:09,183]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:20,875]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:14,567]\u001b[0m Trial 1438 finished with value: 20.813663529861355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005379225251562528, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13416925100650196, 'dropout_rate_Layer_2': 0.1277102431486447, 'dropout_rate_Layer_3': 0.029536841639528213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.535249725713362e-05, 'l1_Layer_2': 0.0013410089519492498, 'l1_Layer_3': 5.745794508733873e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.81 | sMAPE for Validation Set is: 28.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.99 | sMAPE for Test Set is: 56.05% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:57:20,657]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:25,526]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:19,718]\u001b[0m Trial 1441 finished with value: 20.546667077747806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009253688370549747, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14244693727597552, 'dropout_rate_Layer_2': 0.11708396456797568, 'dropout_rate_Layer_3': 0.038418173399223966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.017450262515061e-05, 'l1_Layer_2': 0.0020588417161349114, 'l1_Layer_3': 3.792729689641237e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 250, 'n_units_Layer_3': 150}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.55 | sMAPE for Validation Set is: 27.89% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.06 | sMAPE for Test Set is: 55.25% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:58:41,732]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:46,885]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:59:17,806]\u001b[0m Trial 1444 finished with value: 21.651159133336176 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010176799717799, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12218997427213997, 'dropout_rate_Layer_2': 0.12009559567262845, 'dropout_rate_Layer_3': 0.11650843353598728, 'dropout_rate_Layer_4': 0.030986808892209314, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0037740637133442684, 'l1_Layer_2': 6.336425993570066e-05, 'l1_Layer_3': 0.004237342199629685, 'l1_Layer_4': 3.631047676357858e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 235, 'n_units_Layer_4': 115}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.65 | sMAPE for Validation Set is: 29.07% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.83 | sMAPE for Test Set is: 56.84% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:00:31,902]\u001b[0m Trial 1445 finished with value: 20.993379691353198 and parameters: {'n_hidden': 4, 'learning_rate': 0.001202673331748449, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09440190760233458, 'dropout_rate_Layer_2': 0.10129390571659777, 'dropout_rate_Layer_3': 0.08682524462322165, 'dropout_rate_Layer_4': 0.0238345096414239, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020758136765080147, 'l1_Layer_2': 3.1635160195851984e-05, 'l1_Layer_3': 0.0019528324665133024, 'l1_Layer_4': 4.624934085067785e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 115, 'n_units_Layer_3': 220, 'n_units_Layer_4': 105}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.99 | sMAPE for Validation Set is: 28.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.09 | sMAPE for Test Set is: 56.36% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:00:41,993]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:01:17,238]\u001b[0m Trial 1447 finished with value: 21.38196558079129 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012013373823645472, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08952393988109099, 'dropout_rate_Layer_2': 0.09883041130612982, 'dropout_rate_Layer_3': 0.08024600112235863, 'dropout_rate_Layer_4': 0.021978270389457245, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00439638863625727, 'l1_Layer_2': 2.8223076278630806e-05, 'l1_Layer_3': 0.0019732597671856724, 'l1_Layer_4': 5.360206537704222e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 120, 'n_units_Layer_3': 225, 'n_units_Layer_4': 105}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.38 | sMAPE for Validation Set is: 28.69% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.98 | sMAPE for Test Set is: 56.59% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:02:15,271]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:02:51,339]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:04:22,018]\u001b[0m Trial 1450 finished with value: 21.590348576746564 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006241403727422052, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08062674947835895, 'dropout_rate_Layer_2': 0.20129728781925432, 'dropout_rate_Layer_3': 0.053076650485272873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021308148122337963, 'l1_Layer_2': 0.00013848318096385098, 'l1_Layer_3': 5.8837723307556244e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 190, 'n_units_Layer_3': 285}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.59 | sMAPE for Validation Set is: 29.21% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.33 | sMAPE for Test Set is: 57.29% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:04:32,160]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:07,984]\u001b[0m Trial 1452 finished with value: 20.492534156438918 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006834649685860806, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06588235068363828, 'dropout_rate_Layer_2': 0.2330014852078794, 'dropout_rate_Layer_3': 0.05269193087432178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022818052206553608, 'l1_Layer_2': 0.0001798567202401687, 'l1_Layer_3': 7.898640434120263e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.49 | sMAPE for Validation Set is: 27.95% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.41 | sMAPE for Test Set is: 55.15% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:07:16,221]\u001b[0m Trial 1453 finished with value: 20.705780447579407 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010368612733263156, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09481309311323581, 'dropout_rate_Layer_2': 0.10271004293988382, 'dropout_rate_Layer_3': 0.08862971632806088, 'dropout_rate_Layer_4': 0.04041080389436452, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002503785180383469, 'l1_Layer_2': 4.343619545909321e-05, 'l1_Layer_3': 0.002177187810766547, 'l1_Layer_4': 4.5676525098553595e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 115, 'n_units_Layer_3': 220, 'n_units_Layer_4': 120}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.71 | sMAPE for Validation Set is: 28.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 59.63 | sMAPE for Test Set is: 56.19% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:07:56,193]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:08:02,399]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:08:07,257]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:08:16,170]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:08:25,129]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:12,532]\u001b[0m Trial 1459 finished with value: 20.762048944201553 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007922910151614215, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12677006504801333, 'dropout_rate_Layer_2': 0.15368244960398827, 'dropout_rate_Layer_3': 0.05724462733953096, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.338096518170723e-05, 'l1_Layer_2': 0.00265020645586928, 'l1_Layer_3': 3.384386882619794e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.76 | sMAPE for Validation Set is: 28.24% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.12 | sMAPE for Test Set is: 55.91% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:09:17,405]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:38,714]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:47,667]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:05,352]\u001b[0m Trial 1463 finished with value: 20.456344448677378 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006858385945844129, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0723571671721093, 'dropout_rate_Layer_2': 0.21680010890396773, 'dropout_rate_Layer_3': 0.056466842117064917, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001995390203776089, 'l1_Layer_2': 0.00011830199728124071, 'l1_Layer_3': 5.0200644397779156e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 165, 'n_units_Layer_3': 280}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.46 | sMAPE for Validation Set is: 27.73% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.31 | sMAPE for Test Set is: 56.38% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:12:26,266]\u001b[0m Trial 1464 finished with value: 20.791773139214076 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008105702306611106, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10134153169021197, 'dropout_rate_Layer_2': 0.11720878938884735, 'dropout_rate_Layer_3': 0.13491121169114037, 'dropout_rate_Layer_4': 0.025509994503153645, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001998303979494843, 'l1_Layer_2': 2.487967724268238e-05, 'l1_Layer_3': 0.002851346160843185, 'l1_Layer_4': 4.665594220834308e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 125, 'n_units_Layer_3': 215, 'n_units_Layer_4': 115}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.79 | sMAPE for Validation Set is: 27.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 60.15 | sMAPE for Test Set is: 56.98% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:12:32,343]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:37,801]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:14:23,713]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:15:15,268]\u001b[0m Trial 1468 finished with value: 20.449958655006032 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006910813023440729, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08767518865480442, 'dropout_rate_Layer_2': 0.23467523354841707, 'dropout_rate_Layer_3': 0.04477503776899481, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016075117308214457, 'l1_Layer_2': 7.337113254045635e-05, 'l1_Layer_3': 6.112829161836477e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 175, 'n_units_Layer_3': 250}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.45 | sMAPE for Validation Set is: 27.84% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.54 | sMAPE for Test Set is: 56.47% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:15:30,768]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:32,176]\u001b[0m Trial 1470 finished with value: 21.13925313563043 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008092218159851792, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14950005970031505, 'dropout_rate_Layer_2': 0.10001024518008021, 'dropout_rate_Layer_3': 0.08934204294105179, 'dropout_rate_Layer_4': 0.007888229884061144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002034525761391681, 'l1_Layer_2': 2.7629388080946765e-05, 'l1_Layer_3': 0.002974176988363065, 'l1_Layer_4': 4.7872360604870114e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 130, 'n_units_Layer_3': 235, 'n_units_Layer_4': 120}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.14 | sMAPE for Validation Set is: 28.49% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.75 | sMAPE for Test Set is: 56.44% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:18:02,565]\u001b[0m Trial 1471 finished with value: 20.82675023313841 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008050871567464572, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09748865046013802, 'dropout_rate_Layer_2': 0.0987883531059616, 'dropout_rate_Layer_3': 0.13744867611269238, 'dropout_rate_Layer_4': 0.0056152976756579775, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0021373131912125246, 'l1_Layer_2': 2.210389714064224e-05, 'l1_Layer_3': 0.002957316256592397, 'l1_Layer_4': 4.7100229039798195e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 130, 'n_units_Layer_3': 235, 'n_units_Layer_4': 120}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.83 | sMAPE for Validation Set is: 28.81% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.27 | sMAPE for Test Set is: 58.41% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:19:03,494]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:20:05,127]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:21:05,260]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:21:29,078]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:21:33,853]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:21:39,984]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:21:48,607]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:23:04,977]\u001b[0m Trial 1479 finished with value: 20.838295020443322 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007106637311808027, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10181445156423895, 'dropout_rate_Layer_2': 0.10947122393045827, 'dropout_rate_Layer_3': 0.0880774843150769, 'dropout_rate_Layer_4': 0.01678059666396315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004857643082539813, 'l1_Layer_2': 2.181438720136997e-05, 'l1_Layer_3': 0.003392143383323323, 'l1_Layer_4': 5.810565208437101e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 115, 'n_units_Layer_3': 220, 'n_units_Layer_4': 135}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.84 | sMAPE for Validation Set is: 27.90% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.96 | sMAPE for Test Set is: 56.08% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:23:11,335]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:24:23,104]\u001b[0m Trial 1481 finished with value: 21.030733389550235 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006825443061727373, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08440180407774933, 'dropout_rate_Layer_2': 0.08340983595933982, 'dropout_rate_Layer_3': 0.08845434257182248, 'dropout_rate_Layer_4': 0.007726710921735179, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005242210786862965, 'l1_Layer_2': 2.3030086265114922e-05, 'l1_Layer_3': 0.0033497914299630742, 'l1_Layer_4': 4.735601623828025e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 115, 'n_units_Layer_3': 245, 'n_units_Layer_4': 135}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.03 | sMAPE for Validation Set is: 28.24% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.75 | sMAPE for Test Set is: 56.29% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:24:27,942]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:25:39,385]\u001b[0m Trial 1483 finished with value: 20.86194310449133 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006517155939323721, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08345677634606138, 'dropout_rate_Layer_2': 0.082749924278466, 'dropout_rate_Layer_3': 0.08212995462817856, 'dropout_rate_Layer_4': 0.00010450736077488262, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004519506991112618, 'l1_Layer_2': 1.8433937530635226e-05, 'l1_Layer_3': 0.0023281537323504953, 'l1_Layer_4': 8.291494354515616e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 225, 'n_units_Layer_4': 140}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.86 | sMAPE for Validation Set is: 28.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.54 | sMAPE for Test Set is: 56.19% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:26:01,244]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:26:06,049]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:26:22,128]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:27:13,914]\u001b[0m Trial 1487 finished with value: 20.53385252394268 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006823169239269893, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12429847997762074, 'dropout_rate_Layer_2': 0.14444775696668108, 'dropout_rate_Layer_3': 0.04505396671027556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.483049133348841e-05, 'l1_Layer_2': 0.001083189773559846, 'l1_Layer_3': 3.233799685102414e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.53 | sMAPE for Validation Set is: 27.92% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.61 | sMAPE for Test Set is: 55.71% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:28:07,522]\u001b[0m Trial 1488 finished with value: 20.714078852362253 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006964428967343128, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1258608782398683, 'dropout_rate_Layer_2': 0.11028864081480204, 'dropout_rate_Layer_3': 0.05803555300245574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.136713136502338e-05, 'l1_Layer_2': 0.0010443943317707304, 'l1_Layer_3': 2.5501435610083207e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 275, 'n_units_Layer_3': 155}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.71 | sMAPE for Validation Set is: 28.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.73 | sMAPE for Test Set is: 56.01% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:28:23,601]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:29:13,525]\u001b[0m Trial 1490 finished with value: 21.403961307643957 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006393812482265802, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07864353015699599, 'dropout_rate_Layer_2': 0.08246874013971167, 'dropout_rate_Layer_3': 0.08750166748002383, 'dropout_rate_Layer_4': 0.00167967076076084, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003139521435717216, 'l1_Layer_2': 2.3521024980652408e-05, 'l1_Layer_3': 0.0018001486740088022, 'l1_Layer_4': 7.539229236704886e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 120, 'n_units_Layer_3': 235, 'n_units_Layer_4': 120}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.40 | sMAPE for Validation Set is: 28.65% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.21 | sMAPE for Test Set is: 56.75% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:31:00,616]\u001b[0m Trial 1491 finished with value: 20.594270574963502 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005786441881740322, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09079326006823049, 'dropout_rate_Layer_2': 0.0929272941173866, 'dropout_rate_Layer_3': 0.07142747471432495, 'dropout_rate_Layer_4': 0.041407761751882766, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006429603486453735, 'l1_Layer_2': 2.161346347484662e-05, 'l1_Layer_3': 0.002904646083352278, 'l1_Layer_4': 5.2336520837065705e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 115, 'n_units_Layer_3': 250, 'n_units_Layer_4': 130}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.59 | sMAPE for Validation Set is: 27.93% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.68 | sMAPE for Test Set is: 56.11% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:32:15,932]\u001b[0m Trial 1492 finished with value: 21.290380665050055 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006852893923144945, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0865949493659467, 'dropout_rate_Layer_2': 0.09457725128420057, 'dropout_rate_Layer_3': 0.07232687310121398, 'dropout_rate_Layer_4': 0.040767478549950796, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005205069995804824, 'l1_Layer_2': 1.4614843503406575e-05, 'l1_Layer_3': 0.0023310728698725616, 'l1_Layer_4': 7.028921243301041e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 115, 'n_units_Layer_3': 250, 'n_units_Layer_4': 135}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.29 | sMAPE for Validation Set is: 28.51% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.82 | sMAPE for Test Set is: 56.67% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:32:20,746]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:33:16,759]\u001b[0m Trial 1494 finished with value: 20.880786249795776 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009691818984825944, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1223656255901589, 'dropout_rate_Layer_2': 0.10935616224310957, 'dropout_rate_Layer_3': 0.0473793718540085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.252645099302208e-05, 'l1_Layer_2': 0.0011250478637023237, 'l1_Layer_3': 3.032896080397844e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 275, 'n_units_Layer_3': 145}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.88 | sMAPE for Validation Set is: 28.33% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.21 | sMAPE for Test Set is: 55.83% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:34:09,812]\u001b[0m Trial 1495 finished with value: 21.540822135893773 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007194847240546569, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08011788298466385, 'dropout_rate_Layer_2': 0.09572680178125961, 'dropout_rate_Layer_3': 0.08465750276905105, 'dropout_rate_Layer_4': 0.038191866310017045, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006111259271084882, 'l1_Layer_2': 2.5162718230517243e-05, 'l1_Layer_3': 0.0032639756835665134, 'l1_Layer_4': 5.104111712261062e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 115, 'n_units_Layer_3': 230, 'n_units_Layer_4': 120}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.54 | sMAPE for Validation Set is: 28.76% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.70 | sMAPE for Test Set is: 56.48% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:34:14,530]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:29,309]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:25,771]\u001b[0m Trial 1498 finished with value: 20.394011503641167 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006855764852489935, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06079984005286229, 'dropout_rate_Layer_2': 0.2355677316121468, 'dropout_rate_Layer_3': 0.0444628469937262, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001846772937063482, 'l1_Layer_2': 6.957792458487638e-05, 'l1_Layer_3': 5.950594208024045e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 1399 with value: 20.26036708024017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.39 | sMAPE for Validation Set is: 27.68% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.05 | sMAPE for Test Set is: 55.74% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:35:31,643]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-01-01, MAE is:27.82 & sMAPE is:34.99% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :27.82 & 34.99% & 0.59\n",
      "for 2022-01-02, MAE is:43.80 & sMAPE is:59.77% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :35.81 & 47.38% & 0.51\n",
      "for 2022-01-03, MAE is:16.80 & sMAPE is:27.25% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :29.47 & 40.67% & 0.41\n",
      "for 2022-01-04, MAE is:68.74 & sMAPE is:69.20% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :39.29 & 47.80% & 0.84\n",
      "for 2022-01-05, MAE is:14.46 & sMAPE is:14.67% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :34.32 & 41.17% & 0.73\n",
      "for 2022-01-06, MAE is:67.38 & sMAPE is:42.80% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :39.83 & 41.45% & 0.72\n",
      "for 2022-01-07, MAE is:22.10 & sMAPE is:14.27% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :37.30 & 37.56% & 0.65\n",
      "for 2022-01-08, MAE is:24.91 & sMAPE is:19.12% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :35.75 & 35.26% & 0.61\n",
      "for 2022-01-09, MAE is:39.39 & sMAPE is:31.73% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :36.15 & 34.87% & 0.60\n",
      "for 2022-01-10, MAE is:89.74 & sMAPE is:41.83% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :41.51 & 35.56% & 0.59\n",
      "for 2022-01-11, MAE is:37.61 & sMAPE is:17.38% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :41.16 & 33.91% & 0.58\n",
      "for 2022-01-12, MAE is:67.58 & sMAPE is:50.99% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :43.36 & 35.33% & 0.60\n",
      "for 2022-01-13, MAE is:62.27 & sMAPE is:125.56% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :44.81 & 42.27% & 0.59\n",
      "for 2022-01-14, MAE is:22.86 & sMAPE is:44.24% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :43.25 & 42.41% & 0.56\n",
      "for 2022-01-15, MAE is:78.16 & sMAPE is:76.44% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :45.57 & 44.68% & 0.62\n",
      "for 2022-01-16, MAE is:82.34 & sMAPE is:130.87% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :47.87 & 50.07% & 0.63\n",
      "for 2022-01-17, MAE is:34.10 & sMAPE is:56.73% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :47.06 & 50.46% & 0.60\n",
      "for 2022-01-18, MAE is:40.05 & sMAPE is:31.07% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :46.67 & 49.38% & 0.60\n",
      "for 2022-01-19, MAE is:51.27 & sMAPE is:98.16% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :46.91 & 51.95% & 0.59\n",
      "for 2022-01-20, MAE is:44.29 & sMAPE is:76.34% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :46.78 & 53.17% & 0.60\n",
      "for 2022-01-21, MAE is:45.72 & sMAPE is:53.51% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :46.73 & 53.19% & 0.61\n",
      "for 2022-01-22, MAE is:51.61 & sMAPE is:40.46% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :46.95 & 52.61% & 0.64\n",
      "for 2022-01-23, MAE is:17.10 & sMAPE is:19.07% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :45.66 & 51.15% & 0.62\n",
      "for 2022-01-24, MAE is:35.05 & sMAPE is:71.23% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :45.21 & 51.99% & 0.64\n",
      "for 2022-01-25, MAE is:91.63 & sMAPE is:76.54% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :47.07 & 52.97% & 0.67\n",
      "for 2022-01-26, MAE is:40.52 & sMAPE is:44.36% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :46.82 & 52.64% & 0.67\n",
      "for 2022-01-27, MAE is:36.32 & sMAPE is:73.14% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :46.43 & 53.40% & 0.68\n",
      "for 2022-01-28, MAE is:55.31 & sMAPE is:60.47% & rMAE is:5.24 ||| daily mean of MAE & sMAPE & rMAE till now are :46.75 & 53.65% & 0.84\n",
      "for 2022-01-29, MAE is:79.32 & sMAPE is:135.63% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :47.87 & 56.48% & 0.83\n",
      "for 2022-01-30, MAE is:24.80 & sMAPE is:112.67% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :47.10 & 58.35% & 0.81\n",
      "for 2022-01-31, MAE is:107.31 & sMAPE is:85.77% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :49.04 & 59.23% & 0.82\n",
      "for 2022-02-01, MAE is:47.08 & sMAPE is:34.70% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :48.98 & 58.47% & 0.81\n",
      "for 2022-02-02, MAE is:65.96 & sMAPE is:56.17% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :49.50 & 58.40% & 0.82\n",
      "for 2022-02-03, MAE is:37.68 & sMAPE is:23.21% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :49.15 & 57.36% & 0.81\n",
      "for 2022-02-04, MAE is:79.11 & sMAPE is:92.19% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :50.01 & 58.36% & 0.82\n",
      "for 2022-02-05, MAE is:20.31 & sMAPE is:70.36% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :49.18 & 58.69% & 0.86\n",
      "for 2022-02-06, MAE is:23.27 & sMAPE is:49.21% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :48.48 & 58.44% & 0.89\n",
      "for 2022-02-07, MAE is:26.89 & sMAPE is:43.44% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :47.91 & 58.04% & 0.88\n",
      "for 2022-02-08, MAE is:60.57 & sMAPE is:105.51% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :48.24 & 59.26% & 0.87\n",
      "for 2022-02-09, MAE is:32.28 & sMAPE is:65.14% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :47.84 & 59.41% & 0.86\n",
      "for 2022-02-10, MAE is:20.27 & sMAPE is:39.94% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :47.17 & 58.93% & 0.84\n",
      "for 2022-02-11, MAE is:56.87 & sMAPE is:67.75% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :47.40 & 59.14% & 0.85\n",
      "for 2022-02-12, MAE is:30.57 & sMAPE is:75.68% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :47.00 & 59.52% & 0.88\n",
      "for 2022-02-13, MAE is:16.88 & sMAPE is:68.55% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :46.32 & 59.73% & 0.88\n",
      "for 2022-02-14, MAE is:41.48 & sMAPE is:73.36% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :46.21 & 60.03% & 0.89\n",
      "for 2022-02-15, MAE is:24.36 & sMAPE is:48.48% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :45.74 & 59.78% & 0.89\n",
      "for 2022-02-16, MAE is:29.99 & sMAPE is:43.04% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :45.40 & 59.43% & 0.89\n",
      "for 2022-02-17, MAE is:19.25 & sMAPE is:33.53% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :44.86 & 58.89% & 0.90\n",
      "for 2022-02-18, MAE is:23.91 & sMAPE is:36.66% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :44.43 & 58.43% & 0.89\n",
      "for 2022-02-19, MAE is:41.99 & sMAPE is:90.81% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :44.38 & 59.08% & 0.91\n",
      "for 2022-02-20, MAE is:28.84 & sMAPE is:55.06% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :44.08 & 59.00% & 0.91\n",
      "for 2022-02-21, MAE is:28.19 & sMAPE is:50.15% & rMAE is:4.11 ||| daily mean of MAE & sMAPE & rMAE till now are :43.77 & 58.83% & 0.97\n",
      "for 2022-02-22, MAE is:63.51 & sMAPE is:90.63% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :44.14 & 59.43% & 0.98\n",
      "for 2022-02-23, MAE is:28.22 & sMAPE is:36.93% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :43.85 & 59.01% & 0.98\n",
      "for 2022-02-24, MAE is:27.81 & sMAPE is:54.18% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :43.56 & 58.93% & 0.98\n",
      "for 2022-02-25, MAE is:24.97 & sMAPE is:36.58% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :43.22 & 58.53% & 0.99\n",
      "for 2022-02-26, MAE is:62.12 & sMAPE is:63.95% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :43.56 & 58.62% & 0.98\n",
      "for 2022-02-27, MAE is:16.68 & sMAPE is:14.66% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :43.09 & 57.86% & 0.97\n",
      "for 2022-02-28, MAE is:49.90 & sMAPE is:31.70% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :43.21 & 57.42% & 0.96\n",
      "for 2022-03-01, MAE is:45.30 & sMAPE is:51.28% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :43.24 & 57.32% & 0.97\n",
      "for 2022-03-02, MAE is:95.10 & sMAPE is:53.45% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :44.09 & 57.26% & 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-03, MAE is:52.64 & sMAPE is:26.07% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :44.23 & 56.75% & 0.96\n",
      "for 2022-03-04, MAE is:80.51 & sMAPE is:37.79% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :44.81 & 56.45% & 0.95\n",
      "for 2022-03-05, MAE is:77.55 & sMAPE is:44.52% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :45.32 & 56.27% & 0.95\n",
      "for 2022-03-06, MAE is:53.13 & sMAPE is:50.23% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :45.44 & 56.17% & 0.96\n",
      "for 2022-03-07, MAE is:123.28 & sMAPE is:69.64% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :46.62 & 56.38% & 0.97\n",
      "for 2022-03-08, MAE is:124.02 & sMAPE is:52.27% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :47.77 & 56.32% & 0.97\n",
      "for 2022-03-09, MAE is:61.91 & sMAPE is:22.29% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :47.98 & 55.81% & 0.97\n",
      "for 2022-03-10, MAE is:85.70 & sMAPE is:64.46% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :48.53 & 55.94% & 0.98\n",
      "for 2022-03-11, MAE is:63.65 & sMAPE is:80.27% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :48.74 & 56.29% & 0.97\n",
      "for 2022-03-12, MAE is:36.09 & sMAPE is:40.07% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :48.57 & 56.06% & 0.96\n",
      "for 2022-03-13, MAE is:32.16 & sMAPE is:51.08% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :48.34 & 55.99% & 0.96\n",
      "for 2022-03-14, MAE is:81.81 & sMAPE is:58.75% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :48.80 & 56.03% & 0.96\n",
      "for 2022-03-15, MAE is:96.29 & sMAPE is:43.92% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :49.44 & 55.86% & 0.96\n",
      "for 2022-03-16, MAE is:59.32 & sMAPE is:28.28% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :49.57 & 55.50% & 0.97\n",
      "for 2022-03-17, MAE is:81.64 & sMAPE is:92.71% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :49.99 & 55.99% & 0.97\n",
      "for 2022-03-18, MAE is:62.07 & sMAPE is:80.13% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :50.15 & 56.30% & 0.97\n",
      "for 2022-03-19, MAE is:81.08 & sMAPE is:112.01% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :50.55 & 57.01% & 0.98\n",
      "for 2022-03-20, MAE is:24.84 & sMAPE is:63.42% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :50.22 & 57.09% & 0.98\n",
      "for 2022-03-21, MAE is:67.58 & sMAPE is:71.91% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :50.44 & 57.28% & 0.98\n",
      "for 2022-03-22, MAE is:96.25 & sMAPE is:65.21% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :51.00 & 57.38% & 0.99\n",
      "for 2022-03-23, MAE is:50.69 & sMAPE is:28.37% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :51.00 & 57.02% & 0.99\n",
      "for 2022-03-24, MAE is:62.31 & sMAPE is:39.82% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :51.13 & 56.82% & 0.99\n",
      "for 2022-03-25, MAE is:77.86 & sMAPE is:116.60% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :51.45 & 57.53% & 1.01\n",
      "for 2022-03-26, MAE is:29.99 & sMAPE is:117.38% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :51.20 & 58.23% & 1.00\n",
      "for 2022-03-27, MAE is:32.34 & sMAPE is:65.31% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :50.98 & 58.32% & 1.00\n",
      "for 2022-03-28, MAE is:18.59 & sMAPE is:72.13% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :50.61 & 58.47% & 0.99\n",
      "for 2022-03-29, MAE is:124.46 & sMAPE is:100.96% & rMAE is:4.08 ||| daily mean of MAE & sMAPE & rMAE till now are :51.45 & 58.96% & 1.02\n",
      "for 2022-03-30, MAE is:37.24 & sMAPE is:18.93% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :51.29 & 58.51% & 1.03\n",
      "for 2022-03-31, MAE is:29.44 & sMAPE is:14.88% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :51.05 & 58.02% & 1.02\n",
      "for 2022-04-01, MAE is:28.32 & sMAPE is:18.90% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :50.80 & 57.59% & 1.01\n",
      "for 2022-04-02, MAE is:20.98 & sMAPE is:20.28% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :50.47 & 57.19% & 1.00\n",
      "for 2022-04-03, MAE is:25.68 & sMAPE is:31.57% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :50.21 & 56.91% & 1.00\n",
      "for 2022-04-04, MAE is:16.21 & sMAPE is:24.02% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :49.84 & 56.56% & 0.99\n",
      "for 2022-04-05, MAE is:39.33 & sMAPE is:60.58% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :49.73 & 56.60% & 0.99\n",
      "for 2022-04-06, MAE is:44.04 & sMAPE is:47.48% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :49.67 & 56.51% & 0.98\n",
      "for 2022-04-07, MAE is:22.33 & sMAPE is:27.05% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :49.39 & 56.21% & 0.97\n",
      "for 2022-04-08, MAE is:31.46 & sMAPE is:75.36% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :49.21 & 56.40% & 0.97\n",
      "for 2022-04-09, MAE is:15.90 & sMAPE is:43.65% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :48.87 & 56.27% & 0.96\n",
      "for 2022-04-10, MAE is:7.12 & sMAPE is:40.13% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :48.45 & 56.11% & 0.95\n",
      "for 2022-04-11, MAE is:112.01 & sMAPE is:111.18% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :49.08 & 56.66% & 0.95\n",
      "for 2022-04-12, MAE is:47.46 & sMAPE is:34.51% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :49.07 & 56.44% & 0.95\n",
      "for 2022-04-13, MAE is:31.33 & sMAPE is:28.10% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :48.90 & 56.16% & 0.95\n",
      "for 2022-04-14, MAE is:51.41 & sMAPE is:49.50% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :48.92 & 56.10% & 0.96\n",
      "for 2022-04-15, MAE is:13.05 & sMAPE is:18.26% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :48.58 & 55.74% & 0.95\n",
      "for 2022-04-16, MAE is:13.60 & sMAPE is:25.16% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :48.25 & 55.45% & 0.95\n",
      "for 2022-04-17, MAE is:15.57 & sMAPE is:37.65% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :47.94 & 55.28% & 0.94\n",
      "for 2022-04-18, MAE is:22.24 & sMAPE is:27.23% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :47.71 & 55.02% & 0.94\n",
      "for 2022-04-19, MAE is:80.80 & sMAPE is:62.40% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :48.01 & 55.09% & 0.95\n",
      "for 2022-04-20, MAE is:31.03 & sMAPE is:31.48% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :47.85 & 54.88% & 0.95\n",
      "for 2022-04-21, MAE is:21.50 & sMAPE is:39.75% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :47.62 & 54.74% & 0.95\n",
      "for 2022-04-22, MAE is:23.69 & sMAPE is:39.51% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :47.40 & 54.60% & 0.95\n",
      "for 2022-04-23, MAE is:37.04 & sMAPE is:63.40% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :47.31 & 54.68% & 0.95\n",
      "for 2022-04-24, MAE is:44.48 & sMAPE is:66.18% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :47.29 & 54.78% & 0.95\n",
      "for 2022-04-25, MAE is:112.42 & sMAPE is:77.19% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :47.85 & 54.98% & 0.95\n",
      "for 2022-04-26, MAE is:52.62 & sMAPE is:27.71% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :47.89 & 54.74% & 0.95\n",
      "for 2022-04-27, MAE is:19.82 & sMAPE is:9.42% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :47.65 & 54.36% & 0.94\n",
      "for 2022-04-28, MAE is:44.54 & sMAPE is:21.50% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :47.63 & 54.08% & 0.94\n",
      "for 2022-04-29, MAE is:51.47 & sMAPE is:26.17% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :47.66 & 53.84% & 0.93\n",
      "for 2022-04-30, MAE is:14.16 & sMAPE is:7.52% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :47.38 & 53.46% & 0.92\n",
      "for 2022-05-01, MAE is:47.04 & sMAPE is:31.76% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :47.38 & 53.28% & 0.92\n",
      "for 2022-05-02, MAE is:48.50 & sMAPE is:31.88% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :47.39 & 53.10% & 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-03, MAE is:48.69 & sMAPE is:32.41% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :47.40 & 52.93% & 0.92\n",
      "for 2022-05-04, MAE is:40.82 & sMAPE is:20.72% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :47.34 & 52.67% & 0.93\n",
      "for 2022-05-05, MAE is:29.24 & sMAPE is:14.54% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :47.20 & 52.37% & 0.94\n",
      "for 2022-05-06, MAE is:18.16 & sMAPE is:8.78% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :46.97 & 52.02% & 0.94\n",
      "for 2022-05-07, MAE is:29.79 & sMAPE is:23.90% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :46.83 & 51.80% & 0.94\n",
      "for 2022-05-08, MAE is:28.69 & sMAPE is:22.18% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :46.69 & 51.57% & 0.94\n",
      "for 2022-05-09, MAE is:42.81 & sMAPE is:26.20% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :46.66 & 51.37% & 0.95\n",
      "for 2022-05-10, MAE is:68.76 & sMAPE is:80.53% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :46.83 & 51.60% & 0.95\n",
      "for 2022-05-11, MAE is:38.90 & sMAPE is:61.88% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :46.77 & 51.68% & 0.94\n",
      "for 2022-05-12, MAE is:50.75 & sMAPE is:77.56% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :46.80 & 51.87% & 0.94\n",
      "for 2022-05-13, MAE is:46.10 & sMAPE is:56.91% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :46.80 & 51.91% & 0.93\n",
      "for 2022-05-14, MAE is:38.97 & sMAPE is:127.81% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :46.74 & 52.48% & 0.93\n",
      "for 2022-05-15, MAE is:49.95 & sMAPE is:130.68% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :46.76 & 53.06% & 0.93\n",
      "for 2022-05-16, MAE is:59.27 & sMAPE is:64.76% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :46.85 & 53.14% & 0.93\n",
      "for 2022-05-17, MAE is:61.79 & sMAPE is:36.57% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :46.96 & 53.02% & 0.93\n",
      "for 2022-05-18, MAE is:52.84 & sMAPE is:34.29% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :47.01 & 52.89% & 0.92\n",
      "for 2022-05-19, MAE is:55.53 & sMAPE is:33.53% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :47.07 & 52.75% & 0.92\n",
      "for 2022-05-20, MAE is:34.97 & sMAPE is:24.21% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :46.98 & 52.54% & 0.92\n",
      "for 2022-05-21, MAE is:48.24 & sMAPE is:47.31% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :46.99 & 52.51% & 0.91\n",
      "for 2022-05-22, MAE is:31.34 & sMAPE is:23.13% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :46.88 & 52.30% & 0.91\n",
      "for 2022-05-23, MAE is:31.96 & sMAPE is:19.19% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :46.78 & 52.07% & 0.91\n",
      "for 2022-05-24, MAE is:34.01 & sMAPE is:37.10% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :46.69 & 51.96% & 0.91\n",
      "for 2022-05-25, MAE is:39.25 & sMAPE is:30.05% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :46.64 & 51.81% & 0.91\n",
      "for 2022-05-26, MAE is:85.10 & sMAPE is:131.30% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :46.90 & 52.36% & 0.90\n",
      "for 2022-05-27, MAE is:54.60 & sMAPE is:125.78% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :46.95 & 52.86% & 0.90\n",
      "for 2022-05-28, MAE is:39.82 & sMAPE is:143.19% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :46.90 & 53.47% & 0.90\n",
      "for 2022-05-29, MAE is:61.34 & sMAPE is:53.12% & rMAE is:4.78 ||| daily mean of MAE & sMAPE & rMAE till now are :47.00 & 53.46% & 0.92\n",
      "for 2022-05-30, MAE is:42.00 & sMAPE is:21.55% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :46.97 & 53.25% & 0.92\n",
      "for 2022-05-31, MAE is:46.27 & sMAPE is:43.19% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :46.96 & 53.18% & 0.92\n",
      "for 2022-06-01, MAE is:74.37 & sMAPE is:68.27% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :47.14 & 53.28% & 0.93\n",
      "for 2022-06-02, MAE is:34.24 & sMAPE is:27.37% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :47.06 & 53.11% & 0.92\n",
      "for 2022-06-03, MAE is:81.69 & sMAPE is:79.28% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :47.28 & 53.28% & 0.92\n",
      "for 2022-06-04, MAE is:30.40 & sMAPE is:22.00% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :47.17 & 53.08% & 0.91\n",
      "for 2022-06-05, MAE is:102.70 & sMAPE is:126.97% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :47.53 & 53.56% & 0.92\n",
      "for 2022-06-06, MAE is:36.63 & sMAPE is:76.64% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :47.46 & 53.70% & 0.91\n",
      "for 2022-06-07, MAE is:81.13 & sMAPE is:68.93% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :47.67 & 53.80% & 0.92\n",
      "for 2022-06-08, MAE is:20.23 & sMAPE is:13.82% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :47.50 & 53.55% & 0.92\n",
      "for 2022-06-09, MAE is:49.42 & sMAPE is:36.55% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :47.51 & 53.44% & 0.92\n",
      "for 2022-06-10, MAE is:39.26 & sMAPE is:27.91% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :47.46 & 53.28% & 0.92\n",
      "for 2022-06-11, MAE is:43.11 & sMAPE is:42.69% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :47.43 & 53.22% & 0.92\n",
      "for 2022-06-12, MAE is:82.65 & sMAPE is:128.03% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :47.65 & 53.68% & 0.93\n",
      "for 2022-06-13, MAE is:102.43 & sMAPE is:99.90% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :47.98 & 53.96% & 0.93\n",
      "for 2022-06-14, MAE is:56.86 & sMAPE is:54.58% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :48.04 & 53.96% & 0.94\n",
      "for 2022-06-15, MAE is:43.31 & sMAPE is:22.53% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :48.01 & 53.77% & 0.93\n",
      "for 2022-06-16, MAE is:47.24 & sMAPE is:26.85% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :48.01 & 53.61% & 0.93\n",
      "for 2022-06-17, MAE is:78.78 & sMAPE is:49.68% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :48.19 & 53.59% & 0.93\n",
      "for 2022-06-18, MAE is:65.87 & sMAPE is:155.83% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :48.29 & 54.19% & 0.93\n",
      "for 2022-06-19, MAE is:15.31 & sMAPE is:118.55% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :48.10 & 54.57% & 0.93\n",
      "for 2022-06-20, MAE is:169.01 & sMAPE is:102.06% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :48.81 & 54.85% & 0.94\n",
      "for 2022-06-21, MAE is:54.12 & sMAPE is:28.35% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :48.84 & 54.70% & 0.94\n",
      "for 2022-06-22, MAE is:99.56 & sMAPE is:69.21% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :49.13 & 54.78% & 0.94\n",
      "for 2022-06-23, MAE is:61.12 & sMAPE is:23.57% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :49.20 & 54.60% & 0.93\n",
      "for 2022-06-24, MAE is:93.41 & sMAPE is:59.46% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :49.45 & 54.63% & 0.94\n",
      "for 2022-06-25, MAE is:127.90 & sMAPE is:111.74% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :49.90 & 54.95% & 0.94\n",
      "for 2022-06-26, MAE is:70.90 & sMAPE is:39.68% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :50.02 & 54.87% & 0.94\n",
      "for 2022-06-27, MAE is:51.53 & sMAPE is:18.30% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :50.02 & 54.66% & 0.93\n",
      "for 2022-06-28, MAE is:50.05 & sMAPE is:16.48% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :50.02 & 54.45% & 0.93\n",
      "for 2022-06-29, MAE is:20.92 & sMAPE is:6.47% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :49.86 & 54.18% & 0.93\n",
      "for 2022-06-30, MAE is:53.53 & sMAPE is:17.56% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :49.88 & 53.98% & 0.93\n",
      "for 2022-07-01, MAE is:40.41 & sMAPE is:13.72% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :49.83 & 53.76% & 0.93\n",
      "for 2022-07-02, MAE is:180.09 & sMAPE is:117.32% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :50.54 & 54.10% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-03, MAE is:82.89 & sMAPE is:64.22% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :50.72 & 54.16% & 0.94\n",
      "for 2022-07-04, MAE is:63.40 & sMAPE is:28.30% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :50.79 & 54.02% & 0.94\n",
      "for 2022-07-05, MAE is:83.83 & sMAPE is:78.01% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :50.97 & 54.15% & 0.93\n",
      "for 2022-07-06, MAE is:70.02 & sMAPE is:88.93% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :51.07 & 54.33% & 0.93\n",
      "for 2022-07-07, MAE is:49.59 & sMAPE is:63.02% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :51.06 & 54.38% & 0.93\n",
      "for 2022-07-08, MAE is:60.20 & sMAPE is:64.17% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :51.11 & 54.43% & 0.92\n",
      "for 2022-07-09, MAE is:65.49 & sMAPE is:157.49% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :51.18 & 54.98% & 0.92\n",
      "for 2022-07-10, MAE is:40.01 & sMAPE is:147.20% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :51.12 & 55.46% & 0.92\n",
      "for 2022-07-11, MAE is:228.82 & sMAPE is:130.42% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :52.05 & 55.85% & 0.92\n",
      "for 2022-07-12, MAE is:150.00 & sMAPE is:76.23% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :52.56 & 55.95% & 0.93\n",
      "for 2022-07-13, MAE is:63.47 & sMAPE is:144.21% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :52.61 & 56.41% & 0.93\n",
      "for 2022-07-14, MAE is:27.18 & sMAPE is:161.01% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :52.48 & 56.95% & 0.92\n",
      "for 2022-07-15, MAE is:33.33 & sMAPE is:174.60% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :52.39 & 57.55% & 0.92\n",
      "for 2022-07-16, MAE is:13.36 & sMAPE is:157.34% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :52.19 & 58.05% & 0.92\n",
      "for 2022-07-17, MAE is:13.98 & sMAPE is:118.40% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :51.99 & 58.36% & 0.92\n",
      "for 2022-07-18, MAE is:16.45 & sMAPE is:50.34% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :51.82 & 58.32% & 0.91\n",
      "for 2022-07-19, MAE is:27.34 & sMAPE is:23.69% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :51.69 & 58.14% & 0.91\n",
      "for 2022-07-20, MAE is:26.21 & sMAPE is:38.03% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :51.57 & 58.04% & 0.91\n",
      "for 2022-07-21, MAE is:243.85 & sMAPE is:163.83% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :52.52 & 58.57% & 0.91\n",
      "for 2022-07-22, MAE is:95.32 & sMAPE is:72.89% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :52.73 & 58.64% & 0.91\n",
      "for 2022-07-23, MAE is:43.11 & sMAPE is:49.38% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :52.68 & 58.59% & 0.90\n",
      "for 2022-07-24, MAE is:16.02 & sMAPE is:25.81% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :52.50 & 58.43% & 0.90\n",
      "for 2022-07-25, MAE is:50.49 & sMAPE is:125.71% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :52.49 & 58.76% & 0.90\n",
      "for 2022-07-26, MAE is:29.47 & sMAPE is:135.87% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :52.38 & 59.13% & 0.90\n",
      "for 2022-07-27, MAE is:59.94 & sMAPE is:128.73% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :52.42 & 59.47% & 0.90\n",
      "for 2022-07-28, MAE is:56.02 & sMAPE is:70.81% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :52.44 & 59.52% & 0.90\n",
      "for 2022-07-29, MAE is:69.97 & sMAPE is:47.69% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :52.52 & 59.46% & 0.90\n",
      "for 2022-07-30, MAE is:71.15 & sMAPE is:78.54% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :52.61 & 59.55% & 0.90\n",
      "for 2022-07-31, MAE is:59.73 & sMAPE is:120.61% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :52.64 & 59.84% & 0.90\n",
      "for 2022-08-01, MAE is:91.03 & sMAPE is:91.76% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :52.82 & 59.99% & 0.90\n",
      "for 2022-08-02, MAE is:54.39 & sMAPE is:130.93% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :52.83 & 60.32% & 0.90\n",
      "for 2022-08-03, MAE is:29.27 & sMAPE is:166.17% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :52.72 & 60.82% & 0.90\n",
      "for 2022-08-04, MAE is:23.81 & sMAPE is:140.02% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :52.59 & 61.18% & 0.90\n",
      "for 2022-08-05, MAE is:15.16 & sMAPE is:91.85% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :52.41 & 61.32% & 0.89\n",
      "for 2022-08-06, MAE is:19.72 & sMAPE is:154.34% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :52.26 & 61.75% & 0.89\n",
      "for 2022-08-07, MAE is:25.49 & sMAPE is:114.01% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :52.14 & 61.99% & 0.89\n",
      "for 2022-08-08, MAE is:204.42 & sMAPE is:108.49% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :52.83 & 62.20% & 0.89\n",
      "for 2022-08-09, MAE is:95.82 & sMAPE is:41.12% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :53.03 & 62.11% & 0.89\n",
      "for 2022-08-10, MAE is:145.45 & sMAPE is:90.42% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :53.44 & 62.23% & 0.89\n",
      "for 2022-08-11, MAE is:126.63 & sMAPE is:74.86% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :53.77 & 62.29% & 0.89\n",
      "for 2022-08-12, MAE is:156.09 & sMAPE is:45.23% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :54.23 & 62.21% & 0.88\n",
      "for 2022-08-13, MAE is:77.23 & sMAPE is:25.38% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :54.33 & 62.05% & 0.88\n",
      "for 2022-08-14, MAE is:77.15 & sMAPE is:28.74% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :54.43 & 61.90% & 0.88\n",
      "for 2022-08-15, MAE is:103.33 & sMAPE is:47.09% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :54.65 & 61.84% & 0.88\n",
      "for 2022-08-16, MAE is:129.64 & sMAPE is:55.07% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :54.98 & 61.81% & 0.88\n",
      "for 2022-08-17, MAE is:143.29 & sMAPE is:33.26% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :55.36 & 61.68% & 0.88\n",
      "for 2022-08-18, MAE is:106.79 & sMAPE is:25.34% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :55.59 & 61.52% & 0.88\n",
      "for 2022-08-19, MAE is:144.44 & sMAPE is:56.12% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :55.97 & 61.50% & 0.87\n",
      "for 2022-08-20, MAE is:141.35 & sMAPE is:110.70% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :56.34 & 61.71% & 0.87\n",
      "for 2022-08-21, MAE is:257.22 & sMAPE is:152.35% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :57.20 & 62.10% & 0.88\n",
      "for 2022-08-22, MAE is:103.88 & sMAPE is:22.52% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :57.40 & 61.93% & 0.88\n",
      "for 2022-08-23, MAE is:90.81 & sMAPE is:23.46% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :57.54 & 61.77% & 0.88\n",
      "for 2022-08-24, MAE is:73.29 & sMAPE is:29.97% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :57.61 & 61.63% & 0.87\n",
      "for 2022-08-25, MAE is:169.34 & sMAPE is:52.24% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :58.08 & 61.60% & 0.88\n",
      "for 2022-08-26, MAE is:141.96 & sMAPE is:70.57% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :58.43 & 61.63% & 0.88\n",
      "for 2022-08-27, MAE is:129.71 & sMAPE is:87.16% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :58.73 & 61.74% & 0.88\n",
      "for 2022-08-28, MAE is:143.06 & sMAPE is:88.21% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :59.08 & 61.85% & 0.88\n",
      "for 2022-08-29, MAE is:176.87 & sMAPE is:93.37% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :59.57 & 61.98% & 0.88\n",
      "for 2022-08-30, MAE is:236.25 & sMAPE is:93.84% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :60.30 & 62.11% & 0.88\n",
      "for 2022-08-31, MAE is:162.62 & sMAPE is:42.78% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :60.72 & 62.03% & 0.88\n",
      "for 2022-09-01, MAE is:117.51 & sMAPE is:28.27% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :60.96 & 61.89% & 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-02, MAE is:127.26 & sMAPE is:32.20% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :61.23 & 61.77% & 0.88\n",
      "for 2022-09-03, MAE is:106.18 & sMAPE is:47.39% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :61.41 & 61.71% & 0.88\n",
      "for 2022-09-04, MAE is:114.90 & sMAPE is:63.60% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :61.63 & 61.72% & 0.88\n",
      "for 2022-09-05, MAE is:81.21 & sMAPE is:25.81% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :61.70 & 61.58% & 0.88\n",
      "for 2022-09-06, MAE is:87.79 & sMAPE is:33.30% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :61.81 & 61.46% & 0.88\n",
      "for 2022-09-07, MAE is:91.88 & sMAPE is:32.52% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :61.93 & 61.35% & 0.88\n",
      "for 2022-09-08, MAE is:84.92 & sMAPE is:34.64% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :62.02 & 61.24% & 0.88\n",
      "for 2022-09-09, MAE is:58.25 & sMAPE is:31.25% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :62.01 & 61.12% & 0.87\n",
      "for 2022-09-10, MAE is:56.46 & sMAPE is:31.56% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :61.98 & 61.01% & 0.87\n",
      "for 2022-09-11, MAE is:122.80 & sMAPE is:42.78% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :62.22 & 60.93% & 0.87\n",
      "for 2022-09-12, MAE is:96.11 & sMAPE is:31.76% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :62.36 & 60.82% & 0.87\n",
      "for 2022-09-13, MAE is:151.54 & sMAPE is:106.62% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :62.70 & 61.00% & 0.87\n",
      "for 2022-09-14, MAE is:46.27 & sMAPE is:79.19% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :62.64 & 61.07% & 0.87\n",
      "for 2022-09-15, MAE is:28.54 & sMAPE is:27.84% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :62.51 & 60.94% & 0.87\n",
      "for 2022-09-16, MAE is:47.11 & sMAPE is:80.84% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :62.45 & 61.02% & 0.86\n",
      "for 2022-09-17, MAE is:33.12 & sMAPE is:94.39% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :62.34 & 61.15% & 0.86\n",
      "for 2022-09-18, MAE is:35.74 & sMAPE is:52.82% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :62.23 & 61.11% & 0.86\n",
      "for 2022-09-19, MAE is:77.29 & sMAPE is:56.67% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :62.29 & 61.10% & 0.86\n",
      "for 2022-09-20, MAE is:214.64 & sMAPE is:141.53% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :62.87 & 61.40% & 0.86\n",
      "for 2022-09-21, MAE is:85.06 & sMAPE is:26.85% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :62.95 & 61.27% & 0.86\n",
      "for 2022-09-22, MAE is:80.42 & sMAPE is:36.46% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :63.02 & 61.18% & 0.85\n",
      "for 2022-09-23, MAE is:103.91 & sMAPE is:46.75% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :63.17 & 61.12% & 0.85\n",
      "for 2022-09-24, MAE is:109.43 & sMAPE is:78.87% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :63.35 & 61.19% & 0.85\n",
      "for 2022-09-25, MAE is:50.96 & sMAPE is:32.71% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :63.30 & 61.08% & 0.85\n",
      "for 2022-09-26, MAE is:94.32 & sMAPE is:76.03% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :63.42 & 61.14% & 0.85\n",
      "for 2022-09-27, MAE is:49.14 & sMAPE is:98.96% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :63.36 & 61.28% & 0.85\n",
      "for 2022-09-28, MAE is:21.28 & sMAPE is:45.99% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :63.21 & 61.22% & 0.85\n",
      "for 2022-09-29, MAE is:72.41 & sMAPE is:57.91% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :63.24 & 61.21% & 0.85\n",
      "for 2022-09-30, MAE is:71.40 & sMAPE is:47.35% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :63.27 & 61.16% & 0.85\n",
      "for 2022-10-01, MAE is:56.86 & sMAPE is:97.60% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :63.25 & 61.29% & 0.85\n",
      "for 2022-10-02, MAE is:53.69 & sMAPE is:86.55% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :63.21 & 61.39% & 0.84\n",
      "for 2022-10-03, MAE is:65.70 & sMAPE is:32.51% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :63.22 & 61.28% & 0.84\n",
      "for 2022-10-04, MAE is:49.46 & sMAPE is:34.41% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :63.17 & 61.18% & 0.84\n",
      "for 2022-10-05, MAE is:32.10 & sMAPE is:81.96% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :63.06 & 61.26% & 0.84\n",
      "for 2022-10-06, MAE is:34.30 & sMAPE is:170.31% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :62.96 & 61.65% & 0.84\n",
      "for 2022-10-07, MAE is:29.74 & sMAPE is:136.73% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :62.84 & 61.92% & 0.84\n",
      "for 2022-10-08, MAE is:5.14 & sMAPE is:105.91% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :62.63 & 62.07% & 0.83\n",
      "for 2022-10-09, MAE is:8.36 & sMAPE is:90.00% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :62.44 & 62.17% & 0.83\n",
      "for 2022-10-10, MAE is:40.01 & sMAPE is:149.23% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :62.36 & 62.48% & 0.83\n",
      "for 2022-10-11, MAE is:38.15 & sMAPE is:124.02% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :62.28 & 62.70% & 0.83\n",
      "for 2022-10-12, MAE is:111.30 & sMAPE is:156.08% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :62.45 & 63.03% & 0.83\n",
      "for 2022-10-13, MAE is:56.01 & sMAPE is:121.33% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :62.43 & 63.23% & 0.83\n",
      "for 2022-10-14, MAE is:123.83 & sMAPE is:146.60% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :62.64 & 63.52% & 0.83\n",
      "for 2022-10-15, MAE is:24.93 & sMAPE is:108.96% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :62.51 & 63.68% & 0.83\n",
      "for 2022-10-16, MAE is:17.85 & sMAPE is:113.35% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :62.36 & 63.85% & 0.84\n",
      "for 2022-10-17, MAE is:62.54 & sMAPE is:131.87% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :62.36 & 64.08% & 0.84\n",
      "for 2022-10-18, MAE is:50.62 & sMAPE is:116.37% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :62.32 & 64.26% & 0.84\n",
      "for 2022-10-19, MAE is:66.79 & sMAPE is:105.22% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :62.33 & 64.40% & 0.84\n",
      "for 2022-10-20, MAE is:42.58 & sMAPE is:43.54% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :62.26 & 64.33% & 0.84\n",
      "for 2022-10-21, MAE is:61.09 & sMAPE is:87.83% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :62.26 & 64.41% & 0.85\n",
      "for 2022-10-22, MAE is:60.26 & sMAPE is:85.24% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :62.25 & 64.48% & 0.85\n",
      "for 2022-10-23, MAE is:19.37 & sMAPE is:38.35% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :62.11 & 64.39% & 0.84\n",
      "for 2022-10-24, MAE is:20.37 & sMAPE is:40.43% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :61.97 & 64.31% & 0.84\n",
      "for 2022-10-25, MAE is:21.60 & sMAPE is:36.83% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :61.83 & 64.22% & 0.84\n",
      "for 2022-10-26, MAE is:39.62 & sMAPE is:56.07% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :61.76 & 64.19% & 0.84\n",
      "for 2022-10-27, MAE is:21.19 & sMAPE is:35.46% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :61.62 & 64.10% & 0.84\n",
      "for 2022-10-28, MAE is:25.58 & sMAPE is:52.16% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :61.50 & 64.06% & 0.84\n",
      "for 2022-10-29, MAE is:31.26 & sMAPE is:103.90% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :61.40 & 64.19% & 0.84\n",
      "for 2022-10-30, MAE is:59.46 & sMAPE is:110.90% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :61.40 & 64.35% & 0.84\n",
      "for 2022-10-31, MAE is:40.30 & sMAPE is:36.85% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :61.33 & 64.25% & 0.84\n",
      "for 2022-11-01, MAE is:30.68 & sMAPE is:41.12% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :61.23 & 64.18% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-02, MAE is:17.83 & sMAPE is:35.06% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :61.08 & 64.08% & 0.84\n",
      "for 2022-11-03, MAE is:21.53 & sMAPE is:51.71% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :60.96 & 64.04% & 0.84\n",
      "for 2022-11-04, MAE is:42.18 & sMAPE is:97.28% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :60.89 & 64.15% & 0.84\n",
      "for 2022-11-05, MAE is:48.74 & sMAPE is:68.17% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :60.86 & 64.16% & 0.84\n",
      "for 2022-11-06, MAE is:21.52 & sMAPE is:47.61% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :60.73 & 64.11% & 0.84\n",
      "for 2022-11-07, MAE is:14.86 & sMAPE is:79.65% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :60.58 & 64.16% & 0.84\n",
      "for 2022-11-08, MAE is:17.86 & sMAPE is:55.95% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :60.44 & 64.13% & 0.84\n",
      "for 2022-11-09, MAE is:11.38 & sMAPE is:49.94% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :60.29 & 64.09% & 0.84\n",
      "for 2022-11-10, MAE is:20.52 & sMAPE is:67.40% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :60.16 & 64.10% & 0.84\n",
      "for 2022-11-11, MAE is:22.25 & sMAPE is:174.28% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :60.04 & 64.45% & 0.84\n",
      "for 2022-11-12, MAE is:11.89 & sMAPE is:140.95% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :59.89 & 64.69% & 0.84\n",
      "for 2022-11-13, MAE is:72.96 & sMAPE is:197.28% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :59.93 & 65.11% & 0.84\n",
      "for 2022-11-14, MAE is:53.98 & sMAPE is:47.14% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :59.91 & 65.05% & 0.84\n",
      "for 2022-11-15, MAE is:20.05 & sMAPE is:45.52% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :59.79 & 64.99% & 0.84\n",
      "for 2022-11-16, MAE is:13.85 & sMAPE is:82.54% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :59.64 & 65.05% & 0.84\n",
      "for 2022-11-17, MAE is:12.81 & sMAPE is:34.01% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :59.50 & 64.95% & 0.84\n",
      "for 2022-11-18, MAE is:72.78 & sMAPE is:111.77% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :59.54 & 65.10% & 0.84\n",
      "for 2022-11-19, MAE is:118.23 & sMAPE is:89.75% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :59.72 & 65.17% & 0.84\n",
      "for 2022-11-20, MAE is:42.89 & sMAPE is:24.23% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :59.67 & 65.05% & 0.84\n",
      "for 2022-11-21, MAE is:94.89 & sMAPE is:45.76% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :59.78 & 64.99% & 0.84\n",
      "for 2022-11-22, MAE is:21.27 & sMAPE is:12.07% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :59.66 & 64.82% & 0.84\n",
      "for 2022-11-23, MAE is:33.74 & sMAPE is:26.71% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :59.58 & 64.71% & 0.84\n",
      "for 2022-11-24, MAE is:142.46 & sMAPE is:84.58% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :59.83 & 64.77% & 0.84\n",
      "for 2022-11-25, MAE is:89.18 & sMAPE is:41.42% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :59.92 & 64.70% & 0.83\n",
      "for 2022-11-26, MAE is:43.34 & sMAPE is:21.20% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :59.87 & 64.57% & 0.83\n",
      "for 2022-11-27, MAE is:23.26 & sMAPE is:15.72% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :59.76 & 64.42% & 0.83\n",
      "for 2022-11-28, MAE is:72.11 & sMAPE is:51.09% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :59.80 & 64.38% & 0.83\n",
      "for 2022-11-29, MAE is:210.88 & sMAPE is:82.98% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :60.25 & 64.43% & 0.83\n",
      "for 2022-11-30, MAE is:141.40 & sMAPE is:44.45% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :60.49 & 64.37% & 0.83\n",
      "for 2022-12-01, MAE is:115.26 & sMAPE is:36.02% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :60.66 & 64.29% & 0.83\n",
      "for 2022-12-02, MAE is:71.68 & sMAPE is:24.87% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :60.69 & 64.17% & 0.83\n",
      "for 2022-12-03, MAE is:51.95 & sMAPE is:23.40% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :60.66 & 64.05% & 0.84\n",
      "for 2022-12-04, MAE is:62.46 & sMAPE is:27.09% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :60.67 & 63.94% & 0.84\n",
      "for 2022-12-05, MAE is:89.78 & sMAPE is:33.04% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :60.75 & 63.85% & 0.84\n",
      "for 2022-12-06, MAE is:79.29 & sMAPE is:24.76% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :60.81 & 63.74% & 0.84\n",
      "for 2022-12-07, MAE is:49.07 & sMAPE is:17.68% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :60.77 & 63.60% & 0.84\n",
      "for 2022-12-08, MAE is:88.84 & sMAPE is:26.88% & rMAE is:8.36 ||| daily mean of MAE & sMAPE & rMAE till now are :60.86 & 63.49% & 0.86\n",
      "for 2022-12-09, MAE is:128.17 & sMAPE is:38.26% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :61.05 & 63.42% & 0.86\n",
      "for 2022-12-10, MAE is:43.89 & sMAPE is:12.95% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :61.00 & 63.27% & 0.86\n",
      "for 2022-12-11, MAE is:40.58 & sMAPE is:13.82% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :60.94 & 63.13% & 0.86\n",
      "for 2022-12-12, MAE is:114.50 & sMAPE is:29.83% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :61.10 & 63.03% & 0.86\n",
      "for 2022-12-13, MAE is:109.84 & sMAPE is:28.01% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :61.24 & 62.93% & 0.87\n",
      "for 2022-12-14, MAE is:116.00 & sMAPE is:30.63% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :61.40 & 62.84% & 0.87\n",
      "for 2022-12-15, MAE is:53.21 & sMAPE is:14.86% & rMAE is:2.86 ||| daily mean of MAE & sMAPE & rMAE till now are :61.37 & 62.70% & 0.87\n",
      "for 2022-12-16, MAE is:83.17 & sMAPE is:22.55% & rMAE is:3.05 ||| daily mean of MAE & sMAPE & rMAE till now are :61.44 & 62.59% & 0.88\n",
      "for 2022-12-17, MAE is:57.75 & sMAPE is:20.60% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :61.42 & 62.47% & 0.88\n",
      "for 2022-12-18, MAE is:28.73 & sMAPE is:15.46% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :61.33 & 62.33% & 0.88\n",
      "for 2022-12-19, MAE is:22.31 & sMAPE is:13.55% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :61.22 & 62.20% & 0.87\n",
      "for 2022-12-20, MAE is:26.68 & sMAPE is:14.36% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :61.12 & 62.06% & 0.87\n",
      "for 2022-12-21, MAE is:46.02 & sMAPE is:23.95% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :61.08 & 61.95% & 0.87\n",
      "for 2022-12-22, MAE is:34.99 & sMAPE is:20.01% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :61.01 & 61.84% & 0.87\n",
      "for 2022-12-23, MAE is:24.04 & sMAPE is:14.60% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :60.90 & 61.70% & 0.86\n",
      "for 2022-12-24, MAE is:33.64 & sMAPE is:31.01% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :60.83 & 61.62% & 0.86\n",
      "for 2022-12-25, MAE is:27.79 & sMAPE is:35.77% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :60.74 & 61.55% & 0.86\n",
      "for 2022-12-26, MAE is:30.85 & sMAPE is:58.15% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :60.65 & 61.54% & 0.86\n",
      "for 2022-12-27, MAE is:23.33 & sMAPE is:35.56% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :60.55 & 61.46% & 0.86\n",
      "for 2022-12-28, MAE is:22.44 & sMAPE is:36.22% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :60.44 & 61.39% & 0.86\n",
      "for 2022-12-29, MAE is:41.49 & sMAPE is:75.51% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :60.39 & 61.43% & 0.85\n",
      "for 2022-12-30, MAE is:21.07 & sMAPE is:107.89% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :60.28 & 61.56% & 0.85\n",
      "for 2022-12-31, MAE is:12.14 & sMAPE is:116.72% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :60.15 & 61.71% & 0.85\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:03:36,002]\u001b[0m A new study created in RDB with name: SE_4_2023\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:03:50,684]\u001b[0m Trial 0 finished with value: 92.12955091335698 and parameters: {'n_hidden': 4, 'learning_rate': 0.01964219392381131, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23356429238410611, 'dropout_rate_Layer_2': 0.2895177235751562, 'dropout_rate_Layer_3': 0.13811964446957742, 'dropout_rate_Layer_4': 0.23512881495271107, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032357461094841447, 'l1_Layer_2': 2.5278958822460455e-05, 'l1_Layer_3': 0.001538041990319464, 'l1_Layer_4': 0.009407852546072591, 'n_units_Layer_1': 195, 'n_units_Layer_2': 195, 'n_units_Layer_3': 195, 'n_units_Layer_4': 280}. Best is trial 0 with value: 92.12955091335698.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 92.13 | sMAPE for Validation Set is: 77.46% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 46.88 | sMAPE for Test Set is: 79.18% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:04:06,027]\u001b[0m Trial 1 finished with value: 89.02562847975246 and parameters: {'n_hidden': 3, 'learning_rate': 0.0994312055922404, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3300030187772457, 'dropout_rate_Layer_2': 0.03604777472282006, 'dropout_rate_Layer_3': 0.05307700861067186, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029916299186771114, 'l1_Layer_2': 5.721154410662058e-05, 'l1_Layer_3': 0.011397007896641838, 'n_units_Layer_1': 50, 'n_units_Layer_2': 275, 'n_units_Layer_3': 75}. Best is trial 1 with value: 89.02562847975246.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 89.03 | sMAPE for Validation Set is: 73.08% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 38.25 | sMAPE for Test Set is: 51.29% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:04:12,325]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:04:17,559]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:04:50,286]\u001b[0m Trial 4 finished with value: 123.68896534383855 and parameters: {'n_hidden': 3, 'learning_rate': 0.000538931037206045, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36034107667384696, 'dropout_rate_Layer_2': 0.341581972917073, 'dropout_rate_Layer_3': 0.07492186353135755, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.815941733649343e-05, 'l1_Layer_2': 0.00019109307464167227, 'l1_Layer_3': 0.00017941955197833077, 'n_units_Layer_1': 105, 'n_units_Layer_2': 160, 'n_units_Layer_3': 95}. Best is trial 1 with value: 89.02562847975246.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 123.69 | sMAPE for Validation Set is: 106.99% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 52.38 | sMAPE for Test Set is: 86.18% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:05:22,862]\u001b[0m Trial 5 finished with value: 91.4483080109399 and parameters: {'n_hidden': 3, 'learning_rate': 0.06273340606916275, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.267437882750762, 'dropout_rate_Layer_2': 0.11718456276956052, 'dropout_rate_Layer_3': 0.3727669795240734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.005175857267555478, 'l1_Layer_2': 0.00016571962859674677, 'l1_Layer_3': 0.01999031829135244, 'n_units_Layer_1': 290, 'n_units_Layer_2': 215, 'n_units_Layer_3': 115}. Best is trial 1 with value: 89.02562847975246.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 91.45 | sMAPE for Validation Set is: 76.04% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 46.71 | sMAPE for Test Set is: 64.07% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:05:27,116]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:05:40,894]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:05:54,521]\u001b[0m Trial 8 finished with value: 100.81665292267469 and parameters: {'n_hidden': 3, 'learning_rate': 0.00677870442791322, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32689480008285016, 'dropout_rate_Layer_2': 0.06313324617619172, 'dropout_rate_Layer_3': 0.16620203044048362, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2550235711595995e-05, 'l1_Layer_2': 1.3446731684873852e-05, 'l1_Layer_3': 0.0003791378281637164, 'n_units_Layer_1': 70, 'n_units_Layer_2': 55, 'n_units_Layer_3': 275}. Best is trial 1 with value: 89.02562847975246.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 100.82 | sMAPE for Validation Set is: 79.53% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 52.55 | sMAPE for Test Set is: 60.80% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:10:16,840]\u001b[0m Trial 9 finished with value: 78.50718772295689 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012282802155078563, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10492669234874726, 'dropout_rate_Layer_2': 0.37278635230654755, 'dropout_rate_Layer_3': 0.18362346418446723, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.014954991898566583, 'l1_Layer_2': 8.817054929054446e-05, 'l1_Layer_3': 1.4398372209614235e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 245, 'n_units_Layer_3': 165}. Best is trial 9 with value: 78.50718772295689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.51 | sMAPE for Validation Set is: 64.54% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 27.28 | sMAPE for Test Set is: 43.62% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:10:21,028]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:10:27,500]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:10:32,268]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:10:37,459]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:10:43,529]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:10:47,350]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:10:53,204]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:11:10,886]\u001b[0m Trial 17 finished with value: 100.06629850136282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005999304161774025, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.049260464996530653, 'dropout_rate_Layer_2': 0.3659537150043049, 'dropout_rate_Layer_3': 0.24051774180835495, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012323331923430165, 'l1_Layer_2': 0.01324979332283284, 'l1_Layer_3': 0.00032705401246208466, 'n_units_Layer_1': 260, 'n_units_Layer_2': 200, 'n_units_Layer_3': 125}. Best is trial 9 with value: 78.50718772295689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 100.07 | sMAPE for Validation Set is: 81.27% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 33.48 | sMAPE for Test Set is: 50.50% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:11:15,773]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:11:23,246]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:11:28,550]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:11:33,505]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:11:38,077]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:12:20,360]\u001b[0m Trial 23 finished with value: 77.52229234954332 and parameters: {'n_hidden': 3, 'learning_rate': 0.0063534311435118765, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015522495861968945, 'dropout_rate_Layer_2': 0.03825302474031172, 'dropout_rate_Layer_3': 0.3909149458653854, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.006299292010668019, 'l1_Layer_2': 0.0005038001487655276, 'l1_Layer_3': 1.4384746277668795e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 50, 'n_units_Layer_3': 290}. Best is trial 23 with value: 77.52229234954332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.52 | sMAPE for Validation Set is: 65.92% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 30.05 | sMAPE for Test Set is: 47.13% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:12:26,148]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:12:30,787]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:13:35,689]\u001b[0m Trial 26 finished with value: 84.82747113339437 and parameters: {'n_hidden': 3, 'learning_rate': 0.001187130146784768, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3167161183964341, 'dropout_rate_Layer_2': 0.06325223073767865, 'dropout_rate_Layer_3': 0.20714798351593688, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.000506184780844617, 'l1_Layer_2': 0.007565002334016885, 'l1_Layer_3': 1.215212260913985e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 135, 'n_units_Layer_3': 155}. Best is trial 23 with value: 77.52229234954332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 84.83 | sMAPE for Validation Set is: 69.82% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 26.23 | sMAPE for Test Set is: 42.61% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:13:41,561]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:13:46,149]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:13:51,620]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:13:56,171]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:15:41,728]\u001b[0m Trial 31 finished with value: 82.46021778287668 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027629315292925435, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11065952724651945, 'dropout_rate_Layer_2': 0.20605594067041447, 'dropout_rate_Layer_3': 0.3146414138564674, 'dropout_rate_Layer_4': 0.12967861066906303, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0015722313373841199, 'l1_Layer_2': 1.2575175174826582e-05, 'l1_Layer_3': 0.001994223524333624, 'l1_Layer_4': 0.004731388088381415, 'n_units_Layer_1': 65, 'n_units_Layer_2': 50, 'n_units_Layer_3': 285, 'n_units_Layer_4': 205}. Best is trial 23 with value: 77.52229234954332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 82.46 | sMAPE for Validation Set is: 67.67% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 30.09 | sMAPE for Test Set is: 50.35% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:15:55,373]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:16:00,243]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:16:38,206]\u001b[0m Trial 34 finished with value: 69.59163822063493 and parameters: {'n_hidden': 3, 'learning_rate': 0.006238505020147039, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0013910969099391935, 'dropout_rate_Layer_2': 0.0233479314969959, 'dropout_rate_Layer_3': 0.07034634826469506, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021670123967183364, 'l1_Layer_2': 5.124533024146278e-05, 'l1_Layer_3': 0.024383953233552302, 'n_units_Layer_1': 175, 'n_units_Layer_2': 240, 'n_units_Layer_3': 170}. Best is trial 34 with value: 69.59163822063493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 69.59 | sMAPE for Validation Set is: 61.55% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 27.76 | sMAPE for Test Set is: 42.91% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:16:43,514]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:16:49,067]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:16:56,305]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:03,680]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:08,700]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:19,408]\u001b[0m Trial 40 finished with value: 103.99368353880095 and parameters: {'n_hidden': 4, 'learning_rate': 0.04977882738944282, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18131168212492793, 'dropout_rate_Layer_2': 0.3377725481828299, 'dropout_rate_Layer_3': 0.21052139115233445, 'dropout_rate_Layer_4': 0.358739363207941, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002569915479526939, 'l1_Layer_2': 0.00561577190889297, 'l1_Layer_3': 5.37276250927615e-05, 'l1_Layer_4': 0.0004527676272891907, 'n_units_Layer_1': 160, 'n_units_Layer_2': 275, 'n_units_Layer_3': 120, 'n_units_Layer_4': 290}. Best is trial 34 with value: 69.59163822063493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 103.99 | sMAPE for Validation Set is: 84.20% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 41.69 | sMAPE for Test Set is: 56.70% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:17:24,064]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:29,167]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:17:38,409]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:18:04,430]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:18:12,869]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:18:24,613]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:18:39,042]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:18:44,947]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:18:51,286]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:19:21,258]\u001b[0m Trial 50 finished with value: 70.17650270173893 and parameters: {'n_hidden': 3, 'learning_rate': 0.013715556648328055, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08103367658196174, 'dropout_rate_Layer_2': 0.30753450044742914, 'dropout_rate_Layer_3': 0.3804990996514159, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025200980817127034, 'l1_Layer_2': 0.00014697212467078765, 'l1_Layer_3': 6.309128787405136e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195}. Best is trial 34 with value: 69.59163822063493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.18 | sMAPE for Validation Set is: 61.96% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 31.36 | sMAPE for Test Set is: 44.59% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:19:50,720]\u001b[0m Trial 51 finished with value: 71.93384223963018 and parameters: {'n_hidden': 3, 'learning_rate': 0.014322117329859801, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05301055692776058, 'dropout_rate_Layer_2': 0.3929585751039396, 'dropout_rate_Layer_3': 0.3876784278151415, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02925334013897021, 'l1_Layer_2': 0.0001944337553068372, 'l1_Layer_3': 3.781919656830377e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 155, 'n_units_Layer_3': 195}. Best is trial 34 with value: 69.59163822063493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 71.93 | sMAPE for Validation Set is: 61.67% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 26.08 | sMAPE for Test Set is: 43.19% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:19:57,324]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:20:05,898]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:20:11,269]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:20:19,294]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:20:24,932]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:20:31,253]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:20:55,803]\u001b[0m Trial 58 finished with value: 85.41432896293963 and parameters: {'n_hidden': 4, 'learning_rate': 0.018164756422528076, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3043250402129266, 'dropout_rate_Layer_2': 0.18117443342570827, 'dropout_rate_Layer_3': 0.05696681054967938, 'dropout_rate_Layer_4': 0.24295575912153827, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007888279652174129, 'l1_Layer_2': 0.0002731217422820883, 'l1_Layer_3': 0.0007376232571699346, 'l1_Layer_4': 0.0019172122206835465, 'n_units_Layer_1': 50, 'n_units_Layer_2': 215, 'n_units_Layer_3': 225, 'n_units_Layer_4': 260}. Best is trial 34 with value: 69.59163822063493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 85.41 | sMAPE for Validation Set is: 70.53% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 35.17 | sMAPE for Test Set is: 50.64% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:22:23,918]\u001b[0m Trial 59 finished with value: 83.6474476845715 and parameters: {'n_hidden': 4, 'learning_rate': 0.0074810240606458835, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37633631034183457, 'dropout_rate_Layer_2': 0.17207412984372034, 'dropout_rate_Layer_3': 0.0020233486285790026, 'dropout_rate_Layer_4': 0.24362191483969828, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009395663097158806, 'l1_Layer_2': 0.0002640657550487306, 'l1_Layer_3': 0.0005368261092194828, 'l1_Layer_4': 0.0018899940574762459, 'n_units_Layer_1': 60, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 34 with value: 69.59163822063493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 83.65 | sMAPE for Validation Set is: 70.83% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 32.49 | sMAPE for Test Set is: 56.72% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:23:01,528]\u001b[0m Trial 60 finished with value: 66.93997872840924 and parameters: {'n_hidden': 3, 'learning_rate': 0.015797083773645387, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.050566599058044816, 'dropout_rate_Layer_2': 0.3119704500928641, 'dropout_rate_Layer_3': 0.399986852099528, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04035671725759119, 'l1_Layer_2': 0.00030840411311538465, 'l1_Layer_3': 5.0650165224686354e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 135, 'n_units_Layer_3': 200}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 66.94 | sMAPE for Validation Set is: 59.35% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 26.36 | sMAPE for Test Set is: 40.63% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:23:13,416]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:23:24,185]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:23:29,521]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:23:41,690]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:24:51,528]\u001b[0m Trial 65 finished with value: 82.35902944740636 and parameters: {'n_hidden': 4, 'learning_rate': 0.0125676489358424, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34725859409107585, 'dropout_rate_Layer_2': 0.19362535015935456, 'dropout_rate_Layer_3': 0.05677149551977329, 'dropout_rate_Layer_4': 0.23663358568351475, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007102233848725551, 'l1_Layer_2': 0.0002625891585001779, 'l1_Layer_3': 0.0007402426007829429, 'l1_Layer_4': 0.0016315214625819486, 'n_units_Layer_1': 110, 'n_units_Layer_2': 190, 'n_units_Layer_3': 220, 'n_units_Layer_4': 260}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 82.36 | sMAPE for Validation Set is: 68.93% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 35.90 | sMAPE for Test Set is: 48.87% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:24:58,569]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:25:23,509]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:25:37,237]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:25:49,822]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:25:56,275]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:26:02,710]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:26:08,299]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:26:16,493]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:26:21,669]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:26:27,873]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:26:32,484]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:27:14,133]\u001b[0m Trial 77 finished with value: 82.75651026282452 and parameters: {'n_hidden': 4, 'learning_rate': 0.0163398426679284, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36923161275035965, 'dropout_rate_Layer_2': 0.12839189453870098, 'dropout_rate_Layer_3': 0.04858226260736287, 'dropout_rate_Layer_4': 0.29517939054329806, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004717849071258356, 'l1_Layer_2': 0.00015356846820524595, 'l1_Layer_3': 0.0015532206271127629, 'l1_Layer_4': 0.00011625356462094138, 'n_units_Layer_1': 60, 'n_units_Layer_2': 205, 'n_units_Layer_3': 155, 'n_units_Layer_4': 215}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 82.76 | sMAPE for Validation Set is: 68.94% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 37.15 | sMAPE for Test Set is: 51.10% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:27:38,151]\u001b[0m Trial 78 finished with value: 68.48066742338283 and parameters: {'n_hidden': 3, 'learning_rate': 0.00951657985152046, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045889232849469455, 'dropout_rate_Layer_2': 0.395021208857845, 'dropout_rate_Layer_3': 0.3010105722229244, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0101476463113637, 'l1_Layer_2': 0.0001639189728795783, 'l1_Layer_3': 2.9175949503326476e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 135, 'n_units_Layer_3': 185}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 68.48 | sMAPE for Validation Set is: 60.39% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.98 | sMAPE for Test Set is: 40.88% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:29:18,849]\u001b[0m Trial 79 finished with value: 79.62463095175266 and parameters: {'n_hidden': 4, 'learning_rate': 0.007863552075583705, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3633799840018559, 'dropout_rate_Layer_2': 0.13320644420612684, 'dropout_rate_Layer_3': 0.00041495838976648297, 'dropout_rate_Layer_4': 0.2985004097478298, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005670432572248593, 'l1_Layer_2': 0.0001614191017434638, 'l1_Layer_3': 0.0014939973157697569, 'l1_Layer_4': 7.953766733171283e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 210, 'n_units_Layer_3': 120, 'n_units_Layer_4': 215}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 79.62 | sMAPE for Validation Set is: 66.52% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 28.93 | sMAPE for Test Set is: 43.92% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:29:55,285]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:30:11,557]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:30:38,259]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:31:25,676]\u001b[0m Trial 83 finished with value: 77.56316065785994 and parameters: {'n_hidden': 4, 'learning_rate': 0.008335038017836614, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34662670166342524, 'dropout_rate_Layer_2': 0.15607797988762231, 'dropout_rate_Layer_3': 0.04060352805253499, 'dropout_rate_Layer_4': 0.264224781713157, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0040128559713655575, 'l1_Layer_2': 0.0002885957938989458, 'l1_Layer_3': 0.0004943540262949158, 'l1_Layer_4': 0.001255623029954626, 'n_units_Layer_1': 65, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160, 'n_units_Layer_4': 260}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.56 | sMAPE for Validation Set is: 66.58% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 34.08 | sMAPE for Test Set is: 57.08% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:31:37,789]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:32:57,312]\u001b[0m Trial 85 finished with value: 76.99895974734198 and parameters: {'n_hidden': 4, 'learning_rate': 0.006240259320925843, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3599507069666054, 'dropout_rate_Layer_2': 0.16446984984456486, 'dropout_rate_Layer_3': 0.013045936643829331, 'dropout_rate_Layer_4': 0.2776764165867319, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003806225967920711, 'l1_Layer_2': 0.000232479423524207, 'l1_Layer_3': 0.0013697354898525068, 'l1_Layer_4': 0.002101379638653171, 'n_units_Layer_1': 60, 'n_units_Layer_2': 215, 'n_units_Layer_3': 145, 'n_units_Layer_4': 235}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.00 | sMAPE for Validation Set is: 66.09% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 31.39 | sMAPE for Test Set is: 45.96% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:33:09,866]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:11,364]\u001b[0m Trial 87 finished with value: 77.95602156150719 and parameters: {'n_hidden': 4, 'learning_rate': 0.005541633585804181, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36157493188166373, 'dropout_rate_Layer_2': 0.16203624584109855, 'dropout_rate_Layer_3': 0.019712083694799116, 'dropout_rate_Layer_4': 0.34303056353415395, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003810597924378279, 'l1_Layer_2': 0.00011335793765620238, 'l1_Layer_3': 0.002382387123210988, 'l1_Layer_4': 0.0005393265059191766, 'n_units_Layer_1': 65, 'n_units_Layer_2': 225, 'n_units_Layer_3': 160, 'n_units_Layer_4': 235}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.96 | sMAPE for Validation Set is: 64.89% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 29.70 | sMAPE for Test Set is: 43.15% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:34:17,147]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:22,624]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:31,127]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:34:46,556]\u001b[0m Trial 91 finished with value: 74.28724613212783 and parameters: {'n_hidden': 3, 'learning_rate': 0.021948785589398962, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08123280446342669, 'dropout_rate_Layer_2': 0.3023967168157974, 'dropout_rate_Layer_3': 0.327450242466597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008866210810235605, 'l1_Layer_2': 2.7534142192188516e-05, 'l1_Layer_3': 8.188224161370365e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 220}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.29 | sMAPE for Validation Set is: 64.31% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 27.16 | sMAPE for Test Set is: 42.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:34:54,136]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:35:06,320]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:35:12,340]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:35:28,732]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:35:37,343]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:35:53,135]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:08,567]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:24,947]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:33,020]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:40,777]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:49,051]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:36:58,124]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:03,744]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:21,478]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:27,333]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:33,353]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:38,910]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:43,414]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:37:54,540]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:38:03,112]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:38:10,852]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:38:28,334]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:38:36,641]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:38:45,197]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:38:50,335]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:02,695]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:08,216]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:12,988]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:20,243]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:26,648]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:34,572]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:41,329]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:39:49,935]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:22,329]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:27,132]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:36,571]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:49,583]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:40:55,722]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:08,382]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:17,157]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:22,712]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:28,432]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:33,772]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:40,510]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:46,064]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:41:52,688]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:42:49,800]\u001b[0m Trial 138 finished with value: 72.16856130833732 and parameters: {'n_hidden': 3, 'learning_rate': 0.013985246496247593, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3859322437504672, 'dropout_rate_Layer_2': 0.0271327364493828, 'dropout_rate_Layer_3': 0.02167481416260575, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028571954477430227, 'l1_Layer_2': 0.0001804608373542459, 'l1_Layer_3': 0.0004671594168090651, 'n_units_Layer_1': 55, 'n_units_Layer_2': 270, 'n_units_Layer_3': 85}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.17 | sMAPE for Validation Set is: 61.24% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 27.15 | sMAPE for Test Set is: 41.73% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:42:54,204]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:02,311]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:43:32,671]\u001b[0m Trial 141 finished with value: 73.1450814524365 and parameters: {'n_hidden': 4, 'learning_rate': 0.009288497508265665, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38857971690790594, 'dropout_rate_Layer_2': 0.10326009886461537, 'dropout_rate_Layer_3': 0.0001737445431884803, 'dropout_rate_Layer_4': 0.2842441608526779, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003989929557282303, 'l1_Layer_2': 8.325292281794799e-05, 'l1_Layer_3': 0.0006320983533556898, 'l1_Layer_4': 0.000984932938437406, 'n_units_Layer_1': 80, 'n_units_Layer_2': 240, 'n_units_Layer_3': 105, 'n_units_Layer_4': 235}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.15 | sMAPE for Validation Set is: 64.14% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 32.24 | sMAPE for Test Set is: 46.45% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:43:37,823]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:44:13,871]\u001b[0m Trial 143 finished with value: 72.85250221152768 and parameters: {'n_hidden': 4, 'learning_rate': 0.008705537336492937, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3886352355681495, 'dropout_rate_Layer_2': 0.1010237012956452, 'dropout_rate_Layer_3': 0.008099223649506389, 'dropout_rate_Layer_4': 0.2871339607420566, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003485876538546013, 'l1_Layer_2': 8.082354050818963e-05, 'l1_Layer_3': 0.00160060883579579, 'l1_Layer_4': 0.0002789738467135331, 'n_units_Layer_1': 80, 'n_units_Layer_2': 270, 'n_units_Layer_3': 110, 'n_units_Layer_4': 230}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.85 | sMAPE for Validation Set is: 63.30% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 29.85 | sMAPE for Test Set is: 45.96% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:44:35,820]\u001b[0m Trial 144 finished with value: 68.07077948757583 and parameters: {'n_hidden': 3, 'learning_rate': 0.006400226087295907, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01888888786316998, 'dropout_rate_Layer_2': 0.36877368453492476, 'dropout_rate_Layer_3': 0.3702703224097234, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.019470728783118486, 'l1_Layer_2': 3.7777962140957415e-05, 'l1_Layer_3': 5.915507259414812e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 190, 'n_units_Layer_3': 205}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 68.07 | sMAPE for Validation Set is: 59.30% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 33.10 | sMAPE for Test Set is: 46.55% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:44:45,361]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:10,968]\u001b[0m Trial 146 finished with value: 74.1274016316443 and parameters: {'n_hidden': 4, 'learning_rate': 0.009036460989022867, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.388870625399432, 'dropout_rate_Layer_2': 0.10350359284050681, 'dropout_rate_Layer_3': 0.023620201660529104, 'dropout_rate_Layer_4': 0.2878559724050679, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002190481363632612, 'l1_Layer_2': 5.235392813865589e-05, 'l1_Layer_3': 0.0013079155432215077, 'l1_Layer_4': 0.00023650131182180686, 'n_units_Layer_1': 105, 'n_units_Layer_2': 240, 'n_units_Layer_3': 100, 'n_units_Layer_4': 225}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.13 | sMAPE for Validation Set is: 64.26% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 32.12 | sMAPE for Test Set is: 47.14% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:45:14,738]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:45:19,943]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:46:03,663]\u001b[0m Trial 149 finished with value: 69.81308306231413 and parameters: {'n_hidden': 3, 'learning_rate': 0.005839700977185541, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1479472344798822, 'dropout_rate_Layer_2': 0.241817914410674, 'dropout_rate_Layer_3': 0.377774369991976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0009272876108012678, 'l1_Layer_2': 0.006159915680225223, 'l1_Layer_3': 0.01755791829614765, 'n_units_Layer_1': 175, 'n_units_Layer_2': 165, 'n_units_Layer_3': 115}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 69.81 | sMAPE for Validation Set is: 61.57% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 27.36 | sMAPE for Test Set is: 47.55% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:46:35,656]\u001b[0m Trial 150 finished with value: 70.6173922853158 and parameters: {'n_hidden': 4, 'learning_rate': 0.008978506332872543, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38779191515233313, 'dropout_rate_Layer_2': 0.10388845333389415, 'dropout_rate_Layer_3': 0.02117697005669524, 'dropout_rate_Layer_4': 0.31470564967367304, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0022358273557985357, 'l1_Layer_2': 8.093217387474112e-05, 'l1_Layer_3': 0.00043318046189267, 'l1_Layer_4': 0.00035473798558440694, 'n_units_Layer_1': 100, 'n_units_Layer_2': 265, 'n_units_Layer_3': 105, 'n_units_Layer_4': 225}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.62 | sMAPE for Validation Set is: 60.38% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 28.22 | sMAPE for Test Set is: 42.35% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:47:09,434]\u001b[0m Trial 151 finished with value: 71.85120032652131 and parameters: {'n_hidden': 3, 'learning_rate': 0.008777608035199383, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38883773050832177, 'dropout_rate_Layer_2': 0.10715154145221183, 'dropout_rate_Layer_3': 0.010669049569950637, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021893969085682997, 'l1_Layer_2': 4.9455481080026666e-05, 'l1_Layer_3': 0.000416564576895803, 'n_units_Layer_1': 95, 'n_units_Layer_2': 270, 'n_units_Layer_3': 85}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 71.85 | sMAPE for Validation Set is: 61.33% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 31.97 | sMAPE for Test Set is: 44.25% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:47:15,288]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:19,025]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:22,678]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:26,432]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:35,505]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:44,997]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:47:49,884]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:21,107]\u001b[0m Trial 159 finished with value: 74.9409174107276 and parameters: {'n_hidden': 3, 'learning_rate': 0.008809762094780555, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3840869119990547, 'dropout_rate_Layer_2': 0.1136005140897144, 'dropout_rate_Layer_3': 0.01034866861440669, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034263191843767367, 'l1_Layer_2': 6.599215997444104e-05, 'l1_Layer_3': 0.0004249118332473947, 'n_units_Layer_1': 80, 'n_units_Layer_2': 260, 'n_units_Layer_3': 70}. Best is trial 60 with value: 66.93997872840924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.94 | sMAPE for Validation Set is: 62.62% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 28.91 | sMAPE for Test Set is: 42.42% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:48:24,928]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:48:28,500]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:00,726]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:07,749]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:34,663]\u001b[0m Trial 164 finished with value: 57.907471823092386 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031167445914121873, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1985037299714581, 'dropout_rate_Layer_2': 0.1318079545157866, 'dropout_rate_Layer_3': 0.07894729649006345, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011264765000210928, 'l1_Layer_2': 0.07397655060509639, 'l1_Layer_3': 1.886314940527639e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155}. Best is trial 164 with value: 57.907471823092386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.91 | sMAPE for Validation Set is: 56.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.24 | sMAPE for Test Set is: 41.28% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:49:38,402]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:53,382]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:49:58,061]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:50:37,629]\u001b[0m Trial 168 finished with value: 70.3212651263391 and parameters: {'n_hidden': 3, 'learning_rate': 0.008523675079278419, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3548284326457021, 'dropout_rate_Layer_2': 0.10805803087024113, 'dropout_rate_Layer_3': 0.007522396539126503, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016267524551234413, 'l1_Layer_2': 5.7260827677055904e-05, 'l1_Layer_3': 0.00018046516086076946, 'n_units_Layer_1': 115, 'n_units_Layer_2': 270, 'n_units_Layer_3': 65}. Best is trial 164 with value: 57.907471823092386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.32 | sMAPE for Validation Set is: 62.27% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 28.84 | sMAPE for Test Set is: 44.83% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:50:55,893]\u001b[0m Trial 169 finished with value: 73.81475298820483 and parameters: {'n_hidden': 3, 'learning_rate': 0.01144207480256107, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39424689716236405, 'dropout_rate_Layer_2': 0.10735113324445045, 'dropout_rate_Layer_3': 0.006550312063253211, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016079474686004468, 'l1_Layer_2': 3.173105084054346e-05, 'l1_Layer_3': 0.00016745693692280121, 'n_units_Layer_1': 120, 'n_units_Layer_2': 270, 'n_units_Layer_3': 60}. Best is trial 164 with value: 57.907471823092386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.81 | sMAPE for Validation Set is: 63.86% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 30.92 | sMAPE for Test Set is: 43.28% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:51:00,130]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:51:33,067]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:51:39,606]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:51:43,329]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:51:50,234]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:52:13,404]\u001b[0m Trial 175 finished with value: 73.4850877953974 and parameters: {'n_hidden': 3, 'learning_rate': 0.008344715857643644, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3992273236744414, 'dropout_rate_Layer_2': 0.10904038480077435, 'dropout_rate_Layer_3': 0.026519210922792927, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002002054538628331, 'l1_Layer_2': 4.863917626187146e-05, 'l1_Layer_3': 0.0002598758216005145, 'n_units_Layer_1': 110, 'n_units_Layer_2': 270, 'n_units_Layer_3': 80}. Best is trial 164 with value: 57.907471823092386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.49 | sMAPE for Validation Set is: 62.26% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 27.49 | sMAPE for Test Set is: 42.28% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:52:17,624]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:52:58,891]\u001b[0m Trial 177 finished with value: 67.45266908117331 and parameters: {'n_hidden': 3, 'learning_rate': 0.007452466299035152, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3773020863902831, 'dropout_rate_Layer_2': 0.10836946432129133, 'dropout_rate_Layer_3': 0.007604189687185247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012370858141282496, 'l1_Layer_2': 2.6587667065005394e-05, 'l1_Layer_3': 0.00013469852963256626, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 105}. Best is trial 164 with value: 57.907471823092386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 67.45 | sMAPE for Validation Set is: 58.79% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 28.30 | sMAPE for Test Set is: 41.82% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:53:04,664]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:53:22,694]\u001b[0m Trial 179 finished with value: 61.08760369530992 and parameters: {'n_hidden': 3, 'learning_rate': 0.008108188813392241, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19808270383003582, 'dropout_rate_Layer_2': 0.12806391042011991, 'dropout_rate_Layer_3': 0.12520560679336784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.569814238672876e-05, 'l1_Layer_2': 2.7649802842083764e-05, 'l1_Layer_3': 0.007715398608098223, 'n_units_Layer_1': 215, 'n_units_Layer_2': 300, 'n_units_Layer_3': 245}. Best is trial 164 with value: 57.907471823092386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.09 | sMAPE for Validation Set is: 60.92% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 29.81 | sMAPE for Test Set is: 50.08% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:54:02,179]\u001b[0m Trial 180 finished with value: 55.42788649587436 and parameters: {'n_hidden': 3, 'learning_rate': 0.014516922224350297, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06745914210755025, 'dropout_rate_Layer_2': 0.3457507315004392, 'dropout_rate_Layer_3': 0.31275855771928773, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04476244326796716, 'l1_Layer_2': 0.0004906742911049637, 'l1_Layer_3': 1.4117404411887464e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 180}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.43 | sMAPE for Validation Set is: 54.03% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.80 | sMAPE for Test Set is: 41.56% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:54:27,699]\u001b[0m Trial 181 finished with value: 58.13748542930272 and parameters: {'n_hidden': 3, 'learning_rate': 0.02680786358969008, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09513413931584017, 'dropout_rate_Layer_2': 0.3358243899173246, 'dropout_rate_Layer_3': 0.289320999552083, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04933143270434467, 'l1_Layer_2': 0.0005492127645727895, 'l1_Layer_3': 1.4388679388976726e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 180}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.14 | sMAPE for Validation Set is: 56.53% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.43 | sMAPE for Test Set is: 43.71% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:55:08,250]\u001b[0m Trial 182 finished with value: 70.43341604536471 and parameters: {'n_hidden': 3, 'learning_rate': 0.007436863785213345, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3801273742155497, 'dropout_rate_Layer_2': 0.08370259672859208, 'dropout_rate_Layer_3': 0.0010983441038105793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011073926947823068, 'l1_Layer_2': 2.7891990311629936e-05, 'l1_Layer_3': 0.00013243852891421526, 'n_units_Layer_1': 125, 'n_units_Layer_2': 295, 'n_units_Layer_3': 110}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.43 | sMAPE for Validation Set is: 60.43% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 26.55 | sMAPE for Test Set is: 40.97% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:55:43,629]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:55:49,685]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:56:27,626]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:56:57,767]\u001b[0m Trial 186 finished with value: 71.67412686956203 and parameters: {'n_hidden': 3, 'learning_rate': 0.010091384921713648, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3739800950282419, 'dropout_rate_Layer_2': 0.06503069741729253, 'dropout_rate_Layer_3': 0.00020600423557579642, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001023840272448323, 'l1_Layer_2': 3.567311738443201e-05, 'l1_Layer_3': 0.00019022735044347739, 'n_units_Layer_1': 105, 'n_units_Layer_2': 280, 'n_units_Layer_3': 115}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 71.67 | sMAPE for Validation Set is: 61.08% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 29.98 | sMAPE for Test Set is: 43.28% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:57:03,854]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:57:20,030]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:57:24,727]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:57:51,898]\u001b[0m Trial 190 finished with value: 70.13989149058803 and parameters: {'n_hidden': 3, 'learning_rate': 0.007842962214629571, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39209850916225564, 'dropout_rate_Layer_2': 0.08464840505363075, 'dropout_rate_Layer_3': 0.02637796612827252, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014334606143905292, 'l1_Layer_2': 3.184907053369682e-05, 'l1_Layer_3': 0.00017090020844845786, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 100}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.14 | sMAPE for Validation Set is: 60.15% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 30.04 | sMAPE for Test Set is: 43.96% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:58:04,442]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 01:58:39,893]\u001b[0m Trial 192 finished with value: 70.656352192959 and parameters: {'n_hidden': 3, 'learning_rate': 0.007704065768850627, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3544937754280896, 'dropout_rate_Layer_2': 0.08376022547373135, 'dropout_rate_Layer_3': 0.030338582332802837, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007031761268936688, 'l1_Layer_2': 2.7136612981619266e-05, 'l1_Layer_3': 0.00016234377271582098, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 90}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.66 | sMAPE for Validation Set is: 60.88% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 28.28 | sMAPE for Test Set is: 43.62% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 01:59:16,806]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:00:03,844]\u001b[0m Trial 194 finished with value: 67.43348985847548 and parameters: {'n_hidden': 3, 'learning_rate': 0.0064910962714186575, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3697145746959627, 'dropout_rate_Layer_2': 0.07028221302577703, 'dropout_rate_Layer_3': 0.030698416459865978, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007189325648781709, 'l1_Layer_2': 2.7144549223159844e-05, 'l1_Layer_3': 0.0002651090860418767, 'n_units_Layer_1': 100, 'n_units_Layer_2': 300, 'n_units_Layer_3': 90}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 67.43 | sMAPE for Validation Set is: 58.81% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 27.92 | sMAPE for Test Set is: 41.77% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:00:39,759]\u001b[0m Trial 195 finished with value: 56.20519769457687 and parameters: {'n_hidden': 3, 'learning_rate': 0.008390706977214295, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10385459577898867, 'dropout_rate_Layer_2': 0.35997716075953234, 'dropout_rate_Layer_3': 0.285405658144422, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09833132125502969, 'l1_Layer_2': 0.0008113420349031079, 'l1_Layer_3': 1.3428844811065968e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.21 | sMAPE for Validation Set is: 54.81% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.17 | sMAPE for Test Set is: 42.47% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:01:17,271]\u001b[0m Trial 196 finished with value: 68.22093779890314 and parameters: {'n_hidden': 3, 'learning_rate': 0.006863941908266277, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3539591501435029, 'dropout_rate_Layer_2': 0.06638362838983475, 'dropout_rate_Layer_3': 0.0316302791192066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009720215614264203, 'l1_Layer_2': 1.4914571587192416e-05, 'l1_Layer_3': 0.0001906569890405683, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 105}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 68.22 | sMAPE for Validation Set is: 59.12% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 28.41 | sMAPE for Test Set is: 42.10% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:01:41,841]\u001b[0m Trial 197 finished with value: 59.89452563431454 and parameters: {'n_hidden': 3, 'learning_rate': 0.017881107861121383, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12336655691475171, 'dropout_rate_Layer_2': 0.2835012400988417, 'dropout_rate_Layer_3': 0.27493714721087714, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09192998634411695, 'l1_Layer_2': 0.0006236646411556768, 'l1_Layer_3': 1.3785348144266412e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.89 | sMAPE for Validation Set is: 57.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.37 | sMAPE for Test Set is: 46.54% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:02:15,957]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:02:22,612]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:02:52,903]\u001b[0m Trial 200 finished with value: 57.628835783380204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033758137657584103, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2331052076325333, 'dropout_rate_Layer_2': 0.13951451910707235, 'dropout_rate_Layer_3': 0.12240451407902092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0372259359697049e-05, 'l1_Layer_2': 1.476727760161965e-05, 'l1_Layer_3': 0.0012039775427486411, 'n_units_Layer_1': 250, 'n_units_Layer_2': 290, 'n_units_Layer_3': 220}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.63 | sMAPE for Validation Set is: 56.66% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.56 | sMAPE for Test Set is: 44.41% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:02:56,607]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:03:19,708]\u001b[0m Trial 202 finished with value: 70.87654214391495 and parameters: {'n_hidden': 3, 'learning_rate': 0.007057828108726454, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3539933927129868, 'dropout_rate_Layer_2': 0.05519232949329972, 'dropout_rate_Layer_3': 0.015108233176077195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009516165237686734, 'l1_Layer_2': 2.2952983829819715e-05, 'l1_Layer_3': 8.545290293358998e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 300, 'n_units_Layer_3': 90}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.88 | sMAPE for Validation Set is: 60.72% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 29.90 | sMAPE for Test Set is: 42.88% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:04:03,029]\u001b[0m Trial 203 finished with value: 69.35074626910863 and parameters: {'n_hidden': 3, 'learning_rate': 0.007271721186874131, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35953024960398805, 'dropout_rate_Layer_2': 0.057888361037592935, 'dropout_rate_Layer_3': 0.018548074276104783, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009542668686028778, 'l1_Layer_2': 1.6525398289132234e-05, 'l1_Layer_3': 8.045315083570114e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 300, 'n_units_Layer_3': 90}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 69.35 | sMAPE for Validation Set is: 60.47% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 29.00 | sMAPE for Test Set is: 43.95% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:04:40,225]\u001b[0m Trial 204 finished with value: 68.6275613772192 and parameters: {'n_hidden': 3, 'learning_rate': 0.007046235358939195, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3526283030461939, 'dropout_rate_Layer_2': 0.054346409791206994, 'dropout_rate_Layer_3': 0.04249812334973499, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008581940952365345, 'l1_Layer_2': 2.211932235848615e-05, 'l1_Layer_3': 8.074133126180254e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 90}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 68.63 | sMAPE for Validation Set is: 59.27% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 26.86 | sMAPE for Test Set is: 41.79% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:04:54,589]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:05:09,080]\u001b[0m Trial 206 finished with value: 77.50091633836206 and parameters: {'n_hidden': 3, 'learning_rate': 0.012817172727890243, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23979288435534277, 'dropout_rate_Layer_2': 0.3727435968697024, 'dropout_rate_Layer_3': 0.35242891137853144, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0160823659013037, 'l1_Layer_2': 8.422227243061804e-05, 'l1_Layer_3': 0.002276148317589982, 'n_units_Layer_1': 110, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.50 | sMAPE for Validation Set is: 65.73% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 32.21 | sMAPE for Test Set is: 49.13% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:05:31,770]\u001b[0m Trial 207 finished with value: 73.60692179411039 and parameters: {'n_hidden': 3, 'learning_rate': 0.016136059596359956, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.219802984783565, 'dropout_rate_Layer_2': 0.3885643223609263, 'dropout_rate_Layer_3': 0.36755602856552433, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01273573775486789, 'l1_Layer_2': 1.0227455390915499e-05, 'l1_Layer_3': 0.0006543007658972727, 'n_units_Layer_1': 95, 'n_units_Layer_2': 100, 'n_units_Layer_3': 120}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.61 | sMAPE for Validation Set is: 63.58% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 31.89 | sMAPE for Test Set is: 45.05% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:05:57,908]\u001b[0m Trial 208 finished with value: 70.55771059634687 and parameters: {'n_hidden': 3, 'learning_rate': 0.0057723318630141, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34400298314497446, 'dropout_rate_Layer_2': 0.05671522358920544, 'dropout_rate_Layer_3': 0.04195063165019621, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009134715414771681, 'l1_Layer_2': 2.325645984618651e-05, 'l1_Layer_3': 7.815138785664204e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 285, 'n_units_Layer_3': 95}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.56 | sMAPE for Validation Set is: 60.50% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 30.73 | sMAPE for Test Set is: 43.21% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:06:25,898]\u001b[0m Trial 209 finished with value: 58.07856680009396 and parameters: {'n_hidden': 3, 'learning_rate': 0.017182148421774963, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10403558556759929, 'dropout_rate_Layer_2': 0.3156153937305701, 'dropout_rate_Layer_3': 0.24657024048868406, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.056520326382780865, 'l1_Layer_2': 0.0007370618706265527, 'l1_Layer_3': 1.5233062896485246e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 70, 'n_units_Layer_3': 255}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.08 | sMAPE for Validation Set is: 56.75% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 29.41 | sMAPE for Test Set is: 49.15% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:06:29,668]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:43,111]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:06:57,291]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:07:00,794]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:08:00,308]\u001b[0m Trial 214 finished with value: 67.16380660031871 and parameters: {'n_hidden': 3, 'learning_rate': 0.006026353881710277, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34399588162523054, 'dropout_rate_Layer_2': 0.06802530582595533, 'dropout_rate_Layer_3': 0.0631988405665222, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000423780142209336, 'l1_Layer_2': 1.0162403447290531e-05, 'l1_Layer_3': 9.937956184475396e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 285, 'n_units_Layer_3': 95}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 67.16 | sMAPE for Validation Set is: 59.18% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 28.65 | sMAPE for Test Set is: 41.84% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:08:04,162]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:08:33,954]\u001b[0m Trial 216 finished with value: 58.3278140869265 and parameters: {'n_hidden': 3, 'learning_rate': 0.017206241050338023, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10829842211437057, 'dropout_rate_Layer_2': 0.3119618982713869, 'dropout_rate_Layer_3': 0.24511576668786927, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09597908729964255, 'l1_Layer_2': 0.001194610202808297, 'l1_Layer_3': 1.4376005861129815e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 65, 'n_units_Layer_3': 250}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.33 | sMAPE for Validation Set is: 56.65% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.40 | sMAPE for Test Set is: 43.84% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:09:12,917]\u001b[0m Trial 217 finished with value: 67.17475298210908 and parameters: {'n_hidden': 3, 'learning_rate': 0.005729763211058534, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3321647842689735, 'dropout_rate_Layer_2': 0.040808822139255456, 'dropout_rate_Layer_3': 0.04686639988832886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000414389830586103, 'l1_Layer_2': 1.0174606650885315e-05, 'l1_Layer_3': 6.449569674129667e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 290, 'n_units_Layer_3': 95}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 67.17 | sMAPE for Validation Set is: 59.21% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 27.14 | sMAPE for Test Set is: 42.30% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:09:17,538]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:09:49,467]\u001b[0m Trial 219 finished with value: 58.88927748303618 and parameters: {'n_hidden': 3, 'learning_rate': 0.018581722719592988, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10446941976267664, 'dropout_rate_Layer_2': 0.3207752805117998, 'dropout_rate_Layer_3': 0.2532245666284638, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09874617603544947, 'l1_Layer_2': 0.0012664811209489781, 'l1_Layer_3': 1.5406708024175697e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 60, 'n_units_Layer_3': 285}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.89 | sMAPE for Validation Set is: 57.19% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 30.55 | sMAPE for Test Set is: 49.40% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:10:14,471]\u001b[0m Trial 220 finished with value: 60.95187585319665 and parameters: {'n_hidden': 3, 'learning_rate': 0.03114585008365967, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10568915239094535, 'dropout_rate_Layer_2': 0.3188608488625865, 'dropout_rate_Layer_3': 0.24254389985195426, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.062401182438212945, 'l1_Layer_2': 0.0013043714327512401, 'l1_Layer_3': 1.7932417406616748e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 60, 'n_units_Layer_3': 280}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.95 | sMAPE for Validation Set is: 59.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 30.68 | sMAPE for Test Set is: 48.36% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:10:29,016]\u001b[0m Trial 221 finished with value: 74.07007461345853 and parameters: {'n_hidden': 3, 'learning_rate': 0.017258379782512875, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2072277246180939, 'dropout_rate_Layer_2': 0.3249928360444989, 'dropout_rate_Layer_3': 0.36569602905436666, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013907083312234633, 'l1_Layer_2': 1.1623855646507891e-05, 'l1_Layer_3': 0.000912306319120007, 'n_units_Layer_1': 90, 'n_units_Layer_2': 95, 'n_units_Layer_3': 165}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.07 | sMAPE for Validation Set is: 66.86% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 38.04 | sMAPE for Test Set is: 66.59% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:10:57,107]\u001b[0m Trial 222 finished with value: 70.44198770579429 and parameters: {'n_hidden': 3, 'learning_rate': 0.006376140031310953, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3307250970375616, 'dropout_rate_Layer_2': 0.05646169211875933, 'dropout_rate_Layer_3': 0.0464916711230782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007858753228998587, 'l1_Layer_2': 1.4293740572158207e-05, 'l1_Layer_3': 5.9823106265437964e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 300, 'n_units_Layer_3': 90}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.44 | sMAPE for Validation Set is: 60.56% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 28.51 | sMAPE for Test Set is: 42.88% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:11:05,247]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:11:20,189]\u001b[0m Trial 224 finished with value: 78.60452856019471 and parameters: {'n_hidden': 3, 'learning_rate': 0.01808598127222801, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20906414547673624, 'dropout_rate_Layer_2': 0.32119098178939354, 'dropout_rate_Layer_3': 0.36384621140710394, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014290947298108937, 'l1_Layer_2': 1.338351601383845e-05, 'l1_Layer_3': 0.002564758378984393, 'n_units_Layer_1': 80, 'n_units_Layer_2': 100, 'n_units_Layer_3': 145}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.60 | sMAPE for Validation Set is: 67.30% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 47.61 | sMAPE for Test Set is: 56.69% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:11:56,620]\u001b[0m Trial 225 finished with value: 68.45791867841466 and parameters: {'n_hidden': 3, 'learning_rate': 0.005759072423907795, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33212879080719515, 'dropout_rate_Layer_2': 0.06812975229270979, 'dropout_rate_Layer_3': 0.06293228583570945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003691754082288379, 'l1_Layer_2': 1.4429785656034374e-05, 'l1_Layer_3': 6.125965598288851e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 295, 'n_units_Layer_3': 105}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 68.46 | sMAPE for Validation Set is: 59.94% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 28.61 | sMAPE for Test Set is: 43.68% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:12:26,165]\u001b[0m Trial 226 finished with value: 56.00488327366069 and parameters: {'n_hidden': 3, 'learning_rate': 0.005953929638646243, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3247193137251838, 'dropout_rate_Layer_2': 0.07028817402370197, 'dropout_rate_Layer_3': 0.06064740192424016, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00036544529560216503, 'l1_Layer_2': 1.4304091985903893e-05, 'l1_Layer_3': 5.963642064376692e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 285, 'n_units_Layer_3': 105}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.00 | sMAPE for Validation Set is: 54.79% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.48 | sMAPE for Test Set is: 40.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:12:59,592]\u001b[0m Trial 227 finished with value: 58.35252960104739 and parameters: {'n_hidden': 3, 'learning_rate': 0.012115927216391972, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14352009756951298, 'dropout_rate_Layer_2': 0.32987855814148076, 'dropout_rate_Layer_3': 0.23818168520330874, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06888085645624746, 'l1_Layer_2': 0.0016237937581607587, 'l1_Layer_3': 2.352404295613053e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 50, 'n_units_Layer_3': 270}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.35 | sMAPE for Validation Set is: 56.70% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.63 | sMAPE for Test Set is: 44.88% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:13:34,821]\u001b[0m Trial 228 finished with value: 62.3666306203304 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026773276705625818, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24935978760543687, 'dropout_rate_Layer_2': 0.11989604698789331, 'dropout_rate_Layer_3': 0.143161155424402, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015835266585541654, 'l1_Layer_2': 1.2100290496288177e-05, 'l1_Layer_3': 0.001512652349834048, 'n_units_Layer_1': 300, 'n_units_Layer_2': 265, 'n_units_Layer_3': 205}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.37 | sMAPE for Validation Set is: 59.22% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.36 | sMAPE for Test Set is: 46.54% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:13:55,288]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:14:36,873]\u001b[0m Trial 230 finished with value: 55.57222503856158 and parameters: {'n_hidden': 3, 'learning_rate': 0.006082865192305596, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3240728930433622, 'dropout_rate_Layer_2': 0.07061351997805324, 'dropout_rate_Layer_3': 0.06089377360025014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00032432329329051975, 'l1_Layer_2': 1.5070670117329285e-05, 'l1_Layer_3': 5.658433717230844e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 290, 'n_units_Layer_3': 105}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.57 | sMAPE for Validation Set is: 54.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.40 | sMAPE for Test Set is: 43.11% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:15:04,562]\u001b[0m Trial 231 finished with value: 56.23735098713964 and parameters: {'n_hidden': 3, 'learning_rate': 0.006221682086647966, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3261205548358626, 'dropout_rate_Layer_2': 0.06929616854152136, 'dropout_rate_Layer_3': 0.06233516909202165, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003712638165678218, 'l1_Layer_2': 1.3379177672710473e-05, 'l1_Layer_3': 4.434313934923706e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 295, 'n_units_Layer_3': 110}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.24 | sMAPE for Validation Set is: 55.00% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.82 | sMAPE for Test Set is: 40.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:15:26,747]\u001b[0m Trial 232 finished with value: 55.71044588345209 and parameters: {'n_hidden': 3, 'learning_rate': 0.004433899259298956, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32370865819827305, 'dropout_rate_Layer_2': 0.06962115671186264, 'dropout_rate_Layer_3': 0.06188880886262535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000360150728659672, 'l1_Layer_2': 1.4223814720694901e-05, 'l1_Layer_3': 5.3888312220875025e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 290, 'n_units_Layer_3': 110}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.71 | sMAPE for Validation Set is: 54.33% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.39 | sMAPE for Test Set is: 40.62% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:15:40,676]\u001b[0m Trial 233 finished with value: 74.60581565517786 and parameters: {'n_hidden': 3, 'learning_rate': 0.015558298297049232, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2687721576969171, 'dropout_rate_Layer_2': 0.35959361604648776, 'dropout_rate_Layer_3': 0.31814580905422307, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014620502425180551, 'l1_Layer_2': 3.538109578273454e-05, 'l1_Layer_3': 0.0007714962689003251, 'n_units_Layer_1': 50, 'n_units_Layer_2': 115, 'n_units_Layer_3': 115}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.61 | sMAPE for Validation Set is: 64.56% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 41.30 | sMAPE for Test Set is: 55.39% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:16:06,164]\u001b[0m Trial 234 finished with value: 55.95355226290528 and parameters: {'n_hidden': 3, 'learning_rate': 0.004199205535292578, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32777335710150807, 'dropout_rate_Layer_2': 0.0698145902474804, 'dropout_rate_Layer_3': 0.06611086210572296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00032168990619898727, 'l1_Layer_2': 1.4046183174573719e-05, 'l1_Layer_3': 4.613479210100119e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 290, 'n_units_Layer_3': 125}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.95 | sMAPE for Validation Set is: 55.41% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.53 | sMAPE for Test Set is: 44.02% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:16:18,421]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:16:41,242]\u001b[0m Trial 236 finished with value: 55.61273211044847 and parameters: {'n_hidden': 3, 'learning_rate': 0.004333030738308215, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3158104743929792, 'dropout_rate_Layer_2': 0.06907271767300263, 'dropout_rate_Layer_3': 0.06165883097044834, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00033615195858895905, 'l1_Layer_2': 1.3958208506657726e-05, 'l1_Layer_3': 4.444862896793938e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 290, 'n_units_Layer_3': 125}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.61 | sMAPE for Validation Set is: 55.06% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.14 | sMAPE for Test Set is: 41.20% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:17:03,062]\u001b[0m Trial 237 finished with value: 55.43432294522279 and parameters: {'n_hidden': 3, 'learning_rate': 0.004218527135708912, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31631644877986564, 'dropout_rate_Layer_2': 0.06999072717922075, 'dropout_rate_Layer_3': 0.06295505097553111, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00032467956491051477, 'l1_Layer_2': 1.3013800544404944e-05, 'l1_Layer_3': 4.442485455406094e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 285, 'n_units_Layer_3': 125}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.43 | sMAPE for Validation Set is: 54.56% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.31 | sMAPE for Test Set is: 41.01% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:17:16,440]\u001b[0m Trial 238 finished with value: 76.6812314364142 and parameters: {'n_hidden': 3, 'learning_rate': 0.020052213026769686, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2893336844494761, 'dropout_rate_Layer_2': 0.3533500630209603, 'dropout_rate_Layer_3': 0.2784156590372366, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012364006255278401, 'l1_Layer_2': 2.773759499340471e-05, 'l1_Layer_3': 0.0006431776082592634, 'n_units_Layer_1': 50, 'n_units_Layer_2': 115, 'n_units_Layer_3': 80}. Best is trial 180 with value: 55.42788649587436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 76.68 | sMAPE for Validation Set is: 68.19% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 36.46 | sMAPE for Test Set is: 60.82% | rMAE for Test Set is: 0.86\n",
      "MAE for Validation Set is: 54.82 | sMAPE for Validation Set is: 54.41% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.54 | sMAPE for Test Set is: 41.47% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:17:40,576]\u001b[0m Trial 239 finished with value: 54.82320134434669 and parameters: {'n_hidden': 3, 'learning_rate': 0.004514161761980733, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31296274832555526, 'dropout_rate_Layer_2': 0.06771232309803671, 'dropout_rate_Layer_3': 0.06484800320854608, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003473804161203555, 'l1_Layer_2': 1.1762567492052442e-05, 'l1_Layer_3': 4.0046675927202856e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 125}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:18:01,844]\u001b[0m Trial 240 finished with value: 55.93655800386938 and parameters: {'n_hidden': 3, 'learning_rate': 0.004100335788967014, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31369150138468904, 'dropout_rate_Layer_2': 0.07379818732129648, 'dropout_rate_Layer_3': 0.07789324997545403, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00033136267997414646, 'l1_Layer_2': 1.1770279539681471e-05, 'l1_Layer_3': 4.300034350721204e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 290, 'n_units_Layer_3': 130}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.94 | sMAPE for Validation Set is: 54.45% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.30 | sMAPE for Test Set is: 40.35% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:18:33,217]\u001b[0m Trial 241 finished with value: 73.24650858712153 and parameters: {'n_hidden': 4, 'learning_rate': 0.014787587617980831, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3095561224799537, 'dropout_rate_Layer_2': 0.10938566077897696, 'dropout_rate_Layer_3': 0.14991685620228368, 'dropout_rate_Layer_4': 0.013441626828351871, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.005928201203629637, 'l1_Layer_2': 0.0002327061201081712, 'l1_Layer_3': 0.08496362557843902, 'l1_Layer_4': 1.2308924446739451e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 245, 'n_units_Layer_3': 195, 'n_units_Layer_4': 55}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.25 | sMAPE for Validation Set is: 64.79% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 29.24 | sMAPE for Test Set is: 44.82% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:18:52,685]\u001b[0m Trial 242 finished with value: 55.79470869466899 and parameters: {'n_hidden': 3, 'learning_rate': 0.00440462444601537, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.315532047393993, 'dropout_rate_Layer_2': 0.07374548672224725, 'dropout_rate_Layer_3': 0.08031834304358401, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003445794746123665, 'l1_Layer_2': 1.2111504765664804e-05, 'l1_Layer_3': 4.1558809366297484e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 280, 'n_units_Layer_3': 125}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.79 | sMAPE for Validation Set is: 54.29% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.93 | sMAPE for Test Set is: 41.25% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:19:13,220]\u001b[0m Trial 243 finished with value: 55.37952163410218 and parameters: {'n_hidden': 3, 'learning_rate': 0.004321732743566865, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31736061603120214, 'dropout_rate_Layer_2': 0.07196809550290006, 'dropout_rate_Layer_3': 0.07612276527864116, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027103969909288584, 'l1_Layer_2': 1.0000800476947787e-05, 'l1_Layer_3': 4.355980926486381e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 130}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.38 | sMAPE for Validation Set is: 55.06% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.29 | sMAPE for Test Set is: 42.25% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:19:18,524]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:19:32,919]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:19:44,912]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:19:58,403]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:20:20,290]\u001b[0m Trial 248 finished with value: 54.97022416839227 and parameters: {'n_hidden': 3, 'learning_rate': 0.004277841234493501, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31647349031354544, 'dropout_rate_Layer_2': 0.07163423261983067, 'dropout_rate_Layer_3': 0.0786733341412541, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002808832527489086, 'l1_Layer_2': 1.1265051840083732e-05, 'l1_Layer_3': 4.179204815249742e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 285, 'n_units_Layer_3': 125}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.97 | sMAPE for Validation Set is: 54.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.70 | sMAPE for Test Set is: 41.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:20:35,235]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:20:51,963]\u001b[0m Trial 250 finished with value: 55.895403829337454 and parameters: {'n_hidden': 3, 'learning_rate': 0.004265749471373176, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3149615790293199, 'dropout_rate_Layer_2': 0.07854925401639454, 'dropout_rate_Layer_3': 0.08039103575054951, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002827834121646068, 'l1_Layer_2': 1.1623935405295805e-05, 'l1_Layer_3': 4.075160983645967e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 125}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.90 | sMAPE for Validation Set is: 54.51% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.19 | sMAPE for Test Set is: 39.67% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:20:57,783]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:04,209]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:17,771]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:21:46,778]\u001b[0m Trial 254 finished with value: 57.04851456223474 and parameters: {'n_hidden': 3, 'learning_rate': 0.008510311916167131, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09291846167862515, 'dropout_rate_Layer_2': 0.33925574319042345, 'dropout_rate_Layer_3': 0.213103741773234, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08918336358064674, 'l1_Layer_2': 0.0014948255534573097, 'l1_Layer_3': 2.9068263309231068e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 80, 'n_units_Layer_3': 275}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.05 | sMAPE for Validation Set is: 54.71% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.48 | sMAPE for Test Set is: 44.10% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:21:59,337]\u001b[0m Trial 255 finished with value: 74.45754083832965 and parameters: {'n_hidden': 3, 'learning_rate': 0.02005117760572434, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22580401580003617, 'dropout_rate_Layer_2': 0.35264500435354096, 'dropout_rate_Layer_3': 0.2837282828788589, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.022043515828404515, 'l1_Layer_2': 2.4070604511606562e-05, 'l1_Layer_3': 0.0003993366972720531, 'n_units_Layer_1': 50, 'n_units_Layer_2': 115, 'n_units_Layer_3': 90}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.46 | sMAPE for Validation Set is: 64.66% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 37.77 | sMAPE for Test Set is: 54.30% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:22:32,711]\u001b[0m Trial 256 finished with value: 56.62399325507875 and parameters: {'n_hidden': 3, 'learning_rate': 0.008308539543167837, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08800860909993818, 'dropout_rate_Layer_2': 0.34390113825674573, 'dropout_rate_Layer_3': 0.22196663512214979, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05495805804953413, 'l1_Layer_2': 0.001619533631759576, 'l1_Layer_3': 2.9487073293994145e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 80, 'n_units_Layer_3': 265}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.62 | sMAPE for Validation Set is: 54.89% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 25.53 | sMAPE for Test Set is: 41.33% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:22:53,042]\u001b[0m Trial 257 finished with value: 56.03336439738366 and parameters: {'n_hidden': 3, 'learning_rate': 0.004211865675642551, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3115268097244599, 'dropout_rate_Layer_2': 0.07399788509793413, 'dropout_rate_Layer_3': 0.08526785642230514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002883904897877985, 'l1_Layer_2': 1.1815778948021946e-05, 'l1_Layer_3': 4.005366411299327e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 125}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.03 | sMAPE for Validation Set is: 54.56% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 23.96 | sMAPE for Test Set is: 39.14% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:23:13,834]\u001b[0m Trial 258 finished with value: 55.9941900068475 and parameters: {'n_hidden': 3, 'learning_rate': 0.003918236369922911, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31404202661325287, 'dropout_rate_Layer_2': 0.07591311248814445, 'dropout_rate_Layer_3': 0.08388788092687474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002672252696577442, 'l1_Layer_2': 1.2163544111270571e-05, 'l1_Layer_3': 3.799183948328467e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 125}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.99 | sMAPE for Validation Set is: 53.81% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.16 | sMAPE for Test Set is: 39.65% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:23:19,070]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:23:39,944]\u001b[0m Trial 260 finished with value: 55.528672755028936 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037117934878611236, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31188517153148904, 'dropout_rate_Layer_2': 0.0767272202072062, 'dropout_rate_Layer_3': 0.08429080192861126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002863199518053188, 'l1_Layer_2': 1.2264670379421894e-05, 'l1_Layer_3': 3.8396286995035345e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 125}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.53 | sMAPE for Validation Set is: 53.78% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.08 | sMAPE for Test Set is: 39.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:24:00,535]\u001b[0m Trial 261 finished with value: 100.39233802336332 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033281570179013826, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15719711183852897, 'dropout_rate_Layer_2': 0.1784751155088104, 'dropout_rate_Layer_3': 0.07857426042579232, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002601083279633898, 'l1_Layer_2': 0.09869952112542069, 'l1_Layer_3': 0.0023682362337300563, 'n_units_Layer_1': 260, 'n_units_Layer_2': 115, 'n_units_Layer_3': 290}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 100.39 | sMAPE for Validation Set is: 83.66% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 80.70 | sMAPE for Test Set is: 79.44% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:24:13,985]\u001b[0m Trial 262 finished with value: 76.37531065927162 and parameters: {'n_hidden': 3, 'learning_rate': 0.020830759610166616, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22450025207118574, 'dropout_rate_Layer_2': 0.37477763027206273, 'dropout_rate_Layer_3': 0.3687186526473319, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.053548983913044725, 'l1_Layer_2': 2.2760676288004543e-05, 'l1_Layer_3': 0.0003168940990520824, 'n_units_Layer_1': 70, 'n_units_Layer_2': 115, 'n_units_Layer_3': 125}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 76.38 | sMAPE for Validation Set is: 66.92% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 35.64 | sMAPE for Test Set is: 60.07% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:24:33,764]\u001b[0m Trial 263 finished with value: 55.49448405108319 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036646154318906725, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29714181221644304, 'dropout_rate_Layer_2': 0.09037281142650248, 'dropout_rate_Layer_3': 0.0844681936342863, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025862493023240206, 'l1_Layer_2': 1.2505202751490813e-05, 'l1_Layer_3': 3.303473875824922e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 125}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.49 | sMAPE for Validation Set is: 54.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.16 | sMAPE for Test Set is: 39.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:24:50,703]\u001b[0m Trial 264 finished with value: 56.116505312152704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036461092679350576, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29418839760949184, 'dropout_rate_Layer_2': 0.07864359489333823, 'dropout_rate_Layer_3': 0.09839238042963888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027822473926611635, 'l1_Layer_2': 1.2106272468407986e-05, 'l1_Layer_3': 3.164772310463291e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 280, 'n_units_Layer_3': 130}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.12 | sMAPE for Validation Set is: 54.82% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.99 | sMAPE for Test Set is: 42.31% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:25:08,178]\u001b[0m Trial 265 finished with value: 56.780962664842455 and parameters: {'n_hidden': 3, 'learning_rate': 0.004347086865004559, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3140191435574782, 'dropout_rate_Layer_2': 0.07660253406380009, 'dropout_rate_Layer_3': 0.08298881628133484, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026418141405682214, 'l1_Layer_2': 1.2132012382244068e-05, 'l1_Layer_3': 4.0987138953936044e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 125}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.78 | sMAPE for Validation Set is: 55.18% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 25.37 | sMAPE for Test Set is: 41.69% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:25:26,093]\u001b[0m Trial 266 finished with value: 55.99039044118738 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037302811249995535, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3010545069123691, 'dropout_rate_Layer_2': 0.0897687665524489, 'dropout_rate_Layer_3': 0.07674893774886801, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002183503966847665, 'l1_Layer_2': 1.7367259821837763e-05, 'l1_Layer_3': 3.550954731819289e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.99 | sMAPE for Validation Set is: 55.02% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.12 | sMAPE for Test Set is: 40.98% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:25:56,325]\u001b[0m Trial 267 finished with value: 56.91085364258968 and parameters: {'n_hidden': 3, 'learning_rate': 0.008508122905620355, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07295935451021276, 'dropout_rate_Layer_2': 0.35791529955129403, 'dropout_rate_Layer_3': 0.2227197628952872, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05351188062923137, 'l1_Layer_2': 0.0017618369308070347, 'l1_Layer_3': 2.718699201483613e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 100, 'n_units_Layer_3': 240}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.91 | sMAPE for Validation Set is: 55.11% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.93 | sMAPE for Test Set is: 43.70% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:26:17,899]\u001b[0m Trial 268 finished with value: 55.70817184167697 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036028069283088066, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31938606615281295, 'dropout_rate_Layer_2': 0.09243145388292091, 'dropout_rate_Layer_3': 0.07393886754210086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002161602408642077, 'l1_Layer_2': 1.7781358466235914e-05, 'l1_Layer_3': 3.323548527673714e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.71 | sMAPE for Validation Set is: 54.08% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.96 | sMAPE for Test Set is: 39.89% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:26:39,110]\u001b[0m Trial 269 finished with value: 55.86178715965809 and parameters: {'n_hidden': 3, 'learning_rate': 0.003553692210555403, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30034054750137873, 'dropout_rate_Layer_2': 0.09235496103367619, 'dropout_rate_Layer_3': 0.07490693276685642, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022169436208325784, 'l1_Layer_2': 1.7829490540550618e-05, 'l1_Layer_3': 3.218903655570097e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.86 | sMAPE for Validation Set is: 54.34% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 23.85 | sMAPE for Test Set is: 39.50% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:27:02,031]\u001b[0m Trial 270 finished with value: 55.82409377641522 and parameters: {'n_hidden': 3, 'learning_rate': 0.00822032093494837, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07238453324409627, 'dropout_rate_Layer_2': 0.3832325345817391, 'dropout_rate_Layer_3': 0.22827687927397386, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03097915233494036, 'l1_Layer_2': 0.0027988244022965486, 'l1_Layer_3': 2.8875667249613357e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 100, 'n_units_Layer_3': 265}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.82 | sMAPE for Validation Set is: 55.19% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.37 | sMAPE for Test Set is: 43.99% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:27:23,667]\u001b[0m Trial 271 finished with value: 55.487498736267206 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034333094144716582, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2992226321605626, 'dropout_rate_Layer_2': 0.09170410503368188, 'dropout_rate_Layer_3': 0.07379473290322662, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022434029529515694, 'l1_Layer_2': 1.7858819373656182e-05, 'l1_Layer_3': 2.8484844350967166e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 135}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.49 | sMAPE for Validation Set is: 54.41% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.09 | sMAPE for Test Set is: 42.09% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:27:37,954]\u001b[0m Trial 272 finished with value: 76.1232165086236 and parameters: {'n_hidden': 3, 'learning_rate': 0.01367656385108864, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24152171053159216, 'dropout_rate_Layer_2': 0.3411444136480027, 'dropout_rate_Layer_3': 0.32532543625375304, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.023144219748459417, 'l1_Layer_2': 4.363473953150719e-05, 'l1_Layer_3': 0.0004772586799576208, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 80}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 76.12 | sMAPE for Validation Set is: 64.92% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 34.51 | sMAPE for Test Set is: 46.96% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:27:54,822]\u001b[0m Trial 273 finished with value: 55.02871014850842 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032457585961984583, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3041299982022388, 'dropout_rate_Layer_2': 0.0928188094751197, 'dropout_rate_Layer_3': 0.07447378920337322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001930435187534345, 'l1_Layer_2': 1.8161762340031113e-05, 'l1_Layer_3': 2.9841698541306746e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.03 | sMAPE for Validation Set is: 54.21% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.24 | sMAPE for Test Set is: 41.19% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:28:13,166]\u001b[0m Trial 274 finished with value: 56.92747314070065 and parameters: {'n_hidden': 3, 'learning_rate': 0.008661679738388694, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07574879435145669, 'dropout_rate_Layer_2': 0.3573476258607864, 'dropout_rate_Layer_3': 0.22209393280222783, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03069962889395674, 'l1_Layer_2': 0.0038879541779393064, 'l1_Layer_3': 3.0465547324873006e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 105, 'n_units_Layer_3': 235}. Best is trial 239 with value: 54.82320134434669.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.93 | sMAPE for Validation Set is: 56.00% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.57 | sMAPE for Test Set is: 44.73% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:28:17,158]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:28:41,407]\u001b[0m Trial 276 finished with value: 54.791386096080565 and parameters: {'n_hidden': 3, 'learning_rate': 0.003272969980012148, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.285028375947438, 'dropout_rate_Layer_2': 0.09277511231789826, 'dropout_rate_Layer_3': 0.09996195445074108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015095838316262806, 'l1_Layer_2': 1.7451251769925305e-05, 'l1_Layer_3': 2.82538835895073e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 135}. Best is trial 276 with value: 54.791386096080565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.79 | sMAPE for Validation Set is: 54.12% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.74 | sMAPE for Test Set is: 40.59% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:28:59,155]\u001b[0m Trial 277 finished with value: 55.32973941546897 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030570556126107763, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28600671704261504, 'dropout_rate_Layer_2': 0.09344128464086288, 'dropout_rate_Layer_3': 0.09184878328041333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015815653241124702, 'l1_Layer_2': 1.80489458289691e-05, 'l1_Layer_3': 2.544754417703133e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 276 with value: 54.791386096080565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.33 | sMAPE for Validation Set is: 54.44% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.94 | sMAPE for Test Set is: 40.72% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:29:14,053]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:29:42,493]\u001b[0m Trial 279 finished with value: 56.16799552643099 and parameters: {'n_hidden': 3, 'learning_rate': 0.009502349187426118, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07229281649877094, 'dropout_rate_Layer_2': 0.36237893733802395, 'dropout_rate_Layer_3': 0.22495120567936974, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.029791678633851355, 'l1_Layer_2': 0.003164342214364119, 'l1_Layer_3': 5.003631021894738e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 105, 'n_units_Layer_3': 235}. Best is trial 276 with value: 54.791386096080565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.17 | sMAPE for Validation Set is: 54.47% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.08 | sMAPE for Test Set is: 41.86% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:30:07,209]\u001b[0m Trial 280 finished with value: 55.36675131581081 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030318696518076686, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28817159423390193, 'dropout_rate_Layer_2': 0.09427639417073502, 'dropout_rate_Layer_3': 0.09365789818211487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015571669336964864, 'l1_Layer_2': 1.6472598700991572e-05, 'l1_Layer_3': 2.4749466947800325e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 276 with value: 54.791386096080565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.37 | sMAPE for Validation Set is: 54.30% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.45 | sMAPE for Test Set is: 40.04% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:30:12,219]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:30:24,922]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:30:39,850]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:31:12,747]\u001b[0m Trial 284 finished with value: 75.83824166842457 and parameters: {'n_hidden': 3, 'learning_rate': 0.010984941722477335, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31274706423057813, 'dropout_rate_Layer_2': 0.3579074241628596, 'dropout_rate_Layer_3': 0.3350261532982993, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010043781791208791, 'l1_Layer_2': 7.427928604733085e-05, 'l1_Layer_3': 0.0006924514143150245, 'n_units_Layer_1': 70, 'n_units_Layer_2': 80, 'n_units_Layer_3': 50}. Best is trial 276 with value: 54.791386096080565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.84 | sMAPE for Validation Set is: 65.14% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 30.56 | sMAPE for Test Set is: 44.97% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:31:20,303]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:31:43,820]\u001b[0m Trial 286 finished with value: 54.910817481349234 and parameters: {'n_hidden': 3, 'learning_rate': 0.003118679308998806, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28690928322541426, 'dropout_rate_Layer_2': 0.0919121667065112, 'dropout_rate_Layer_3': 0.09301974123034482, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001305696094431157, 'l1_Layer_2': 1.778483708279795e-05, 'l1_Layer_3': 2.3557241372980405e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 276 with value: 54.791386096080565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.91 | sMAPE for Validation Set is: 53.93% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.06 | sMAPE for Test Set is: 40.74% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:32:02,454]\u001b[0m Trial 287 finished with value: 54.82209870686474 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029634322309155005, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28724785175469336, 'dropout_rate_Layer_2': 0.08884091400816954, 'dropout_rate_Layer_3': 0.10486477847984757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001381452907367115, 'l1_Layer_2': 1.589091133731707e-05, 'l1_Layer_3': 2.6319899139206716e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 285, 'n_units_Layer_3': 135}. Best is trial 276 with value: 54.791386096080565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.82 | sMAPE for Validation Set is: 54.00% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.86 | sMAPE for Test Set is: 41.30% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:32:29,558]\u001b[0m Trial 288 finished with value: 56.09684385904608 and parameters: {'n_hidden': 3, 'learning_rate': 0.007084789923522958, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.054775844075009336, 'dropout_rate_Layer_2': 0.38351338900664056, 'dropout_rate_Layer_3': 0.2237891017664112, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.024908645565340008, 'l1_Layer_2': 0.006511593803282114, 'l1_Layer_3': 6.70663169444042e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 276 with value: 54.791386096080565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.10 | sMAPE for Validation Set is: 54.75% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.12 | sMAPE for Test Set is: 40.17% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:32:54,173]\u001b[0m Trial 289 finished with value: 54.18004926531916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027762594760774137, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.285543797903222, 'dropout_rate_Layer_2': 0.08736603333498344, 'dropout_rate_Layer_3': 0.0936119947549028, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015370106471347287, 'l1_Layer_2': 1.60211600203148e-05, 'l1_Layer_3': 2.3042218450767116e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 285, 'n_units_Layer_3': 135}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.18 | sMAPE for Validation Set is: 53.11% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 24.64 | sMAPE for Test Set is: 41.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:33:17,714]\u001b[0m Trial 290 finished with value: 54.89599486405165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030632783229607406, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28334060493054514, 'dropout_rate_Layer_2': 0.09840919551653064, 'dropout_rate_Layer_3': 0.10270822846817337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013030671220659568, 'l1_Layer_2': 1.9579281842345493e-05, 'l1_Layer_3': 2.4151435116323197e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.90 | sMAPE for Validation Set is: 54.57% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.44 | sMAPE for Test Set is: 40.45% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:33:41,453]\u001b[0m Trial 291 finished with value: 56.54856762174788 and parameters: {'n_hidden': 3, 'learning_rate': 0.007388674221921673, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05853260701026062, 'dropout_rate_Layer_2': 0.3848232445532727, 'dropout_rate_Layer_3': 0.22575520740876767, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03401674637555686, 'l1_Layer_2': 0.006673004135739666, 'l1_Layer_3': 4.8820047696882295e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 105, 'n_units_Layer_3': 240}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.55 | sMAPE for Validation Set is: 55.29% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 25.88 | sMAPE for Test Set is: 41.70% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:34:10,405]\u001b[0m Trial 292 finished with value: 55.93592296616103 and parameters: {'n_hidden': 3, 'learning_rate': 0.006949466025463501, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.059702389311332045, 'dropout_rate_Layer_2': 0.38710427713210993, 'dropout_rate_Layer_3': 0.2269994965882123, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02374089540897505, 'l1_Layer_2': 0.008342811848818509, 'l1_Layer_3': 6.850509381576251e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 115, 'n_units_Layer_3': 245}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.94 | sMAPE for Validation Set is: 54.18% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.06 | sMAPE for Test Set is: 43.51% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:34:24,234]\u001b[0m Trial 293 finished with value: 70.60228302558956 and parameters: {'n_hidden': 3, 'learning_rate': 0.016346530398073208, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22736877235087177, 'dropout_rate_Layer_2': 0.33603261148875113, 'dropout_rate_Layer_3': 0.37594207348151487, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.038903735006760316, 'l1_Layer_2': 1.697430363751707e-05, 'l1_Layer_3': 0.0002737232702897102, 'n_units_Layer_1': 125, 'n_units_Layer_2': 75, 'n_units_Layer_3': 100}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.60 | sMAPE for Validation Set is: 63.33% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 32.24 | sMAPE for Test Set is: 54.10% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:34:50,460]\u001b[0m Trial 294 finished with value: 54.912774843349155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029512300125865594, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2854490910031492, 'dropout_rate_Layer_2': 0.08561958489459627, 'dropout_rate_Layer_3': 0.10319761365363965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014710568696378793, 'l1_Layer_2': 1.878701924629219e-05, 'l1_Layer_3': 2.4721684936637788e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 285, 'n_units_Layer_3': 145}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.91 | sMAPE for Validation Set is: 53.66% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.39 | sMAPE for Test Set is: 39.60% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:35:55,438]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:10,004]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:13,589]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:36:35,038]\u001b[0m Trial 298 finished with value: 56.12874267385492 and parameters: {'n_hidden': 3, 'learning_rate': 0.007125630020212056, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06176113029816844, 'dropout_rate_Layer_2': 0.3880368579036268, 'dropout_rate_Layer_3': 0.20054347914016907, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017085557987813242, 'l1_Layer_2': 0.009366406385686641, 'l1_Layer_3': 8.593000166451487e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 120, 'n_units_Layer_3': 265}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.13 | sMAPE for Validation Set is: 54.60% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.57 | sMAPE for Test Set is: 41.78% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:36:58,565]\u001b[0m Trial 299 finished with value: 55.12018109491959 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028618135111314388, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27392942650856844, 'dropout_rate_Layer_2': 0.09757073917621281, 'dropout_rate_Layer_3': 0.09843782225685865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016125926587087316, 'l1_Layer_2': 1.6264735553140036e-05, 'l1_Layer_3': 2.3051816114751723e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 265, 'n_units_Layer_3': 145}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.12 | sMAPE for Validation Set is: 54.38% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.49 | sMAPE for Test Set is: 40.37% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:37:09,664]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:37:30,607]\u001b[0m Trial 301 finished with value: 55.03084052145197 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024944094084391314, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2705038157115764, 'dropout_rate_Layer_2': 0.09731751300323074, 'dropout_rate_Layer_3': 0.09163813653369828, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011285318768495391, 'l1_Layer_2': 1.6863345248911546e-05, 'l1_Layer_3': 2.0725125204038695e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.03 | sMAPE for Validation Set is: 54.32% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.85 | sMAPE for Test Set is: 40.31% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:37:58,215]\u001b[0m Trial 302 finished with value: 56.13146163593388 and parameters: {'n_hidden': 3, 'learning_rate': 0.006581120339575872, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05612040141657728, 'dropout_rate_Layer_2': 0.38398823290207756, 'dropout_rate_Layer_3': 0.2000302121611477, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016676136417324215, 'l1_Layer_2': 0.011118811792491433, 'l1_Layer_3': 6.879330665200559e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 125, 'n_units_Layer_3': 245}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.13 | sMAPE for Validation Set is: 54.45% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.93 | sMAPE for Test Set is: 42.13% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:38:23,258]\u001b[0m Trial 303 finished with value: 54.578314955808686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024625221007082585, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27200089445294084, 'dropout_rate_Layer_2': 0.09760557448325465, 'dropout_rate_Layer_3': 0.10944743958699818, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011674122753085723, 'l1_Layer_2': 1.993197359989523e-05, 'l1_Layer_3': 2.0535632515746047e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.58 | sMAPE for Validation Set is: 53.37% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.35 | sMAPE for Test Set is: 39.94% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:38:31,813]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:38:43,273]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:00,986]\u001b[0m Trial 306 finished with value: 54.702785712553464 and parameters: {'n_hidden': 3, 'learning_rate': 0.002648796041561519, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28838405031673203, 'dropout_rate_Layer_2': 0.08772656182543298, 'dropout_rate_Layer_3': 0.09342356673506233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010713358757207404, 'l1_Layer_2': 1.981267476116732e-05, 'l1_Layer_3': 1.9383107204939564e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.70 | sMAPE for Validation Set is: 54.02% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.47 | sMAPE for Test Set is: 40.78% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:39:18,968]\u001b[0m Trial 307 finished with value: 55.075085256971214 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025521695238086605, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2888286900825243, 'dropout_rate_Layer_2': 0.09559748794877623, 'dropout_rate_Layer_3': 0.09287147755451798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.66413576296378e-05, 'l1_Layer_2': 2.0522252610587875e-05, 'l1_Layer_3': 1.8766452949618208e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.08 | sMAPE for Validation Set is: 53.93% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.11 | sMAPE for Test Set is: 40.93% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:39:42,482]\u001b[0m Trial 308 finished with value: 54.74269304237621 and parameters: {'n_hidden': 3, 'learning_rate': 0.002444865191676246, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2865184899293332, 'dropout_rate_Layer_2': 0.09838365975177178, 'dropout_rate_Layer_3': 0.10306657606521621, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.998228505389766e-05, 'l1_Layer_2': 2.1605001941025524e-05, 'l1_Layer_3': 1.9233699922226114e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.74 | sMAPE for Validation Set is: 53.72% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.88 | sMAPE for Test Set is: 40.91% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:39:46,808]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:39:54,585]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:40:18,401]\u001b[0m Trial 311 finished with value: 57.006031817216524 and parameters: {'n_hidden': 3, 'learning_rate': 0.007029102660549393, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05054387023898993, 'dropout_rate_Layer_2': 0.38547268885835495, 'dropout_rate_Layer_3': 0.19242965312225868, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01744504379460795, 'l1_Layer_2': 0.009390198762367352, 'l1_Layer_3': 6.476066336767416e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 225}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.01 | sMAPE for Validation Set is: 54.82% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.59 | sMAPE for Test Set is: 42.33% | rMAE for Test Set is: 0.62\n",
      "MAE for Validation Set is: 57.78 | sMAPE for Validation Set is: 55.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.14 | sMAPE for Test Set is: 43.48% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:40:55,335]\u001b[0m Trial 312 finished with value: 57.78130182269052 and parameters: {'n_hidden': 3, 'learning_rate': 0.0051280913319539925, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2866320827374462, 'dropout_rate_Layer_2': 0.08748857987610908, 'dropout_rate_Layer_3': 0.044572901808191345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.999814669262033e-05, 'l1_Layer_2': 0.002117659792827831, 'l1_Layer_3': 0.0025288851162730023, 'n_units_Layer_1': 190, 'n_units_Layer_2': 230, 'n_units_Layer_3': 170}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:41:19,402]\u001b[0m Trial 313 finished with value: 55.02753871812282 and parameters: {'n_hidden': 3, 'learning_rate': 0.002529935911687128, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28770270859437663, 'dropout_rate_Layer_2': 0.117634755973655, 'dropout_rate_Layer_3': 0.09289244524996847, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.75623394776002e-05, 'l1_Layer_2': 2.103390317754441e-05, 'l1_Layer_3': 1.9167880951928015e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 250, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.03 | sMAPE for Validation Set is: 55.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.95 | sMAPE for Test Set is: 42.00% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:41:33,054]\u001b[0m Trial 314 finished with value: 72.84343588546723 and parameters: {'n_hidden': 3, 'learning_rate': 0.01565428520112131, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23481774585004228, 'dropout_rate_Layer_2': 0.3373164288014486, 'dropout_rate_Layer_3': 0.38209244485447896, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.020301398222601658, 'l1_Layer_2': 4.548510058562228e-05, 'l1_Layer_3': 0.000503023110776814, 'n_units_Layer_1': 70, 'n_units_Layer_2': 75, 'n_units_Layer_3': 130}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.84 | sMAPE for Validation Set is: 63.86% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 36.68 | sMAPE for Test Set is: 52.77% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:41:54,945]\u001b[0m Trial 315 finished with value: 54.68536012456161 and parameters: {'n_hidden': 3, 'learning_rate': 0.002489677306688115, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28763502758814774, 'dropout_rate_Layer_2': 0.11969334483512475, 'dropout_rate_Layer_3': 0.1153179669033394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.265203431694839e-05, 'l1_Layer_2': 2.1708290582586513e-05, 'l1_Layer_3': 1.9061534596148355e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.69 | sMAPE for Validation Set is: 54.13% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.74 | sMAPE for Test Set is: 41.29% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:41:59,503]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:42:23,018]\u001b[0m Trial 317 finished with value: 54.82477524094645 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025253907113002554, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2732023323190256, 'dropout_rate_Layer_2': 0.11552124643003228, 'dropout_rate_Layer_3': 0.11788545638651914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010105143822240573, 'l1_Layer_2': 2.0591342163726843e-05, 'l1_Layer_3': 1.8534789805341414e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.82 | sMAPE for Validation Set is: 53.49% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.00 | sMAPE for Test Set is: 38.99% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:42:49,372]\u001b[0m Trial 318 finished with value: 54.82292395613075 and parameters: {'n_hidden': 3, 'learning_rate': 0.002381547681898155, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27226488033712665, 'dropout_rate_Layer_2': 0.12290480359293224, 'dropout_rate_Layer_3': 0.12128054789598855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.655762543861772e-05, 'l1_Layer_2': 2.5348660917257834e-05, 'l1_Layer_3': 1.936347976155781e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 155}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.82 | sMAPE for Validation Set is: 54.19% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.11 | sMAPE for Test Set is: 41.43% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:43:02,768]\u001b[0m Trial 319 finished with value: 73.8971049576429 and parameters: {'n_hidden': 3, 'learning_rate': 0.018505180967387944, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22733594581386127, 'dropout_rate_Layer_2': 0.3358646576487342, 'dropout_rate_Layer_3': 0.3999137365638063, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.022173203136975284, 'l1_Layer_2': 1.745635216970014e-05, 'l1_Layer_3': 0.00022910678786798252, 'n_units_Layer_1': 95, 'n_units_Layer_2': 75, 'n_units_Layer_3': 135}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.90 | sMAPE for Validation Set is: 65.43% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 33.58 | sMAPE for Test Set is: 52.59% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:43:07,723]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:43:12,913]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:43:24,891]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:43:52,482]\u001b[0m Trial 323 finished with value: 54.81851954398667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025249816434011994, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.279193823874304, 'dropout_rate_Layer_2': 0.11798059323214533, 'dropout_rate_Layer_3': 0.1158245551694885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.647836024953019e-05, 'l1_Layer_2': 2.4594263853284784e-05, 'l1_Layer_3': 1.7820534219367018e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.82 | sMAPE for Validation Set is: 53.48% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.66 | sMAPE for Test Set is: 39.95% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:44:21,673]\u001b[0m Trial 324 finished with value: 54.97461560165582 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025378562348769757, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2790389105534846, 'dropout_rate_Layer_2': 0.12025411399595169, 'dropout_rate_Layer_3': 0.11369057435251463, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.924446631064627e-05, 'l1_Layer_2': 2.446738976180517e-05, 'l1_Layer_3': 1.7738664079952024e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.97 | sMAPE for Validation Set is: 53.62% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.67 | sMAPE for Test Set is: 40.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:44:26,105]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:44:45,478]\u001b[0m Trial 326 finished with value: 55.07337204797026 and parameters: {'n_hidden': 3, 'learning_rate': 0.002185361358923529, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28004612203553025, 'dropout_rate_Layer_2': 0.12110224458710248, 'dropout_rate_Layer_3': 0.10649307467450438, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010253987333597132, 'l1_Layer_2': 2.5240011288420928e-05, 'l1_Layer_3': 1.4283100293921416e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 255, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.07 | sMAPE for Validation Set is: 54.04% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.15 | sMAPE for Test Set is: 41.48% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:45:02,853]\u001b[0m Trial 327 finished with value: 54.76638148992561 and parameters: {'n_hidden': 3, 'learning_rate': 0.002108718557451945, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2616463911353515, 'dropout_rate_Layer_2': 0.11864030989922014, 'dropout_rate_Layer_3': 0.11392023111993324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.925924125210452e-05, 'l1_Layer_2': 3.111204034227694e-05, 'l1_Layer_3': 1.663024981755843e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 255, 'n_units_Layer_3': 160}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.77 | sMAPE for Validation Set is: 53.53% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.56 | sMAPE for Test Set is: 40.85% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:45:27,138]\u001b[0m Trial 328 finished with value: 56.17413310674315 and parameters: {'n_hidden': 3, 'learning_rate': 0.007238488635067471, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05944286237806807, 'dropout_rate_Layer_2': 0.38277095523134497, 'dropout_rate_Layer_3': 0.25963083286814503, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03641861295789705, 'l1_Layer_2': 0.007816329625134807, 'l1_Layer_3': 0.00013421620324705535, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.17 | sMAPE for Validation Set is: 54.70% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.37 | sMAPE for Test Set is: 42.77% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:45:31,747]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:45:43,823]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:45:51,582]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:46:37,545]\u001b[0m Trial 332 finished with value: 56.016894392030416 and parameters: {'n_hidden': 3, 'learning_rate': 0.005255793101209297, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07715640266374679, 'dropout_rate_Layer_2': 0.36196246428338125, 'dropout_rate_Layer_3': 0.2623268525843827, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03823991808844169, 'l1_Layer_2': 0.008558683527415754, 'l1_Layer_3': 7.23264623233419e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 90, 'n_units_Layer_3': 245}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.02 | sMAPE for Validation Set is: 54.28% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.89 | sMAPE for Test Set is: 39.46% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:47:08,906]\u001b[0m Trial 333 finished with value: 55.85609336058521 and parameters: {'n_hidden': 3, 'learning_rate': 0.003963299236938493, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07366537791881425, 'dropout_rate_Layer_2': 0.3882696043474974, 'dropout_rate_Layer_3': 0.256879662578175, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03611843827173036, 'l1_Layer_2': 0.008828331039288793, 'l1_Layer_3': 7.446540302118468e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 120, 'n_units_Layer_3': 275}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.86 | sMAPE for Validation Set is: 54.31% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.54 | sMAPE for Test Set is: 41.69% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:47:24,355]\u001b[0m Trial 334 finished with value: 78.16994341105637 and parameters: {'n_hidden': 3, 'learning_rate': 0.011370081680089725, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19206507882504403, 'dropout_rate_Layer_2': 0.3386075458820653, 'dropout_rate_Layer_3': 0.3768232426249697, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.029165442260190497, 'l1_Layer_2': 5.302627145454783e-05, 'l1_Layer_3': 0.000227550136267083, 'n_units_Layer_1': 120, 'n_units_Layer_2': 85, 'n_units_Layer_3': 130}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.17 | sMAPE for Validation Set is: 71.54% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 39.78 | sMAPE for Test Set is: 68.62% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:47:32,328]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:47:43,604]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:48:15,861]\u001b[0m Trial 337 finished with value: 55.83923632450387 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038957494274649224, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07604888722245483, 'dropout_rate_Layer_2': 0.39986315056636085, 'dropout_rate_Layer_3': 0.23366231188751818, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016223181234141962, 'l1_Layer_2': 0.009295510022946107, 'l1_Layer_3': 7.730493641228855e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 140, 'n_units_Layer_3': 275}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.84 | sMAPE for Validation Set is: 54.09% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.31 | sMAPE for Test Set is: 41.39% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:48:20,663]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:48:50,709]\u001b[0m Trial 339 finished with value: 55.90300609020104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036712505948334373, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0810030413859163, 'dropout_rate_Layer_2': 0.39167102830499245, 'dropout_rate_Layer_3': 0.27618292144669987, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011666144710931534, 'l1_Layer_2': 0.008776708889329278, 'l1_Layer_3': 7.3929874910084e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.90 | sMAPE for Validation Set is: 54.14% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.56 | sMAPE for Test Set is: 41.83% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:49:11,961]\u001b[0m Trial 340 finished with value: 55.20522633613151 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026263007687756007, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2770497204806963, 'dropout_rate_Layer_2': 0.13530301569063805, 'dropout_rate_Layer_3': 0.11800099649166909, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.829087831710912e-05, 'l1_Layer_2': 2.2133482343308367e-05, 'l1_Layer_3': 1.5225767278059253e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 260, 'n_units_Layer_3': 140}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.21 | sMAPE for Validation Set is: 54.28% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.37 | sMAPE for Test Set is: 40.19% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:49:18,745]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:49:22,955]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:49:27,594]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:49:32,463]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:49:36,213]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:49:53,379]\u001b[0m Trial 346 finished with value: 72.87573734000657 and parameters: {'n_hidden': 3, 'learning_rate': 0.042214872630449075, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2080439992266385, 'dropout_rate_Layer_2': 0.3023286758389714, 'dropout_rate_Layer_3': 0.3538067720453914, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004504786701230735, 'l1_Layer_2': 2.8142618026475976e-05, 'l1_Layer_3': 0.00021561612317451366, 'n_units_Layer_1': 100, 'n_units_Layer_2': 100, 'n_units_Layer_3': 105}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.88 | sMAPE for Validation Set is: 64.09% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 31.20 | sMAPE for Test Set is: 47.21% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:50:00,255]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:50:12,497]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:50:35,867]\u001b[0m Trial 349 finished with value: 54.769056176307856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023768918279505726, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26906555374602514, 'dropout_rate_Layer_2': 0.11003183350051167, 'dropout_rate_Layer_3': 0.10340992360077489, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011545949549252878, 'l1_Layer_2': 2.2927518224821466e-05, 'l1_Layer_3': 2.048229312021365e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.77 | sMAPE for Validation Set is: 53.39% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.61 | sMAPE for Test Set is: 40.75% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:50:57,993]\u001b[0m Trial 350 finished with value: 54.718277253790774 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032163744034880274, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.283725372898846, 'dropout_rate_Layer_2': 0.10650956107002768, 'dropout_rate_Layer_3': 0.1060096930008167, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011977191036318625, 'l1_Layer_2': 2.8826063363945138e-05, 'l1_Layer_3': 1.4663185620125593e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.72 | sMAPE for Validation Set is: 53.51% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.80 | sMAPE for Test Set is: 41.55% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:51:06,460]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:51:26,026]\u001b[0m Trial 352 finished with value: 54.94442829665119 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023236931812993457, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28166327249528167, 'dropout_rate_Layer_2': 0.11180151860751328, 'dropout_rate_Layer_3': 0.10623133642448726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.812487409779787e-05, 'l1_Layer_2': 2.9598582640336846e-05, 'l1_Layer_3': 1.4847857025222164e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.94 | sMAPE for Validation Set is: 53.98% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.66 | sMAPE for Test Set is: 40.64% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:51:38,566]\u001b[0m Trial 353 finished with value: 75.47958499427516 and parameters: {'n_hidden': 3, 'learning_rate': 0.03039829276391901, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24887834362823671, 'dropout_rate_Layer_2': 0.38363865048817686, 'dropout_rate_Layer_3': 0.3955622340272991, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020205143045900854, 'l1_Layer_2': 5.275107148432236e-05, 'l1_Layer_3': 0.00016997294646209772, 'n_units_Layer_1': 160, 'n_units_Layer_2': 105, 'n_units_Layer_3': 125}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.48 | sMAPE for Validation Set is: 66.86% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 33.27 | sMAPE for Test Set is: 51.53% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:51:52,095]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:52:15,660]\u001b[0m Trial 355 finished with value: 54.721676674884826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023096423326423644, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27648907457554933, 'dropout_rate_Layer_2': 0.10583066895769827, 'dropout_rate_Layer_3': 0.10716881357624397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012116020905888983, 'l1_Layer_2': 2.8652708398925982e-05, 'l1_Layer_3': 1.5075924238971418e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.72 | sMAPE for Validation Set is: 53.61% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.81 | sMAPE for Test Set is: 41.04% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:52:40,586]\u001b[0m Trial 356 finished with value: 54.8826185790933 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022866072976550763, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2495378497128916, 'dropout_rate_Layer_2': 0.11006346449320277, 'dropout_rate_Layer_3': 0.10383310284160924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001266190059630669, 'l1_Layer_2': 3.1064915198717076e-05, 'l1_Layer_3': 1.4328170454550047e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 260, 'n_units_Layer_3': 170}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.88 | sMAPE for Validation Set is: 53.49% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.65 | sMAPE for Test Set is: 40.27% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:53:07,446]\u001b[0m Trial 357 finished with value: 55.60879476425702 and parameters: {'n_hidden': 3, 'learning_rate': 0.0042403582275612655, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06651507195284055, 'dropout_rate_Layer_2': 0.3878768852824551, 'dropout_rate_Layer_3': 0.2374015818052148, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01636482437799844, 'l1_Layer_2': 0.010252990217651987, 'l1_Layer_3': 6.664930954140992e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.61 | sMAPE for Validation Set is: 53.67% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.48 | sMAPE for Test Set is: 41.95% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:53:11,863]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:53:16,344]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:53:23,055]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:53:29,196]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:53:33,689]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:53:58,462]\u001b[0m Trial 363 finished with value: 58.275876775429445 and parameters: {'n_hidden': 3, 'learning_rate': 0.005292812944113864, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08206361561399962, 'dropout_rate_Layer_2': 0.3864200312037469, 'dropout_rate_Layer_3': 0.2502178750704173, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.021153784937103598, 'l1_Layer_2': 0.015229892296851627, 'l1_Layer_3': 0.00010427097332781256, 'n_units_Layer_1': 160, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.28 | sMAPE for Validation Set is: 56.67% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.89 | sMAPE for Test Set is: 43.84% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:54:10,203]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:54:16,278]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:54:36,841]\u001b[0m Trial 366 finished with value: 55.27047530232611 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027959848378681165, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29218593109927354, 'dropout_rate_Layer_2': 0.11009444249362976, 'dropout_rate_Layer_3': 0.1283754669551165, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.119958297674627e-05, 'l1_Layer_2': 2.8255047031084705e-05, 'l1_Layer_3': 2.209122570756851e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 265, 'n_units_Layer_3': 165}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.27 | sMAPE for Validation Set is: 54.59% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.95 | sMAPE for Test Set is: 41.47% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:54:41,145]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:54:46,993]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:54:52,975]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:55:03,436]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:55:14,237]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:55:21,253]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:55:25,409]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:55:29,711]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:55:34,145]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:55:38,642]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:55:45,034]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:55:50,285]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:55:54,778]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:56:07,512]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:56:31,263]\u001b[0m Trial 381 finished with value: 58.33010473498863 and parameters: {'n_hidden': 3, 'learning_rate': 0.003257584059591476, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06585820507075842, 'dropout_rate_Layer_2': 0.3906339931074125, 'dropout_rate_Layer_3': 0.24936091130787932, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03484296771111048, 'l1_Layer_2': 0.019634758431872353, 'l1_Layer_3': 0.0001191707091834698, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 275}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.33 | sMAPE for Validation Set is: 57.14% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.87 | sMAPE for Test Set is: 43.96% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:56:50,306]\u001b[0m Trial 382 finished with value: 54.94107569227057 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026443439652233404, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2935618615719928, 'dropout_rate_Layer_2': 0.10737438453499583, 'dropout_rate_Layer_3': 0.11545366069027997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012130731758387011, 'l1_Layer_2': 2.750702055909671e-05, 'l1_Layer_3': 1.2280591843771583e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 250, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.94 | sMAPE for Validation Set is: 54.71% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.18 | sMAPE for Test Set is: 40.99% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:56:57,018]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:57:21,213]\u001b[0m Trial 384 finished with value: 54.59127087051322 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027573642557171536, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29012053163060864, 'dropout_rate_Layer_2': 0.10070889344148434, 'dropout_rate_Layer_3': 0.1208898878666278, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.705018495197519e-05, 'l1_Layer_2': 4.444962989831447e-05, 'l1_Layer_3': 1.3469474415908418e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 265, 'n_units_Layer_3': 140}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.59 | sMAPE for Validation Set is: 54.44% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.90 | sMAPE for Test Set is: 41.62% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:57:25,685]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:57:45,237]\u001b[0m Trial 386 finished with value: 55.10704291954797 and parameters: {'n_hidden': 3, 'learning_rate': 0.002767725876094718, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.288710093988977, 'dropout_rate_Layer_2': 0.10657056433748113, 'dropout_rate_Layer_3': 0.1191236353169893, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.225306889118873e-05, 'l1_Layer_2': 2.815535570874998e-05, 'l1_Layer_3': 1.257316684414644e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 140}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.11 | sMAPE for Validation Set is: 53.59% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.60 | sMAPE for Test Set is: 40.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:58:02,370]\u001b[0m Trial 387 finished with value: 55.01350811052495 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032837969979019636, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30203032602452273, 'dropout_rate_Layer_2': 0.10062044660614544, 'dropout_rate_Layer_3': 0.10866432489309258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013361604600031497, 'l1_Layer_2': 4.442215550354694e-05, 'l1_Layer_3': 1.4685889593730519e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.01 | sMAPE for Validation Set is: 53.85% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.00 | sMAPE for Test Set is: 41.47% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:58:24,984]\u001b[0m Trial 388 finished with value: 54.8165461068069 and parameters: {'n_hidden': 3, 'learning_rate': 0.002661961336851891, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2663143503567436, 'dropout_rate_Layer_2': 0.11555576869351061, 'dropout_rate_Layer_3': 0.12300738420383378, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.23131776010121e-05, 'l1_Layer_2': 2.205411993034994e-05, 'l1_Layer_3': 2.0030283147545496e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 250, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.82 | sMAPE for Validation Set is: 54.20% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.06 | sMAPE for Test Set is: 42.05% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:58:32,197]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 02:59:23,656]\u001b[0m Trial 390 finished with value: 58.43393120433143 and parameters: {'n_hidden': 4, 'learning_rate': 0.01151860931473711, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33431486661255894, 'dropout_rate_Layer_2': 0.07615233485043753, 'dropout_rate_Layer_3': 0.04580882013092191, 'dropout_rate_Layer_4': 0.14333172370616323, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.81241751683315e-05, 'l1_Layer_2': 9.076839699188768e-05, 'l1_Layer_3': 0.0020411332851628518, 'l1_Layer_4': 1.6184954384486326e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 230, 'n_units_Layer_3': 265, 'n_units_Layer_4': 165}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.43 | sMAPE for Validation Set is: 56.20% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.23 | sMAPE for Test Set is: 42.85% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 02:59:57,533]\u001b[0m Trial 391 finished with value: 58.64281112345376 and parameters: {'n_hidden': 3, 'learning_rate': 0.0043203302524475115, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2884331070955783, 'dropout_rate_Layer_2': 0.09405831082020673, 'dropout_rate_Layer_3': 0.09545605666356675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.753372071025141e-05, 'l1_Layer_2': 0.0021711931036477905, 'l1_Layer_3': 0.0031527429991176355, 'n_units_Layer_1': 230, 'n_units_Layer_2': 270, 'n_units_Layer_3': 175}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.64 | sMAPE for Validation Set is: 56.22% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.39 | sMAPE for Test Set is: 43.54% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:00:19,899]\u001b[0m Trial 392 finished with value: 54.75232996046821 and parameters: {'n_hidden': 3, 'learning_rate': 0.002951799286990008, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2657105342358087, 'dropout_rate_Layer_2': 0.13090037461096155, 'dropout_rate_Layer_3': 0.12544844881901707, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.6241643660661065e-05, 'l1_Layer_2': 2.1477992439440637e-05, 'l1_Layer_3': 2.0203750190081096e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.75 | sMAPE for Validation Set is: 53.11% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.48 | sMAPE for Test Set is: 40.40% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:00:31,147]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:00:35,358]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:00:43,142]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:00:55,453]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:01:03,509]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:01:07,180]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:01:13,635]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:01:33,251]\u001b[0m Trial 400 finished with value: 55.03283506446687 and parameters: {'n_hidden': 3, 'learning_rate': 0.002451581195910989, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2773506356339488, 'dropout_rate_Layer_2': 0.10016890031180634, 'dropout_rate_Layer_3': 0.09721040660875022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011392917684243445, 'l1_Layer_2': 2.7027198185751363e-05, 'l1_Layer_3': 2.7819013603106376e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 155}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.03 | sMAPE for Validation Set is: 54.34% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.64 | sMAPE for Test Set is: 40.36% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:01:36,921]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:02:00,323]\u001b[0m Trial 402 finished with value: 72.48016563126161 and parameters: {'n_hidden': 3, 'learning_rate': 0.00891488651038656, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23338914043403192, 'dropout_rate_Layer_2': 0.2963450248303126, 'dropout_rate_Layer_3': 0.3395982253913026, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005037703756704774, 'l1_Layer_2': 4.458088732938871e-05, 'l1_Layer_3': 0.0002872769975913217, 'n_units_Layer_1': 105, 'n_units_Layer_2': 70, 'n_units_Layer_3': 215}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.48 | sMAPE for Validation Set is: 61.62% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 31.37 | sMAPE for Test Set is: 43.38% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:02:12,568]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:02:16,270]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:02:20,091]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:02:28,280]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:02:39,720]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:02:46,045]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:02:50,416]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:02:54,069]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:03:16,370]\u001b[0m Trial 411 finished with value: 54.84329883122774 and parameters: {'n_hidden': 3, 'learning_rate': 0.002320074926955781, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27971681284735167, 'dropout_rate_Layer_2': 0.11095011908766635, 'dropout_rate_Layer_3': 0.10717509476923073, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.738665256405144e-05, 'l1_Layer_2': 2.9510206601008637e-05, 'l1_Layer_3': 1.660904207093057e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.84 | sMAPE for Validation Set is: 53.71% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.78 | sMAPE for Test Set is: 40.72% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:03:27,846]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:03:48,264]\u001b[0m Trial 413 finished with value: 54.89472143876708 and parameters: {'n_hidden': 3, 'learning_rate': 0.002624961627002965, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29443775031410246, 'dropout_rate_Layer_2': 0.12400821707339814, 'dropout_rate_Layer_3': 0.12025673094516541, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011226546592209822, 'l1_Layer_2': 2.7398125370405332e-05, 'l1_Layer_3': 2.4062023460289945e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 255, 'n_units_Layer_3': 165}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.89 | sMAPE for Validation Set is: 53.52% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.88 | sMAPE for Test Set is: 40.37% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:03:52,468]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:04:04,410]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:04:08,827]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:04:21,491]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:04:26,646]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:04:44,910]\u001b[0m Trial 419 finished with value: 55.025003905533445 and parameters: {'n_hidden': 3, 'learning_rate': 0.002908944062799321, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26722814811448675, 'dropout_rate_Layer_2': 0.12463012453738295, 'dropout_rate_Layer_3': 0.10431110379012559, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014230789246982923, 'l1_Layer_2': 3.202711734534687e-05, 'l1_Layer_3': 2.4983839346194366e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 270, 'n_units_Layer_3': 165}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.03 | sMAPE for Validation Set is: 54.50% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.96 | sMAPE for Test Set is: 41.73% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:05:03,543]\u001b[0m Trial 420 finished with value: 54.98260180370306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023871561148224897, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2883901825283224, 'dropout_rate_Layer_2': 0.09761694615234501, 'dropout_rate_Layer_3': 0.0897828892283397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.060765869100657e-05, 'l1_Layer_2': 4.101599340193611e-05, 'l1_Layer_3': 1.707898199824831e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.98 | sMAPE for Validation Set is: 54.03% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.78 | sMAPE for Test Set is: 40.95% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:05:26,546]\u001b[0m Trial 421 finished with value: 56.53072482516313 and parameters: {'n_hidden': 3, 'learning_rate': 0.004248063045334503, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09772848915127269, 'dropout_rate_Layer_2': 0.3813587921191924, 'dropout_rate_Layer_3': 0.21818087619133475, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007776481327429947, 'l1_Layer_2': 0.00791154076799496, 'l1_Layer_3': 7.883000786059518e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.53 | sMAPE for Validation Set is: 55.02% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 25.18 | sMAPE for Test Set is: 40.40% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:05:34,502]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:05:46,245]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:05:56,253]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:06:00,541]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:06:11,483]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:06:16,087]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:06:19,723]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:06:26,512]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:06:31,030]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:06:34,769]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:06:39,972]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:06:45,161]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:07:10,115]\u001b[0m Trial 434 finished with value: 60.299115447637455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019542004494174704, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24558130217043736, 'dropout_rate_Layer_2': 0.15076532216843588, 'dropout_rate_Layer_3': 0.0432023986689944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3045006289956545e-05, 'l1_Layer_2': 0.00044794508267865336, 'l1_Layer_3': 0.0004844194029904193, 'n_units_Layer_1': 190, 'n_units_Layer_2': 210, 'n_units_Layer_3': 135}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.30 | sMAPE for Validation Set is: 59.70% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.60 | sMAPE for Test Set is: 44.93% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:07:17,788]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:07:22,306]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:07:25,879]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:07:32,215]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:07:36,771]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:07:41,141]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:07:47,263]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:08:07,262]\u001b[0m Trial 442 finished with value: 54.55813640648433 and parameters: {'n_hidden': 3, 'learning_rate': 0.003080044044463837, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27175922921831197, 'dropout_rate_Layer_2': 0.09835161314491073, 'dropout_rate_Layer_3': 0.10862714533645677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.453415064191618e-05, 'l1_Layer_2': 4.424039855980508e-05, 'l1_Layer_3': 1.9707034438608723e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 250, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.56 | sMAPE for Validation Set is: 53.42% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.62 | sMAPE for Test Set is: 40.76% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:08:19,473]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:08:23,476]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:08:28,431]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:08:34,966]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:08:41,008]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:08:58,118]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:09:23,258]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:09:30,614]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:09:34,319]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:09:37,905]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:09:41,475]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:10:21,490]\u001b[0m Trial 454 finished with value: 58.08982813890552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019879353596350927, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22354555250329589, 'dropout_rate_Layer_2': 0.195014999628219, 'dropout_rate_Layer_3': 0.16506950572372686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.687003179218946e-05, 'l1_Layer_2': 0.0006487391346588826, 'l1_Layer_3': 0.00153290483048358, 'n_units_Layer_1': 245, 'n_units_Layer_2': 285, 'n_units_Layer_3': 160}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.09 | sMAPE for Validation Set is: 56.45% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.08 | sMAPE for Test Set is: 44.72% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:10:44,259]\u001b[0m Trial 455 finished with value: 56.341582743369 and parameters: {'n_hidden': 3, 'learning_rate': 0.009417727747488582, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07766257519265467, 'dropout_rate_Layer_2': 0.36426484917572516, 'dropout_rate_Layer_3': 0.20021905452022992, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01788315762812772, 'l1_Layer_2': 0.006804139127574136, 'l1_Layer_3': 6.757496801972751e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 115, 'n_units_Layer_3': 260}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.34 | sMAPE for Validation Set is: 55.00% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.00 | sMAPE for Test Set is: 42.17% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:11:04,776]\u001b[0m Trial 456 finished with value: 56.381518391114376 and parameters: {'n_hidden': 3, 'learning_rate': 0.007856814611843798, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05234061531081611, 'dropout_rate_Layer_2': 0.37912959037783883, 'dropout_rate_Layer_3': 0.24573753299294604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013683585395637337, 'l1_Layer_2': 0.00442876651297795, 'l1_Layer_3': 3.361977455185605e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 110, 'n_units_Layer_3': 270}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.38 | sMAPE for Validation Set is: 54.95% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.09 | sMAPE for Test Set is: 42.01% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:11:11,164]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:11:30,579]\u001b[0m Trial 458 finished with value: 56.426053164359 and parameters: {'n_hidden': 3, 'learning_rate': 0.006506471492709906, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06514120723885215, 'dropout_rate_Layer_2': 0.3566833448673984, 'dropout_rate_Layer_3': 0.2270730684781009, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.026515176431518357, 'l1_Layer_2': 0.003140807997543248, 'l1_Layer_3': 9.910100180930207e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 120, 'n_units_Layer_3': 235}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.43 | sMAPE for Validation Set is: 54.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.12 | sMAPE for Test Set is: 40.91% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:11:35,233]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:11:41,924]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:11:54,618]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:11:59,423]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:12:06,045]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:12:09,627]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:12:29,580]\u001b[0m Trial 465 finished with value: 60.29169531234635 and parameters: {'n_hidden': 3, 'learning_rate': 0.007999822852432751, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26907731019471026, 'dropout_rate_Layer_2': 0.09708718804834188, 'dropout_rate_Layer_3': 0.1164813724322181, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3083506265696126e-05, 'l1_Layer_2': 0.002537489051204047, 'l1_Layer_3': 0.0010302310414885632, 'n_units_Layer_1': 160, 'n_units_Layer_2': 180, 'n_units_Layer_3': 225}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.29 | sMAPE for Validation Set is: 58.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 26.77 | sMAPE for Test Set is: 43.71% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:13:11,698]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:13:16,503]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:13:20,290]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:13:25,194]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:13:33,567]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:13:37,972]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:13:49,965]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:13:53,885]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:13:58,755]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:14:02,304]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:14:14,886]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:14:21,307]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:14:32,998]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:14:40,790]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:14:45,060]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:14:51,930]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:15:04,593]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:15:11,016]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:15:35,985]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:15:40,173]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:15:43,889]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:15:50,698]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:15:54,802]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:16:17,653]\u001b[0m Trial 489 finished with value: 54.99965795209017 and parameters: {'n_hidden': 3, 'learning_rate': 0.002185160085579997, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26574276505323213, 'dropout_rate_Layer_2': 0.11969084496329264, 'dropout_rate_Layer_3': 0.13726072666274594, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015736656267301401, 'l1_Layer_2': 1.6919860463047235e-05, 'l1_Layer_3': 2.8774462446153547e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.00 | sMAPE for Validation Set is: 54.19% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.60 | sMAPE for Test Set is: 40.92% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:16:21,908]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:16:35,484]\u001b[0m Trial 491 finished with value: 76.84768306733092 and parameters: {'n_hidden': 3, 'learning_rate': 0.017059295308015098, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2053647293976878, 'dropout_rate_Layer_2': 0.30886962750203045, 'dropout_rate_Layer_3': 0.3849306687800334, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01126310946726854, 'l1_Layer_2': 2.2708096545756534e-05, 'l1_Layer_3': 0.001034049087502352, 'n_units_Layer_1': 90, 'n_units_Layer_2': 60, 'n_units_Layer_3': 145}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 76.85 | sMAPE for Validation Set is: 65.42% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 43.16 | sMAPE for Test Set is: 57.02% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:16:40,020]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:16:52,867]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:17:05,777]\u001b[0m Trial 494 finished with value: 74.47044453464461 and parameters: {'n_hidden': 3, 'learning_rate': 0.02400201659955443, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23957432130453807, 'dropout_rate_Layer_2': 0.2922529682647667, 'dropout_rate_Layer_3': 0.36006780029424856, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016134221762865813, 'l1_Layer_2': 1.3466015969472202e-05, 'l1_Layer_3': 0.0004418096522667673, 'n_units_Layer_1': 100, 'n_units_Layer_2': 100, 'n_units_Layer_3': 135}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.47 | sMAPE for Validation Set is: 64.93% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 38.46 | sMAPE for Test Set is: 54.11% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:17:09,414]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:17:25,775]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:17:32,149]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:17:46,575]\u001b[0m Trial 498 finished with value: 75.64039215551519 and parameters: {'n_hidden': 3, 'learning_rate': 0.028957203450640248, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2162898880833125, 'dropout_rate_Layer_2': 0.32041452140321897, 'dropout_rate_Layer_3': 0.345796429758702, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005244122911264182, 'l1_Layer_2': 2.917793251230444e-05, 'l1_Layer_3': 0.0003679475313975625, 'n_units_Layer_1': 75, 'n_units_Layer_2': 75, 'n_units_Layer_3': 170}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.64 | sMAPE for Validation Set is: 65.13% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 44.48 | sMAPE for Test Set is: 54.24% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:17:59,721]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:18:03,307]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:18:13,818]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:18:18,784]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:18:22,408]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:18:37,153]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:18:48,546]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:19:11,865]\u001b[0m Trial 506 finished with value: 56.69491561126221 and parameters: {'n_hidden': 3, 'learning_rate': 0.00612042376283605, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03178027153819986, 'dropout_rate_Layer_2': 0.3900400817595275, 'dropout_rate_Layer_3': 0.23396406430070063, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02152139075252126, 'l1_Layer_2': 0.0076728980296795835, 'l1_Layer_3': 1.7977892182765703e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 130, 'n_units_Layer_3': 255}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.69 | sMAPE for Validation Set is: 55.59% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.45 | sMAPE for Test Set is: 41.32% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:19:15,552]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:19:37,259]\u001b[0m Trial 508 finished with value: 79.19289066063403 and parameters: {'n_hidden': 3, 'learning_rate': 0.02049323649964911, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1845282689780186, 'dropout_rate_Layer_2': 0.36323831035779613, 'dropout_rate_Layer_3': 0.30773148419490626, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06428215193095997, 'l1_Layer_2': 1.0141526498975866e-05, 'l1_Layer_3': 0.0005837985571717393, 'n_units_Layer_1': 85, 'n_units_Layer_2': 280, 'n_units_Layer_3': 185}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 79.19 | sMAPE for Validation Set is: 66.41% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 30.04 | sMAPE for Test Set is: 43.98% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:19:42,369]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:19:45,955]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:19:51,900]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:19:57,505]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:20:05,324]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:20:13,430]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:20:20,950]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:20:33,062]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:20:38,735]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:20:46,122]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:21:09,236]\u001b[0m Trial 519 finished with value: 61.847046528269914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019607704802386927, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33019446966208443, 'dropout_rate_Layer_2': 0.13546718857961823, 'dropout_rate_Layer_3': 0.062118216197452274, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.936182942603686e-05, 'l1_Layer_2': 0.0029672806294985437, 'l1_Layer_3': 0.0039126551344514475, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 190}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.85 | sMAPE for Validation Set is: 59.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 27.66 | sMAPE for Test Set is: 45.38% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:21:13,147]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:21:16,899]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:21:23,520]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:21:27,907]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:21:35,431]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:21:56,724]\u001b[0m Trial 525 finished with value: 55.12259120154914 and parameters: {'n_hidden': 3, 'learning_rate': 0.002865979991596241, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29311263030697027, 'dropout_rate_Layer_2': 0.12287624507934411, 'dropout_rate_Layer_3': 0.10587350034710657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013230139498726583, 'l1_Layer_2': 4.491011716351219e-05, 'l1_Layer_3': 2.636289876185709e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.12 | sMAPE for Validation Set is: 53.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.97 | sMAPE for Test Set is: 40.70% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:22:10,695]\u001b[0m Trial 526 finished with value: 77.78751157657005 and parameters: {'n_hidden': 3, 'learning_rate': 0.022756770228018048, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18502664533849833, 'dropout_rate_Layer_2': 0.24208193598036948, 'dropout_rate_Layer_3': 0.35555781463184616, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04588204098687474, 'l1_Layer_2': 1.3095239038646369e-05, 'l1_Layer_3': 0.0007952868253355863, 'n_units_Layer_1': 70, 'n_units_Layer_2': 140, 'n_units_Layer_3': 120}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.79 | sMAPE for Validation Set is: 68.11% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 35.88 | sMAPE for Test Set is: 62.84% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:22:22,179]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:22:26,630]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:22:30,299]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:22:36,804]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:22:48,559]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:23:19,983]\u001b[0m Trial 532 finished with value: 55.257288469394716 and parameters: {'n_hidden': 3, 'learning_rate': 0.005811281543911566, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.052577246001793455, 'dropout_rate_Layer_2': 0.3842531684307805, 'dropout_rate_Layer_3': 0.18120213481631822, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012090468950636039, 'l1_Layer_2': 0.003123458579236749, 'l1_Layer_3': 1.2338657295672615e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 120, 'n_units_Layer_3': 220}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.26 | sMAPE for Validation Set is: 53.66% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.18 | sMAPE for Test Set is: 41.05% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:23:24,234]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:23:28,292]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:23:35,108]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:23:39,334]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:23:42,987]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:23:56,393]\u001b[0m Trial 538 finished with value: 74.94105650131122 and parameters: {'n_hidden': 3, 'learning_rate': 0.01960693356713768, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22298623932922607, 'dropout_rate_Layer_2': 0.35278143331054423, 'dropout_rate_Layer_3': 0.2951868154629775, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.020212813900307176, 'l1_Layer_2': 2.4127995122410294e-05, 'l1_Layer_3': 0.00039675173556748733, 'n_units_Layer_1': 60, 'n_units_Layer_2': 120, 'n_units_Layer_3': 90}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.94 | sMAPE for Validation Set is: 67.35% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 37.30 | sMAPE for Test Set is: 58.15% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:24:00,058]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:24:07,778]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:24:12,828]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:24:19,825]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:24:23,601]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:24:30,523]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:24:51,010]\u001b[0m Trial 545 finished with value: 54.615430161849645 and parameters: {'n_hidden': 3, 'learning_rate': 0.003016876957747038, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29827467025583787, 'dropout_rate_Layer_2': 0.061351003421092974, 'dropout_rate_Layer_3': 0.11250971226946019, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018790143473487592, 'l1_Layer_2': 1.9246465135579868e-05, 'l1_Layer_3': 4.905297422101514e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 250, 'n_units_Layer_3': 145}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.62 | sMAPE for Validation Set is: 53.68% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.26 | sMAPE for Test Set is: 41.65% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:25:10,025]\u001b[0m Trial 546 finished with value: 54.90860247065575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033550214199064847, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30632832649236585, 'dropout_rate_Layer_2': 0.0642842599168024, 'dropout_rate_Layer_3': 0.11209990847298566, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018580048557722534, 'l1_Layer_2': 3.857691976992529e-05, 'l1_Layer_3': 1.650929852365228e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 240, 'n_units_Layer_3': 135}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.91 | sMAPE for Validation Set is: 53.80% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.53 | sMAPE for Test Set is: 42.82% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:25:15,897]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:25:27,053]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:25:32,014]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:25:36,526]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:25:56,098]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:26:03,922]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:26:24,002]\u001b[0m Trial 553 finished with value: 76.44402103284716 and parameters: {'n_hidden': 3, 'learning_rate': 0.026705046384413577, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24997931611895435, 'dropout_rate_Layer_2': 0.3150342150062629, 'dropout_rate_Layer_3': 0.321694564110782, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012761704344145669, 'l1_Layer_2': 1.9332299471626046e-05, 'l1_Layer_3': 0.0002677510293391465, 'n_units_Layer_1': 55, 'n_units_Layer_2': 100, 'n_units_Layer_3': 75}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 76.44 | sMAPE for Validation Set is: 65.24% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 29.79 | sMAPE for Test Set is: 45.70% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:26:29,081]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:26:32,961]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:26:37,150]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:26:44,746]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:26:48,594]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:27:01,983]\u001b[0m Trial 559 finished with value: 75.4737156322812 and parameters: {'n_hidden': 3, 'learning_rate': 0.01566983087777666, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22857482222642905, 'dropout_rate_Layer_2': 0.389933514912652, 'dropout_rate_Layer_3': 0.3889788800449805, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.020175620499165933, 'l1_Layer_2': 3.773548260834895e-05, 'l1_Layer_3': 0.0005077377263674148, 'n_units_Layer_1': 75, 'n_units_Layer_2': 110, 'n_units_Layer_3': 110}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.47 | sMAPE for Validation Set is: 65.30% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 38.43 | sMAPE for Test Set is: 51.30% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:27:06,262]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:27:14,128]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:27:22,351]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:27:28,904]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:27:35,977]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:27:49,059]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:27:52,991]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:27:59,734]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:28:06,501]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:28:23,879]\u001b[0m Trial 569 finished with value: 55.32996576028552 and parameters: {'n_hidden': 3, 'learning_rate': 0.003456356261817467, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26817543116667886, 'dropout_rate_Layer_2': 0.2626902871769508, 'dropout_rate_Layer_3': 0.12999786698048682, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015950160432116339, 'l1_Layer_2': 2.269897700556229e-05, 'l1_Layer_3': 5.0215974390866014e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 255, 'n_units_Layer_3': 120}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.33 | sMAPE for Validation Set is: 54.04% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 26.72 | sMAPE for Test Set is: 45.75% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:29:21,336]\u001b[0m Trial 570 finished with value: 58.20363917013092 and parameters: {'n_hidden': 3, 'learning_rate': 0.001504566512816887, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2538835215656281, 'dropout_rate_Layer_2': 0.1891244404126371, 'dropout_rate_Layer_3': 0.1382513023547131, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0147197873032815e-05, 'l1_Layer_2': 0.011492009393568078, 'l1_Layer_3': 0.0014790498145075706, 'n_units_Layer_1': 240, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.20 | sMAPE for Validation Set is: 56.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.14 | sMAPE for Test Set is: 43.83% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:29:25,208]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:29:32,363]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:29:36,308]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:29:40,765]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:29:44,705]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:30:24,147]\u001b[0m Trial 576 finished with value: 57.701315973704915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017641486410822304, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2198342159932561, 'dropout_rate_Layer_2': 0.08162946526875073, 'dropout_rate_Layer_3': 0.09090395612640259, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.771396490854748e-05, 'l1_Layer_2': 0.0038400990310819686, 'l1_Layer_3': 1.0324721478909039e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 135, 'n_units_Layer_3': 160}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.70 | sMAPE for Validation Set is: 56.34% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.45 | sMAPE for Test Set is: 43.54% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:30:28,010]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:30:34,487]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:30:38,484]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:30:43,397]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:30:50,083]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:30:54,564]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:30:58,782]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:31:02,594]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:32:01,044]\u001b[0m Trial 585 finished with value: 55.83267475566911 and parameters: {'n_hidden': 3, 'learning_rate': 0.003024766978998412, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3130268616255532, 'dropout_rate_Layer_2': 0.06511533757352475, 'dropout_rate_Layer_3': 0.0916458280417925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.064344688419675e-05, 'l1_Layer_2': 0.003628765096400438, 'l1_Layer_3': 1.5006883730542814e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 140, 'n_units_Layer_3': 135}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.83 | sMAPE for Validation Set is: 54.40% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.77 | sMAPE for Test Set is: 46.54% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:32:25,341]\u001b[0m Trial 586 finished with value: 54.58922879081871 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024507869703959016, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28999893909684704, 'dropout_rate_Layer_2': 0.12080239822527425, 'dropout_rate_Layer_3': 0.10170296458702485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.404198871644162e-05, 'l1_Layer_2': 1.9619635370353023e-05, 'l1_Layer_3': 1.1772168873594996e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 140}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.59 | sMAPE for Validation Set is: 53.57% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.70 | sMAPE for Test Set is: 40.68% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:32:31,992]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:32:39,592]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:32:44,074]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:32:56,481]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:33:01,805]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:33:06,182]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:33:19,695]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:33:45,317]\u001b[0m Trial 594 finished with value: 54.70087716910842 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025543206086519337, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25547066338660407, 'dropout_rate_Layer_2': 0.14186237025298393, 'dropout_rate_Layer_3': 0.09412089920204851, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.211925516053675e-05, 'l1_Layer_2': 2.1245113190317685e-05, 'l1_Layer_3': 1.0957611667709493e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 265, 'n_units_Layer_3': 140}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.70 | sMAPE for Validation Set is: 54.38% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.26 | sMAPE for Test Set is: 40.69% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:33:56,131]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:34:00,586]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:34:04,277]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:34:08,769]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:34:32,092]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:34:52,514]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:34:56,602]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:35:01,423]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:35:25,590]\u001b[0m Trial 603 finished with value: 56.02799280881798 and parameters: {'n_hidden': 3, 'learning_rate': 0.00801363352817785, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04733276335210958, 'dropout_rate_Layer_2': 0.38308281742977063, 'dropout_rate_Layer_3': 0.2480970268103837, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012133433639767613, 'l1_Layer_2': 0.004411173616388632, 'l1_Layer_3': 3.750989612616149e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 110, 'n_units_Layer_3': 270}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.03 | sMAPE for Validation Set is: 53.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.26 | sMAPE for Test Set is: 40.96% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:35:29,379]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:35:36,819]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:35:40,702]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:35:44,675]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:36:00,301]\u001b[0m Trial 608 finished with value: 78.39725057314423 and parameters: {'n_hidden': 3, 'learning_rate': 0.01834528198841296, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27075887881554017, 'dropout_rate_Layer_2': 0.32473465093412135, 'dropout_rate_Layer_3': 0.3995433352864757, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02797611993115667, 'l1_Layer_2': 4.9910205247558e-05, 'l1_Layer_3': 0.00019216332541222752, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 95}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.40 | sMAPE for Validation Set is: 67.61% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 32.27 | sMAPE for Test Set is: 56.81% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:36:06,827]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:36:27,144]\u001b[0m Trial 610 finished with value: 56.13457203882703 and parameters: {'n_hidden': 3, 'learning_rate': 0.008037582807980701, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.037435425768207235, 'dropout_rate_Layer_2': 0.35934187242636756, 'dropout_rate_Layer_3': 0.23917568388156796, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010286905758997343, 'l1_Layer_2': 0.004385047979918291, 'l1_Layer_3': 2.2775166911788503e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 105, 'n_units_Layer_3': 230}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.13 | sMAPE for Validation Set is: 55.12% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.82 | sMAPE for Test Set is: 41.99% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:36:30,914]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:36:34,649]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:36:47,461]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:37:00,471]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:37:04,609]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:37:08,862]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:37:13,199]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:37:18,253]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:37:25,956]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:37:45,423]\u001b[0m Trial 620 finished with value: 55.0350393678498 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027814126124830786, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3003322875958601, 'dropout_rate_Layer_2': 0.11391994126853876, 'dropout_rate_Layer_3': 0.10722549741928392, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013338970278382441, 'l1_Layer_2': 7.666470208258987e-05, 'l1_Layer_3': 9.803041366595816e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 265, 'n_units_Layer_3': 155}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.04 | sMAPE for Validation Set is: 54.78% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.12 | sMAPE for Test Set is: 42.04% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:37:49,179]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:37:57,202]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:38:21,571]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:38:28,143]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:38:31,897]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:38:36,885]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:38:40,672]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:38:44,358]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:38:48,245]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:39:00,954]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:39:07,658]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:39:14,000]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:39:17,886]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:39:22,407]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:39:26,910]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:39:31,580]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:39:35,515]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:39:46,894]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:39:51,381]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:39:56,018]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:40:02,540]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:40:16,417]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:40:22,606]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:40:26,643]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:41:39,586]\u001b[0m Trial 645 finished with value: 56.34842893194332 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024367538240500555, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3197484688687794, 'dropout_rate_Layer_2': 0.030838973111681288, 'dropout_rate_Layer_3': 0.018906865630192574, 'dropout_rate_Layer_4': 0.2418643581208032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.109685620477538e-05, 'l1_Layer_2': 0.004164566296292755, 'l1_Layer_3': 2.6357349567168816e-05, 'l1_Layer_4': 0.007304159508002826, 'n_units_Layer_1': 225, 'n_units_Layer_2': 170, 'n_units_Layer_3': 175, 'n_units_Layer_4': 225}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.35 | sMAPE for Validation Set is: 55.45% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 28.54 | sMAPE for Test Set is: 49.73% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:42:21,854]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:42:26,023]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:42:29,896]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:42:33,766]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:42:41,272]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:42:45,092]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:42:57,317]\u001b[0m Trial 652 finished with value: 73.59606457605888 and parameters: {'n_hidden': 3, 'learning_rate': 0.03059055175847501, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26004274881033634, 'dropout_rate_Layer_2': 0.28453269724528235, 'dropout_rate_Layer_3': 0.359864638097258, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0493886294409672, 'l1_Layer_2': 1.3826907674229184e-05, 'l1_Layer_3': 0.00041890752576828345, 'n_units_Layer_1': 100, 'n_units_Layer_2': 100, 'n_units_Layer_3': 85}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.60 | sMAPE for Validation Set is: 73.10% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 41.21 | sMAPE for Test Set is: 82.46% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:43:22,823]\u001b[0m Trial 653 finished with value: 56.82924053384272 and parameters: {'n_hidden': 3, 'learning_rate': 0.008879206312934816, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08256870988466199, 'dropout_rate_Layer_2': 0.3773789909466843, 'dropout_rate_Layer_3': 0.23420993990709293, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02486983520486087, 'l1_Layer_2': 0.00792245164121972, 'l1_Layer_3': 6.340683807777127e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.83 | sMAPE for Validation Set is: 55.03% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.57 | sMAPE for Test Set is: 42.74% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:43:27,961]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:43:35,116]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:43:38,983]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:43:42,903]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:43:46,860]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:43:50,761]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:43:57,185]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:44:03,624]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:44:09,862]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:44:13,749]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:44:18,753]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:44:32,363]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:44:44,157]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:45:16,717]\u001b[0m Trial 667 finished with value: 55.204506703697604 and parameters: {'n_hidden': 3, 'learning_rate': 0.006544954369832528, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05537172521491896, 'dropout_rate_Layer_2': 0.1463149728832839, 'dropout_rate_Layer_3': 0.24300111987654938, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028041368264085906, 'l1_Layer_2': 0.0007919893797553291, 'l1_Layer_3': 5.573551806266297e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 95, 'n_units_Layer_3': 280}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.20 | sMAPE for Validation Set is: 54.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.96 | sMAPE for Test Set is: 40.99% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:45:20,521]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:45:24,925]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:45:45,306]\u001b[0m Trial 670 finished with value: 55.61906263930431 and parameters: {'n_hidden': 3, 'learning_rate': 0.006518148741964612, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03610042257970303, 'dropout_rate_Layer_2': 0.15843622116125777, 'dropout_rate_Layer_3': 0.24332396119343086, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.029976006101517193, 'l1_Layer_2': 0.0010489164221879682, 'l1_Layer_3': 5.1571612856918336e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.62 | sMAPE for Validation Set is: 54.79% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.54 | sMAPE for Test Set is: 40.91% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:45:50,009]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:47:03,088]\u001b[0m Trial 672 finished with value: 56.847137874238875 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032550501775955327, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3124691945966688, 'dropout_rate_Layer_2': 0.05040830617650701, 'dropout_rate_Layer_3': 0.0604505150415497, 'dropout_rate_Layer_4': 0.30441109331356075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.229296181048667e-05, 'l1_Layer_2': 0.0017406840171122042, 'l1_Layer_3': 2.6773948295574176e-05, 'l1_Layer_4': 0.004133344659120111, 'n_units_Layer_1': 210, 'n_units_Layer_2': 130, 'n_units_Layer_3': 170, 'n_units_Layer_4': 225}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.85 | sMAPE for Validation Set is: 55.65% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.06 | sMAPE for Test Set is: 47.87% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:47:07,510]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:47:14,066]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:47:26,825]\u001b[0m Trial 675 finished with value: 71.76212827845713 and parameters: {'n_hidden': 3, 'learning_rate': 0.030246509355355274, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2827343352769022, 'dropout_rate_Layer_2': 0.31278779049008565, 'dropout_rate_Layer_3': 0.3868011815673642, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.030576341009708338, 'l1_Layer_2': 1.773806642679516e-05, 'l1_Layer_3': 0.00031012578326767854, 'n_units_Layer_1': 80, 'n_units_Layer_2': 95, 'n_units_Layer_3': 85}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 71.76 | sMAPE for Validation Set is: 66.77% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 39.15 | sMAPE for Test Set is: 69.10% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:47:30,713]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:49:38,396]\u001b[0m Trial 677 finished with value: 56.30907080952903 and parameters: {'n_hidden': 4, 'learning_rate': 0.003078269111126784, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37274802244203387, 'dropout_rate_Layer_2': 0.045931468715683085, 'dropout_rate_Layer_3': 0.05975451799045868, 'dropout_rate_Layer_4': 0.2996029478735336, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.0756786304958376e-05, 'l1_Layer_2': 0.001335809880295672, 'l1_Layer_3': 3.4903436645446994e-05, 'l1_Layer_4': 0.005619325755307372, 'n_units_Layer_1': 215, 'n_units_Layer_2': 90, 'n_units_Layer_3': 140, 'n_units_Layer_4': 225}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.31 | sMAPE for Validation Set is: 55.51% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.74 | sMAPE for Test Set is: 46.20% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:49:49,980]\u001b[0m Trial 678 finished with value: 78.31046877781607 and parameters: {'n_hidden': 3, 'learning_rate': 0.03142724783331888, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.287570564588865, 'dropout_rate_Layer_2': 0.3132330062629859, 'dropout_rate_Layer_3': 0.3914886473799273, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08507593773822669, 'l1_Layer_2': 1.4769338258187248e-05, 'l1_Layer_3': 0.0003004132499899722, 'n_units_Layer_1': 80, 'n_units_Layer_2': 80, 'n_units_Layer_3': 55}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.31 | sMAPE for Validation Set is: 66.31% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 30.81 | sMAPE for Test Set is: 48.56% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:49:54,716]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:50:02,733]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:50:07,009]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:50:10,843]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:50:15,529]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:50:56,180]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:51:02,503]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:51:06,956]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:51:36,541]\u001b[0m Trial 687 finished with value: 54.513561568685226 and parameters: {'n_hidden': 3, 'learning_rate': 0.002260244461003935, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2714907634233445, 'dropout_rate_Layer_2': 0.11673509822933176, 'dropout_rate_Layer_3': 0.1722671638667565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.823152752060052e-05, 'l1_Layer_2': 1.584938590806066e-05, 'l1_Layer_3': 0.0013179768277346905, 'n_units_Layer_1': 235, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.51 | sMAPE for Validation Set is: 53.63% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.81 | sMAPE for Test Set is: 41.23% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:51:43,615]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:51:47,575]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:51:52,750]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:51:56,522]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:52:21,835]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:52:25,677]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:52:30,176]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:52:34,579]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:52:38,278]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:53:54,663]\u001b[0m Trial 697 finished with value: 57.010835480559024 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024409500516481856, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35952925017366866, 'dropout_rate_Layer_2': 0.020280822832335062, 'dropout_rate_Layer_3': 0.05989536951305774, 'dropout_rate_Layer_4': 0.29716653484342037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.4639313388852426e-05, 'l1_Layer_2': 0.0015852062194477783, 'l1_Layer_3': 1.9529651533299333e-05, 'l1_Layer_4': 0.008918322438090846, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 240, 'n_units_Layer_4': 190}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.01 | sMAPE for Validation Set is: 55.79% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.42 | sMAPE for Test Set is: 47.54% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:54:02,065]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:54:06,292]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:54:18,952]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:54:55,596]\u001b[0m Trial 701 finished with value: 55.31185553424032 and parameters: {'n_hidden': 3, 'learning_rate': 0.006706283875704982, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056411717099395485, 'dropout_rate_Layer_2': 0.24512824481051215, 'dropout_rate_Layer_3': 0.2554726884640845, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05224940672110444, 'l1_Layer_2': 0.000658477710348303, 'l1_Layer_3': 1.0428489675289973e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.31 | sMAPE for Validation Set is: 54.20% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.75 | sMAPE for Test Set is: 39.61% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:54:59,686]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:55:04,720]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:55:08,600]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:55:12,444]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:55:17,024]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:55:21,117]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:55:25,586]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:55:30,034]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:55:34,921]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:55:39,424]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:55:43,874]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:55:56,008]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:56:04,241]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:56:08,468]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:56:12,384]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:56:33,408]\u001b[0m Trial 717 finished with value: 54.376027299029126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023279998058462832, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01996436567340934, 'dropout_rate_Layer_2': 0.07259451594712142, 'dropout_rate_Layer_3': 0.09709656921248914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001718326433215235, 'l1_Layer_2': 2.0809230882429305e-05, 'l1_Layer_3': 0.001092101558796618, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 130}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.38 | sMAPE for Validation Set is: 53.47% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 24.53 | sMAPE for Test Set is: 40.65% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:56:37,376]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:56:41,202]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:56:45,923]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:58:17,544]\u001b[0m Trial 721 finished with value: 56.39972814413506 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025713931608998845, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3536049763309606, 'dropout_rate_Layer_2': 0.01738312011653432, 'dropout_rate_Layer_3': 0.003331289126596193, 'dropout_rate_Layer_4': 0.30043036299372694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011551924699230408, 'l1_Layer_2': 0.0017829832852159465, 'l1_Layer_3': 1.725915177379751e-05, 'l1_Layer_4': 0.009821652985080188, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 105, 'n_units_Layer_4': 190}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.40 | sMAPE for Validation Set is: 54.77% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.05 | sMAPE for Test Set is: 43.13% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:58:23,124]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:58:29,322]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:58:33,042]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:58:52,155]\u001b[0m Trial 725 finished with value: 55.76771518930349 and parameters: {'n_hidden': 3, 'learning_rate': 0.003335034490332983, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03773577374868235, 'dropout_rate_Layer_2': 0.2520251777592472, 'dropout_rate_Layer_3': 0.23994899445944037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.021120765010804066, 'l1_Layer_2': 0.0007794679088567186, 'l1_Layer_3': 1.78395193363928e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 135, 'n_units_Layer_3': 285}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.77 | sMAPE for Validation Set is: 53.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.95 | sMAPE for Test Set is: 39.82% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:59:16,668]\u001b[0m Trial 726 finished with value: 55.74124548626838 and parameters: {'n_hidden': 3, 'learning_rate': 0.002818610014642923, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03276991780409298, 'dropout_rate_Layer_2': 0.28125582840933805, 'dropout_rate_Layer_3': 0.23945092629004366, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020211809405040082, 'l1_Layer_2': 0.0008185322711513043, 'l1_Layer_3': 1.6552438943049436e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.74 | sMAPE for Validation Set is: 54.56% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.15 | sMAPE for Test Set is: 43.44% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 03:59:22,767]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:59:29,203]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 03:59:33,044]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:00:10,558]\u001b[0m Trial 730 finished with value: 55.038293870969625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032720650885708223, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02238892693658815, 'dropout_rate_Layer_2': 0.287812435108199, 'dropout_rate_Layer_3': 0.23966707293412803, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01677834351913543, 'l1_Layer_2': 0.0007977263051027729, 'l1_Layer_3': 1.636280140141264e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 150, 'n_units_Layer_3': 290}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.04 | sMAPE for Validation Set is: 53.46% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.96 | sMAPE for Test Set is: 40.78% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:00:14,401]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:00:18,101]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:00:23,069]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:00:58,109]\u001b[0m Trial 734 finished with value: 54.953619088815174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026076299726237404, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018723800865589897, 'dropout_rate_Layer_2': 0.2768111483692894, 'dropout_rate_Layer_3': 0.23718127790656218, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015083353262325993, 'l1_Layer_2': 0.0006226398591209681, 'l1_Layer_3': 1.680817042488323e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 145, 'n_units_Layer_3': 290}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.95 | sMAPE for Validation Set is: 53.59% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.92 | sMAPE for Test Set is: 40.97% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:01:03,179]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:01:07,146]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:01:33,019]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:01:39,180]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:01:44,088]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:01:48,506]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:02:02,113]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:02:05,920]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:02:29,823]\u001b[0m Trial 743 finished with value: 55.6216968323512 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033762599053349146, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016321514702347974, 'dropout_rate_Layer_2': 0.2761727712118216, 'dropout_rate_Layer_3': 0.24679600839131274, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015464431591129374, 'l1_Layer_2': 0.000692695791647527, 'l1_Layer_3': 1.696576507352423e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 135, 'n_units_Layer_3': 295}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.62 | sMAPE for Validation Set is: 54.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.01 | sMAPE for Test Set is: 40.25% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:02:34,222]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:02:38,297]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:03:04,011]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:03:11,436]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:03:15,873]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:03:57,561]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:04:01,532]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:04:05,367]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:04:11,391]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:04:16,970]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:04:30,016]\u001b[0m Trial 754 finished with value: 75.89691183093109 and parameters: {'n_hidden': 3, 'learning_rate': 0.018505229294147173, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.219045662597554, 'dropout_rate_Layer_2': 0.3176527094935583, 'dropout_rate_Layer_3': 0.38030448557065294, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.022916170567065654, 'l1_Layer_2': 4.012754864668825e-05, 'l1_Layer_3': 0.000252664200228782, 'n_units_Layer_1': 65, 'n_units_Layer_2': 65, 'n_units_Layer_3': 95}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.90 | sMAPE for Validation Set is: 66.59% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 35.44 | sMAPE for Test Set is: 60.82% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:04:34,342]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:04:38,322]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:05:53,894]\u001b[0m Trial 757 finished with value: 55.68732729501454 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028792408921162606, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32404281665729046, 'dropout_rate_Layer_2': 0.03670022601485154, 'dropout_rate_Layer_3': 0.024937823843929577, 'dropout_rate_Layer_4': 0.24594696932093751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.478110168456495e-05, 'l1_Layer_2': 0.010275228790637492, 'l1_Layer_3': 1.557337789943856e-05, 'l1_Layer_4': 0.018428892171148088, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 130, 'n_units_Layer_4': 270}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.69 | sMAPE for Validation Set is: 53.77% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.78 | sMAPE for Test Set is: 39.98% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:05:57,680]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:06:01,826]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:06:06,271]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:06:10,638]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:06:14,448]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:06:40,041]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:07:03,349]\u001b[0m Trial 764 finished with value: 55.410969527636816 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035791616190788177, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025198619414768156, 'dropout_rate_Layer_2': 0.2733578988776268, 'dropout_rate_Layer_3': 0.2331549580313339, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017349264767954835, 'l1_Layer_2': 0.001131408797836142, 'l1_Layer_3': 1.6594151907569047e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.41 | sMAPE for Validation Set is: 53.80% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.32 | sMAPE for Test Set is: 41.43% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:07:07,455]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:07:13,411]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:07:17,952]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:07:21,865]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:07:26,047]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:07:31,184]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:07:38,894]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:08:36,789]\u001b[0m Trial 772 finished with value: 56.98408749296748 and parameters: {'n_hidden': 4, 'learning_rate': 0.003164426637032413, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3119524116113485, 'dropout_rate_Layer_2': 0.04644053627195992, 'dropout_rate_Layer_3': 0.004657448903491123, 'dropout_rate_Layer_4': 0.26334232734857965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011137922381922416, 'l1_Layer_2': 0.003403703502518466, 'l1_Layer_3': 1.9493712652642432e-05, 'l1_Layer_4': 0.0038220117882182044, 'n_units_Layer_1': 180, 'n_units_Layer_2': 160, 'n_units_Layer_3': 130, 'n_units_Layer_4': 255}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.98 | sMAPE for Validation Set is: 55.02% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.46 | sMAPE for Test Set is: 43.85% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:08:40,659]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:08:45,315]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:09:04,963]\u001b[0m Trial 775 finished with value: 55.837175168396705 and parameters: {'n_hidden': 3, 'learning_rate': 0.003927940298051017, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030410876601570123, 'dropout_rate_Layer_2': 0.27239390785550727, 'dropout_rate_Layer_3': 0.24692401655591184, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012655994961423344, 'l1_Layer_2': 0.0014448983117077905, 'l1_Layer_3': 1.894466661107381e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 135, 'n_units_Layer_3': 290}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.84 | sMAPE for Validation Set is: 54.21% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.09 | sMAPE for Test Set is: 40.13% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:09:08,875]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:09:12,825]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:09:40,316]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:09:48,243]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:09:54,497]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:10:00,181]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:10:04,816]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:10:11,276]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:10:15,330]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:10:19,151]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:10:43,745]\u001b[0m Trial 786 finished with value: 54.759162327915135 and parameters: {'n_hidden': 3, 'learning_rate': 0.00184995995251893, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1620316603616595, 'dropout_rate_Layer_2': 0.11518653493668794, 'dropout_rate_Layer_3': 0.21180693711937032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.00733350474524e-05, 'l1_Layer_2': 3.078955863576127e-05, 'l1_Layer_3': 5.785191067208792e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.76 | sMAPE for Validation Set is: 53.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.90 | sMAPE for Test Set is: 40.04% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:10:58,230]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:11:05,506]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:11:29,490]\u001b[0m Trial 789 finished with value: 54.64408846679901 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018059018461501826, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05177784268961863, 'dropout_rate_Layer_2': 0.17672076172487278, 'dropout_rate_Layer_3': 0.1983925015090088, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.434895781281376e-05, 'l1_Layer_2': 4.459113489976243e-05, 'l1_Layer_3': 4.910619140231137e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.64 | sMAPE for Validation Set is: 53.64% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.66 | sMAPE for Test Set is: 41.59% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:11:33,269]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:11:38,737]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:11:42,719]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:11:50,957]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:11:57,825]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:12:01,788]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:12:24,997]\u001b[0m Trial 796 finished with value: 75.89273979963093 and parameters: {'n_hidden': 3, 'learning_rate': 0.013570802415767106, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2317098799140159, 'dropout_rate_Layer_2': 0.3302473530977655, 'dropout_rate_Layer_3': 0.39935171712392586, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009947929650991727, 'l1_Layer_2': 5.050641377142854e-05, 'l1_Layer_3': 0.0004167650407681699, 'n_units_Layer_1': 80, 'n_units_Layer_2': 80, 'n_units_Layer_3': 175}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.89 | sMAPE for Validation Set is: 64.88% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 29.45 | sMAPE for Test Set is: 44.83% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:12:32,644]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:12:40,185]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:12:44,940]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:12:50,793]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:13:04,089]\u001b[0m Trial 801 finished with value: 77.63752945304942 and parameters: {'n_hidden': 3, 'learning_rate': 0.026117359436151913, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24235010146817326, 'dropout_rate_Layer_2': 0.29404671013147476, 'dropout_rate_Layer_3': 0.3579461611644048, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014155710790732077, 'l1_Layer_2': 1.5606993704978264e-05, 'l1_Layer_3': 0.000427417527135839, 'n_units_Layer_1': 100, 'n_units_Layer_2': 100, 'n_units_Layer_3': 120}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.64 | sMAPE for Validation Set is: 72.84% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 42.26 | sMAPE for Test Set is: 74.84% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:13:08,092]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:13:12,712]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:13:17,683]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:13:30,824]\u001b[0m Trial 805 finished with value: 74.01732314416093 and parameters: {'n_hidden': 3, 'learning_rate': 0.022250035210425703, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25583162919415053, 'dropout_rate_Layer_2': 0.3454684354459199, 'dropout_rate_Layer_3': 0.3452402070878777, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015624090122621316, 'l1_Layer_2': 1.0311658077382297e-05, 'l1_Layer_3': 0.0006318891466394656, 'n_units_Layer_1': 110, 'n_units_Layer_2': 90, 'n_units_Layer_3': 155}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.02 | sMAPE for Validation Set is: 64.10% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 31.63 | sMAPE for Test Set is: 46.44% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:13:35,665]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:13:42,970]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:13:50,193]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:14:12,112]\u001b[0m Trial 809 finished with value: 55.61291195523889 and parameters: {'n_hidden': 3, 'learning_rate': 0.003257529259885018, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02743605925979709, 'dropout_rate_Layer_2': 0.30097286925468897, 'dropout_rate_Layer_3': 0.2443250610746288, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018707013771340347, 'l1_Layer_2': 0.0006846602102107305, 'l1_Layer_3': 1.668569139704033e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.61 | sMAPE for Validation Set is: 53.86% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.64 | sMAPE for Test Set is: 40.98% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:14:16,132]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:15:02,502]\u001b[0m Trial 811 finished with value: 55.696469131128474 and parameters: {'n_hidden': 4, 'learning_rate': 0.00277360655230451, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32871947200245316, 'dropout_rate_Layer_2': 0.014748575550516903, 'dropout_rate_Layer_3': 0.02702749755061961, 'dropout_rate_Layer_4': 0.1978136001997289, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.7110562014221484e-05, 'l1_Layer_2': 0.002239300840693922, 'l1_Layer_3': 1.6468819347325812e-05, 'l1_Layer_4': 0.018271834635286154, 'n_units_Layer_1': 205, 'n_units_Layer_2': 135, 'n_units_Layer_3': 80, 'n_units_Layer_4': 210}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.70 | sMAPE for Validation Set is: 54.62% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.42 | sMAPE for Test Set is: 42.15% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:15:15,315]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:15:19,451]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:15:43,521]\u001b[0m Trial 814 finished with value: 54.656446336836495 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031981956516263905, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10601131392523619, 'dropout_rate_Layer_2': 0.09939757460067403, 'dropout_rate_Layer_3': 0.19886175210272508, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005702052386716064, 'l1_Layer_2': 0.00021820803948652463, 'l1_Layer_3': 3.483236593000745e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 130}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.66 | sMAPE for Validation Set is: 53.38% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.99 | sMAPE for Test Set is: 40.31% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:15:47,541]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:16:08,092]\u001b[0m Trial 816 finished with value: 55.64956120904043 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039386295619256865, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03284563036434233, 'dropout_rate_Layer_2': 0.28434486401320425, 'dropout_rate_Layer_3': 0.2581758091687021, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02251935761907818, 'l1_Layer_2': 0.0007008237809605141, 'l1_Layer_3': 1.6790440588186967e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.65 | sMAPE for Validation Set is: 54.87% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.17 | sMAPE for Test Set is: 44.13% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:16:21,702]\u001b[0m Trial 817 finished with value: 75.18566128190419 and parameters: {'n_hidden': 3, 'learning_rate': 0.017130972419806434, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26747514024021596, 'dropout_rate_Layer_2': 0.34474554817878006, 'dropout_rate_Layer_3': 0.38500577152844495, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008337940650436292, 'l1_Layer_2': 1.0014915991506101e-05, 'l1_Layer_3': 0.0006828317634257963, 'n_units_Layer_1': 110, 'n_units_Layer_2': 55, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.19 | sMAPE for Validation Set is: 65.09% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 34.56 | sMAPE for Test Set is: 56.56% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:16:41,366]\u001b[0m Trial 818 finished with value: 55.67231479775629 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036256375279357486, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027880947382306426, 'dropout_rate_Layer_2': 0.2834826242978402, 'dropout_rate_Layer_3': 0.2588631846542543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.021540451045572444, 'l1_Layer_2': 0.0006937722528624539, 'l1_Layer_3': 1.671229448794597e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.67 | sMAPE for Validation Set is: 54.66% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.23 | sMAPE for Test Set is: 43.91% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:16:45,488]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:17:10,644]\u001b[0m Trial 820 finished with value: 55.42887343409799 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035830333140848673, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028771380642403487, 'dropout_rate_Layer_2': 0.2818231799963433, 'dropout_rate_Layer_3': 0.2583617657421722, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02053199308024776, 'l1_Layer_2': 0.0007025172159791578, 'l1_Layer_3': 1.7574877474531168e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.43 | sMAPE for Validation Set is: 54.49% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.94 | sMAPE for Test Set is: 43.12% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:18:38,280]\u001b[0m Trial 821 finished with value: 55.59907359106691 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028385290278816044, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32737125053707444, 'dropout_rate_Layer_2': 0.014120386042274198, 'dropout_rate_Layer_3': 0.03284210012848182, 'dropout_rate_Layer_4': 0.17997758709030176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.332596504325775e-05, 'l1_Layer_2': 0.010937857083483046, 'l1_Layer_3': 1.7549792349882667e-05, 'l1_Layer_4': 0.024647379991332215, 'n_units_Layer_1': 200, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75, 'n_units_Layer_4': 140}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.60 | sMAPE for Validation Set is: 54.58% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.27 | sMAPE for Test Set is: 41.96% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:18:51,027]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:18:55,348]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:19:01,619]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:19:05,773]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:19:12,598]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:19:17,358]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:19:21,435]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:19:50,376]\u001b[0m Trial 829 finished with value: 54.93653955037596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030857363042605954, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12674672002623888, 'dropout_rate_Layer_2': 0.10966607651218627, 'dropout_rate_Layer_3': 0.22517127272317822, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02034528884656183, 'l1_Layer_2': 0.0006088851351702685, 'l1_Layer_3': 3.166779049174588e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 150}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.94 | sMAPE for Validation Set is: 53.52% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.16 | sMAPE for Test Set is: 41.02% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:19:55,831]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:20:00,001]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:20:04,455]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:20:08,825]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:20:12,879]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:20:16,932]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:20:20,581]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:20:24,705]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:20:30,760]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:20:35,147]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:20:39,700]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:20:46,273]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:21:02,967]\u001b[0m Trial 842 finished with value: 76.95683235102372 and parameters: {'n_hidden': 3, 'learning_rate': 0.015148522313623888, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21026851474478225, 'dropout_rate_Layer_2': 0.3709912899281539, 'dropout_rate_Layer_3': 0.32768878912401983, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006319901010718486, 'l1_Layer_2': 2.2751551451188332e-05, 'l1_Layer_3': 0.0002629213807978819, 'n_units_Layer_1': 85, 'n_units_Layer_2': 70, 'n_units_Layer_3': 140}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 76.96 | sMAPE for Validation Set is: 65.21% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 29.10 | sMAPE for Test Set is: 46.87% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:21:22,269]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:21:27,073]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:22:34,913]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:22:39,135]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:23:10,376]\u001b[0m Trial 847 finished with value: 55.09624364019023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036582678525537184, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03337029852712197, 'dropout_rate_Layer_2': 0.26771635473682376, 'dropout_rate_Layer_3': 0.25262500575047375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02517511110158877, 'l1_Layer_2': 0.0016154698516338958, 'l1_Layer_3': 1.5367934669842808e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.10 | sMAPE for Validation Set is: 53.45% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.31 | sMAPE for Test Set is: 41.27% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:23:47,991]\u001b[0m Trial 848 finished with value: 55.10421213473854 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027485940881568772, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.340904309551781, 'dropout_rate_Layer_2': 0.029375715475440177, 'dropout_rate_Layer_3': 0.03165837904952473, 'dropout_rate_Layer_4': 0.19163775072798622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5192202929394469e-05, 'l1_Layer_2': 0.0066759314807734275, 'l1_Layer_3': 1.4457737503601108e-05, 'l1_Layer_4': 0.01411250870394137, 'n_units_Layer_1': 150, 'n_units_Layer_2': 65, 'n_units_Layer_3': 90, 'n_units_Layer_4': 275}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.10 | sMAPE for Validation Set is: 54.07% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.81 | sMAPE for Test Set is: 42.97% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:23:54,646]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:23:58,750]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:24:32,289]\u001b[0m Trial 851 finished with value: 55.15700538577613 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036534180744054166, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03538484205217272, 'dropout_rate_Layer_2': 0.26806474937545394, 'dropout_rate_Layer_3': 0.23885988573373654, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025810766451353023, 'l1_Layer_2': 0.001512454860878245, 'l1_Layer_3': 1.6093316917890365e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.16 | sMAPE for Validation Set is: 53.36% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.12 | sMAPE for Test Set is: 40.85% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:24:36,306]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:24:48,655]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:24:52,690]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:25:06,198]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:25:11,047]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:25:17,663]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:25:31,790]\u001b[0m Trial 858 finished with value: 72.24511389876335 and parameters: {'n_hidden': 3, 'learning_rate': 0.01059927161194158, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22374071588504693, 'dropout_rate_Layer_2': 0.36025608055449015, 'dropout_rate_Layer_3': 0.3766970083136873, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017391997595615317, 'l1_Layer_2': 1.4199967028320194e-05, 'l1_Layer_3': 0.00034417221158395897, 'n_units_Layer_1': 130, 'n_units_Layer_2': 80, 'n_units_Layer_3': 170}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.25 | sMAPE for Validation Set is: 63.22% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 31.90 | sMAPE for Test Set is: 52.98% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:26:21,490]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:26:51,304]\u001b[0m Trial 860 finished with value: 69.76379552078258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0122008206364545, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25186096426279597, 'dropout_rate_Layer_2': 0.33168055134731833, 'dropout_rate_Layer_3': 0.37814378371112317, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01857133758783776, 'l1_Layer_2': 1.258212292542475e-05, 'l1_Layer_3': 0.00033111996919293684, 'n_units_Layer_1': 135, 'n_units_Layer_2': 65, 'n_units_Layer_3': 185}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 69.76 | sMAPE for Validation Set is: 61.03% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 27.43 | sMAPE for Test Set is: 43.64% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:26:57,926]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:27:01,981]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:27:06,061]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:27:09,985]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:27:13,960]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:27:18,410]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:27:31,378]\u001b[0m Trial 867 finished with value: 74.05549963088188 and parameters: {'n_hidden': 3, 'learning_rate': 0.011591279695883852, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24859602597979175, 'dropout_rate_Layer_2': 0.36312686716534376, 'dropout_rate_Layer_3': 0.37832957002442885, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018191970929402886, 'l1_Layer_2': 1.3932095070938745e-05, 'l1_Layer_3': 0.00034342596370747863, 'n_units_Layer_1': 130, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.06 | sMAPE for Validation Set is: 65.17% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 33.04 | sMAPE for Test Set is: 50.17% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:27:35,869]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:27:40,543]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:27:44,734]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:27:48,620]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:27:52,683]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:27:59,478]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:28:11,540]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:28:15,675]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:28:21,095]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:28:30,386]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:28:34,633]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:28:46,862]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:28:53,608]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:28:57,563]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:29:23,354]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:30:29,374]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:30:40,222]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:30:44,008]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:31:33,719]\u001b[0m Trial 886 finished with value: 54.52894067851054 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020915381285730524, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3330863493900051, 'dropout_rate_Layer_2': 0.03616592598417201, 'dropout_rate_Layer_3': 0.01670561802228728, 'dropout_rate_Layer_4': 0.25452584215452323, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.177550067516686e-05, 'l1_Layer_2': 0.00725207646493392, 'l1_Layer_3': 2.1723434572433244e-05, 'l1_Layer_4': 0.008653286131119894, 'n_units_Layer_1': 150, 'n_units_Layer_2': 65, 'n_units_Layer_3': 65, 'n_units_Layer_4': 245}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.53 | sMAPE for Validation Set is: 54.05% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.28 | sMAPE for Test Set is: 42.19% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:31:40,625]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:32:12,447]\u001b[0m Trial 888 finished with value: 54.410986994837366 and parameters: {'n_hidden': 3, 'learning_rate': 0.002103028561567824, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13379755746240654, 'dropout_rate_Layer_2': 0.10463641946754963, 'dropout_rate_Layer_3': 0.09759526619413718, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.132183848475333e-05, 'l1_Layer_2': 1.72301094422841e-05, 'l1_Layer_3': 0.001397374280136217, 'n_units_Layer_1': 240, 'n_units_Layer_2': 245, 'n_units_Layer_3': 135}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.41 | sMAPE for Validation Set is: 53.52% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.11 | sMAPE for Test Set is: 41.86% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:32:49,537]\u001b[0m Trial 889 finished with value: 55.83677549546633 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020586101487906575, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.337164911798046, 'dropout_rate_Layer_2': 0.06937508457182823, 'dropout_rate_Layer_3': 0.051036033939245724, 'dropout_rate_Layer_4': 0.1877396060359432, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0344601786487126e-05, 'l1_Layer_2': 0.0062340443131055434, 'l1_Layer_3': 1.4111668850274646e-05, 'l1_Layer_4': 0.049067549121061926, 'n_units_Layer_1': 155, 'n_units_Layer_2': 60, 'n_units_Layer_3': 65, 'n_units_Layer_4': 270}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.84 | sMAPE for Validation Set is: 54.54% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.58 | sMAPE for Test Set is: 41.60% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:32:56,527]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:33:01,082]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:34:17,355]\u001b[0m Trial 892 finished with value: 55.207816298477205 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014509070696665963, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34069427838408095, 'dropout_rate_Layer_2': 0.11246689583160613, 'dropout_rate_Layer_3': 0.030126737338893185, 'dropout_rate_Layer_4': 0.18482056614753345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.258022195772795e-05, 'l1_Layer_2': 0.007233284947588526, 'l1_Layer_3': 1.4998739497159677e-05, 'l1_Layer_4': 0.0560569069867408, 'n_units_Layer_1': 165, 'n_units_Layer_2': 60, 'n_units_Layer_3': 65, 'n_units_Layer_4': 270}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.21 | sMAPE for Validation Set is: 54.10% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.29 | sMAPE for Test Set is: 41.92% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:34:21,580]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:34:49,565]\u001b[0m Trial 894 finished with value: 54.30303740615978 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021356150710643527, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15787885568430676, 'dropout_rate_Layer_2': 0.09197280494812396, 'dropout_rate_Layer_3': 0.0831343093969434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.395498119107967e-05, 'l1_Layer_2': 6.055648273071191e-05, 'l1_Layer_3': 0.0016743477390736134, 'n_units_Layer_1': 235, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.30 | sMAPE for Validation Set is: 53.72% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 25.13 | sMAPE for Test Set is: 41.25% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:34:55,692]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:35:19,096]\u001b[0m Trial 896 finished with value: 54.700462187483105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020742957615584967, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1041423826090158, 'dropout_rate_Layer_2': 0.3160312925994958, 'dropout_rate_Layer_3': 0.07901305723160214, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.20936379158541e-05, 'l1_Layer_2': 4.6264126436586044e-05, 'l1_Layer_3': 0.0016543061752419415, 'n_units_Layer_1': 235, 'n_units_Layer_2': 235, 'n_units_Layer_3': 125}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.70 | sMAPE for Validation Set is: 54.20% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.64 | sMAPE for Test Set is: 42.07% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:35:22,648]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:35:54,296]\u001b[0m Trial 898 finished with value: 54.64586452049184 and parameters: {'n_hidden': 3, 'learning_rate': 0.001965986561875729, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11290603821707329, 'dropout_rate_Layer_2': 0.3334258620937276, 'dropout_rate_Layer_3': 0.081626465416203, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008267078806905045, 'l1_Layer_2': 4.3010173819505735e-05, 'l1_Layer_3': 0.001602955638589437, 'n_units_Layer_1': 230, 'n_units_Layer_2': 235, 'n_units_Layer_3': 125}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.65 | sMAPE for Validation Set is: 53.43% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.55 | sMAPE for Test Set is: 42.08% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:36:07,905]\u001b[0m Trial 899 finished with value: 74.64820182207451 and parameters: {'n_hidden': 3, 'learning_rate': 0.01167320002489082, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24429718713282383, 'dropout_rate_Layer_2': 0.3794552924920935, 'dropout_rate_Layer_3': 0.37996037687607354, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01889592364947465, 'l1_Layer_2': 1.4311433450896194e-05, 'l1_Layer_3': 0.0003039644578239775, 'n_units_Layer_1': 130, 'n_units_Layer_2': 70, 'n_units_Layer_3': 185}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.65 | sMAPE for Validation Set is: 65.34% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 32.49 | sMAPE for Test Set is: 50.89% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:36:14,262]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:36:21,067]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:36:25,071]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:36:39,313]\u001b[0m Trial 903 finished with value: 74.78545634134964 and parameters: {'n_hidden': 3, 'learning_rate': 0.012470394719555852, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2648093657693808, 'dropout_rate_Layer_2': 0.3610939007269889, 'dropout_rate_Layer_3': 0.3767119888716786, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01838784814280541, 'l1_Layer_2': 1.46038531528207e-05, 'l1_Layer_3': 0.0003675218557891429, 'n_units_Layer_1': 140, 'n_units_Layer_2': 60, 'n_units_Layer_3': 175}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.79 | sMAPE for Validation Set is: 64.41% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 30.71 | sMAPE for Test Set is: 48.50% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:36:43,103]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:36:56,030]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:37:00,250]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:37:04,036]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:37:08,406]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:37:13,545]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:37:17,264]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:37:21,130]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:37:40,033]\u001b[0m Trial 912 finished with value: 55.7489606086084 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034485973984479962, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040573980251548125, 'dropout_rate_Layer_2': 0.27729833292721223, 'dropout_rate_Layer_3': 0.2297795062412266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01797131336822664, 'l1_Layer_2': 0.0005800218150490441, 'l1_Layer_3': 1.7397749358827234e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 125, 'n_units_Layer_3': 275}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.75 | sMAPE for Validation Set is: 53.97% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.60 | sMAPE for Test Set is: 41.79% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:37:46,072]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:37:50,191]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:38:03,402]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:38:07,940]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:38:11,658]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:38:16,113]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:38:28,924]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:38:41,184]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:38:55,962]\u001b[0m Trial 921 finished with value: 78.03055446263839 and parameters: {'n_hidden': 3, 'learning_rate': 0.009406872195163786, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25065341000362007, 'dropout_rate_Layer_2': 0.3450541647646299, 'dropout_rate_Layer_3': 0.35160338000235536, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016130764468110466, 'l1_Layer_2': 3.275596913423368e-05, 'l1_Layer_3': 0.00048058285951139436, 'n_units_Layer_1': 120, 'n_units_Layer_2': 65, 'n_units_Layer_3': 215}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.03 | sMAPE for Validation Set is: 66.70% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 32.00 | sMAPE for Test Set is: 53.42% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:39:09,508]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:39:17,244]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:39:44,019]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:40:32,126]\u001b[0m Trial 925 finished with value: 54.345553021970545 and parameters: {'n_hidden': 3, 'learning_rate': 0.001958086685837768, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09666633428877286, 'dropout_rate_Layer_2': 0.09027272464539533, 'dropout_rate_Layer_3': 0.2152447125785677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004469039361357193, 'l1_Layer_2': 5.507839806666319e-05, 'l1_Layer_3': 0.0014473328206847233, 'n_units_Layer_1': 240, 'n_units_Layer_2': 245, 'n_units_Layer_3': 245}. Best is trial 289 with value: 54.18004926531916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.35 | sMAPE for Validation Set is: 52.71% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 25.04 | sMAPE for Test Set is: 40.82% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:40:44,033]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:40:57,931]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:41:04,503]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:41:08,340]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:41:14,028]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:41:19,032]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:41:22,885]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:41:27,406]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:41:31,758]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:41:36,313]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:41:40,633]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:41:44,937]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:41:50,908]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:41:55,262]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:42:03,669]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:42:07,420]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:42:12,293]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:42:16,079]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:42:20,783]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:42:25,537]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:42:33,443]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:43:14,309]\u001b[0m Trial 947 finished with value: 53.94590779191136 and parameters: {'n_hidden': 3, 'learning_rate': 0.004661329737798977, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04497007352351444, 'dropout_rate_Layer_2': 0.2652361519726715, 'dropout_rate_Layer_3': 0.24263619623529384, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032884753306257667, 'l1_Layer_2': 0.000421702323187869, 'l1_Layer_3': 1.9103740932849783e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 135, 'n_units_Layer_3': 285}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.95 | sMAPE for Validation Set is: 53.25% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 24.82 | sMAPE for Test Set is: 40.68% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:43:21,933]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:43:26,638]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:44:23,102]\u001b[0m Trial 950 finished with value: 55.25868662381413 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018191532306895953, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33883622983333805, 'dropout_rate_Layer_2': 0.03830723164465509, 'dropout_rate_Layer_3': 0.052138026449198405, 'dropout_rate_Layer_4': 0.19773166952159166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0028075306882644e-05, 'l1_Layer_2': 0.006972519443489163, 'l1_Layer_3': 1.540297659113243e-05, 'l1_Layer_4': 0.04836138814915995, 'n_units_Layer_1': 150, 'n_units_Layer_2': 70, 'n_units_Layer_3': 60, 'n_units_Layer_4': 280}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.26 | sMAPE for Validation Set is: 54.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.25 | sMAPE for Test Set is: 41.98% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:44:28,289]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:44:38,498]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:44:42,384]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:44:48,623]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:44:54,575]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:45:14,343]\u001b[0m Trial 956 finished with value: 56.382850714351015 and parameters: {'n_hidden': 3, 'learning_rate': 0.004312705891282567, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045779212304651665, 'dropout_rate_Layer_2': 0.24757697439580106, 'dropout_rate_Layer_3': 0.35090978694149677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.019082987859250628, 'l1_Layer_2': 0.0005951988732008546, 'l1_Layer_3': 1.4969329199820417e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.38 | sMAPE for Validation Set is: 54.42% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.80 | sMAPE for Test Set is: 41.65% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:45:26,720]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:45:30,537]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:45:34,878]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:45:39,282]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:45:43,068]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:45:57,179]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:46:04,269]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:46:45,753]\u001b[0m Trial 964 finished with value: 54.93411562618646 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011193550276376379, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34423996251122607, 'dropout_rate_Layer_2': 0.011972930868739289, 'dropout_rate_Layer_3': 0.030620792637502108, 'dropout_rate_Layer_4': 0.20238124316967634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1824610183560047e-05, 'l1_Layer_2': 0.004596236205503741, 'l1_Layer_3': 1.7968768660433248e-05, 'l1_Layer_4': 0.010822339909389082, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 60, 'n_units_Layer_4': 250}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.93 | sMAPE for Validation Set is: 54.00% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.15 | sMAPE for Test Set is: 41.43% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:46:49,340]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:46:53,060]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:46:58,047]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:47:01,834]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:47:13,409]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:47:17,696]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:47:21,233]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:47:47,922]\u001b[0m Trial 972 finished with value: 55.33612017655429 and parameters: {'n_hidden': 3, 'learning_rate': 0.003727755834598229, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2787871310752621, 'dropout_rate_Layer_2': 0.27907260513887067, 'dropout_rate_Layer_3': 0.2557388512216705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004387648132117655, 'l1_Layer_2': 0.0003523153223384771, 'l1_Layer_3': 1.2831088860633717e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 130, 'n_units_Layer_3': 300}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.34 | sMAPE for Validation Set is: 53.88% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.21 | sMAPE for Test Set is: 41.04% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:47:52,910]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:47:58,931]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:48:03,218]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:48:07,288]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:48:12,009]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:48:16,863]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:48:20,663]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:48:25,366]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:48:29,140]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:48:33,443]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:48:38,298]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:48:41,984]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:49:00,982]\u001b[0m Trial 985 finished with value: 55.393319188778456 and parameters: {'n_hidden': 3, 'learning_rate': 0.0053588878056733055, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12158246322034903, 'dropout_rate_Layer_2': 0.31216239583291383, 'dropout_rate_Layer_3': 0.163587824630688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002919860344974781, 'l1_Layer_2': 4.7511509707059145e-05, 'l1_Layer_3': 0.0005763156764876077, 'n_units_Layer_1': 240, 'n_units_Layer_2': 265, 'n_units_Layer_3': 125}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.39 | sMAPE for Validation Set is: 53.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.28 | sMAPE for Test Set is: 40.18% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:49:04,903]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:49:55,057]\u001b[0m Trial 987 finished with value: 55.29280844772661 and parameters: {'n_hidden': 4, 'learning_rate': 0.001194421140957693, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34586987847500616, 'dropout_rate_Layer_2': 0.02424542727554805, 'dropout_rate_Layer_3': 0.0347532009972718, 'dropout_rate_Layer_4': 0.1983467478184324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0278586523249608e-05, 'l1_Layer_2': 0.01141576785095088, 'l1_Layer_3': 2.0494885679236847e-05, 'l1_Layer_4': 0.011614954053115674, 'n_units_Layer_1': 195, 'n_units_Layer_2': 55, 'n_units_Layer_3': 60, 'n_units_Layer_4': 250}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.29 | sMAPE for Validation Set is: 54.19% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.77 | sMAPE for Test Set is: 41.15% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:50:07,836]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:50:11,621]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:50:16,422]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:50:20,466]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:50:28,221]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:50:32,427]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:50:36,208]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:50:40,526]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:50:45,235]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:50:49,436]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:50:54,423]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:50:57,857]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:51:05,299]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:51:09,457]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:51:17,173]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:51:21,175]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:52:10,734]\u001b[0m Trial 1004 finished with value: 55.147913651410896 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010375426913035951, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3483994960557229, 'dropout_rate_Layer_2': 0.02859204891692878, 'dropout_rate_Layer_3': 0.013214384785364984, 'dropout_rate_Layer_4': 0.2462837838898237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0261624088864875e-05, 'l1_Layer_2': 0.01184044972418235, 'l1_Layer_3': 2.2859682473793322e-05, 'l1_Layer_4': 0.010019937306761406, 'n_units_Layer_1': 190, 'n_units_Layer_2': 55, 'n_units_Layer_3': 60, 'n_units_Layer_4': 245}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.15 | sMAPE for Validation Set is: 54.27% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.65 | sMAPE for Test Set is: 42.23% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:52:25,181]\u001b[0m Trial 1005 finished with value: 74.35426488236396 and parameters: {'n_hidden': 3, 'learning_rate': 0.01617661857346538, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20286849654034372, 'dropout_rate_Layer_2': 0.33105849936164106, 'dropout_rate_Layer_3': 0.3605784003665216, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009995655372455125, 'l1_Layer_2': 1.629780355617608e-05, 'l1_Layer_3': 0.0006722049225512519, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.35 | sMAPE for Validation Set is: 64.81% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 35.19 | sMAPE for Test Set is: 53.08% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:52:30,049]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:52:37,842]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:52:41,951]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:52:46,120]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:52:50,807]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:53:03,484]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:53:07,838]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:53:14,277]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:53:21,349]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:53:44,684]\u001b[0m Trial 1015 finished with value: 72.76849978758635 and parameters: {'n_hidden': 3, 'learning_rate': 0.018628831639009618, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26938946183621976, 'dropout_rate_Layer_2': 0.3420754825659954, 'dropout_rate_Layer_3': 0.3691669881789096, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0082501688628459, 'l1_Layer_2': 2.267950313502167e-05, 'l1_Layer_3': 0.0005231791706907766, 'n_units_Layer_1': 95, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.77 | sMAPE for Validation Set is: 62.15% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 31.34 | sMAPE for Test Set is: 45.43% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:53:49,623]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:53:53,727]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:53:59,063]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:54:22,584]\u001b[0m Trial 1019 finished with value: 54.91104052232769 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038886117882878097, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04898863018981735, 'dropout_rate_Layer_2': 0.26702203642390376, 'dropout_rate_Layer_3': 0.17014961692690367, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006195090709770056, 'l1_Layer_2': 0.00120979122570729, 'l1_Layer_3': 2.312524404216909e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 125, 'n_units_Layer_3': 290}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.91 | sMAPE for Validation Set is: 53.44% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.32 | sMAPE for Test Set is: 41.66% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:54:26,687]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:54:30,824]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:54:35,210]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:54:49,689]\u001b[0m Trial 1023 finished with value: 75.59839234586478 and parameters: {'n_hidden': 3, 'learning_rate': 0.01859184275045183, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2693317855615048, 'dropout_rate_Layer_2': 0.3424300802688467, 'dropout_rate_Layer_3': 0.3729170170146315, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004724233544126841, 'l1_Layer_2': 2.2454239446523504e-05, 'l1_Layer_3': 0.000432511436496943, 'n_units_Layer_1': 140, 'n_units_Layer_2': 100, 'n_units_Layer_3': 155}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.60 | sMAPE for Validation Set is: 66.76% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 36.46 | sMAPE for Test Set is: 58.60% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:55:47,409]\u001b[0m Trial 1024 finished with value: 54.77590065634548 and parameters: {'n_hidden': 4, 'learning_rate': 0.001150505471154756, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3401572100759909, 'dropout_rate_Layer_2': 0.006166668574240212, 'dropout_rate_Layer_3': 0.04254753444413591, 'dropout_rate_Layer_4': 0.1619514805094766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.032127634052656e-05, 'l1_Layer_2': 0.007750425329933324, 'l1_Layer_3': 2.1123942817290626e-05, 'l1_Layer_4': 0.010151640643965605, 'n_units_Layer_1': 200, 'n_units_Layer_2': 60, 'n_units_Layer_3': 55, 'n_units_Layer_4': 240}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.78 | sMAPE for Validation Set is: 53.70% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.59 | sMAPE for Test Set is: 40.61% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:56:09,398]\u001b[0m Trial 1025 finished with value: 54.99219868214186 and parameters: {'n_hidden': 3, 'learning_rate': 0.003177514539642769, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04995903570343385, 'dropout_rate_Layer_2': 0.2739148492757384, 'dropout_rate_Layer_3': 0.16462001091371037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0046893557904856, 'l1_Layer_2': 0.0011563280369746914, 'l1_Layer_3': 2.3036650216010602e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 200, 'n_units_Layer_3': 295}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.99 | sMAPE for Validation Set is: 53.71% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.21 | sMAPE for Test Set is: 41.62% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:56:30,752]\u001b[0m Trial 1026 finished with value: 55.2934660345824 and parameters: {'n_hidden': 3, 'learning_rate': 0.003129563249771815, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.044172399139595524, 'dropout_rate_Layer_2': 0.26828836517373067, 'dropout_rate_Layer_3': 0.16529152431392563, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006751126950413586, 'l1_Layer_2': 0.0011766213680852297, 'l1_Layer_3': 2.7919309196261915e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 200, 'n_units_Layer_3': 300}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.29 | sMAPE for Validation Set is: 53.87% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.16 | sMAPE for Test Set is: 41.15% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:56:53,085]\u001b[0m Trial 1027 finished with value: 54.33383055637987 and parameters: {'n_hidden': 3, 'learning_rate': 0.003094486342061438, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04376131102390982, 'dropout_rate_Layer_2': 0.26462272790667724, 'dropout_rate_Layer_3': 0.16224857989331445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004567422964292547, 'l1_Layer_2': 0.0009018988116057273, 'l1_Layer_3': 2.6274146268017222e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 200, 'n_units_Layer_3': 300}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.33 | sMAPE for Validation Set is: 53.22% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 25.02 | sMAPE for Test Set is: 41.18% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:57:29,751]\u001b[0m Trial 1028 finished with value: 54.306368158487544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028068113657748047, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048727970397369466, 'dropout_rate_Layer_2': 0.2638762288974331, 'dropout_rate_Layer_3': 0.18938076519049107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004695313818941865, 'l1_Layer_2': 0.0011783989883262958, 'l1_Layer_3': 2.463666468561913e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 205, 'n_units_Layer_3': 300}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.31 | sMAPE for Validation Set is: 53.29% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 24.40 | sMAPE for Test Set is: 39.76% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:57:36,272]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:57:50,770]\u001b[0m Trial 1030 finished with value: 72.9799005581974 and parameters: {'n_hidden': 3, 'learning_rate': 0.021567583802909133, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2963968775909531, 'dropout_rate_Layer_2': 0.3545753155031785, 'dropout_rate_Layer_3': 0.39944040009293474, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007437763577931432, 'l1_Layer_2': 2.8726271859257307e-05, 'l1_Layer_3': 0.0005535239467304416, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 140}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.98 | sMAPE for Validation Set is: 66.03% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 31.24 | sMAPE for Test Set is: 47.87% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:57:54,504]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:57:59,294]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:58:03,561]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:58:07,652]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:58:12,387]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:58:26,109]\u001b[0m Trial 1036 finished with value: 70.91053473362015 and parameters: {'n_hidden': 3, 'learning_rate': 0.02118634981854167, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2975553341697772, 'dropout_rate_Layer_2': 0.34059829893487525, 'dropout_rate_Layer_3': 0.39676447209813, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0076090663700154795, 'l1_Layer_2': 2.8788366021440075e-05, 'l1_Layer_3': 0.0005567002798326136, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 145}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.91 | sMAPE for Validation Set is: 64.51% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 37.31 | sMAPE for Test Set is: 55.58% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:58:29,722]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:58:33,856]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:58:39,893]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:58:44,875]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:58:49,145]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:59:03,459]\u001b[0m Trial 1042 finished with value: 74.61743778608836 and parameters: {'n_hidden': 3, 'learning_rate': 0.02955611962673983, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31393951093942685, 'dropout_rate_Layer_2': 0.31188949894403745, 'dropout_rate_Layer_3': 0.3963148346151288, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006380353685283218, 'l1_Layer_2': 4.12175513066146e-05, 'l1_Layer_3': 0.0005220068362018307, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 130}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.62 | sMAPE for Validation Set is: 67.20% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 34.90 | sMAPE for Test Set is: 62.32% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 04:59:07,378]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:59:12,472]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:59:24,408]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 04:59:49,862]\u001b[0m Trial 1046 finished with value: 54.56027810260226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023036359485821977, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 3.503653038226112e-05, 'dropout_rate_Layer_2': 0.08350236338606534, 'dropout_rate_Layer_3': 0.31997880583506116, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008321114699766421, 'l1_Layer_2': 2.292466206271798e-05, 'l1_Layer_3': 9.176349126229271e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.56 | sMAPE for Validation Set is: 53.39% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.75 | sMAPE for Test Set is: 41.57% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:00:02,590]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:00:06,650]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:00:10,805]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:00:14,756]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:00:21,910]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:00:26,089]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:00:38,753]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:00:43,065]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:00:57,311]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:01:07,637]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:01:26,302]\u001b[0m Trial 1057 finished with value: 54.95513148405298 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029253368911612834, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02709095383982169, 'dropout_rate_Layer_2': 0.09137298933944979, 'dropout_rate_Layer_3': 0.28139371871466173, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00079708450740429, 'l1_Layer_2': 0.00018318956479021167, 'l1_Layer_3': 0.0003257453438213148, 'n_units_Layer_1': 250, 'n_units_Layer_2': 290, 'n_units_Layer_3': 155}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.96 | sMAPE for Validation Set is: 53.89% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.62 | sMAPE for Test Set is: 40.82% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:01:39,414]\u001b[0m Trial 1058 finished with value: 74.79344800974376 and parameters: {'n_hidden': 3, 'learning_rate': 0.023090861901268973, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28540330727187635, 'dropout_rate_Layer_2': 0.3447826900446346, 'dropout_rate_Layer_3': 0.384516959387134, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003769675854860113, 'l1_Layer_2': 2.425680696666111e-05, 'l1_Layer_3': 0.0006234786250136616, 'n_units_Layer_1': 205, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.79 | sMAPE for Validation Set is: 66.81% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 32.61 | sMAPE for Test Set is: 53.35% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:01:51,190]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:01:55,727]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:02:00,048]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:02:04,585]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:02:09,339]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:02:21,182]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:02:34,926]\u001b[0m Trial 1065 finished with value: 71.46839384633984 and parameters: {'n_hidden': 3, 'learning_rate': 0.02200415639809411, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27548148761797964, 'dropout_rate_Layer_2': 0.33032985147102745, 'dropout_rate_Layer_3': 0.36763837514636105, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009556095841096795, 'l1_Layer_2': 3.371583817108275e-05, 'l1_Layer_3': 0.00043952922588790476, 'n_units_Layer_1': 185, 'n_units_Layer_2': 75, 'n_units_Layer_3': 135}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 71.47 | sMAPE for Validation Set is: 68.41% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 36.93 | sMAPE for Test Set is: 68.88% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:02:39,113]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:02:43,450]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:02:47,954]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:03:13,892]\u001b[0m Trial 1069 finished with value: 54.14535143299053 and parameters: {'n_hidden': 3, 'learning_rate': 0.003210236577783672, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05227315545178012, 'dropout_rate_Layer_2': 0.2417416150891631, 'dropout_rate_Layer_3': 0.15294494039791393, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006999156074147958, 'l1_Layer_2': 0.0008767827985606679, 'l1_Layer_3': 3.186048309800212e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 205, 'n_units_Layer_3': 295}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.15 | sMAPE for Validation Set is: 53.54% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 24.77 | sMAPE for Test Set is: 40.90% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:03:17,946]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:03:48,737]\u001b[0m Trial 1071 finished with value: 54.32744217711538 and parameters: {'n_hidden': 3, 'learning_rate': 0.002623434849804539, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008866392279149964, 'dropout_rate_Layer_2': 0.26455966077812487, 'dropout_rate_Layer_3': 0.15651855281547516, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008005845282435257, 'l1_Layer_2': 0.0008950860393498311, 'l1_Layer_3': 2.767807227097534e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 210, 'n_units_Layer_3': 295}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.33 | sMAPE for Validation Set is: 53.11% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 24.44 | sMAPE for Test Set is: 39.42% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:04:01,799]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:04:06,636]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:04:10,623]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:04:14,943]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:04:25,333]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:04:33,123]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:05:05,183]\u001b[0m Trial 1078 finished with value: 54.365053045086114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031397286274546963, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008061262025882365, 'dropout_rate_Layer_2': 0.2634145099307213, 'dropout_rate_Layer_3': 0.15465355012824827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005008442575333849, 'l1_Layer_2': 0.0008877225189785131, 'l1_Layer_3': 3.051451616219321e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 195, 'n_units_Layer_3': 295}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.37 | sMAPE for Validation Set is: 53.55% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 24.79 | sMAPE for Test Set is: 40.92% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:05:19,129]\u001b[0m Trial 1079 finished with value: 75.74961077129262 and parameters: {'n_hidden': 3, 'learning_rate': 0.01999478173523157, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3125220548473957, 'dropout_rate_Layer_2': 0.33058990018638185, 'dropout_rate_Layer_3': 0.3584583108705792, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0033707869754543074, 'l1_Layer_2': 5.723619472667715e-05, 'l1_Layer_3': 0.0004981544185742228, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 120}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.75 | sMAPE for Validation Set is: 67.89% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 38.55 | sMAPE for Test Set is: 58.06% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:05:31,290]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:05:36,194]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:05:40,530]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:05:44,351]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:05:48,521]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:05:52,773]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:06:20,280]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:06:25,685]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:06:29,405]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:06:36,660]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:06:40,831]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:06:47,653]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:06:53,108]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:07:06,234]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:07:10,773]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:07:14,543]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:07:19,329]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:07:23,533]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:08:08,937]\u001b[0m Trial 1098 finished with value: 54.066957203232825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030719710973315965, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01779054778846365, 'dropout_rate_Layer_2': 0.263281615475511, 'dropout_rate_Layer_3': 0.15408488503893028, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00570850684288847, 'l1_Layer_2': 0.0009179541137548946, 'l1_Layer_3': 3.287512936102976e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 215, 'n_units_Layer_3': 300}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.07 | sMAPE for Validation Set is: 53.65% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 25.45 | sMAPE for Test Set is: 41.46% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:08:13,108]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:08:17,545]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:08:29,505]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:08:42,115]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:08:46,018]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:08:50,306]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:08:55,476]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:08:59,696]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:09:04,534]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:09:12,374]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:09:19,896]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:09:27,819]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:09:32,390]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:09:59,276]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:10:03,383]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:10:07,319]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:10:12,390]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:10:16,411]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:11:06,685]\u001b[0m Trial 1117 finished with value: 54.71111677196719 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015076604418344849, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34726744825381267, 'dropout_rate_Layer_2': 0.026881426289488974, 'dropout_rate_Layer_3': 0.01272945251881909, 'dropout_rate_Layer_4': 0.1731074433242124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.2924985931267033e-05, 'l1_Layer_2': 0.007827230159365968, 'l1_Layer_3': 4.0030144937496746e-05, 'l1_Layer_4': 0.007840427795360008, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 70, 'n_units_Layer_4': 55}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.71 | sMAPE for Validation Set is: 53.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.38 | sMAPE for Test Set is: 41.43% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:11:11,023]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:11:15,109]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:11:19,246]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:11:23,300]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:11:27,937]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:11:35,875]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:11:40,263]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:11:44,701]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:11:52,690]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:11:56,894]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:12:00,797]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:12:05,901]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:12:09,938]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:12:14,926]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:12:45,301]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:12:49,521]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:12:53,724]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:13:50,455]\u001b[0m Trial 1135 finished with value: 55.06890267994286 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008764030215346728, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3532339969406057, 'dropout_rate_Layer_2': 0.043725996892920324, 'dropout_rate_Layer_3': 0.013109014887037524, 'dropout_rate_Layer_4': 0.2043460884564642, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.2228654865106531e-05, 'l1_Layer_2': 0.008899049124071022, 'l1_Layer_3': 3.300159114563385e-05, 'l1_Layer_4': 0.01185439298874718, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 60, 'n_units_Layer_4': 275}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.07 | sMAPE for Validation Set is: 54.18% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.19 | sMAPE for Test Set is: 42.08% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:13:57,627]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:14:02,632]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:14:06,569]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:14:21,498]\u001b[0m Trial 1139 finished with value: 77.52294800133468 and parameters: {'n_hidden': 3, 'learning_rate': 0.02842085316492046, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2952728775265034, 'dropout_rate_Layer_2': 0.32609824851052716, 'dropout_rate_Layer_3': 0.37825985902374115, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013765868547474533, 'l1_Layer_2': 2.4159491358581156e-05, 'l1_Layer_3': 0.0003049026478575658, 'n_units_Layer_1': 180, 'n_units_Layer_2': 85, 'n_units_Layer_3': 105}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.52 | sMAPE for Validation Set is: 73.01% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 36.28 | sMAPE for Test Set is: 70.80% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:14:29,437]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:14:33,791]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:14:48,051]\u001b[0m Trial 1142 finished with value: 72.38670837035419 and parameters: {'n_hidden': 3, 'learning_rate': 0.015872159370554174, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32064376481330237, 'dropout_rate_Layer_2': 0.31695979043463823, 'dropout_rate_Layer_3': 0.3663484286637325, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006960835815140243, 'l1_Layer_2': 2.0442287866045778e-05, 'l1_Layer_3': 0.0007681783199924543, 'n_units_Layer_1': 105, 'n_units_Layer_2': 75, 'n_units_Layer_3': 155}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.39 | sMAPE for Validation Set is: 64.03% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 33.74 | sMAPE for Test Set is: 51.83% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:15:15,106]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:15:19,713]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:15:24,183]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:15:28,153]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:15:32,373]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:15:37,610]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:15:48,868]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:15:53,374]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:15:57,661]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:16:01,648]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:16:09,419]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:16:13,591]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:16:27,300]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:16:31,971]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:16:36,743]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:16:41,097]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:16:47,002]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:16:53,222]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:17:00,896]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:17:04,951]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:17:12,856]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:17:17,127]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:17:21,481]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:17:29,354]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:17:33,624]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:17:38,461]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:17:46,517]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:17:59,793]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:18:04,183]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:18:26,068]\u001b[0m Trial 1172 finished with value: 74.29353897252007 and parameters: {'n_hidden': 3, 'learning_rate': 0.024618703101257945, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28054682875373427, 'dropout_rate_Layer_2': 0.357615371431815, 'dropout_rate_Layer_3': 0.2708807562877287, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03187634493171559, 'l1_Layer_2': 1.1844156811388819e-05, 'l1_Layer_3': 0.0008996182731536955, 'n_units_Layer_1': 110, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.29 | sMAPE for Validation Set is: 63.12% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.57 | sMAPE for Test Set is: 44.42% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:18:30,121]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:18:34,458]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:18:38,845]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:18:43,416]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:18:48,169]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:18:52,623]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:18:57,661]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:19:11,605]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:19:16,293]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:19:22,965]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:19:48,252]\u001b[0m Trial 1183 finished with value: 54.27676142944929 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037119015088377004, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02581630857885128, 'dropout_rate_Layer_2': 0.3297671919877511, 'dropout_rate_Layer_3': 0.1491842311531219, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004398827242254242, 'l1_Layer_2': 0.00045845546249803285, 'l1_Layer_3': 4.06277066426522e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 185, 'n_units_Layer_3': 290}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.28 | sMAPE for Validation Set is: 53.91% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 24.36 | sMAPE for Test Set is: 40.80% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:19:55,525]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:20:08,416]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:20:12,439]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:20:17,360]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:20:22,248]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:20:26,456]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:20:31,466]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:20:39,241]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:20:44,155]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:20:48,235]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:20:51,976]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:20:56,304]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:21:02,039]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:21:06,729]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:21:10,699]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:21:15,622]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:21:36,389]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:21:40,692]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:21:45,334]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:21:50,434]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:21:58,106]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:22:02,092]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:22:14,543]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:23:00,791]\u001b[0m Trial 1207 finished with value: 55.005412113214334 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015417533925773555, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3157747575631469, 'dropout_rate_Layer_2': 0.0580654729837838, 'dropout_rate_Layer_3': 0.011895507757120354, 'dropout_rate_Layer_4': 0.17887637460334663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.283961890899422e-05, 'l1_Layer_2': 0.0036824016352960728, 'l1_Layer_3': 2.50035372778944e-05, 'l1_Layer_4': 0.008368403937709537, 'n_units_Layer_1': 150, 'n_units_Layer_2': 80, 'n_units_Layer_3': 75, 'n_units_Layer_4': 280}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.01 | sMAPE for Validation Set is: 54.19% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.38 | sMAPE for Test Set is: 40.97% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:23:05,738]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:23:10,019]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:23:13,951]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:23:18,562]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:23:25,642]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:23:30,639]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:23:34,353]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:23:38,340]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:23:42,401]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:23:46,597]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:23:50,999]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:23:55,064]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:24:07,661]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:24:11,663]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:24:18,453]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:24:32,411]\u001b[0m Trial 1223 finished with value: 73.63773091873031 and parameters: {'n_hidden': 3, 'learning_rate': 0.018206362193906735, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22889834092146544, 'dropout_rate_Layer_2': 0.36618302226247257, 'dropout_rate_Layer_3': 0.39973048603631883, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009906191855336699, 'l1_Layer_2': 1.2037068595118523e-05, 'l1_Layer_3': 0.00039354676830268904, 'n_units_Layer_1': 90, 'n_units_Layer_2': 75, 'n_units_Layer_3': 145}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.64 | sMAPE for Validation Set is: 63.40% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 39.09 | sMAPE for Test Set is: 51.30% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:24:37,654]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:24:41,792]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:24:45,911]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:24:52,720]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:24:57,373]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:25:27,770]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:25:31,896]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:26:18,597]\u001b[0m Trial 1231 finished with value: 54.73283097639004 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015604542578104743, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3186056899264602, 'dropout_rate_Layer_2': 0.07555200617784232, 'dropout_rate_Layer_3': 0.017133734431896537, 'dropout_rate_Layer_4': 0.16800641873650093, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.6845942201750846e-05, 'l1_Layer_2': 0.003934292189168801, 'l1_Layer_3': 3.115858047055416e-05, 'l1_Layer_4': 0.010711441495614293, 'n_units_Layer_1': 135, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60, 'n_units_Layer_4': 290}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.73 | sMAPE for Validation Set is: 53.81% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.59 | sMAPE for Test Set is: 42.73% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:26:22,368]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:26:26,484]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:27:16,452]\u001b[0m Trial 1234 finished with value: 54.812240542390036 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015819514490972282, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31224514906641515, 'dropout_rate_Layer_2': 0.0801371509394381, 'dropout_rate_Layer_3': 0.018220461558759442, 'dropout_rate_Layer_4': 0.16558364100281386, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.7201458334048435e-05, 'l1_Layer_2': 0.003876799424611303, 'l1_Layer_3': 4.852318630145203e-05, 'l1_Layer_4': 0.012519404521430662, 'n_units_Layer_1': 130, 'n_units_Layer_2': 85, 'n_units_Layer_3': 75, 'n_units_Layer_4': 300}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.81 | sMAPE for Validation Set is: 53.73% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.69 | sMAPE for Test Set is: 42.00% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:27:21,343]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:27:25,713]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:27:29,831]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:27:37,571]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:27:42,259]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:27:46,145]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:27:50,980]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:27:55,604]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:27:59,741]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:28:05,878]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:28:10,434]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:28:14,498]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:28:23,795]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:28:28,478]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:29:16,475]\u001b[0m Trial 1249 finished with value: 54.72453014745921 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016781964197573685, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3106896217534299, 'dropout_rate_Layer_2': 0.0765084027882321, 'dropout_rate_Layer_3': 0.0165879559769667, 'dropout_rate_Layer_4': 0.16311345096742969, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.807701436404455e-05, 'l1_Layer_2': 0.0034205897328089736, 'l1_Layer_3': 4.734325195362948e-05, 'l1_Layer_4': 0.012153249538612248, 'n_units_Layer_1': 135, 'n_units_Layer_2': 80, 'n_units_Layer_3': 95, 'n_units_Layer_4': 300}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.72 | sMAPE for Validation Set is: 53.80% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.37 | sMAPE for Test Set is: 41.95% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:29:21,276]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:29:48,782]\u001b[0m Trial 1251 finished with value: 69.66305057079654 and parameters: {'n_hidden': 3, 'learning_rate': 0.00989609914031337, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22982662887149852, 'dropout_rate_Layer_2': 0.39000077076849043, 'dropout_rate_Layer_3': 0.3998496189705826, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009095538238374728, 'l1_Layer_2': 2.020189523897788e-05, 'l1_Layer_3': 0.00019687382494084808, 'n_units_Layer_1': 95, 'n_units_Layer_2': 70, 'n_units_Layer_3': 135}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 69.66 | sMAPE for Validation Set is: 60.55% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 26.63 | sMAPE for Test Set is: 43.73% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:29:56,326]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:30:00,607]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:30:04,363]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:30:08,984]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:30:15,382]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:30:19,592]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:30:24,549]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:31:10,690]\u001b[0m Trial 1259 finished with value: 54.828928368926405 and parameters: {'n_hidden': 4, 'learning_rate': 0.001642158109473375, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31585683235150797, 'dropout_rate_Layer_2': 0.07738803379753517, 'dropout_rate_Layer_3': 0.020687924929603127, 'dropout_rate_Layer_4': 0.160763543629997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.9232205330112505e-05, 'l1_Layer_2': 0.003976174875515578, 'l1_Layer_3': 9.057059582199491e-05, 'l1_Layer_4': 0.006183974430469848, 'n_units_Layer_1': 135, 'n_units_Layer_2': 95, 'n_units_Layer_3': 90, 'n_units_Layer_4': 300}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.83 | sMAPE for Validation Set is: 54.02% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.97 | sMAPE for Test Set is: 42.88% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:31:14,867]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:31:19,586]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:31:23,519]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:31:28,385]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:31:55,270]\u001b[0m Trial 1264 finished with value: 55.293368895540596 and parameters: {'n_hidden': 3, 'learning_rate': 0.00199428741187284, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09959956933819392, 'dropout_rate_Layer_2': 0.0137462595539187, 'dropout_rate_Layer_3': 0.21951791132457837, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.843851491965119e-05, 'l1_Layer_2': 4.404756043235225e-05, 'l1_Layer_3': 4.317029612075761e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 245, 'n_units_Layer_3': 140}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.29 | sMAPE for Validation Set is: 54.06% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.98 | sMAPE for Test Set is: 40.44% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:32:00,249]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:32:04,088]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:32:08,852]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:32:13,100]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:32:17,428]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:32:22,520]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:32:26,953]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:32:31,803]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:32:36,137]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:32:40,515]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:32:55,246]\u001b[0m Trial 1275 finished with value: 75.34521568238401 and parameters: {'n_hidden': 3, 'learning_rate': 0.009931027009974542, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22989085335426235, 'dropout_rate_Layer_2': 0.3873815065931185, 'dropout_rate_Layer_3': 0.3984838988887702, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009249753586289114, 'l1_Layer_2': 2.0762589770603e-05, 'l1_Layer_3': 0.0002473689591255904, 'n_units_Layer_1': 95, 'n_units_Layer_2': 70, 'n_units_Layer_3': 140}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.35 | sMAPE for Validation Set is: 64.37% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 32.01 | sMAPE for Test Set is: 47.72% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:33:00,040]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:33:13,678]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:33:17,737]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:33:24,706]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:33:29,849]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:33:34,764]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:33:48,684]\u001b[0m Trial 1282 finished with value: 72.48579984074128 and parameters: {'n_hidden': 3, 'learning_rate': 0.01811210787003024, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.207269477469438, 'dropout_rate_Layer_2': 0.37877167962711583, 'dropout_rate_Layer_3': 0.3806529756874081, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011484463091611405, 'l1_Layer_2': 1.724193514158796e-05, 'l1_Layer_3': 0.0002940778535956629, 'n_units_Layer_1': 90, 'n_units_Layer_2': 55, 'n_units_Layer_3': 130}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.49 | sMAPE for Validation Set is: 63.51% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 32.93 | sMAPE for Test Set is: 49.59% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:33:54,052]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:33:58,985]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:34:11,800]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:34:18,971]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:34:23,209]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:34:59,204]\u001b[0m Trial 1288 finished with value: 54.384722724481655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022639655430975814, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10578969548213654, 'dropout_rate_Layer_2': 0.12287116281494576, 'dropout_rate_Layer_3': 0.1262601157669101, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002527770082529569, 'l1_Layer_2': 0.0011184835557514058, 'l1_Layer_3': 1.7215487577081855e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 260, 'n_units_Layer_3': 185}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.38 | sMAPE for Validation Set is: 54.47% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 25.18 | sMAPE for Test Set is: 41.14% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:35:03,790]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:35:07,698]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:35:12,199]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:35:40,338]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:35:44,177]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:35:49,261]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:35:53,646]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:35:58,119]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:36:02,711]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:36:07,137]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:36:11,542]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:36:15,296]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:36:19,974]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:36:23,906]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:36:27,753]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.08 | sMAPE for Validation Set is: 67.60% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 37.32 | sMAPE for Test Set is: 63.03% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:36:42,076]\u001b[0m Trial 1304 finished with value: 77.0844012453919 and parameters: {'n_hidden': 3, 'learning_rate': 0.012116003297537401, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20613649786188562, 'dropout_rate_Layer_2': 0.3706730234469177, 'dropout_rate_Layer_3': 0.3807590895783474, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011298342652773241, 'l1_Layer_2': 1.2046867917041914e-05, 'l1_Layer_3': 0.0003225878584563574, 'n_units_Layer_1': 70, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:36:46,213]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:36:50,486]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:36:56,874]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:37:01,745]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:37:06,599]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:37:10,886]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:37:15,257]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:37:20,911]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:37:24,798]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:37:28,701]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:37:42,343]\u001b[0m Trial 1315 finished with value: 74.98032503759394 and parameters: {'n_hidden': 3, 'learning_rate': 0.014040911799036918, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2193474935118535, 'dropout_rate_Layer_2': 0.39279947478292526, 'dropout_rate_Layer_3': 0.374141384355991, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00785429513296797, 'l1_Layer_2': 1.897989106032102e-05, 'l1_Layer_3': 0.0002677039573018311, 'n_units_Layer_1': 90, 'n_units_Layer_2': 55, 'n_units_Layer_3': 145}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.98 | sMAPE for Validation Set is: 64.39% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 33.78 | sMAPE for Test Set is: 48.45% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:37:47,033]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:37:53,372]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:37:58,059]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:38:03,013]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:38:07,567]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:38:20,244]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:38:24,615]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:38:28,868]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:38:32,771]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:38:45,631]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:38:50,035]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:38:54,022]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:38:58,192]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:39:02,613]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:39:07,350]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:39:22,128]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:39:26,549]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:39:31,787]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:39:44,580]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:39:48,885]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:39:53,537]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:01,295]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:06,199]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:11,253]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:15,822]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:20,211]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:24,777]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:29,218]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:34,553]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:38,993]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:43,547]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:48,684]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:52,954]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:40:57,325]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:41:02,613]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:41:22,646]\u001b[0m Trial 1351 finished with value: 55.36501700978346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026731084563684257, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2734399568620705, 'dropout_rate_Layer_2': 0.3679423636118071, 'dropout_rate_Layer_3': 0.09824918797665586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.313821205798603e-05, 'l1_Layer_2': 0.00022714849249003754, 'l1_Layer_3': 0.0001877759451070348, 'n_units_Layer_1': 250, 'n_units_Layer_2': 265, 'n_units_Layer_3': 145}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.37 | sMAPE for Validation Set is: 54.06% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 26.23 | sMAPE for Test Set is: 42.89% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:41:26,699]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:41:38,359]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:41:42,963]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:41:47,450]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:41:52,537]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:41:57,175]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:42:02,461]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:42:15,522]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:42:20,344]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:42:25,631]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:43:09,067]\u001b[0m Trial 1362 finished with value: 55.21070766762049 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012882562232048248, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30932311835109677, 'dropout_rate_Layer_2': 0.058922857347354925, 'dropout_rate_Layer_3': 0.04194755182422804, 'dropout_rate_Layer_4': 0.14973867615286401, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.7355089976680527e-05, 'l1_Layer_2': 0.0030604363369310253, 'l1_Layer_3': 9.318464663909559e-05, 'l1_Layer_4': 0.01371407992574467, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 95, 'n_units_Layer_4': 290}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.21 | sMAPE for Validation Set is: 54.39% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 26.16 | sMAPE for Test Set is: 43.82% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:43:13,571]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:43:19,072]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:43:24,163]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:43:28,664]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:43:33,417]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:43:38,008]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:43:42,262]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:43:56,657]\u001b[0m Trial 1370 finished with value: 76.78847468727308 and parameters: {'n_hidden': 3, 'learning_rate': 0.009593262576737666, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24611594513646465, 'dropout_rate_Layer_2': 0.3796046990655187, 'dropout_rate_Layer_3': 0.37518989868033514, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007359340441786861, 'l1_Layer_2': 1.4464363729359815e-05, 'l1_Layer_3': 0.00018970490855640832, 'n_units_Layer_1': 75, 'n_units_Layer_2': 60, 'n_units_Layer_3': 80}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 76.79 | sMAPE for Validation Set is: 67.30% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 32.82 | sMAPE for Test Set is: 53.68% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:44:05,330]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:44:09,901]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:44:16,171]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:44:22,912]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:44:51,186]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:44:55,804]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:45:01,411]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:45:05,898]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:45:10,686]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:45:15,556]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:45:19,860]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:45:23,863]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:45:28,200]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:45:33,054]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:46:00,611]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:46:08,600]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:46:12,670]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:46:20,077]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:46:26,746]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:46:34,854]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:46:42,611]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:46:47,149]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:46:53,104]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:46:57,658]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:47:05,614]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:47:10,368]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:47:23,942]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:47:27,933]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:47:32,387]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:47:36,974]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:47:41,661]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:47:47,366]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:47:51,969]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:48:42,561]\u001b[0m Trial 1404 finished with value: 54.62979684274068 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018605155559421073, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2863478028906001, 'dropout_rate_Layer_2': 0.0637910778367416, 'dropout_rate_Layer_3': 0.009471099786779416, 'dropout_rate_Layer_4': 0.18498900983243632, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.437403273901077e-05, 'l1_Layer_2': 0.005401144834118649, 'l1_Layer_3': 4.381339555218003e-05, 'l1_Layer_4': 0.014570977027383634, 'n_units_Layer_1': 145, 'n_units_Layer_2': 80, 'n_units_Layer_3': 80, 'n_units_Layer_4': 300}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.63 | sMAPE for Validation Set is: 53.79% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.92 | sMAPE for Test Set is: 40.72% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:49:27,766]\u001b[0m Trial 1405 finished with value: 55.02266683823725 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019904695716751906, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27924793913397394, 'dropout_rate_Layer_2': 0.07062291261833203, 'dropout_rate_Layer_3': 0.00831709886817348, 'dropout_rate_Layer_4': 0.1354280602889817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.370614890712789e-05, 'l1_Layer_2': 0.005414461006408497, 'l1_Layer_3': 4.241714973062814e-05, 'l1_Layer_4': 0.012782415912437731, 'n_units_Layer_1': 125, 'n_units_Layer_2': 85, 'n_units_Layer_3': 70, 'n_units_Layer_4': 300}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.02 | sMAPE for Validation Set is: 54.22% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 26.03 | sMAPE for Test Set is: 41.58% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:49:31,771]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:49:36,305]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:49:40,740]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:49:44,710]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:49:49,332]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:49:53,926]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:49:58,243]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:50:10,867]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:50:14,787]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:50:22,723]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:50:27,095]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:50:31,641]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:50:36,069]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:50:41,219]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:50:45,457]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:50:49,899]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:50:57,534]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:51:01,590]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:51:20,647]\u001b[0m Trial 1424 finished with value: 55.56449382408121 and parameters: {'n_hidden': 3, 'learning_rate': 0.002925311152527841, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05753848923792462, 'dropout_rate_Layer_2': 0.2681985953107338, 'dropout_rate_Layer_3': 0.2834754082770928, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012512285258365122, 'l1_Layer_2': 1.0065339534680408e-05, 'l1_Layer_3': 0.0007121954553524262, 'n_units_Layer_1': 255, 'n_units_Layer_2': 180, 'n_units_Layer_3': 295}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.56 | sMAPE for Validation Set is: 54.01% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.93 | sMAPE for Test Set is: 39.95% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:51:26,014]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:51:30,909]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:51:38,521]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:51:43,861]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:51:48,198]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:52:01,907]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:52:06,705]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:52:11,147]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:52:19,110]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:52:23,862]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:52:28,233]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:52:34,038]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:52:39,442]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:52:43,879]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:52:48,499]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:52:52,669]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:52:57,220]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:53:27,698]\u001b[0m Trial 1442 finished with value: 55.090557801458 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022352936884969237, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2475384364267225, 'dropout_rate_Layer_2': 0.30126039119224274, 'dropout_rate_Layer_3': 0.09911022606619856, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.07273686766635e-05, 'l1_Layer_2': 3.659466396517615e-05, 'l1_Layer_3': 0.0014993087265648627, 'n_units_Layer_1': 235, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.09 | sMAPE for Validation Set is: 54.61% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 26.29 | sMAPE for Test Set is: 45.84% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:53:33,320]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:53:38,273]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:53:43,261]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:53:49,834]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:54:01,577]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:54:07,632]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:54:11,935]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:54:18,057]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:54:44,128]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:54:48,466]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:55:15,071]\u001b[0m Trial 1453 finished with value: 54.923725073856595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016025217456262753, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15097270799007284, 'dropout_rate_Layer_2': 0.3289156175867131, 'dropout_rate_Layer_3': 0.02940713210182888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.412539339753858e-05, 'l1_Layer_2': 5.96975032238488e-05, 'l1_Layer_3': 2.4313311291544485e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.92 | sMAPE for Validation Set is: 54.48% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.03 | sMAPE for Test Set is: 41.74% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:55:20,792]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:55:25,360]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:55:31,318]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:55:35,521]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:55:39,724]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:55:45,079]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:55:50,184]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:55:54,420]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:55:58,407]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:56:03,425]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:56:34,877]\u001b[0m Trial 1464 finished with value: 55.28849285171835 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018994189428665406, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2914157714775334, 'dropout_rate_Layer_2': 0.09211588846347496, 'dropout_rate_Layer_3': 0.02187190604073521, 'dropout_rate_Layer_4': 0.14532348730690814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.751470878526695e-05, 'l1_Layer_2': 0.0019587573184092822, 'l1_Layer_3': 5.890571672743352e-05, 'l1_Layer_4': 0.020764707249009594, 'n_units_Layer_1': 110, 'n_units_Layer_2': 115, 'n_units_Layer_3': 75, 'n_units_Layer_4': 295}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.29 | sMAPE for Validation Set is: 54.33% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.47 | sMAPE for Test Set is: 39.63% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:56:43,920]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:56:48,339]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:56:53,400]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:57:20,842]\u001b[0m Trial 1468 finished with value: 55.00135946369204 and parameters: {'n_hidden': 3, 'learning_rate': 0.008125889890256898, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18352999859896207, 'dropout_rate_Layer_2': 0.11147267826587086, 'dropout_rate_Layer_3': 0.17711133581207775, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.100086753675406e-05, 'l1_Layer_2': 4.068881464177976e-05, 'l1_Layer_3': 9.476288651545099e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 245, 'n_units_Layer_3': 165}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.00 | sMAPE for Validation Set is: 54.41% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.50 | sMAPE for Test Set is: 39.95% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:57:25,159]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:57:32,651]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:57:38,290]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:57:43,862]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:57:56,703]\u001b[0m Trial 1473 finished with value: 71.82504157321634 and parameters: {'n_hidden': 3, 'learning_rate': 0.02167426024117053, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24577523802749604, 'dropout_rate_Layer_2': 0.3438411502947668, 'dropout_rate_Layer_3': 0.299175092855643, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.021035737085986456, 'l1_Layer_2': 1.4498951851289512e-05, 'l1_Layer_3': 0.00047880135100691304, 'n_units_Layer_1': 120, 'n_units_Layer_2': 70, 'n_units_Layer_3': 160}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 71.83 | sMAPE for Validation Set is: 63.63% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 36.46 | sMAPE for Test Set is: 57.60% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:58:24,495]\u001b[0m Trial 1474 finished with value: 55.71215355632774 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038020437447947356, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06963441564098476, 'dropout_rate_Layer_2': 0.3316682187524225, 'dropout_rate_Layer_3': 0.30843198891119306, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004398547970150897, 'l1_Layer_2': 5.905119775983848e-05, 'l1_Layer_3': 0.0029339848567801093, 'n_units_Layer_1': 295, 'n_units_Layer_2': 140, 'n_units_Layer_3': 295}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.71 | sMAPE for Validation Set is: 54.16% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.17 | sMAPE for Test Set is: 42.82% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 05:58:29,133]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:58:33,803]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:58:38,940]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 05:59:17,504]\u001b[0m Trial 1478 finished with value: 54.09390328365788 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027599698932733764, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048584708711320125, 'dropout_rate_Layer_2': 0.2642354441950688, 'dropout_rate_Layer_3': 0.1985779734694085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005753811490797899, 'l1_Layer_2': 2.29740310502864e-05, 'l1_Layer_3': 1.3380029460161623e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 270}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.09 | sMAPE for Validation Set is: 52.94% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 23.97 | sMAPE for Test Set is: 39.12% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 06:00:06,230]\u001b[0m Trial 1479 finished with value: 54.736758881807326 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016918259409240152, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2967202734124351, 'dropout_rate_Layer_2': 0.08161093554140512, 'dropout_rate_Layer_3': 0.00900022202330439, 'dropout_rate_Layer_4': 0.11298026190126523, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.2040126897313193e-05, 'l1_Layer_2': 0.004393337803668783, 'l1_Layer_3': 4.685414017594942e-05, 'l1_Layer_4': 0.005535248912839464, 'n_units_Layer_1': 130, 'n_units_Layer_2': 80, 'n_units_Layer_3': 80, 'n_units_Layer_4': 300}. Best is trial 947 with value: 53.94590779191136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.74 | sMAPE for Validation Set is: 54.40% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.66 | sMAPE for Test Set is: 42.43% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 06:00:11,351]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:00:15,872]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:00:20,092]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:00:25,813]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:00:29,867]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:00:34,404]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:00:38,857]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:00:44,061]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:00:56,305]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:01:00,859]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:01:06,180]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:01:10,767]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:01:14,837]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:01:20,325]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:01:28,448]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:01:33,001]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:01:40,742]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:01:48,549]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:01:53,336]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 06:01:57,786]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-01-01, MAE is:13.92 & sMAPE is:115.08% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :13.92 & 115.08% & 0.18\n",
      "for 2023-01-02, MAE is:82.15 & sMAPE is:99.14% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :48.04 & 107.11% & 0.56\n",
      "for 2023-01-03, MAE is:6.70 & sMAPE is:5.26% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :34.26 & 73.16% & 0.41\n",
      "for 2023-01-04, MAE is:32.06 & sMAPE is:37.58% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :33.71 & 64.26% & 0.67\n",
      "for 2023-01-05, MAE is:56.76 & sMAPE is:57.65% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :38.32 & 62.94% & 0.67\n",
      "for 2023-01-06, MAE is:18.08 & sMAPE is:17.39% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :34.94 & 55.35% & 0.59\n",
      "for 2023-01-07, MAE is:13.94 & sMAPE is:20.15% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :31.94 & 50.32% & 0.54\n",
      "for 2023-01-08, MAE is:14.91 & sMAPE is:49.94% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :29.81 & 50.27% & 0.56\n",
      "for 2023-01-09, MAE is:51.48 & sMAPE is:58.19% & rMAE is:4.30 ||| daily mean of MAE & sMAPE & rMAE till now are :32.22 & 51.15% & 0.98\n",
      "for 2023-01-10, MAE is:22.31 & sMAPE is:24.28% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :31.23 & 48.47% & 0.98\n",
      "for 2023-01-11, MAE is:21.58 & sMAPE is:32.87% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :30.35 & 47.05% & 0.98\n",
      "for 2023-01-12, MAE is:14.68 & sMAPE is:41.40% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :29.05 & 46.58% & 0.92\n",
      "for 2023-01-13, MAE is:8.96 & sMAPE is:16.18% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :27.50 & 44.24% & 0.87\n",
      "for 2023-01-14, MAE is:12.06 & sMAPE is:19.72% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :26.40 & 42.49% & 0.85\n",
      "for 2023-01-15, MAE is:20.56 & sMAPE is:75.94% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :26.01 & 44.72% & 0.84\n",
      "for 2023-01-16, MAE is:25.09 & sMAPE is:39.96% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :25.95 & 44.42% & 0.83\n",
      "for 2023-01-17, MAE is:14.14 & sMAPE is:25.92% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :25.26 & 43.33% & 0.80\n",
      "for 2023-01-18, MAE is:42.07 & sMAPE is:52.09% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :26.19 & 43.82% & 0.82\n",
      "for 2023-01-19, MAE is:41.71 & sMAPE is:43.05% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :27.01 & 43.78% & 0.81\n",
      "for 2023-01-20, MAE is:52.77 & sMAPE is:37.34% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :28.30 & 43.46% & 0.79\n",
      "for 2023-01-21, MAE is:14.33 & sMAPE is:11.73% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :27.63 & 41.95% & 0.76\n",
      "for 2023-01-22, MAE is:33.97 & sMAPE is:27.15% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :27.92 & 41.27% & 0.74\n",
      "for 2023-01-23, MAE is:46.23 & sMAPE is:27.55% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :28.71 & 40.68% & 0.73\n",
      "for 2023-01-24, MAE is:68.01 & sMAPE is:51.57% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :30.35 & 41.13% & 0.72\n",
      "for 2023-01-25, MAE is:21.68 & sMAPE is:47.92% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :30.01 & 41.40% & 0.72\n",
      "for 2023-01-26, MAE is:77.33 & sMAPE is:84.20% & rMAE is:2.53 ||| daily mean of MAE & sMAPE & rMAE till now are :31.83 & 43.05% & 0.79\n",
      "for 2023-01-27, MAE is:67.32 & sMAPE is:58.68% & rMAE is:4.12 ||| daily mean of MAE & sMAPE & rMAE till now are :33.14 & 43.63% & 0.91\n",
      "for 2023-01-28, MAE is:84.54 & sMAPE is:97.94% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :34.98 & 45.57% & 0.92\n",
      "for 2023-01-29, MAE is:11.39 & sMAPE is:48.39% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :34.16 & 45.66% & 0.89\n",
      "for 2023-01-30, MAE is:37.16 & sMAPE is:83.51% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :34.26 & 46.93% & 0.87\n",
      "for 2023-01-31, MAE is:19.61 & sMAPE is:46.91% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :33.79 & 46.92% & 0.85\n",
      "for 2023-02-01, MAE is:17.95 & sMAPE is:26.41% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :33.30 & 46.28% & 0.83\n",
      "for 2023-02-02, MAE is:38.37 & sMAPE is:33.90% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :33.45 & 45.91% & 0.85\n",
      "for 2023-02-03, MAE is:28.88 & sMAPE is:26.07% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :33.31 & 45.33% & 0.84\n",
      "for 2023-02-04, MAE is:43.99 & sMAPE is:37.55% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :33.62 & 45.10% & 0.83\n",
      "for 2023-02-05, MAE is:15.80 & sMAPE is:18.64% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :33.12 & 44.37% & 0.81\n",
      "for 2023-02-06, MAE is:69.14 & sMAPE is:53.95% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :34.10 & 44.63% & 0.80\n",
      "for 2023-02-07, MAE is:36.31 & sMAPE is:24.93% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :34.16 & 44.11% & 0.79\n",
      "for 2023-02-08, MAE is:48.71 & sMAPE is:47.85% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :34.53 & 44.20% & 0.81\n",
      "for 2023-02-09, MAE is:24.78 & sMAPE is:60.09% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :34.29 & 44.60% & 0.79\n",
      "for 2023-02-10, MAE is:23.48 & sMAPE is:54.86% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :34.02 & 44.85% & 0.79\n",
      "for 2023-02-11, MAE is:29.30 & sMAPE is:66.38% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :33.91 & 45.36% & 0.78\n",
      "for 2023-02-12, MAE is:60.72 & sMAPE is:106.89% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :34.53 & 46.80% & 0.78\n",
      "for 2023-02-13, MAE is:25.09 & sMAPE is:35.45% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :34.32 & 46.54% & 0.77\n",
      "for 2023-02-14, MAE is:50.72 & sMAPE is:52.25% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :34.68 & 46.66% & 0.79\n",
      "for 2023-02-15, MAE is:24.34 & sMAPE is:19.52% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :34.46 & 46.07% & 0.79\n",
      "for 2023-02-16, MAE is:32.22 & sMAPE is:33.53% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :34.41 & 45.81% & 0.78\n",
      "for 2023-02-17, MAE is:31.69 & sMAPE is:60.08% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :34.35 & 46.10% & 0.81\n",
      "for 2023-02-18, MAE is:13.47 & sMAPE is:45.27% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :33.93 & 46.09% & 0.80\n",
      "for 2023-02-19, MAE is:48.22 & sMAPE is:120.64% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :34.21 & 47.58% & 0.81\n",
      "for 2023-02-20, MAE is:39.22 & sMAPE is:54.17% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :34.31 & 47.71% & 0.82\n",
      "for 2023-02-21, MAE is:27.78 & sMAPE is:30.39% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :34.19 & 47.38% & 0.81\n",
      "for 2023-02-22, MAE is:38.94 & sMAPE is:35.55% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :34.28 & 47.15% & 0.83\n",
      "for 2023-02-23, MAE is:28.66 & sMAPE is:39.32% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :34.17 & 47.01% & 0.85\n",
      "for 2023-02-24, MAE is:15.89 & sMAPE is:24.02% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :33.84 & 46.59% & 0.84\n",
      "for 2023-02-25, MAE is:15.46 & sMAPE is:36.31% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :33.51 & 46.41% & 0.87\n",
      "for 2023-02-26, MAE is:54.78 & sMAPE is:99.03% & rMAE is:2.99 ||| daily mean of MAE & sMAPE & rMAE till now are :33.88 & 47.33% & 0.91\n",
      "for 2023-02-27, MAE is:66.84 & sMAPE is:63.18% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :34.45 & 47.60% & 0.91\n",
      "for 2023-02-28, MAE is:29.97 & sMAPE is:27.49% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :34.38 & 47.26% & 0.91\n",
      "for 2023-03-01, MAE is:29.43 & sMAPE is:25.85% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :34.29 & 46.90% & 0.91\n",
      "for 2023-03-02, MAE is:34.34 & sMAPE is:31.50% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :34.29 & 46.65% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-03, MAE is:43.98 & sMAPE is:65.01% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :34.45 & 46.95% & 0.91\n",
      "for 2023-03-04, MAE is:53.80 & sMAPE is:94.26% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :34.76 & 47.70% & 0.92\n",
      "for 2023-03-05, MAE is:26.88 & sMAPE is:25.81% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :34.64 & 47.36% & 0.91\n",
      "for 2023-03-06, MAE is:24.17 & sMAPE is:18.74% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :34.47 & 46.92% & 0.92\n",
      "for 2023-03-07, MAE is:33.39 & sMAPE is:28.65% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :34.46 & 46.64% & 0.92\n",
      "for 2023-03-08, MAE is:43.33 & sMAPE is:42.03% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :34.59 & 46.57% & 0.95\n",
      "for 2023-03-09, MAE is:24.94 & sMAPE is:18.91% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :34.45 & 46.16% & 0.95\n",
      "for 2023-03-10, MAE is:12.92 & sMAPE is:12.13% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :34.14 & 45.67% & 0.94\n",
      "for 2023-03-11, MAE is:12.88 & sMAPE is:14.98% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :33.83 & 45.23% & 0.93\n",
      "for 2023-03-12, MAE is:15.00 & sMAPE is:18.69% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :33.57 & 44.86% & 0.92\n",
      "for 2023-03-13, MAE is:53.94 & sMAPE is:73.96% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :33.85 & 45.26% & 0.92\n",
      "for 2023-03-14, MAE is:25.69 & sMAPE is:63.71% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :33.74 & 45.52% & 0.91\n",
      "for 2023-03-15, MAE is:27.91 & sMAPE is:42.56% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :33.66 & 45.48% & 0.91\n",
      "for 2023-03-16, MAE is:20.39 & sMAPE is:26.31% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :33.48 & 45.22% & 0.90\n",
      "for 2023-03-17, MAE is:29.59 & sMAPE is:60.50% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :33.43 & 45.42% & 0.90\n",
      "for 2023-03-18, MAE is:8.91 & sMAPE is:34.93% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :33.11 & 45.28% & 0.89\n",
      "for 2023-03-19, MAE is:38.49 & sMAPE is:73.06% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :33.18 & 45.64% & 0.90\n",
      "for 2023-03-20, MAE is:45.80 & sMAPE is:60.64% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :33.34 & 45.83% & 0.90\n",
      "for 2023-03-21, MAE is:22.93 & sMAPE is:28.04% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :33.21 & 45.61% & 0.89\n",
      "for 2023-03-22, MAE is:23.84 & sMAPE is:47.93% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :33.10 & 45.64% & 0.89\n",
      "for 2023-03-23, MAE is:7.51 & sMAPE is:30.98% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :32.78 & 45.46% & 0.88\n",
      "for 2023-03-24, MAE is:10.89 & sMAPE is:32.29% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :32.52 & 45.30% & 0.88\n",
      "for 2023-03-25, MAE is:14.13 & sMAPE is:67.77% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :32.30 & 45.57% & 0.89\n",
      "for 2023-03-26, MAE is:14.36 & sMAPE is:39.54% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :32.09 & 45.50% & 0.89\n",
      "for 2023-03-27, MAE is:20.13 & sMAPE is:34.92% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :31.95 & 45.37% & 0.88\n",
      "for 2023-03-28, MAE is:43.90 & sMAPE is:56.83% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :32.09 & 45.51% & 0.89\n",
      "for 2023-03-29, MAE is:17.57 & sMAPE is:17.25% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :31.92 & 45.18% & 0.88\n",
      "for 2023-03-30, MAE is:20.41 & sMAPE is:25.41% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :31.79 & 44.96% & 0.87\n",
      "for 2023-03-31, MAE is:32.52 & sMAPE is:42.96% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :31.80 & 44.94% & 0.87\n",
      "for 2023-04-01, MAE is:6.78 & sMAPE is:19.39% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :31.53 & 44.66% & 0.87\n",
      "for 2023-04-02, MAE is:23.63 & sMAPE is:54.52% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :31.44 & 44.77% & 0.88\n",
      "for 2023-04-03, MAE is:37.32 & sMAPE is:44.21% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :31.50 & 44.76% & 0.88\n",
      "for 2023-04-04, MAE is:28.71 & sMAPE is:26.31% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :31.47 & 44.56% & 0.88\n",
      "for 2023-04-05, MAE is:30.57 & sMAPE is:25.56% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :31.47 & 44.36% & 0.89\n",
      "for 2023-04-06, MAE is:20.65 & sMAPE is:23.81% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :31.35 & 44.15% & 0.89\n",
      "for 2023-04-07, MAE is:10.96 & sMAPE is:19.36% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :31.14 & 43.89% & 0.88\n",
      "for 2023-04-08, MAE is:15.75 & sMAPE is:33.95% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :30.99 & 43.79% & 0.89\n",
      "for 2023-04-09, MAE is:8.45 & sMAPE is:18.14% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :30.76 & 43.53% & 0.89\n",
      "for 2023-04-10, MAE is:18.89 & sMAPE is:67.15% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :30.64 & 43.77% & 0.88\n",
      "for 2023-04-11, MAE is:17.73 & sMAPE is:63.22% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :30.51 & 43.96% & 0.87\n",
      "for 2023-04-12, MAE is:44.45 & sMAPE is:83.40% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :30.65 & 44.35% & 0.87\n",
      "for 2023-04-13, MAE is:15.92 & sMAPE is:75.67% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :30.50 & 44.65% & 0.86\n",
      "for 2023-04-14, MAE is:21.74 & sMAPE is:44.41% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :30.42 & 44.65% & 0.86\n",
      "for 2023-04-15, MAE is:29.43 & sMAPE is:114.68% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :30.41 & 45.32% & 0.88\n",
      "for 2023-04-16, MAE is:43.28 & sMAPE is:85.86% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :30.53 & 45.70% & 0.89\n",
      "for 2023-04-17, MAE is:30.37 & sMAPE is:31.93% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :30.53 & 45.57% & 0.88\n",
      "for 2023-04-18, MAE is:24.55 & sMAPE is:32.03% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :30.48 & 45.45% & 0.88\n",
      "for 2023-04-19, MAE is:15.86 & sMAPE is:30.85% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :30.34 & 45.31% & 0.88\n",
      "for 2023-04-20, MAE is:15.68 & sMAPE is:36.16% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :30.21 & 45.23% & 0.88\n",
      "for 2023-04-21, MAE is:33.14 & sMAPE is:48.72% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :30.23 & 45.26% & 0.88\n",
      "for 2023-04-22, MAE is:6.33 & sMAPE is:22.46% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :30.02 & 45.06% & 0.88\n",
      "for 2023-04-23, MAE is:19.35 & sMAPE is:41.70% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :29.93 & 45.03% & 0.88\n",
      "for 2023-04-24, MAE is:18.56 & sMAPE is:26.59% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :29.83 & 44.87% & 0.88\n",
      "for 2023-04-25, MAE is:31.53 & sMAPE is:66.53% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :29.84 & 45.05% & 0.88\n",
      "for 2023-04-26, MAE is:32.26 & sMAPE is:79.44% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :29.86 & 45.35% & 0.89\n",
      "for 2023-04-27, MAE is:56.69 & sMAPE is:73.39% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :30.09 & 45.59% & 0.89\n",
      "for 2023-04-28, MAE is:9.16 & sMAPE is:9.72% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :29.91 & 45.29% & 0.88\n",
      "for 2023-04-29, MAE is:28.25 & sMAPE is:41.41% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :29.90 & 45.25% & 0.88\n",
      "for 2023-04-30, MAE is:26.61 & sMAPE is:87.97% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :29.87 & 45.61% & 0.89\n",
      "for 2023-05-01, MAE is:25.36 & sMAPE is:41.25% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :29.84 & 45.57% & 0.89\n",
      "for 2023-05-02, MAE is:35.96 & sMAPE is:43.77% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :29.89 & 45.56% & 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-03, MAE is:25.70 & sMAPE is:41.70% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :29.85 & 45.53% & 0.88\n",
      "for 2023-05-04, MAE is:22.76 & sMAPE is:27.01% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :29.79 & 45.38% & 0.89\n",
      "for 2023-05-05, MAE is:10.68 & sMAPE is:12.59% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :29.64 & 45.12% & 0.89\n",
      "for 2023-05-06, MAE is:13.07 & sMAPE is:20.08% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :29.51 & 44.92% & 0.88\n",
      "for 2023-05-07, MAE is:19.08 & sMAPE is:50.93% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :29.43 & 44.96% & 0.88\n",
      "for 2023-05-08, MAE is:20.78 & sMAPE is:32.01% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :29.36 & 44.86% & 0.88\n",
      "for 2023-05-09, MAE is:18.43 & sMAPE is:76.38% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :29.28 & 45.11% & 0.88\n",
      "for 2023-05-10, MAE is:14.07 & sMAPE is:132.55% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :29.16 & 45.78% & 0.87\n",
      "for 2023-05-11, MAE is:41.85 & sMAPE is:79.28% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :29.26 & 46.04% & 0.87\n",
      "for 2023-05-12, MAE is:34.11 & sMAPE is:50.61% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :29.29 & 46.07% & 0.88\n",
      "for 2023-05-13, MAE is:32.26 & sMAPE is:58.57% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :29.31 & 46.16% & 0.88\n",
      "for 2023-05-14, MAE is:27.38 & sMAPE is:56.64% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :29.30 & 46.24% & 0.88\n",
      "for 2023-05-15, MAE is:19.30 & sMAPE is:17.99% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :29.23 & 46.03% & 0.88\n",
      "for 2023-05-16, MAE is:43.01 & sMAPE is:61.47% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :29.33 & 46.15% & 0.88\n",
      "for 2023-05-17, MAE is:31.23 & sMAPE is:164.01% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :29.34 & 47.01% & 0.88\n",
      "for 2023-05-18, MAE is:28.58 & sMAPE is:38.02% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :29.34 & 46.94% & 0.88\n",
      "for 2023-05-19, MAE is:13.11 & sMAPE is:15.48% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :29.22 & 46.72% & 0.88\n",
      "for 2023-05-20, MAE is:31.48 & sMAPE is:73.97% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :29.24 & 46.91% & 0.88\n",
      "for 2023-05-21, MAE is:24.28 & sMAPE is:94.57% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :29.20 & 47.25% & 0.88\n",
      "for 2023-05-22, MAE is:13.25 & sMAPE is:17.56% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :29.09 & 47.04% & 0.88\n",
      "for 2023-05-23, MAE is:19.30 & sMAPE is:36.92% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :29.02 & 46.97% & 0.88\n",
      "for 2023-05-24, MAE is:50.78 & sMAPE is:67.20% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :29.17 & 47.11% & 0.87\n",
      "for 2023-05-25, MAE is:47.60 & sMAPE is:70.61% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :29.30 & 47.27% & 0.88\n",
      "for 2023-05-26, MAE is:28.24 & sMAPE is:78.95% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :29.29 & 47.49% & 0.88\n",
      "for 2023-05-27, MAE is:32.50 & sMAPE is:84.05% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :29.31 & 47.74% & 0.89\n",
      "for 2023-05-28, MAE is:27.98 & sMAPE is:87.96% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :29.30 & 48.01% & 0.89\n",
      "for 2023-05-29, MAE is:30.07 & sMAPE is:109.57% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :29.31 & 48.42% & 0.89\n",
      "for 2023-05-30, MAE is:20.65 & sMAPE is:27.66% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :29.25 & 48.28% & 0.89\n",
      "for 2023-05-31, MAE is:41.43 & sMAPE is:70.93% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :29.33 & 48.43% & 0.89\n",
      "for 2023-06-01, MAE is:30.30 & sMAPE is:58.90% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :29.34 & 48.50% & 0.89\n",
      "for 2023-06-02, MAE is:16.11 & sMAPE is:21.67% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :29.25 & 48.33% & 0.89\n",
      "for 2023-06-03, MAE is:23.02 & sMAPE is:62.49% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :29.21 & 48.42% & 0.90\n",
      "for 2023-06-04, MAE is:21.36 & sMAPE is:63.32% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :29.16 & 48.51% & 0.91\n",
      "for 2023-06-05, MAE is:18.39 & sMAPE is:21.57% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :29.09 & 48.34% & 0.90\n",
      "for 2023-06-06, MAE is:19.03 & sMAPE is:19.91% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :29.03 & 48.16% & 0.91\n",
      "for 2023-06-07, MAE is:19.38 & sMAPE is:20.93% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :28.97 & 47.99% & 0.91\n",
      "for 2023-06-08, MAE is:13.80 & sMAPE is:16.87% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :28.87 & 47.79% & 0.90\n",
      "for 2023-06-09, MAE is:30.42 & sMAPE is:47.82% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :28.88 & 47.79% & 0.91\n",
      "for 2023-06-10, MAE is:8.70 & sMAPE is:37.38% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :28.76 & 47.73% & 0.90\n",
      "for 2023-06-11, MAE is:32.58 & sMAPE is:146.02% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :28.78 & 48.33% & 0.91\n",
      "for 2023-06-12, MAE is:21.26 & sMAPE is:25.12% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :28.73 & 48.19% & 0.92\n",
      "for 2023-06-13, MAE is:16.55 & sMAPE is:20.25% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :28.66 & 48.02% & 0.92\n",
      "for 2023-06-14, MAE is:16.70 & sMAPE is:16.50% & rMAE is:2.99 ||| daily mean of MAE & sMAPE & rMAE till now are :28.59 & 47.83% & 0.94\n",
      "for 2023-06-15, MAE is:23.16 & sMAPE is:19.77% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :28.55 & 47.66% & 0.94\n",
      "for 2023-06-16, MAE is:16.98 & sMAPE is:13.96% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :28.48 & 47.46% & 0.93\n",
      "for 2023-06-17, MAE is:17.11 & sMAPE is:18.90% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :28.42 & 47.29% & 0.93\n",
      "for 2023-06-18, MAE is:22.94 & sMAPE is:28.08% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :28.38 & 47.18% & 0.92\n",
      "for 2023-06-19, MAE is:16.52 & sMAPE is:13.38% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :28.31 & 46.98% & 0.92\n",
      "for 2023-06-20, MAE is:13.75 & sMAPE is:11.69% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :28.23 & 46.77% & 0.92\n",
      "for 2023-06-21, MAE is:18.69 & sMAPE is:16.32% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :28.17 & 46.59% & 0.92\n",
      "for 2023-06-22, MAE is:23.25 & sMAPE is:24.14% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :28.14 & 46.46% & 0.92\n",
      "for 2023-06-23, MAE is:13.66 & sMAPE is:13.27% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :28.06 & 46.27% & 0.92\n",
      "for 2023-06-24, MAE is:46.65 & sMAPE is:94.86% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :28.17 & 46.55% & 0.92\n",
      "for 2023-06-25, MAE is:36.55 & sMAPE is:75.77% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :28.22 & 46.72% & 0.92\n",
      "for 2023-06-26, MAE is:30.03 & sMAPE is:29.52% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :28.23 & 46.62% & 0.92\n",
      "for 2023-06-27, MAE is:15.95 & sMAPE is:20.72% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :28.16 & 46.47% & 0.92\n",
      "for 2023-06-28, MAE is:14.99 & sMAPE is:13.29% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :28.08 & 46.29% & 0.92\n",
      "for 2023-06-29, MAE is:16.04 & sMAPE is:13.78% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :28.02 & 46.11% & 0.92\n",
      "for 2023-06-30, MAE is:16.37 & sMAPE is:15.18% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :27.95 & 45.94% & 0.92\n",
      "CPU times: total: 3d 14h 46min 25s\n",
      "Wall time: 2d 19h 17min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
