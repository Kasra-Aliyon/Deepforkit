{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = 'FR-2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:02:53,940]\u001b[0m A new study created in RDB with name: FR-2020_2020\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:14,734]\u001b[0m Trial 0 finished with value: 5.622331996887534 and parameters: {'n_hidden': 4, 'learning_rate': 0.008442999366180341, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3271157809831389, 'dropout_rate_Layer_2': 0.0831823765883839, 'dropout_rate_Layer_3': 0.04168860727145769, 'dropout_rate_Layer_4': 0.004709303402776088, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.980854622747937e-05, 'l1_Layer_2': 0.00034643640048542904, 'l1_Layer_3': 0.03853970269151032, 'l1_Layer_4': 0.0963476624582392, 'n_units_Layer_1': 210, 'n_units_Layer_2': 150, 'n_units_Layer_3': 210, 'n_units_Layer_4': 270}. Best is trial 0 with value: 5.622331996887534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 17.39% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 8.24 | sMAPE for Test Set is: 31.20% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:03:15,263]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 7.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:19,500]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:21,981]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:22,487]\u001b[0m Trial 3 finished with value: 5.995660365724476 and parameters: {'n_hidden': 3, 'learning_rate': 0.06540284314993103, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1883543311584635, 'dropout_rate_Layer_2': 0.3905020317456598, 'dropout_rate_Layer_3': 0.06594303180560797, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0886219524908386, 'l1_Layer_2': 0.0005991355994584519, 'l1_Layer_3': 0.034336611351073076, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 300}. Best is trial 0 with value: 5.622331996887534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 18.12% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.01 | sMAPE for Test Set is: 30.54% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:03:25,029]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:26,335]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:26,529]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:27,627]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:31,202]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:33,234]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:35,490]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:35,803]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:40,250]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:41,662]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:43,676]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:45,418]\u001b[0m Trial 10 finished with value: 5.187463495389488 and parameters: {'n_hidden': 3, 'learning_rate': 0.041790338757077376, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14843447086287004, 'dropout_rate_Layer_2': 0.031989824165120286, 'dropout_rate_Layer_3': 0.25583484917403576, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004122591799044215, 'l1_Layer_2': 2.2926209331065564e-05, 'l1_Layer_3': 0.00033855312676017696, 'n_units_Layer_1': 140, 'n_units_Layer_2': 145, 'n_units_Layer_3': 70}. Best is trial 10 with value: 5.187463495389488.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 16.24% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 28.64% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:03:47,964]\u001b[0m Trial 1 finished with value: 4.974813417145216 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021735128242167147, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2846505268671356, 'dropout_rate_Layer_2': 0.031647674589288764, 'dropout_rate_Layer_3': 0.009318736575281372, 'dropout_rate_Layer_4': 0.23767990958384974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.03802896187557e-05, 'l1_Layer_2': 1.2145783953113956e-05, 'l1_Layer_3': 7.246180047608934e-05, 'l1_Layer_4': 0.00021158208371975897, 'n_units_Layer_1': 285, 'n_units_Layer_2': 270, 'n_units_Layer_3': 205, 'n_units_Layer_4': 55}. Best is trial 1 with value: 4.974813417145216.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 15.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 24.27% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:03:50,141]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:50,433]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:53,989]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:54,872]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:57,428]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:59,188]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:59,491]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:02,546]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:03,703]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:07,389]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:08,652]\u001b[0m Trial 20 finished with value: 5.714685238797348 and parameters: {'n_hidden': 3, 'learning_rate': 0.028739159599162428, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3190152713857381, 'dropout_rate_Layer_2': 0.3410988089367998, 'dropout_rate_Layer_3': 0.26894159125482936, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0016128857878996107, 'l1_Layer_2': 0.015226743363734993, 'l1_Layer_3': 0.0006588178932693482, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 285}. Best is trial 1 with value: 4.974813417145216.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 17.40% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 8.97 | sMAPE for Test Set is: 32.98% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:04:12,357]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:17,790]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:21,564]\u001b[0m Trial 29 finished with value: 10.434237384689588 and parameters: {'n_hidden': 3, 'learning_rate': 0.04708926192531808, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2934425317741183, 'dropout_rate_Layer_2': 0.384999531006442, 'dropout_rate_Layer_3': 0.027196648834867523, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.022852377941109527, 'l1_Layer_2': 0.008199627443119114, 'l1_Layer_3': 0.00038156019024323363, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 70}. Best is trial 1 with value: 4.974813417145216.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.43 | sMAPE for Validation Set is: 27.85% | rMAE for Validation Set is: 1.33\n",
      "MAE for Test Set is: 15.46 | sMAPE for Test Set is: 46.82% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:04:23,430]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:25,028]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:25,745]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:28,010]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:31,171]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:31,669]\u001b[0m Trial 33 finished with value: 5.481090192244262 and parameters: {'n_hidden': 4, 'learning_rate': 0.01821904883328015, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08976910079468846, 'dropout_rate_Layer_2': 0.34747656069247074, 'dropout_rate_Layer_3': 0.0218211509455605, 'dropout_rate_Layer_4': 0.24679418901529393, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.3394318659090569e-05, 'l1_Layer_2': 0.005772196899181184, 'l1_Layer_3': 4.584592365135475e-05, 'l1_Layer_4': 0.0019034035027897195, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 200, 'n_units_Layer_4': 190}. Best is trial 1 with value: 4.974813417145216.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.08 | sMAPE for Test Set is: 27.92% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:04:34,212]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:34,876]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:36,842]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:39,497]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:40,926]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:44,271]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:46,848]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:49,991]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:52,607]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:55,352]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:57,219]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:58,422]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:05:02,310]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:05:11,197]\u001b[0m Trial 26 finished with value: 5.465271685145645 and parameters: {'n_hidden': 4, 'learning_rate': 0.022142955239024043, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12347912199225237, 'dropout_rate_Layer_2': 0.12491058726344284, 'dropout_rate_Layer_3': 0.39663145322306925, 'dropout_rate_Layer_4': 0.03743899946835616, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011417218236047126, 'l1_Layer_2': 0.04862144832584746, 'l1_Layer_3': 0.0010815953820378426, 'l1_Layer_4': 0.00020689831436211355, 'n_units_Layer_1': 260, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130, 'n_units_Layer_4': 100}. Best is trial 1 with value: 4.974813417145216.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 17.03% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.22 | sMAPE for Test Set is: 31.20% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:05:11,900]\u001b[0m Trial 54 finished with value: 5.562477684633691 and parameters: {'n_hidden': 3, 'learning_rate': 0.03325298092555931, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15623692056159896, 'dropout_rate_Layer_2': 0.20567125121359925, 'dropout_rate_Layer_3': 0.2901020064078849, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004048937639872982, 'l1_Layer_2': 0.00013826417309316106, 'l1_Layer_3': 0.0010148971876963668, 'n_units_Layer_1': 65, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 1 with value: 4.974813417145216.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 16.94% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.63 | sMAPE for Test Set is: 32.00% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:05:15,463]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:05:15,606]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:05:19,599]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:05:31,386]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:05:33,925]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:05:34,177]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:05:54,204]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:06:02,777]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:06:58,484]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:01,876]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:04,086]\u001b[0m Trial 64 finished with value: 4.556027880218609 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023355300718414483, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052899483603221886, 'dropout_rate_Layer_2': 0.10447975407359947, 'dropout_rate_Layer_3': 0.012238795358979128, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005775347183797674, 'l1_Layer_2': 0.002695246067901413, 'l1_Layer_3': 1.3172552998515713e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 150, 'n_units_Layer_3': 205}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 14.52% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 27.99% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:07:04,355]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:08,078]\u001b[0m Trial 52 finished with value: 5.3935291645469166 and parameters: {'n_hidden': 3, 'learning_rate': 0.012963265832985177, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39679381503581324, 'dropout_rate_Layer_2': 0.2969876963713689, 'dropout_rate_Layer_3': 0.09654631630914917, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000516983953430386, 'l1_Layer_2': 0.07936112681004379, 'l1_Layer_3': 0.0005833873452156891, 'n_units_Layer_1': 285, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 16.78% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.54 | sMAPE for Test Set is: 29.29% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:07:08,309]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:11,446]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:11,580]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:14,986]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:20,360]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:20,689]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:22,966]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:26,980]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:27,161]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:27,565]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:31,777]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:32,478]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:34,667]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:36,699]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:39,334]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:44,892]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:46,215]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:49,600]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:51,151]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:53,502]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:56,481]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:01,914]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:04,209]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:06,725]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:08,802]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:09,133]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:12,137]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:12,517]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:16,141]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:17,935]\u001b[0m Trial 81 finished with value: 4.835645017859213 and parameters: {'n_hidden': 3, 'learning_rate': 0.001866086672401227, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004203285682759761, 'dropout_rate_Layer_2': 0.2516596959430029, 'dropout_rate_Layer_3': 0.36826416408245766, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008330944917107286, 'l1_Layer_2': 0.000554552819281987, 'l1_Layer_3': 0.0004984626188824769, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 300}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 15.25% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.50 | sMAPE for Test Set is: 22.67% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:08:19,957]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:21,969]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:25,662]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:25,951]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:29,400]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:32,854]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:37,053]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:39,901]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:41,236]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:42,699]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:45,352]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:46,185]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:46,556]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:49,116]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:51,018]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:53,112]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:54,362]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:54,753]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:58,305]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:59,057]\u001b[0m Trial 44 finished with value: 4.784616939470561 and parameters: {'n_hidden': 4, 'learning_rate': 0.000826483276577741, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.171227719009606, 'dropout_rate_Layer_2': 0.20390716931490227, 'dropout_rate_Layer_3': 0.3716234392224848, 'dropout_rate_Layer_4': 0.3034050298896407, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.72608389263095e-05, 'l1_Layer_2': 0.007634306472543059, 'l1_Layer_3': 2.483533579318346e-05, 'l1_Layer_4': 2.5550222762275044e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 165, 'n_units_Layer_3': 280, 'n_units_Layer_4': 210}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:59,072]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 15.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 24.59% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:09:02,537]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:04,479]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:08,676]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:08,858]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:10,883]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:12,569]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:15,962]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:17,944]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:18,107]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:22,062]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:23,506]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:25,845]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:28,430]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:28,785]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:32,882]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:35,769]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:35,983]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:39,732]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:40,008]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:44,555]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:44,857]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:47,091]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:00,841]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:06,627]\u001b[0m Trial 141 finished with value: 5.774074471907021 and parameters: {'n_hidden': 3, 'learning_rate': 0.006158336558231547, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35657572664139736, 'dropout_rate_Layer_2': 0.11631183175439823, 'dropout_rate_Layer_3': 0.2103730142714791, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00027160654488543834, 'l1_Layer_2': 1.3451845578877578e-05, 'l1_Layer_3': 0.00012201786447863136, 'n_units_Layer_1': 160, 'n_units_Layer_2': 195, 'n_units_Layer_3': 235}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 17.60% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 8.37 | sMAPE for Test Set is: 31.29% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:10:08,867]\u001b[0m Trial 142 finished with value: 5.631527623144607 and parameters: {'n_hidden': 3, 'learning_rate': 0.007081963067515999, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3989582417601904, 'dropout_rate_Layer_2': 0.11514459888440659, 'dropout_rate_Layer_3': 0.21197023456109257, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002960501678382736, 'l1_Layer_2': 8.927635631120915e-05, 'l1_Layer_3': 0.0003225645834064851, 'n_units_Layer_1': 160, 'n_units_Layer_2': 190, 'n_units_Layer_3': 235}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 17.36% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 7.82 | sMAPE for Test Set is: 30.07% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:10:10,973]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:13,511]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:14,817]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:14,936]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:20,805]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:21,546]\u001b[0m Trial 140 finished with value: 5.03650462877817 and parameters: {'n_hidden': 3, 'learning_rate': 0.006545952646593953, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36127981919846136, 'dropout_rate_Layer_2': 0.11779215621700764, 'dropout_rate_Layer_3': 0.2020264763143351, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003544965036958873, 'l1_Layer_2': 0.0006373876675572793, 'l1_Layer_3': 0.00012132500765743296, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 225}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 15.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 27.52% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:10:26,253]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:26,714]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:29,785]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:37,127]\u001b[0m Trial 147 finished with value: 5.607368923414576 and parameters: {'n_hidden': 3, 'learning_rate': 0.007203887683525574, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39293214270942317, 'dropout_rate_Layer_2': 0.06858391056121485, 'dropout_rate_Layer_3': 0.22441211617662893, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003448050811065565, 'l1_Layer_2': 2.3789600959024327e-05, 'l1_Layer_3': 7.487326728873578e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 215, 'n_units_Layer_3': 255}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 8.65 | sMAPE for Test Set is: 32.26% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:10:39,460]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:42,613]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:42,956]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:46,714]\u001b[0m Trial 148 finished with value: 5.067783182568612 and parameters: {'n_hidden': 3, 'learning_rate': 0.011403646555115351, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2631003527706719, 'dropout_rate_Layer_2': 0.16501610077777668, 'dropout_rate_Layer_3': 0.17294880935395585, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.1651819154958534e-05, 'l1_Layer_2': 0.00033830896025022, 'l1_Layer_3': 7.686171498755578e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 16.04% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 27.10% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:10:49,931]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:53,490]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:11:01,178]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:11:04,334]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:11:06,316]\u001b[0m Trial 161 finished with value: 5.415334198337249 and parameters: {'n_hidden': 3, 'learning_rate': 0.012007269688446048, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16261971793259633, 'dropout_rate_Layer_2': 0.19738269186511012, 'dropout_rate_Layer_3': 0.178684993560907, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.128320820381017e-05, 'l1_Layer_2': 1.0359951554518828e-05, 'l1_Layer_3': 0.0002466791422741468, 'n_units_Layer_1': 275, 'n_units_Layer_2': 110, 'n_units_Layer_3': 125}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 16.85% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.13 | sMAPE for Test Set is: 30.96% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:11:08,461]\u001b[0m Trial 157 finished with value: 5.44380599243015 and parameters: {'n_hidden': 3, 'learning_rate': 0.005420789751698569, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39682604170795605, 'dropout_rate_Layer_2': 0.05201252778972365, 'dropout_rate_Layer_3': 0.19590355829290546, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00034087529298348955, 'l1_Layer_2': 6.332681379149568e-05, 'l1_Layer_3': 7.383368069792989e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 235, 'n_units_Layer_3': 230}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 17.11% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 31.13% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:11:13,227]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:11:13,855]\u001b[0m Trial 160 finished with value: 5.3977239451062085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055648147905502775, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3984606831518869, 'dropout_rate_Layer_2': 0.053645504084183726, 'dropout_rate_Layer_3': 0.25607045151908886, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00033660129545673244, 'l1_Layer_2': 5.3865114882763764e-05, 'l1_Layer_3': 0.00010844447701833479, 'n_units_Layer_1': 115, 'n_units_Layer_2': 235, 'n_units_Layer_3': 285}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 16.77% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.60 | sMAPE for Test Set is: 32.02% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:11:20,248]\u001b[0m Trial 163 finished with value: 5.346759205299605 and parameters: {'n_hidden': 3, 'learning_rate': 0.012441042934942383, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16920372465698374, 'dropout_rate_Layer_2': 0.16249229589443295, 'dropout_rate_Layer_3': 0.002225626526002611, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.396625092372709e-05, 'l1_Layer_2': 1.2637770333438542e-05, 'l1_Layer_3': 0.0002980881733413307, 'n_units_Layer_1': 230, 'n_units_Layer_2': 50, 'n_units_Layer_3': 115}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 16.73% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.03 | sMAPE for Test Set is: 30.73% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:11:22,937]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:11:26,736]\u001b[0m Trial 164 finished with value: 5.454538665679135 and parameters: {'n_hidden': 3, 'learning_rate': 0.0054514067872906535, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3997115100778935, 'dropout_rate_Layer_2': 0.09706597971748324, 'dropout_rate_Layer_3': 0.23936584188992696, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002971114208944593, 'l1_Layer_2': 4.7587227688626915e-05, 'l1_Layer_3': 0.00019190193929462837, 'n_units_Layer_1': 130, 'n_units_Layer_2': 215, 'n_units_Layer_3': 250}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 16.92% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.53 | sMAPE for Test Set is: 29.17% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:11:31,150]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:11:39,693]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:11:42,184]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:11:44,342]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:11:47,457]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:11:47,564]\u001b[0m Trial 166 finished with value: 5.904672287385114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0054612271489875375, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38340862680467463, 'dropout_rate_Layer_2': 0.08465370244386496, 'dropout_rate_Layer_3': 0.2414261670188628, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00015754008950575503, 'l1_Layer_2': 7.39542459962548e-05, 'l1_Layer_3': 8.392141963092135e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 245, 'n_units_Layer_3': 300}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 17.98% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 8.19 | sMAPE for Test Set is: 30.97% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:11:51,604]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:11:55,486]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:02,345]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:04,917]\u001b[0m Trial 167 finished with value: 4.616577872891653 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006318852540849724, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22846112261310583, 'dropout_rate_Layer_2': 0.05546572536504765, 'dropout_rate_Layer_3': 0.235965946417159, 'dropout_rate_Layer_4': 0.38594360628862545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00013384736178767827, 'l1_Layer_2': 0.004137646931516783, 'l1_Layer_3': 1.0033316701525497e-05, 'l1_Layer_4': 2.031192958442302e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 70, 'n_units_Layer_3': 215, 'n_units_Layer_4': 205}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 14.87% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 21.24% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:12:07,680]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:10,858]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:14,007]\u001b[0m Trial 179 finished with value: 5.606819892684396 and parameters: {'n_hidden': 3, 'learning_rate': 0.008671650337260414, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16457817857493792, 'dropout_rate_Layer_2': 0.1865873925412649, 'dropout_rate_Layer_3': 0.16687862335478182, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.438561153918609e-05, 'l1_Layer_2': 1.1400394119734955e-05, 'l1_Layer_3': 0.0002739736473063746, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 125}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 7.44 | sMAPE for Test Set is: 28.88% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:12:14,946]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:18,850]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:21,057]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:24,868]\u001b[0m Trial 175 finished with value: 5.866390008491289 and parameters: {'n_hidden': 3, 'learning_rate': 0.005440214485881141, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3490571462034935, 'dropout_rate_Layer_2': 0.034380190026108856, 'dropout_rate_Layer_3': 0.38307451609632787, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002769350687715101, 'l1_Layer_2': 7.602061994105245e-05, 'l1_Layer_3': 4.319223048507231e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 230, 'n_units_Layer_3': 290}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 17.82% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 8.56 | sMAPE for Test Set is: 31.94% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:12:27,380]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:33,337]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:36,202]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:37,992]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:45,814]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:46,214]\u001b[0m Trial 174 finished with value: 4.723725254651111 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035636495611655826, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3628197158244586, 'dropout_rate_Layer_2': 0.08742327074894661, 'dropout_rate_Layer_3': 0.23512146407918963, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00036764646833343584, 'l1_Layer_2': 2.0169367873506247e-05, 'l1_Layer_3': 0.00018215923881891068, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 15.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 22.35% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:12:50,542]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:53,856]\u001b[0m Trial 191 finished with value: 5.773569624570496 and parameters: {'n_hidden': 3, 'learning_rate': 0.015542797642973245, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2343827468917015, 'dropout_rate_Layer_2': 0.17237922054756688, 'dropout_rate_Layer_3': 0.19308226214053126, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.35164585077238e-05, 'l1_Layer_2': 4.2501608392232764e-05, 'l1_Layer_3': 0.00014333118840503876, 'n_units_Layer_1': 230, 'n_units_Layer_2': 50, 'n_units_Layer_3': 135}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 17.65% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.88 | sMAPE for Test Set is: 30.10% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:13:07,608]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:12,204]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:26,125]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:26,721]\u001b[0m Trial 194 finished with value: 5.44281384539116 and parameters: {'n_hidden': 3, 'learning_rate': 0.0046335199963219685, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3445535916638844, 'dropout_rate_Layer_2': 0.011334870569678527, 'dropout_rate_Layer_3': 0.23530490127317777, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00035519121338153215, 'l1_Layer_2': 5.111913141465469e-05, 'l1_Layer_3': 7.648172643019084e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 16.74% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.24 | sMAPE for Test Set is: 31.13% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:13:27,893]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:31,184]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:33,655]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:35,029]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:42,399]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:45,440]\u001b[0m Trial 185 finished with value: 4.658761994627824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024093087806142596, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35866729546970527, 'dropout_rate_Layer_2': 0.023964321354662834, 'dropout_rate_Layer_3': 0.06297779404567314, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000784297355078285, 'l1_Layer_2': 0.00011487649298844376, 'l1_Layer_3': 0.00027223627111661595, 'n_units_Layer_1': 140, 'n_units_Layer_2': 235, 'n_units_Layer_3': 290}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 14.93% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 20.48% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:13:46,666]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:50,139]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:50,284]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:54,698]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:57,570]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:00,724]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:06,854]\u001b[0m Trial 207 finished with value: 5.259320567147027 and parameters: {'n_hidden': 3, 'learning_rate': 0.012306369040328996, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20758218116115068, 'dropout_rate_Layer_2': 0.2140301567926578, 'dropout_rate_Layer_3': 0.15950158088882077, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 7.432634542503038e-05, 'l1_Layer_2': 0.0001544984094902033, 'l1_Layer_3': 2.116240794052994e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 16.39% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.76 | sMAPE for Test Set is: 29.96% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:14:10,800]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:14,955]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:16,223]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:19,865]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:21,863]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:23,254]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:25,499]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:31,005]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:33,044]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:38,525]\u001b[0m Trial 209 finished with value: 4.715174884154589 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005790158758426691, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10697014142940911, 'dropout_rate_Layer_2': 0.01788784553083783, 'dropout_rate_Layer_3': 0.33940868457983187, 'dropout_rate_Layer_4': 0.3722829075362438, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.193395147099791e-05, 'l1_Layer_2': 0.002592887904486074, 'l1_Layer_3': 1.7300751227857563e-05, 'l1_Layer_4': 0.00019068353419341412, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 230, 'n_units_Layer_4': 200}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 15.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.86 | sMAPE for Test Set is: 20.12% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:14:40,562]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:40,674]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:45,154]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:48,384]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:52,644]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:55,813]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:56,286]\u001b[0m Trial 224 finished with value: 7.458890442040158 and parameters: {'n_hidden': 3, 'learning_rate': 0.05506990028943719, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1990651423563506, 'dropout_rate_Layer_2': 0.21714380157639096, 'dropout_rate_Layer_3': 0.10294422370657433, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.841622590542388e-05, 'l1_Layer_2': 0.00018819415659848102, 'l1_Layer_3': 2.225920641895152e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 170, 'n_units_Layer_3': 175}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.46 | sMAPE for Validation Set is: 21.45% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 10.71 | sMAPE for Test Set is: 36.72% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:14:58,624]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:01,115]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:02,182]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:04,127]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:09,709]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:16,582]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:17,215]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:17,314]\u001b[0m Trial 230 finished with value: 5.0998486511622945 and parameters: {'n_hidden': 3, 'learning_rate': 0.006025090647712055, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26530252180714753, 'dropout_rate_Layer_2': 0.08955988166566307, 'dropout_rate_Layer_3': 0.05193606072973585, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00019691675814151658, 'l1_Layer_2': 0.00041027564607867427, 'l1_Layer_3': 6.813123544968398e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 145}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 16.13% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 29.23% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:15:21,339]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:22,348]\u001b[0m Trial 233 finished with value: 5.554981554535736 and parameters: {'n_hidden': 3, 'learning_rate': 0.005992372099482092, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2813207867164944, 'dropout_rate_Layer_2': 0.10765420969447344, 'dropout_rate_Layer_3': 0.09424932802014759, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001729195543983236, 'l1_Layer_2': 0.00046883814867986596, 'l1_Layer_3': 8.771480602090869e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 17.17% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 26.90% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:15:24,971]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:26,310]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:26,706]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:28,625]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:30,879]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:33,130]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:33,768]\u001b[0m Trial 238 finished with value: 7.46655968422774 and parameters: {'n_hidden': 4, 'learning_rate': 0.09308856603861537, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20089553416357367, 'dropout_rate_Layer_2': 0.05422873636100183, 'dropout_rate_Layer_3': 0.3270565096835978, 'dropout_rate_Layer_4': 0.34466665048841005, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0026261415782834947, 'l1_Layer_2': 0.01732742080108001, 'l1_Layer_3': 7.78933173254166e-05, 'l1_Layer_4': 0.002483360934099943, 'n_units_Layer_1': 205, 'n_units_Layer_2': 120, 'n_units_Layer_3': 220, 'n_units_Layer_4': 240}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.47 | sMAPE for Validation Set is: 21.37% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 39.04% | rMAE for Test Set is: 1.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:15:37,903]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:39,400]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:39,707]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:40,082]\u001b[0m Trial 244 finished with value: 6.371019338558061 and parameters: {'n_hidden': 3, 'learning_rate': 0.01986016768692775, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24021477331789118, 'dropout_rate_Layer_2': 0.16264013560516846, 'dropout_rate_Layer_3': 0.0474079000023087, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00045510631270454, 'l1_Layer_2': 6.754119335360657e-05, 'l1_Layer_3': 5.018808445542985e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 195, 'n_units_Layer_3': 100}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 10.17 | sMAPE for Test Set is: 35.84% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:15:45,437]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:46,743]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:50,181]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:50,518]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:51,969]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:55,812]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:01,383]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:01,708]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:03,247]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:05,192]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:08,220]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:09,694]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:12,752]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:13,031]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:13,380]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:17,496]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:18,945]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:21,338]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:23,664]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:27,015]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:31,527]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:34,871]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:39,439]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:43,487]\u001b[0m Trial 270 finished with value: 5.109572605289784 and parameters: {'n_hidden': 3, 'learning_rate': 0.006066120958239933, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.261482661312521, 'dropout_rate_Layer_2': 0.28876424435025716, 'dropout_rate_Layer_3': 0.0014936426589760576, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.611561841195806e-05, 'l1_Layer_2': 0.00011994891185415425, 'l1_Layer_3': 0.00014873603670693004, 'n_units_Layer_1': 160, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 64 with value: 4.556027880218609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 16.13% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.51 | sMAPE for Test Set is: 23.26% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:16:46,865]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:50,659]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:53,787]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:56,931]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:01,097]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:03,393]\u001b[0m Trial 268 finished with value: 4.47667323332599 and parameters: {'n_hidden': 3, 'learning_rate': 0.00104873549282516, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05920761565343524, 'dropout_rate_Layer_2': 0.15966590917310466, 'dropout_rate_Layer_3': 0.26450302784679935, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002286534020924804, 'l1_Layer_2': 0.0006809718926421466, 'l1_Layer_3': 0.00016631248528527554, 'n_units_Layer_1': 195, 'n_units_Layer_2': 75, 'n_units_Layer_3': 200}. Best is trial 268 with value: 4.47667323332599.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 19.31% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:17:07,008]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:10,227]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:13,263]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:17,597]\u001b[0m Trial 275 finished with value: 5.040333150529773 and parameters: {'n_hidden': 3, 'learning_rate': 0.005048986645479176, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27190558941964066, 'dropout_rate_Layer_2': 0.05865564399915105, 'dropout_rate_Layer_3': 0.25442915436366187, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003345700453766666, 'l1_Layer_2': 7.294504399718568e-05, 'l1_Layer_3': 9.306431288514068e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 215, 'n_units_Layer_3': 240}. Best is trial 268 with value: 4.47667323332599.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 15.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 27.81% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:17:21,102]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:27,092]\u001b[0m Trial 281 finished with value: 5.771680568911731 and parameters: {'n_hidden': 3, 'learning_rate': 0.007342552761055131, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36373644189011056, 'dropout_rate_Layer_2': 0.07169786892869244, 'dropout_rate_Layer_3': 0.21810708059308664, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002260931478273907, 'l1_Layer_2': 3.6060276605468955e-05, 'l1_Layer_3': 0.00013321127163623623, 'n_units_Layer_1': 130, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295}. Best is trial 268 with value: 4.47667323332599.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 17.74% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 32.82% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:17:29,455]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:29,777]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:32,753]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:35,097]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:35,359]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:37,608]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:41,626]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:44,830]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:45,062]\u001b[0m Trial 279 finished with value: 4.778550104948397 and parameters: {'n_hidden': 3, 'learning_rate': 0.000939391666296422, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34768324177829274, 'dropout_rate_Layer_2': 0.06437399226027975, 'dropout_rate_Layer_3': 0.0021616469208098933, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022785860232829025, 'l1_Layer_2': 0.002029971513418196, 'l1_Layer_3': 2.331271880380175e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 190, 'n_units_Layer_3': 135}. Best is trial 268 with value: 4.47667323332599.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 15.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 22.21% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:17:45,928]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:51,024]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:52,139]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:57,185]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:01,864]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:15,851]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:17,306]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:21,039]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:22,436]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:26,588]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:26,791]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:31,928]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:36,273]\u001b[0m Trial 300 finished with value: 4.809311222268661 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021423384153476635, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3194345442432924, 'dropout_rate_Layer_2': 0.3927090083586659, 'dropout_rate_Layer_3': 0.02586233670189166, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011679018411261909, 'l1_Layer_2': 0.0003506015728149417, 'l1_Layer_3': 5.6505904830910036e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 270, 'n_units_Layer_3': 140}. Best is trial 268 with value: 4.47667323332599.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 15.36% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 22.62% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:18:40,932]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:42,753]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:42,762]\u001b[0m Trial 290 finished with value: 4.457507893725315 and parameters: {'n_hidden': 3, 'learning_rate': 0.00138934688834924, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028445997374345597, 'dropout_rate_Layer_2': 0.2586458616116569, 'dropout_rate_Layer_3': 0.3229730725364841, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.740379123386357e-05, 'l1_Layer_2': 0.0028100522438008644, 'l1_Layer_3': 4.403194765876997e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 70, 'n_units_Layer_3': 200}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 19.76% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:18:46,570]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:47,903]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:52,477]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:55,915]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:57,901]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:00,724]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:01,025]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:01,670]\u001b[0m Trial 305 finished with value: 4.715222193939504 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012491591724133825, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04544464437327706, 'dropout_rate_Layer_2': 0.2476061850962824, 'dropout_rate_Layer_3': 0.3191982873140352, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.013404059803508e-05, 'l1_Layer_2': 0.004033551640386242, 'l1_Layer_3': 4.089158796354485e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 70, 'n_units_Layer_3': 195}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 15.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 20.06% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:19:05,782]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:08,016]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:08,576]\u001b[0m Trial 311 finished with value: 5.703683244493864 and parameters: {'n_hidden': 3, 'learning_rate': 0.010150526082994518, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26340282376398644, 'dropout_rate_Layer_2': 0.0013177262266792639, 'dropout_rate_Layer_3': 0.23555511645726815, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001873087622562387, 'l1_Layer_2': 3.9307704429883574e-05, 'l1_Layer_3': 0.00032238139312273993, 'n_units_Layer_1': 125, 'n_units_Layer_2': 230, 'n_units_Layer_3': 250}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 8.49 | sMAPE for Test Set is: 31.77% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:19:08,970]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:09,023]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:12,383]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:16,691]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:16,842]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:20,908]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:28,573]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:33,190]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:37,977]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:40,858]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:42,508]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:45,738]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:47,441]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:50,672]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:52,541]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:54,272]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:56,546]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:58,322]\u001b[0m Trial 323 finished with value: 4.488937004382829 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013993973718415694, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021465257962566486, 'dropout_rate_Layer_2': 0.3039684287115928, 'dropout_rate_Layer_3': 0.21204863830324408, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047794329092118844, 'l1_Layer_2': 0.000880278688749933, 'l1_Layer_3': 0.00018241331966339675, 'n_units_Layer_1': 160, 'n_units_Layer_2': 110, 'n_units_Layer_3': 150}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 20.02% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:20:04,622]\u001b[0m Trial 335 finished with value: 4.834914599781374 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008554315330780571, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2932361254598209, 'dropout_rate_Layer_2': 0.2465625969317507, 'dropout_rate_Layer_3': 0.10261392129040181, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8857839996097204e-05, 'l1_Layer_2': 0.00022042659458529443, 'l1_Layer_3': 4.828156069526769e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 15.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 19.90% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:20:04,835]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:10,672]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:13,628]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:15,429]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:18,470]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:18,654]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:25,093]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:29,472]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:41,585]\u001b[0m Trial 339 finished with value: 4.601388508331177 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007466778637726049, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2920003118686304, 'dropout_rate_Layer_2': 0.2947260406858179, 'dropout_rate_Layer_3': 0.12011351542604823, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018412458026296529, 'l1_Layer_2': 0.0003255375016521822, 'l1_Layer_3': 6.423608169944151e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 280, 'n_units_Layer_3': 160}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 24.24% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:20:44,504]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:46,601]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:51,291]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:51,554]\u001b[0m Trial 347 finished with value: 4.749130998208314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008225090965375922, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26020902625244824, 'dropout_rate_Layer_2': 0.018256797300043898, 'dropout_rate_Layer_3': 0.12199384614740463, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00145011431900978, 'l1_Layer_2': 0.00012255307195660438, 'l1_Layer_3': 2.8396246941509156e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 260, 'n_units_Layer_3': 125}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 15.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.33 | sMAPE for Test Set is: 22.15% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:20:54,209]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:57,468]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:00,721]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:02,279]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:06,390]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:06,925]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:10,331]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:10,625]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:16,793]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:21,725]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:26,895]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:30,398]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:30,727]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:36,102]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:40,579]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:42,026]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:46,776]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:53,543]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:58,002]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:58,214]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:59,804]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:03,306]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:05,615]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:06,845]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:09,641]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:09,847]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:10,295]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:15,001]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:21,274]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:27,837]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:31,813]\u001b[0m Trial 371 finished with value: 4.6796890600033985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007832239568644466, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18086764068117342, 'dropout_rate_Layer_2': 0.14357565827497465, 'dropout_rate_Layer_3': 0.03285273889860474, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013085903988054376, 'l1_Layer_2': 0.003435711166304329, 'l1_Layer_3': 3.063665239567997e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 220, 'n_units_Layer_3': 175}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 14.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 22.52% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:22:37,606]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:53,585]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:58,159]\u001b[0m Trial 385 finished with value: 4.650194122427225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009170076804670689, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04600134649066884, 'dropout_rate_Layer_2': 0.08583197728460548, 'dropout_rate_Layer_3': 0.035946912396292496, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.182556430896556e-05, 'l1_Layer_2': 1.4267808532919687e-05, 'l1_Layer_3': 3.0159585535670413e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 205, 'n_units_Layer_3': 195}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 14.79% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 21.82% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:23:09,138]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:23:26,745]\u001b[0m Trial 383 finished with value: 4.944029784051622 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027212122964506104, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31824758080968174, 'dropout_rate_Layer_2': 0.2946114917192948, 'dropout_rate_Layer_3': 0.2419647268569499, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00032864967992328627, 'l1_Layer_2': 0.0006526716174696752, 'l1_Layer_3': 0.00018894376035445066, 'n_units_Layer_1': 135, 'n_units_Layer_2': 270, 'n_units_Layer_3': 290}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 15.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 22.62% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:23:36,280]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:23:39,130]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:23:39,868]\u001b[0m Trial 386 finished with value: 4.619847397972975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013650149411426607, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052278765001339184, 'dropout_rate_Layer_2': 0.1442145989634481, 'dropout_rate_Layer_3': 0.03618474041307331, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021083411816766169, 'l1_Layer_2': 0.0011291675024610104, 'l1_Layer_3': 2.8870120093802822e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 245, 'n_units_Layer_3': 195}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.64 | sMAPE for Test Set is: 23.44% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:23:44,131]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:23:46,695]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:23:50,243]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:23:55,782]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:23:59,830]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:23:59,959]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:03,270]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:04,254]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:05,215]\u001b[0m Trial 388 finished with value: 4.932792160400022 and parameters: {'n_hidden': 3, 'learning_rate': 0.00348892660716154, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26511162442733155, 'dropout_rate_Layer_2': 0.2513506249164526, 'dropout_rate_Layer_3': 0.23764369181900552, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00031701947027249795, 'l1_Layer_2': 1.3716118784741451e-05, 'l1_Layer_3': 0.00018463303878192834, 'n_units_Layer_1': 145, 'n_units_Layer_2': 270, 'n_units_Layer_3': 230}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 15.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 25.94% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:24:08,201]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:08,397]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:09,323]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:13,164]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:16,749]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:21,932]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:31,148]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:38,197]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:41,209]\u001b[0m Trial 403 finished with value: 4.722017756476305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010402903847714611, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26282528723428816, 'dropout_rate_Layer_2': 0.09283640612082046, 'dropout_rate_Layer_3': 0.018175696930673946, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014208536957220008, 'l1_Layer_2': 0.00022716095042993862, 'l1_Layer_3': 0.00011937031611860214, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 150}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 15.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 22.46% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:24:43,973]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:49,338]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:56,626]\u001b[0m Trial 402 finished with value: 4.64441275537347 and parameters: {'n_hidden': 3, 'learning_rate': 0.000563046306090684, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03909009862790221, 'dropout_rate_Layer_2': 0.14743456400474164, 'dropout_rate_Layer_3': 0.06748235752053429, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.079215853996069e-05, 'l1_Layer_2': 1.5318650913270405e-05, 'l1_Layer_3': 6.859517759364303e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 195}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 14.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 22.66% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:25:04,178]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:08,189]\u001b[0m Trial 409 finished with value: 5.7278788125182 and parameters: {'n_hidden': 3, 'learning_rate': 0.004631640387230244, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3607852327510033, 'dropout_rate_Layer_2': 0.30082499131349366, 'dropout_rate_Layer_3': 0.2665617550318145, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002708325459832142, 'l1_Layer_2': 1.1592431523472227e-05, 'l1_Layer_3': 0.00012084818420312838, 'n_units_Layer_1': 135, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 17.65% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 7.71 | sMAPE for Test Set is: 29.59% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:25:11,916]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:12,174]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:12,544]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:18,382]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:18,719]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:26,253]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:30,500]\u001b[0m Trial 412 finished with value: 4.606410430973914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008869341601143436, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03684057263877672, 'dropout_rate_Layer_2': 0.12917305826921066, 'dropout_rate_Layer_3': 0.06778802753067345, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.017740509135619e-05, 'l1_Layer_2': 1.120866150049596e-05, 'l1_Layer_3': 6.947204761532001e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 240, 'n_units_Layer_3': 195}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:30,673]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 23.39% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:25:36,178]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:36,258]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:44,354]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:50,756]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:58,471]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:59,951]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:04,542]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:09,721]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:11,405]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:14,370]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:17,819]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:26,667]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:30,072]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:31,493]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:36,063]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:43,180]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:49,864]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:53,069]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:57,497]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 15.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.27 | sMAPE for Test Set is: 21.94% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:26:59,869]\u001b[0m Trial 418 finished with value: 4.704727868847342 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006222207307487531, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2216288226536854, 'dropout_rate_Layer_2': 0.09121218295954815, 'dropout_rate_Layer_3': 0.021798264680040515, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003116538698185952, 'l1_Layer_2': 8.217722191670822e-05, 'l1_Layer_3': 0.00046080283376706777, 'n_units_Layer_1': 80, 'n_units_Layer_2': 225, 'n_units_Layer_3': 170}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:03,226]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:04,456]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:07,141]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:10,777]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:12,510]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:15,296]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:17,057]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:20,998]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:39,399]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:43,925]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:46,581]\u001b[0m Trial 445 finished with value: 4.89940542004406 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007614628866621101, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24718449967772288, 'dropout_rate_Layer_2': 0.11774491760118033, 'dropout_rate_Layer_3': 0.08005650370678341, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015085230854442013, 'l1_Layer_2': 5.4995125238954696e-05, 'l1_Layer_3': 8.310811594846204e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 260, 'n_units_Layer_3': 170}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 15.51% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 26.60% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:27:47,079]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:51,062]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:27:59,660]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:28:04,136]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:28:07,073]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:28:10,313]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:28:12,636]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:28:16,322]\u001b[0m Trial 443 finished with value: 4.466457626327901 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006773923773247761, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28557301075236935, 'dropout_rate_Layer_2': 0.043130512641946124, 'dropout_rate_Layer_3': 0.013049321746015557, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006560038304059531, 'l1_Layer_2': 9.916173808081943e-05, 'l1_Layer_3': 7.971394533274557e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 14.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 21.70% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:28:21,315]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:28:25,310]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:28:26,591]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:28:29,348]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:28:34,554]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:28:40,066]\u001b[0m Trial 452 finished with value: 4.900377296100561 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031182010140763028, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3344981684971978, 'dropout_rate_Layer_2': 0.061404818790636306, 'dropout_rate_Layer_3': 0.26167045348123, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003449943037496397, 'l1_Layer_2': 0.0007045885066522772, 'l1_Layer_3': 0.0003526482910933187, 'n_units_Layer_1': 140, 'n_units_Layer_2': 225, 'n_units_Layer_3': 255}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 15.54% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 23.19% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:28:44,080]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:28:50,980]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:29:08,571]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:29:12,444]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:29:17,439]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:29:25,659]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:29:28,769]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:29:30,950]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:29:31,529]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:29:34,755]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:29:36,387]\u001b[0m Trial 468 finished with value: 4.607675507628053 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008150734528522113, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05299752486694002, 'dropout_rate_Layer_2': 0.10662781231152223, 'dropout_rate_Layer_3': 0.03904411319410787, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8292397921935544e-05, 'l1_Layer_2': 4.617523871780901e-05, 'l1_Layer_3': 5.94196904287813e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 205, 'n_units_Layer_3': 180}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.33 | sMAPE for Test Set is: 22.39% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:29:41,212]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:29:51,771]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:30:13,403]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:30:13,945]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:30:23,183]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:30:30,295]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:30:37,799]\u001b[0m Trial 481 finished with value: 4.666497653831539 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007380805383015821, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023489596135516447, 'dropout_rate_Layer_2': 0.3923725002244249, 'dropout_rate_Layer_3': 0.03900310395909705, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5272783662863136e-05, 'l1_Layer_2': 3.493446160635472e-05, 'l1_Layer_3': 3.5418413889993064e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 210, 'n_units_Layer_3': 180}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 14.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 22.82% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:30:40,033]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:30:48,744]\u001b[0m Trial 483 finished with value: 4.694038302916167 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007829833165043638, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05574787986443176, 'dropout_rate_Layer_2': 0.19909078084200257, 'dropout_rate_Layer_3': 0.04688001211941854, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.268202157082569e-05, 'l1_Layer_2': 4.666769023773364e-05, 'l1_Layer_3': 3.9356416236918685e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 295, 'n_units_Layer_3': 180}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 15.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.33 | sMAPE for Test Set is: 22.33% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:30:51,715]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:31:15,988]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:31:19,535]\u001b[0m Trial 482 finished with value: 4.848123937301352 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030507668339866895, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23524854096198972, 'dropout_rate_Layer_2': 0.16091560817782552, 'dropout_rate_Layer_3': 0.23736155234452372, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00021970359987348996, 'l1_Layer_2': 4.372810558912159e-05, 'l1_Layer_3': 0.00017338004467973417, 'n_units_Layer_1': 150, 'n_units_Layer_2': 230, 'n_units_Layer_3': 295}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 15.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.65 | sMAPE for Test Set is: 23.09% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:31:24,757]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:31:26,415]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:31:32,857]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:31:33,068]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:31:36,666]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:31:44,287]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:31:58,607]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:32:23,202]\u001b[0m Trial 487 finished with value: 4.7030862269144045 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005056887259519508, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021778536148197275, 'dropout_rate_Layer_2': 0.3932948709879888, 'dropout_rate_Layer_3': 0.04012496265271437, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1963717021399648e-05, 'l1_Layer_2': 4.252376381125317e-05, 'l1_Layer_3': 3.7014967730780366e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 205, 'n_units_Layer_3': 180}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 23.11% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:32:35,997]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:32:41,020]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:33:01,179]\u001b[0m Trial 491 finished with value: 4.602503430978769 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005722705119975292, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05614349141460678, 'dropout_rate_Layer_2': 0.2338666463394628, 'dropout_rate_Layer_3': 0.04922870998364583, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1074466412832047e-05, 'l1_Layer_2': 2.4126936655868534e-05, 'l1_Layer_3': 5.4390225188555546e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 290, 'n_units_Layer_3': 180}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 14.69% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.65 | sMAPE for Test Set is: 23.48% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:33:08,770]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:33:49,122]\u001b[0m Trial 499 finished with value: 4.715703681977103 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028403756564757488, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.263066601390978, 'dropout_rate_Layer_2': 0.27623336429540774, 'dropout_rate_Layer_3': 0.20563455623700397, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00012099992958467615, 'l1_Layer_2': 5.995585948284129e-05, 'l1_Layer_3': 0.00013870597423337397, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 300}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 14.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.26 | sMAPE for Test Set is: 22.01% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:33:52,376]\u001b[0m Trial 504 finished with value: 4.619459544189372 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006382563282088965, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06987150855947208, 'dropout_rate_Layer_2': 0.3113016844946346, 'dropout_rate_Layer_3': 0.048513203923770586, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1119238101030414e-05, 'l1_Layer_2': 2.5044004363069777e-05, 'l1_Layer_3': 3.210532477297265e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 280, 'n_units_Layer_3': 190}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 14.76% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 22.25% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:34:10,020]\u001b[0m Trial 502 finished with value: 4.637836416713353 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006387352575129046, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05643792364927027, 'dropout_rate_Layer_2': 0.35698222620737324, 'dropout_rate_Layer_3': 0.06407664262870387, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.938578767435988e-05, 'l1_Layer_2': 7.565056203100836e-05, 'l1_Layer_3': 3.187907735769109e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 240, 'n_units_Layer_3': 175}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 21.84% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:34:24,225]\u001b[0m Trial 503 finished with value: 4.7897808975036815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022359414628211004, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24689900271909038, 'dropout_rate_Layer_2': 0.11842263871019211, 'dropout_rate_Layer_3': 0.20346201254090326, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.3478875173639838e-05, 'l1_Layer_2': 6.055534755729978e-05, 'l1_Layer_3': 0.0002818964889457309, 'n_units_Layer_1': 165, 'n_units_Layer_2': 180, 'n_units_Layer_3': 280}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 15.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.46 | sMAPE for Test Set is: 26.08% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:34:29,357]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:34:34,991]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:34:40,084]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:34:46,916]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:01,772]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:04,011]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:05,560]\u001b[0m Trial 506 finished with value: 5.018902613299741 and parameters: {'n_hidden': 3, 'learning_rate': 0.002290722057361672, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26338170047167325, 'dropout_rate_Layer_2': 0.20223732831367197, 'dropout_rate_Layer_3': 0.20337650068563132, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001580343593420855, 'l1_Layer_2': 6.202992293987567e-05, 'l1_Layer_3': 0.0013702242731631893, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 275}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 15.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 24.47% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:35:12,592]\u001b[0m Trial 507 finished with value: 4.5437684745717535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006190293759629277, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06875576685741076, 'dropout_rate_Layer_2': 0.29971591611514503, 'dropout_rate_Layer_3': 0.05692904996349961, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0369368065989467e-05, 'l1_Layer_2': 1.8823230707279574e-05, 'l1_Layer_3': 3.1694673929975734e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 280, 'n_units_Layer_3': 190}. Best is trial 290 with value: 4.457507893725315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 22.62% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:35:15,049]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:29,357]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:42,486]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:45,037]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:58,474]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:36:17,884]\u001b[0m Trial 515 finished with value: 4.4531772251968285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008868238744170053, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18857063005167332, 'dropout_rate_Layer_2': 0.10784689860185587, 'dropout_rate_Layer_3': 0.10759063022319561, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001179759385556463, 'l1_Layer_2': 0.00026104708542115944, 'l1_Layer_3': 4.6185338795558224e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 290, 'n_units_Layer_3': 180}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.97 | sMAPE for Test Set is: 20.99% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:36:23,141]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:36:40,331]\u001b[0m Trial 514 finished with value: 4.860680368705835 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018942105306266092, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2631180612746425, 'dropout_rate_Layer_2': 0.1202573911532806, 'dropout_rate_Layer_3': 0.1960476616885779, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.1516354658760996e-05, 'l1_Layer_2': 0.0014532562189347668, 'l1_Layer_3': 0.0001637152336853389, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 285}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 15.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 22.40% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:36:47,451]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:36:51,875]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:36:58,799]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:37:01,302]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:37:04,472]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:37:34,631]\u001b[0m Trial 521 finished with value: 4.896909823828348 and parameters: {'n_hidden': 3, 'learning_rate': 0.001564991623906293, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26389908568589215, 'dropout_rate_Layer_2': 0.2319792884740665, 'dropout_rate_Layer_3': 0.2178635009886816, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001464628112634938, 'l1_Layer_2': 3.9806718754295635e-05, 'l1_Layer_3': 0.00016676836486431487, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 270}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 15.62% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 22.76% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:37:43,947]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:37:49,204]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:37:52,585]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:37:55,380]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:00,929]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:08,673]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:09,434]\u001b[0m Trial 518 finished with value: 4.661964793993331 and parameters: {'n_hidden': 3, 'learning_rate': 0.00195042544424743, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26765241731469697, 'dropout_rate_Layer_2': 0.23305014029202611, 'dropout_rate_Layer_3': 0.19049605706432576, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001484533743518175, 'l1_Layer_2': 5.142700786655482e-05, 'l1_Layer_3': 0.00024034232288731348, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 275}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 23.47% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:38:23,337]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:36,389]\u001b[0m Trial 528 finished with value: 4.5084221667645155 and parameters: {'n_hidden': 3, 'learning_rate': 0.001091742694053116, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10559621936809746, 'dropout_rate_Layer_2': 0.011371647957571458, 'dropout_rate_Layer_3': 0.0755021144101661, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001263977616481362, 'l1_Layer_2': 0.0005568350774180119, 'l1_Layer_3': 2.5503875523276473e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 270, 'n_units_Layer_3': 180}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 22.39% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:38:42,876]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:47,436]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:49,207]\u001b[0m Trial 536 finished with value: 4.627999901962458 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006300969835071416, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0003276045960979197, 'dropout_rate_Layer_2': 0.28649496957865084, 'dropout_rate_Layer_3': 0.027505269993792433, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7506004526970993e-05, 'l1_Layer_2': 2.4742913526816155e-05, 'l1_Layer_3': 0.00015539112696500172, 'n_units_Layer_1': 150, 'n_units_Layer_2': 215, 'n_units_Layer_3': 175}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 14.90% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.23 | sMAPE for Test Set is: 21.88% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:38:56,691]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:58,533]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:39:30,499]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:39:41,976]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:39:46,827]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:40:01,960]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:40:03,398]\u001b[0m Trial 538 finished with value: 4.707578630576143 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016488369155455685, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2745315686286104, 'dropout_rate_Layer_2': 0.2465678073587501, 'dropout_rate_Layer_3': 0.19663305163649014, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014016919479939983, 'l1_Layer_2': 4.029041866850692e-05, 'l1_Layer_3': 0.00023548891180132192, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 15.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.30 | sMAPE for Test Set is: 25.64% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:40:19,424]\u001b[0m Trial 543 finished with value: 4.912393082204922 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016027149013681378, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28145513643277403, 'dropout_rate_Layer_2': 0.2529885767150516, 'dropout_rate_Layer_3': 0.18212420435114926, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00012789672476703695, 'l1_Layer_2': 3.9965474731402756e-05, 'l1_Layer_3': 0.00021458656922572426, 'n_units_Layer_1': 180, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 15.75% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 20.83% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:40:40,024]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:40:49,279]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:40:49,829]\u001b[0m Trial 548 finished with value: 4.503832102385758 and parameters: {'n_hidden': 3, 'learning_rate': 0.001409021432113935, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06605167499530423, 'dropout_rate_Layer_2': 0.009126381406419005, 'dropout_rate_Layer_3': 0.028007366607719686, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007626793915067029, 'l1_Layer_2': 0.0008809841463398384, 'l1_Layer_3': 2.7665945039159663e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 160}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 22.75% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:41:07,416]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:41:16,471]\u001b[0m Trial 551 finished with value: 4.6087396125020925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013741585982833648, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.053910827461908346, 'dropout_rate_Layer_2': 0.019861699326351057, 'dropout_rate_Layer_3': 0.02842111831090109, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021969024438269523, 'l1_Layer_2': 0.00015518195553616056, 'l1_Layer_3': 2.9430188567492524e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 285}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 14.74% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.33 | sMAPE for Test Set is: 22.20% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:41:33,339]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:41:50,683]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:41:57,889]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:42:29,788]\u001b[0m Trial 550 finished with value: 4.691283956009139 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011907458256263234, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27967620295088, 'dropout_rate_Layer_2': 0.24813013487764046, 'dropout_rate_Layer_3': 0.17978063348587656, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.252322284801547e-05, 'l1_Layer_2': 4.811683652218773e-05, 'l1_Layer_3': 0.0002264550591765297, 'n_units_Layer_1': 185, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 14.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 25.74% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:42:47,430]\u001b[0m Trial 558 finished with value: 4.453473227455297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008781870823004988, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.038911923709880586, 'dropout_rate_Layer_2': 0.02114848596197233, 'dropout_rate_Layer_3': 0.01379235352673859, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007308565681332559, 'l1_Layer_2': 0.00023694896401167591, 'l1_Layer_3': 2.91733765586528e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 295, 'n_units_Layer_3': 275}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 21.92% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:43:11,336]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:43:23,262]\u001b[0m Trial 556 finished with value: 4.755021966622529 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016151096457803391, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2737382809110832, 'dropout_rate_Layer_2': 0.2512413358748518, 'dropout_rate_Layer_3': 0.2105887989978122, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.4417660598356816e-05, 'l1_Layer_2': 5.9158801267748114e-05, 'l1_Layer_3': 0.0002858547837760615, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 15.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 25.25% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:43:32,224]\u001b[0m Trial 554 finished with value: 4.623320356847188 and parameters: {'n_hidden': 3, 'learning_rate': 0.000552510998500278, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015249516566144582, 'dropout_rate_Layer_2': 0.2850397205668717, 'dropout_rate_Layer_3': 0.08338841801701484, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.975191463974062e-05, 'l1_Layer_2': 2.776666607797776e-05, 'l1_Layer_3': 0.00023609093459698826, 'n_units_Layer_1': 150, 'n_units_Layer_2': 280, 'n_units_Layer_3': 190}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 14.72% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 24.19% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:43:38,236]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:43:45,135]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:43:50,685]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:44:00,122]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:44:02,273]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:44:21,394]\u001b[0m Trial 560 finished with value: 4.6141787000253 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007087876540284155, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0009165101496645192, 'dropout_rate_Layer_2': 0.27454103782236716, 'dropout_rate_Layer_3': 0.04424215759651554, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.540522979848226e-05, 'l1_Layer_2': 5.6332556414986875e-05, 'l1_Layer_3': 0.00017840326128226478, 'n_units_Layer_1': 130, 'n_units_Layer_2': 280, 'n_units_Layer_3': 190}. Best is trial 515 with value: 4.4531772251968285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 14.79% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 22.71% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:44:28,706]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:44:40,466]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:44:43,220]\u001b[0m Trial 563 finished with value: 4.4525367918247065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011535346598784899, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.057025525851474565, 'dropout_rate_Layer_2': 0.017743789693114964, 'dropout_rate_Layer_3': 0.02506035309858276, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004729353761462837, 'l1_Layer_2': 0.0004929923243812213, 'l1_Layer_3': 4.922450028651446e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 300, 'n_units_Layer_3': 275}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 22.21% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:44:46,259]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:44:50,315]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:44:52,687]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:04,497]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:11,671]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:16,199]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:23,175]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:25,689]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:28,301]\u001b[0m Trial 568 finished with value: 4.652176003286847 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014379113989134585, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25604184439276884, 'dropout_rate_Layer_2': 0.20742799766539954, 'dropout_rate_Layer_3': 0.2039186179003757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.424936646523582e-05, 'l1_Layer_2': 5.1597191401273785e-05, 'l1_Layer_3': 0.00025313458969802193, 'n_units_Layer_1': 190, 'n_units_Layer_2': 130, 'n_units_Layer_3': 260}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 14.90% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.70 | sMAPE for Test Set is: 20.16% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:45:31,898]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:43,018]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:46:07,434]\u001b[0m Trial 580 finished with value: 4.572153263575983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011335558159366735, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08916317692637282, 'dropout_rate_Layer_2': 0.2901526364350413, 'dropout_rate_Layer_3': 0.026133240842745337, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.520055803766225e-05, 'l1_Layer_2': 2.5383666529228614e-05, 'l1_Layer_3': 0.00015399848471633377, 'n_units_Layer_1': 130, 'n_units_Layer_2': 280, 'n_units_Layer_3': 190}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.26 | sMAPE for Test Set is: 22.15% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:46:23,565]\u001b[0m Trial 575 finished with value: 4.510491684977576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011781626528507233, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060941646493766495, 'dropout_rate_Layer_2': 0.013146463661502336, 'dropout_rate_Layer_3': 0.026936152585523055, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047452503619432364, 'l1_Layer_2': 0.0011441150263272236, 'l1_Layer_3': 1.7977051450609043e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 300, 'n_units_Layer_3': 275}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 23.19% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:46:50,079]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:47:06,177]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:47:23,021]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:47:28,182]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:47:39,821]\u001b[0m Trial 583 finished with value: 4.666389877609702 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018140446580936804, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006335904997730735, 'dropout_rate_Layer_2': 0.21627208280365154, 'dropout_rate_Layer_3': 0.17924341869718874, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.661184268863701e-05, 'l1_Layer_2': 6.185157029094006e-05, 'l1_Layer_3': 0.0015748292089957355, 'n_units_Layer_1': 190, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 25.25% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:48:02,038]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:48:08,024]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:48:12,523]\u001b[0m Trial 587 finished with value: 4.478900075654189 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017412756095868483, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.061535730554922854, 'dropout_rate_Layer_2': 0.016704348270128604, 'dropout_rate_Layer_3': 0.012008077594225001, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005290999673962883, 'l1_Layer_2': 0.0014169423904078632, 'l1_Layer_3': 1.9968409594555846e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 300, 'n_units_Layer_3': 275}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 23.66% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:48:23,632]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:48:34,665]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:48:58,299]\u001b[0m Trial 590 finished with value: 4.74472177638355 and parameters: {'n_hidden': 3, 'learning_rate': 0.001868273729961602, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2964048773095077, 'dropout_rate_Layer_2': 0.21404309476280836, 'dropout_rate_Layer_3': 0.18853763100371404, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.0167744434479435e-05, 'l1_Layer_2': 4.710687715733764e-05, 'l1_Layer_3': 0.0013965989410026883, 'n_units_Layer_1': 185, 'n_units_Layer_2': 125, 'n_units_Layer_3': 265}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 15.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 21.55% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:49:02,527]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:09,033]\u001b[0m Trial 594 finished with value: 4.480685835759186 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018604943575139502, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02124262971315837, 'dropout_rate_Layer_2': 0.011297369097122763, 'dropout_rate_Layer_3': 0.05865825842027955, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004209996101771513, 'l1_Layer_2': 0.0012833405178355821, 'l1_Layer_3': 1.6994203965684678e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 295, 'n_units_Layer_3': 270}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 22.87% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:49:11,471]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:15,855]\u001b[0m Trial 592 finished with value: 4.784995181400682 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016944971603547567, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005136061241760803, 'dropout_rate_Layer_2': 0.23211403814541473, 'dropout_rate_Layer_3': 0.1765850404493986, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.7456617459446624e-05, 'l1_Layer_2': 4.833918950854566e-05, 'l1_Layer_3': 0.0013649461445648188, 'n_units_Layer_1': 185, 'n_units_Layer_2': 120, 'n_units_Layer_3': 265}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 22.64% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:49:18,671]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:33,497]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:37,417]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:42,312]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:42,757]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:51,120]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:51,668]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:00,491]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:02,153]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:09,395]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:13,670]\u001b[0m Trial 595 finished with value: 4.6853672140603635 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017561322308879785, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05229566064876598, 'dropout_rate_Layer_2': 0.23410594492883974, 'dropout_rate_Layer_3': 0.18200234467247284, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.559434136486643e-05, 'l1_Layer_2': 5.0829398562089376e-05, 'l1_Layer_3': 0.0013597227200151203, 'n_units_Layer_1': 185, 'n_units_Layer_2': 125, 'n_units_Layer_3': 265}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 15.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 24.96% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:50:16,371]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:18,470]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:24,501]\u001b[0m Trial 598 finished with value: 4.4732873027075915 and parameters: {'n_hidden': 3, 'learning_rate': 0.002440072408243977, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020106735411536243, 'dropout_rate_Layer_2': 0.0017162760382800797, 'dropout_rate_Layer_3': 0.009258695764925426, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005801751460757801, 'l1_Layer_2': 0.0025274686013397694, 'l1_Layer_3': 1.70890012699222e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 295, 'n_units_Layer_3': 270}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:50:32,502]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:33,154]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:43,914]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:59,287]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:02,479]\u001b[0m Trial 611 finished with value: 4.609305243210199 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007189773554547718, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03002059144111804, 'dropout_rate_Layer_2': 0.219991434384241, 'dropout_rate_Layer_3': 0.02001265966402588, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.678261520653579e-05, 'l1_Layer_2': 3.7690230019898365e-05, 'l1_Layer_3': 0.0001935275763813441, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 210}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 14.68% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 21.60% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:51:11,574]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:19,219]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:27,448]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:31,869]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:36,032]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:52,425]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:55,807]\u001b[0m Trial 612 finished with value: 4.680761718341537 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013548424562028834, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02633681819529059, 'dropout_rate_Layer_2': 0.21524807692291645, 'dropout_rate_Layer_3': 0.1694910788560708, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.3046613313010826e-05, 'l1_Layer_2': 4.455832804572703e-05, 'l1_Layer_3': 0.0011955246061916326, 'n_units_Layer_1': 185, 'n_units_Layer_2': 115, 'n_units_Layer_3': 260}. Best is trial 563 with value: 4.4525367918247065.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 14.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 23.96% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:51:56,347]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:56,962]\u001b[0m Trial 618 finished with value: 4.373431905311441 and parameters: {'n_hidden': 3, 'learning_rate': 0.00156848319477722, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03098333553824253, 'dropout_rate_Layer_2': 0.0003284963909516575, 'dropout_rate_Layer_3': 0.008372973810703604, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005727814762360381, 'l1_Layer_2': 0.001450163856600568, 'l1_Layer_3': 1.7453688439000435e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 21.47% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:52:00,998]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:52:12,848]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:52:17,303]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:52:30,061]\u001b[0m Trial 628 finished with value: 4.446123417660982 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034226939075859704, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029790720396425805, 'dropout_rate_Layer_2': 0.0010871576400547991, 'dropout_rate_Layer_3': 0.008013650375486063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037812539404331766, 'l1_Layer_2': 0.002727857624774281, 'l1_Layer_3': 1.5124502190933006e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 265}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.84 | sMAPE for Test Set is: 22.21% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:52:39,173]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:52:46,550]\u001b[0m Trial 619 finished with value: 4.680992909578861 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017094121683146125, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03775797723472929, 'dropout_rate_Layer_2': 0.25625338299244355, 'dropout_rate_Layer_3': 0.17120974473055708, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.280032180178065e-05, 'l1_Layer_2': 5.390132882865776e-05, 'l1_Layer_3': 0.0019205354131663658, 'n_units_Layer_1': 170, 'n_units_Layer_2': 130, 'n_units_Layer_3': 260}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 15.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 23.73% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:53:09,179]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:53:17,820]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:53:22,993]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:53:31,733]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:53:54,534]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:53:59,405]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:54:08,967]\u001b[0m Trial 631 finished with value: 4.570032681859406 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006243338543017311, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05248967752905293, 'dropout_rate_Layer_2': 0.2949249754171421, 'dropout_rate_Layer_3': 0.06755955708779325, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.056697035027734e-05, 'l1_Layer_2': 1.2603678164606348e-05, 'l1_Layer_3': 0.00010805792921069935, 'n_units_Layer_1': 140, 'n_units_Layer_2': 300, 'n_units_Layer_3': 195}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 21.58% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:54:38,676]\u001b[0m Trial 634 finished with value: 4.683697191621117 and parameters: {'n_hidden': 3, 'learning_rate': 0.001392798404064437, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014610408428232581, 'dropout_rate_Layer_2': 0.2559286047649359, 'dropout_rate_Layer_3': 0.18199779237178484, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.360296606026147e-05, 'l1_Layer_2': 6.236112083949807e-05, 'l1_Layer_3': 0.0022761544126932176, 'n_units_Layer_1': 195, 'n_units_Layer_2': 120, 'n_units_Layer_3': 255}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 24.25% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:54:39,305]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:54:48,981]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:55:17,277]\u001b[0m Trial 638 finished with value: 4.597625670948065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006357440278197423, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10225443554801604, 'dropout_rate_Layer_2': 0.28499732320825955, 'dropout_rate_Layer_3': 0.06630395970172523, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.947864878263583e-05, 'l1_Layer_2': 1.3150105888849353e-05, 'l1_Layer_3': 9.178164485140243e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 290, 'n_units_Layer_3': 195}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 22.46% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:55:19,733]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:55:20,316]\u001b[0m Trial 641 finished with value: 4.637775764309938 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008308290395306628, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08505558174654174, 'dropout_rate_Layer_2': 0.28636014194405457, 'dropout_rate_Layer_3': 0.23019382876771946, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6600590029294232e-05, 'l1_Layer_2': 1.1285612935077227e-05, 'l1_Layer_3': 9.031118648674577e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 290, 'n_units_Layer_3': 245}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 14.89% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 22.77% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:55:25,948]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:55:30,024]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:55:36,486]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:55:46,415]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:55:59,050]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:56:16,542]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:56:26,356]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:56:28,823]\u001b[0m Trial 646 finished with value: 4.7893843396993105 and parameters: {'n_hidden': 3, 'learning_rate': 0.002426210239809331, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005821531136481123, 'dropout_rate_Layer_2': 0.26681171428299927, 'dropout_rate_Layer_3': 0.1756702871212742, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.672157992441055e-05, 'l1_Layer_2': 3.348620884429976e-05, 'l1_Layer_3': 0.0016988745761030999, 'n_units_Layer_1': 195, 'n_units_Layer_2': 115, 'n_units_Layer_3': 275}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 22.52% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:56:32,731]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:56:40,377]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:06,477]\u001b[0m Trial 657 finished with value: 4.649996824568654 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007421001713539307, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09607986304102675, 'dropout_rate_Layer_2': 0.23710702761090655, 'dropout_rate_Layer_3': 0.02788857993697314, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.4539928972768e-05, 'l1_Layer_2': 1.2805655067853931e-05, 'l1_Layer_3': 0.00019957594946745788, 'n_units_Layer_1': 130, 'n_units_Layer_2': 295, 'n_units_Layer_3': 220}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 14.91% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 21.60% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:57:06,955]\u001b[0m Trial 655 finished with value: 4.540285975180525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006976501711957532, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00919936587934157, 'dropout_rate_Layer_2': 0.2951242003766608, 'dropout_rate_Layer_3': 0.023726197192949446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.580379604503477e-05, 'l1_Layer_2': 1.3016796464937e-05, 'l1_Layer_3': 0.00011441399294573505, 'n_units_Layer_1': 130, 'n_units_Layer_2': 295, 'n_units_Layer_3': 220}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.97 | sMAPE for Test Set is: 21.36% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:57:11,684]\u001b[0m Trial 654 finished with value: 4.558939762637158 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007282759204394448, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01563959548017369, 'dropout_rate_Layer_2': 0.3290526649968887, 'dropout_rate_Layer_3': 0.027664765777466818, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5960586100737078e-05, 'l1_Layer_2': 1.1578110589391648e-05, 'l1_Layer_3': 0.00019630934896907535, 'n_units_Layer_1': 155, 'n_units_Layer_2': 295, 'n_units_Layer_3': 205}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 20.79% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:57:14,050]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:23,325]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:28,096]\u001b[0m Trial 651 finished with value: 4.718214791817817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015542739153572493, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04114437778960808, 'dropout_rate_Layer_2': 0.20851475309614356, 'dropout_rate_Layer_3': 0.1859143691841271, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.492620354270025e-05, 'l1_Layer_2': 6.030520260590376e-05, 'l1_Layer_3': 0.0017775200153013766, 'n_units_Layer_1': 190, 'n_units_Layer_2': 115, 'n_units_Layer_3': 200}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 15.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 23.46% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:57:30,289]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:33,148]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:50,270]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:59,189]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:58:12,073]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:58:14,982]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:58:53,729]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:58:59,351]\u001b[0m Trial 660 finished with value: 4.739993453376564 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019437035415365222, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007181357143776214, 'dropout_rate_Layer_2': 0.24410264166635323, 'dropout_rate_Layer_3': 0.1577605106597815, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.52620671737763e-05, 'l1_Layer_2': 4.603074500950865e-05, 'l1_Layer_3': 0.001336868152804775, 'n_units_Layer_1': 190, 'n_units_Layer_2': 110, 'n_units_Layer_3': 265}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 15.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.66 | sMAPE for Test Set is: 23.25% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:59:07,835]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:59:19,942]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:59:23,635]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:59:34,228]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:59:42,592]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:59:46,193]\u001b[0m Trial 669 finished with value: 4.726858475634507 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019114842415789216, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007955139967361642, 'dropout_rate_Layer_2': 0.2306840913248373, 'dropout_rate_Layer_3': 0.15289588949751917, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.109112643035842e-05, 'l1_Layer_2': 5.152731405174379e-05, 'l1_Layer_3': 0.001908975132098753, 'n_units_Layer_1': 195, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 24.41% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:59:50,753]\u001b[0m Trial 664 finished with value: 4.602894415759952 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011814157473451544, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03864957935867704, 'dropout_rate_Layer_2': 0.2581058265894104, 'dropout_rate_Layer_3': 0.18115347868888432, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.662759750695162e-05, 'l1_Layer_2': 4.4934894693126796e-05, 'l1_Layer_3': 0.0019080897982991412, 'n_units_Layer_1': 195, 'n_units_Layer_2': 110, 'n_units_Layer_3': 175}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 23.85% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:59:54,407]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:59:55,973]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:59:57,762]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:00,606]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:01,276]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:05,591]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:40,289]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:45,413]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:59,063]\u001b[0m Trial 682 finished with value: 4.54347233163578 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006884749097274593, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08063519568365488, 'dropout_rate_Layer_2': 0.2852990052521834, 'dropout_rate_Layer_3': 0.03885200205781753, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.6013054183267134e-05, 'l1_Layer_2': 1.2669343249965052e-05, 'l1_Layer_3': 5.108096150058593e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 275, 'n_units_Layer_3': 205}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 22.05% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:01:14,761]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:01:19,311]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:01:27,858]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:01:27,999]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:01:33,674]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:01:44,591]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:01:49,229]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:02:24,292]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:02:28,040]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:03:07,339]\u001b[0m Trial 685 finished with value: 4.666080399150068 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011927222007041033, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029240768239044177, 'dropout_rate_Layer_2': 0.21438504348656376, 'dropout_rate_Layer_3': 0.14660028005179915, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.9668378812030355e-05, 'l1_Layer_2': 6.853401655022608e-05, 'l1_Layer_3': 0.0011442730448204986, 'n_units_Layer_1': 195, 'n_units_Layer_2': 105, 'n_units_Layer_3': 170}. Best is trial 618 with value: 4.373431905311441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 14.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 23.99% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:03:14,780]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:03:31,073]\u001b[0m Trial 696 finished with value: 4.330562480255213 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015577285953560843, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03774294787309585, 'dropout_rate_Layer_2': 0.0003809620410091599, 'dropout_rate_Layer_3': 0.05854097222045763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008651963221173116, 'l1_Layer_2': 0.007930435947441632, 'l1_Layer_3': 4.786485851580242e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 260}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 20.56% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:03:40,692]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 21.88% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 23.70% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:03:48,810]\u001b[0m Trial 698 finished with value: 4.4483159793927936 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015618573924257371, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07297781988822545, 'dropout_rate_Layer_2': 0.023514951085138923, 'dropout_rate_Layer_3': 0.054841450971520454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016747745156895554, 'l1_Layer_2': 0.0013140349017203238, 'l1_Layer_3': 3.422645755889538e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 290, 'n_units_Layer_3': 260}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:03:48,886]\u001b[0m Trial 680 finished with value: 4.5250005683286245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007686498828307428, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02198651193266636, 'dropout_rate_Layer_2': 0.22888125508674986, 'dropout_rate_Layer_3': 0.17029993277546768, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.0671067442474636e-05, 'l1_Layer_2': 5.649141282335067e-05, 'l1_Layer_3': 0.0012847310067615027, 'n_units_Layer_1': 210, 'n_units_Layer_2': 105, 'n_units_Layer_3': 155}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:03:58,040]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:03:58,441]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:04:08,498]\u001b[0m Trial 694 finished with value: 4.5192190190200705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005655505428852015, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0850625401321597, 'dropout_rate_Layer_2': 0.28597818712791667, 'dropout_rate_Layer_3': 0.052178162308658106, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2280270336560548e-05, 'l1_Layer_2': 1.6398153878858543e-05, 'l1_Layer_3': 7.19350389575757e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 280, 'n_units_Layer_3': 195}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 14.44% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 23.13% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:04:13,886]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:04:16,495]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:04:23,574]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:04:27,041]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:04:29,698]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:04:41,504]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:04:44,479]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:04:58,946]\u001b[0m Trial 706 finished with value: 4.438212108229126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015473507219087765, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04216435213297549, 'dropout_rate_Layer_2': 0.025891194215578433, 'dropout_rate_Layer_3': 0.03740508787527126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016538589858954301, 'l1_Layer_2': 0.006946600593757251, 'l1_Layer_3': 4.647626996456627e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.24% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 19.26% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:05:14,784]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:05:59,690]\u001b[0m Trial 707 finished with value: 4.646314841404529 and parameters: {'n_hidden': 3, 'learning_rate': 0.002124790817093599, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02296323049611517, 'dropout_rate_Layer_2': 0.21911030484471597, 'dropout_rate_Layer_3': 0.12806639714389864, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.616391284191144e-05, 'l1_Layer_2': 8.66969289099991e-05, 'l1_Layer_3': 0.0007454678183348648, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 150}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 21.70% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:06:33,108]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:39,171]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:41,961]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:44,416]\u001b[0m Trial 711 finished with value: 4.610682940596309 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007960855183911672, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02369844232670902, 'dropout_rate_Layer_2': 0.21911042683095405, 'dropout_rate_Layer_3': 0.15546372630424143, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.851021402932467e-05, 'l1_Layer_2': 7.845111992799215e-05, 'l1_Layer_3': 0.0010513924784424848, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 145}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 14.84% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 23.32% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:06:46,399]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:51,271]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:52,821]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:07:29,909]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:07:34,963]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:07:37,705]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:07:41,196]\u001b[0m Trial 714 finished with value: 4.683876793127043 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005781054257317391, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01919433180746813, 'dropout_rate_Layer_2': 0.14678701866058397, 'dropout_rate_Layer_3': 0.15337965681948762, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.85722390946563e-05, 'l1_Layer_2': 5.547815010677981e-05, 'l1_Layer_3': 0.0007174194779372523, 'n_units_Layer_1': 200, 'n_units_Layer_2': 105, 'n_units_Layer_3': 180}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 14.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 24.51% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:07:47,487]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:07:49,431]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:07:52,323]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:07:58,192]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:08:05,510]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:08:08,497]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:08:17,366]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:08:22,761]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:08:24,356]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:08:30,520]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:08:32,129]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:08:42,640]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:08:49,851]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:08:53,753]\u001b[0m Trial 723 finished with value: 4.36640549544474 and parameters: {'n_hidden': 3, 'learning_rate': 0.001560277670694544, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040778513107827874, 'dropout_rate_Layer_2': 0.0018488317140733929, 'dropout_rate_Layer_3': 0.039224143639411645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003154252719530409, 'l1_Layer_2': 0.005317621134598965, 'l1_Layer_3': 3.207705970204672e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 280, 'n_units_Layer_3': 270}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 23.61% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:09:24,504]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:09:27,327]\u001b[0m Trial 739 finished with value: 4.7757939253217465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012397177402183647, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0444822009359741, 'dropout_rate_Layer_2': 0.23100816511814076, 'dropout_rate_Layer_3': 0.3192350540601954, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015927528726509773, 'l1_Layer_2': 0.0037961986169207044, 'l1_Layer_3': 1.381910041725278e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 15.27% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 20.34% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:09:33,953]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:09:49,047]\u001b[0m Trial 740 finished with value: 4.556079204120228 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008143719625920025, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09055690063247573, 'dropout_rate_Layer_2': 0.18772242623132307, 'dropout_rate_Layer_3': 0.07184011718508052, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.570751822837867e-05, 'l1_Layer_2': 4.018365048800752e-05, 'l1_Layer_3': 0.00025763627189076625, 'n_units_Layer_1': 110, 'n_units_Layer_2': 265, 'n_units_Layer_3': 195}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 14.67% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 22.79% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:09:53,834]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:10:00,405]\u001b[0m Trial 736 finished with value: 4.687700469862372 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006376163246057514, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023118320325704416, 'dropout_rate_Layer_2': 0.20619976371131335, 'dropout_rate_Layer_3': 0.14075304633662283, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.8557765123936414e-05, 'l1_Layer_2': 0.00011938621257901899, 'l1_Layer_3': 0.0007801331389233304, 'n_units_Layer_1': 195, 'n_units_Layer_2': 115, 'n_units_Layer_3': 160}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 15.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 22.74% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:10:04,233]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:10:07,612]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:10:10,116]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:10:49,739]\u001b[0m Trial 743 finished with value: 4.5153393465891005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011217035437048925, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014507179907796267, 'dropout_rate_Layer_2': 0.22320856979083983, 'dropout_rate_Layer_3': 0.1587719167197849, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.587640932377567e-05, 'l1_Layer_2': 5.512647807664341e-05, 'l1_Layer_3': 0.0019291741632160148, 'n_units_Layer_1': 190, 'n_units_Layer_2': 115, 'n_units_Layer_3': 170}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 18.81% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:11:25,793]\u001b[0m Trial 748 finished with value: 4.401673464399921 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012844588647225054, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014963874117045733, 'dropout_rate_Layer_2': 0.043487819620934946, 'dropout_rate_Layer_3': 0.05917674911277544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023919187098553224, 'l1_Layer_2': 0.012454714697197299, 'l1_Layer_3': 4.734869662121274e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 14.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:11:30,693]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:12:00,568]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:12:24,566]\u001b[0m Trial 750 finished with value: 4.370557289306678 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009122980770132248, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020488119830422924, 'dropout_rate_Layer_2': 0.04306593566786748, 'dropout_rate_Layer_3': 0.05745403302045801, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022861700506401163, 'l1_Layer_2': 0.013091843768811446, 'l1_Layer_3': 5.002855175233352e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 295, 'n_units_Layer_3': 290}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 14.14% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 18.61% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:12:30,111]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:12:46,053]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:12:48,802]\u001b[0m Trial 747 finished with value: 4.668866116683133 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006244329396973929, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024238804604619052, 'dropout_rate_Layer_2': 0.20290415830113046, 'dropout_rate_Layer_3': 0.12147228652740402, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.5685307725273866e-05, 'l1_Layer_2': 0.0001247456444900975, 'l1_Layer_3': 0.0007688869162917792, 'n_units_Layer_1': 190, 'n_units_Layer_2': 120, 'n_units_Layer_3': 165}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 23.35% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:12:51,441]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:12:53,832]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:12:55,791]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:12:59,595]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:13:24,785]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:13:32,893]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:13:40,600]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:13:50,397]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:14:05,443]\u001b[0m Trial 764 finished with value: 4.788208372179191 and parameters: {'n_hidden': 3, 'learning_rate': 0.002930207672511908, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08735387060987228, 'dropout_rate_Layer_2': 0.2579608421936775, 'dropout_rate_Layer_3': 0.380210016280365, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.974366003779669e-05, 'l1_Layer_2': 0.0033681147084958026, 'l1_Layer_3': 3.5603951419951406e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 220}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 15.53% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.75 | sMAPE for Test Set is: 21.67% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:14:37,349]\u001b[0m Trial 762 finished with value: 4.6137283323153 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005766801348449373, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016256403607066833, 'dropout_rate_Layer_2': 0.30311269313823613, 'dropout_rate_Layer_3': 0.07973532420685743, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.737616082713371e-05, 'l1_Layer_2': 3.0979212625973885e-05, 'l1_Layer_3': 0.00025742664295820794, 'n_units_Layer_1': 150, 'n_units_Layer_2': 280, 'n_units_Layer_3': 190}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 14.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:14:41,874]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:14:45,722]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:14:48,311]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:15:27,123]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:15:31,641]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:15:34,315]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:16:05,063]\u001b[0m Trial 753 finished with value: 4.481973411059579 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006615722181723367, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03254495165425432, 'dropout_rate_Layer_2': 0.199582682582927, 'dropout_rate_Layer_3': 0.14050656308900614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015187296663854019, 'l1_Layer_2': 8.324601420031475e-05, 'l1_Layer_3': 0.0007724301006140191, 'n_units_Layer_1': 220, 'n_units_Layer_2': 105, 'n_units_Layer_3': 170}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 19.37% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:16:20,808]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:16:31,006]\u001b[0m Trial 766 finished with value: 4.63379040610635 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008253009122911146, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02462146087162764, 'dropout_rate_Layer_2': 0.18627329492600891, 'dropout_rate_Layer_3': 0.12901462985741122, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.774527768132024e-05, 'l1_Layer_2': 0.00012341477837377455, 'l1_Layer_3': 0.0010255302274063587, 'n_units_Layer_1': 190, 'n_units_Layer_2': 125, 'n_units_Layer_3': 155}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 14.84% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 23.19% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:16:45,732]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:16:47,435]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:16:55,091]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:17:01,590]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:17:09,653]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:17:17,027]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:17:26,047]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:17:29,584]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:17:36,468]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:17:40,451]\u001b[0m Trial 777 finished with value: 4.556983929538279 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007952685256468693, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013203117829839482, 'dropout_rate_Layer_2': 0.23986685463218832, 'dropout_rate_Layer_3': 0.2900647969113517, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011473268758505405, 'l1_Layer_2': 0.001442849748794214, 'l1_Layer_3': 0.00010985960464068333, 'n_units_Layer_1': 160, 'n_units_Layer_2': 70, 'n_units_Layer_3': 200}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 14.81% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 20.12% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:18:09,256]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:18:17,647]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:18:20,847]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:19:00,213]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:19:16,824]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:19:21,393]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:19:21,650]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:19:26,767]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:19:42,744]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:19:57,649]\u001b[0m Trial 787 finished with value: 4.6284944083770565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006375543177812163, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01565976013532873, 'dropout_rate_Layer_2': 0.2903558382910057, 'dropout_rate_Layer_3': 0.07977020342134644, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.594383861328173e-05, 'l1_Layer_2': 2.626050348166674e-05, 'l1_Layer_3': 0.00020958894520848977, 'n_units_Layer_1': 160, 'n_units_Layer_2': 285, 'n_units_Layer_3': 190}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 22.08% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:20:13,421]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:20:18,064]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:20:20,415]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:20:27,954]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:20:30,074]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:20:36,297]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:20:45,050]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:20:51,643]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:20:58,905]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:21:06,307]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:21:09,004]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:21:32,011]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:21:47,771]\u001b[0m Trial 794 finished with value: 4.631587036932425 and parameters: {'n_hidden': 3, 'learning_rate': 0.000591143269367334, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019422281872064833, 'dropout_rate_Layer_2': 0.21568405120364886, 'dropout_rate_Layer_3': 0.137382454468059, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.1610798554530386e-05, 'l1_Layer_2': 8.53236826396828e-05, 'l1_Layer_3': 0.0009922059292560576, 'n_units_Layer_1': 235, 'n_units_Layer_2': 105, 'n_units_Layer_3': 140}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 14.85% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.53 | sMAPE for Test Set is: 22.83% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:22:24,831]\u001b[0m Trial 808 finished with value: 4.641197957428697 and parameters: {'n_hidden': 4, 'learning_rate': 0.000724450882531492, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16685719476273847, 'dropout_rate_Layer_2': 0.06712231546578042, 'dropout_rate_Layer_3': 0.22412236609184458, 'dropout_rate_Layer_4': 0.28215821054644813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017935598167944947, 'l1_Layer_2': 0.00022290938203046141, 'l1_Layer_3': 0.00014868072490230465, 'l1_Layer_4': 0.0005442964783443362, 'n_units_Layer_1': 210, 'n_units_Layer_2': 90, 'n_units_Layer_3': 170, 'n_units_Layer_4': 80}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 14.87% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 20.71% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:22:39,182]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:22:48,264]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:23:04,366]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:23:10,643]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:23:26,872]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:24:58,194]\u001b[0m Trial 812 finished with value: 4.486823268437713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005256994042699755, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04393344393612068, 'dropout_rate_Layer_2': 0.1727056743032224, 'dropout_rate_Layer_3': 0.12737067206249197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.0197835711492707e-05, 'l1_Layer_2': 0.0001530361237893826, 'l1_Layer_3': 0.0010000502281116899, 'n_units_Layer_1': 185, 'n_units_Layer_2': 100, 'n_units_Layer_3': 130}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.54 | sMAPE for Test Set is: 19.19% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:25:00,958]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:25:14,052]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:25:20,685]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:25:28,632]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:26:11,916]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:26:21,909]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:26:41,799]\u001b[0m Trial 809 finished with value: 4.52851089583207 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005197548439272153, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03026864667106141, 'dropout_rate_Layer_2': 0.20617037079957862, 'dropout_rate_Layer_3': 0.12956251670228094, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.8365948299600446e-05, 'l1_Layer_2': 0.00014860811976793567, 'l1_Layer_3': 0.0010520447052088247, 'n_units_Layer_1': 240, 'n_units_Layer_2': 95, 'n_units_Layer_3': 140}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 14.53% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 23.87% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:26:47,033]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:26:51,235]\u001b[0m Trial 817 finished with value: 4.4113705599890745 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005391873750346757, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04100758212684497, 'dropout_rate_Layer_2': 0.1735324333554725, 'dropout_rate_Layer_3': 0.1283785098825032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2203479530297676e-05, 'l1_Layer_2': 0.00010749876821269229, 'l1_Layer_3': 0.0009169845444996706, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 19.67% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:27:26,211]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:27:39,034]\u001b[0m Trial 818 finished with value: 4.443050499069513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006965299482800213, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009021164334459993, 'dropout_rate_Layer_2': 6.707384995126991e-05, 'dropout_rate_Layer_3': 0.0306580507992971, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002477000479039176, 'l1_Layer_2': 0.008441174002200994, 'l1_Layer_3': 7.289124012729628e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 285, 'n_units_Layer_3': 250}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 19.77% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:27:46,114]\u001b[0m Trial 822 finished with value: 4.3801258227484405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014504724223449266, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021435712684491133, 'dropout_rate_Layer_2': 0.019841091971400344, 'dropout_rate_Layer_3': 0.03481392943487109, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007561651709705445, 'l1_Layer_2': 0.009822568528806605, 'l1_Layer_3': 7.186432513525234e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 265, 'n_units_Layer_3': 260}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 14.29% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 20.17% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:27:55,532]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:28:00,666]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:28:04,300]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:28:18,525]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:28:24,179]\u001b[0m Trial 825 finished with value: 4.431824933038382 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005004352700566867, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023546118244522497, 'dropout_rate_Layer_2': 0.019802728645898278, 'dropout_rate_Layer_3': 0.02375036991474266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008293014730743895, 'l1_Layer_2': 0.008777063217758766, 'l1_Layer_3': 1.0099267254863428e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 265, 'n_units_Layer_3': 260}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 14.33% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 19.52% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:28:57,224]\u001b[0m Trial 833 finished with value: 4.614327598659242 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006781844857786422, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002011543565574314, 'dropout_rate_Layer_2': 0.2849238819158403, 'dropout_rate_Layer_3': 0.026939351998351332, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.583471142766107e-05, 'l1_Layer_2': 3.1155937687029175e-05, 'l1_Layer_3': 0.00016296457155275508, 'n_units_Layer_1': 150, 'n_units_Layer_2': 275, 'n_units_Layer_3': 175}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 14.83% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 21.75% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:30:08,342]\u001b[0m Trial 832 finished with value: 4.445799819226038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005032527447672171, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.048182487920215136, 'dropout_rate_Layer_2': 0.18749289536336772, 'dropout_rate_Layer_3': 0.1252656194341819, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.89693947867354e-05, 'l1_Layer_2': 0.00013965226449472645, 'l1_Layer_3': 0.0010196983991316816, 'n_units_Layer_1': 245, 'n_units_Layer_2': 85, 'n_units_Layer_3': 125}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:30:18,093]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:30:22,248]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:30:34,398]\u001b[0m Trial 826 finished with value: 4.466755107637751 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005434763369328993, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027107924990437286, 'dropout_rate_Layer_2': 0.17311242867693957, 'dropout_rate_Layer_3': 0.12204051977601216, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8340676694931674e-05, 'l1_Layer_2': 0.00013777907622771924, 'l1_Layer_3': 0.0009297797796355801, 'n_units_Layer_1': 250, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 14.66% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 21.40% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:30:34,840]\u001b[0m Trial 831 finished with value: 4.407133806007091 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005087254651220879, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04835711562551618, 'dropout_rate_Layer_2': 0.1728261042491365, 'dropout_rate_Layer_3': 0.1219089613399949, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.39817378979231e-05, 'l1_Layer_2': 0.00017875647316992237, 'l1_Layer_3': 0.0009945294336089283, 'n_units_Layer_1': 245, 'n_units_Layer_2': 85, 'n_units_Layer_3': 130}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.33% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 18.82% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:30:39,230]\u001b[0m Trial 834 finished with value: 4.408548615456904 and parameters: {'n_hidden': 3, 'learning_rate': 0.000540290303495191, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04638975150344332, 'dropout_rate_Layer_2': 0.18537250083841333, 'dropout_rate_Layer_3': 0.11037729502747329, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7186883097586835e-05, 'l1_Layer_2': 0.0001903987462968496, 'l1_Layer_3': 0.00097474149134915, 'n_units_Layer_1': 225, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 19.06% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:30:43,348]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:30:48,141]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:31:30,108]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:31:42,459]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:32:21,044]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:33:28,359]\u001b[0m Trial 844 finished with value: 4.498526056725219 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005404057901001769, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0503669432701828, 'dropout_rate_Layer_2': 0.14984781720915516, 'dropout_rate_Layer_3': 0.12258454697544914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.758281111986287e-05, 'l1_Layer_2': 0.0001599208641988596, 'l1_Layer_3': 0.0008418184206905901, 'n_units_Layer_1': 245, 'n_units_Layer_2': 80, 'n_units_Layer_3': 120}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:33:30,420]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:33:34,825]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:33:41,377]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:33:46,594]\u001b[0m Trial 841 finished with value: 4.438152478872564 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005010412327842639, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045667843733934683, 'dropout_rate_Layer_2': 0.16923837887885052, 'dropout_rate_Layer_3': 0.10880825663864752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6607772574686065e-05, 'l1_Layer_2': 0.000223637298021408, 'l1_Layer_3': 0.000898696707170118, 'n_units_Layer_1': 235, 'n_units_Layer_2': 75, 'n_units_Layer_3': 130}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:33:48,975]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:33:51,247]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:34:23,548]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:35:05,883]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:35:14,302]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:35:19,314]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:35:36,182]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:35:40,402]\u001b[0m Trial 852 finished with value: 4.473718188782422 and parameters: {'n_hidden': 3, 'learning_rate': 0.000556643381812307, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07415926379375695, 'dropout_rate_Layer_2': 0.17728538649376396, 'dropout_rate_Layer_3': 0.12239598407000937, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4177362778898053e-05, 'l1_Layer_2': 0.00023279800035134172, 'l1_Layer_3': 0.0011302768036992026, 'n_units_Layer_1': 250, 'n_units_Layer_2': 75, 'n_units_Layer_3': 130}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 19.31% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:35:43,429]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:35:51,456]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:36:34,814]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:36:38,360]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:36:47,595]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:37:03,365]\u001b[0m Trial 858 finished with value: 4.553712855877158 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006061385618957715, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06093848182866124, 'dropout_rate_Layer_2': 0.17471751456463633, 'dropout_rate_Layer_3': 0.1110913004794859, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.806035716740627e-05, 'l1_Layer_2': 0.0002957010390310312, 'l1_Layer_3': 0.0008433825134754875, 'n_units_Layer_1': 245, 'n_units_Layer_2': 70, 'n_units_Layer_3': 135}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 19.10% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:37:19,935]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:37:26,882]\u001b[0m Trial 846 finished with value: 4.462291642038682 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005719016153445138, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07548290313339645, 'dropout_rate_Layer_2': 0.17206412905830853, 'dropout_rate_Layer_3': 0.09792981441155714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6186982040422022e-05, 'l1_Layer_2': 0.00024731599484579733, 'l1_Layer_3': 0.001220346138950165, 'n_units_Layer_1': 245, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 19.38% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:37:37,020]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:37:45,034]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:38:10,527]\u001b[0m Trial 859 finished with value: 4.4587600786187584 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005007631925180319, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06252983980377506, 'dropout_rate_Layer_2': 0.1733328250658804, 'dropout_rate_Layer_3': 0.10828771603655662, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1471253931291712e-05, 'l1_Layer_2': 0.00020982469142410807, 'l1_Layer_3': 0.0007748772564996665, 'n_units_Layer_1': 245, 'n_units_Layer_2': 70, 'n_units_Layer_3': 135}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 19.11% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:38:19,597]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:38:27,030]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:38:28,704]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:38:36,385]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:38:38,702]\u001b[0m Trial 863 finished with value: 4.559134309474982 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006856881771972969, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.060576150912993385, 'dropout_rate_Layer_2': 0.16421549026871085, 'dropout_rate_Layer_3': 0.1109473517360701, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7568744194693488e-05, 'l1_Layer_2': 0.00015686219622429193, 'l1_Layer_3': 0.000618037930061007, 'n_units_Layer_1': 255, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 14.78% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 20.03% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:39:33,629]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:39:50,746]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:39:55,896]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:34,123]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:40,424]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:43,339]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:45,806]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:41:13,150]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:41:24,434]\u001b[0m Trial 877 finished with value: 4.4811353908146225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005070785829027039, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.060112593910469345, 'dropout_rate_Layer_2': 0.17264037666612053, 'dropout_rate_Layer_3': 0.11346618095923656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7291698916923378e-05, 'l1_Layer_2': 0.00020838112073174076, 'l1_Layer_3': 0.0006259592759406807, 'n_units_Layer_1': 255, 'n_units_Layer_2': 85, 'n_units_Layer_3': 110}. Best is trial 696 with value: 4.330562480255213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.54 | sMAPE for Test Set is: 19.08% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:41:29,092]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:42:10,277]\u001b[0m Trial 881 finished with value: 4.329528562301975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005748892065602051, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06976519520203761, 'dropout_rate_Layer_2': 0.03490359846824311, 'dropout_rate_Layer_3': 0.02493895345880872, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020839861235196237, 'l1_Layer_2': 0.0019361906251798195, 'l1_Layer_3': 2.2178221513318078e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 265}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.70 | sMAPE for Test Set is: 21.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:42:14,949]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:42:18,398]\u001b[0m Trial 880 finished with value: 4.345453969434154 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013597068228218998, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06925467134084651, 'dropout_rate_Layer_2': 0.029341910929041135, 'dropout_rate_Layer_3': 0.02349070874926893, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020668312093637727, 'l1_Layer_2': 0.0019138319091393306, 'l1_Layer_3': 2.365092424971207e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 265}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 21.46% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:42:22,430]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:42:22,582]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:43:09,518]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:43:17,078]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:43:28,765]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:43:35,801]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:43:50,164]\u001b[0m Trial 891 finished with value: 4.637140347455912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007160562779927873, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013688090901487105, 'dropout_rate_Layer_2': 0.3012864374835296, 'dropout_rate_Layer_3': 0.0457527427726299, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4067355134965107e-05, 'l1_Layer_2': 3.413224034457248e-05, 'l1_Layer_3': 0.00022742726897605572, 'n_units_Layer_1': 150, 'n_units_Layer_2': 275, 'n_units_Layer_3': 175}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 23.20% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:43:55,411]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:44:00,503]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:44:09,585]\u001b[0m Trial 889 finished with value: 4.482723737244167 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005100156014179205, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07620735118746085, 'dropout_rate_Layer_2': 0.1881193858705789, 'dropout_rate_Layer_3': 0.12044178175655289, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9480966974060048e-05, 'l1_Layer_2': 0.00019775620986852677, 'l1_Layer_3': 0.0005361629753906466, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 19.60% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:44:15,163]\u001b[0m Trial 888 finished with value: 4.521347934059535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005058172677668224, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07541084264989334, 'dropout_rate_Layer_2': 0.1877267521842005, 'dropout_rate_Layer_3': 0.08107433392349786, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0200383926336271e-05, 'l1_Layer_2': 0.00018087304192249574, 'l1_Layer_3': 0.0004893556211276927, 'n_units_Layer_1': 250, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 19.98% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:44:18,319]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:45:04,411]\u001b[0m Trial 893 finished with value: 4.539776788458811 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005028975241689098, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07619875452285763, 'dropout_rate_Layer_2': 0.16520575810999938, 'dropout_rate_Layer_3': 0.09364286242323423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5822767141795314e-05, 'l1_Layer_2': 0.00014098032168272066, 'l1_Layer_3': 0.0006143915770957494, 'n_units_Layer_1': 250, 'n_units_Layer_2': 90, 'n_units_Layer_3': 110}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 14.81% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.47 | sMAPE for Test Set is: 19.73% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:45:20,018]\u001b[0m Trial 898 finished with value: 4.651244404014041 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005066204685378159, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07754229407348857, 'dropout_rate_Layer_2': 0.1708805140850903, 'dropout_rate_Layer_3': 0.11424152724181999, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0128301368866222e-05, 'l1_Layer_2': 0.00019663478794906505, 'l1_Layer_3': 0.0004801685886891736, 'n_units_Layer_1': 260, 'n_units_Layer_2': 70, 'n_units_Layer_3': 125}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 19.59% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:45:24,881]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:45:56,719]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:12,806]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:13,508]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:17,757]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:21,269]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:24,533]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:25,374]\u001b[0m Trial 900 finished with value: 4.524276121751558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005973795800088504, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10223043902519541, 'dropout_rate_Layer_2': 0.17156166749893134, 'dropout_rate_Layer_3': 0.09118440020309015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4924575936931221e-05, 'l1_Layer_2': 0.000185698673430249, 'l1_Layer_3': 0.00047468229103733473, 'n_units_Layer_1': 245, 'n_units_Layer_2': 85, 'n_units_Layer_3': 110}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 14.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 19.75% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:46:26,637]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:33,667]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:34,691]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:35,096]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:38,843]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:45,244]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:46,884]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:53,340]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:47:01,543]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:47:14,470]\u001b[0m Trial 902 finished with value: 4.49790231708791 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005013114784539536, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09893342070883925, 'dropout_rate_Layer_2': 0.14957473234994031, 'dropout_rate_Layer_3': 0.0911129005262751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2277974908630812e-05, 'l1_Layer_2': 0.00024839760315188084, 'l1_Layer_3': 0.0004471572998852145, 'n_units_Layer_1': 250, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 14.66% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 20.01% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:47:23,353]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:47:28,167]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:47:50,186]\u001b[0m Trial 917 finished with value: 4.607584377867785 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005065664124900141, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07647806618984737, 'dropout_rate_Layer_2': 0.2930035186873335, 'dropout_rate_Layer_3': 0.1086221504257541, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.779210190374151e-05, 'l1_Layer_2': 1.2405711962916112e-05, 'l1_Layer_3': 3.5258590323599784e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 280, 'n_units_Layer_3': 185}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 14.80% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 22.05% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:47:59,132]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:48:04,138]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:48:07,587]\u001b[0m Trial 914 finished with value: 4.453133767802664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006338844135190905, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10460122634919569, 'dropout_rate_Layer_2': 0.1584933527302956, 'dropout_rate_Layer_3': 0.07990944176761303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.923719375477505e-05, 'l1_Layer_2': 0.00017666692810583203, 'l1_Layer_3': 0.0004427432259722907, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 140}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 20.44% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:48:09,269]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:48:17,155]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:48:20,217]\u001b[0m Trial 919 finished with value: 4.617273959389869 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005259874325402442, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026863877557712874, 'dropout_rate_Layer_2': 0.2360971060180719, 'dropout_rate_Layer_3': 0.06806354276748036, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.201278030376532e-05, 'l1_Layer_2': 1.1655157992685582e-05, 'l1_Layer_3': 0.00012919698549283492, 'n_units_Layer_1': 135, 'n_units_Layer_2': 280, 'n_units_Layer_3': 185}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 23.00% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:48:38,811]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:49:00,092]\u001b[0m Trial 921 finished with value: 4.452297889388807 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005030773720202884, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08341722256759089, 'dropout_rate_Layer_2': 0.15039090472794778, 'dropout_rate_Layer_3': 0.09477845373898672, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3077952104078273e-05, 'l1_Layer_2': 0.00017258568277652973, 'l1_Layer_3': 0.0004418464276238888, 'n_units_Layer_1': 245, 'n_units_Layer_2': 80, 'n_units_Layer_3': 130}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 20.05% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:49:13,867]\u001b[0m Trial 928 finished with value: 4.498867195281625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005551889303650657, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0496023022445897, 'dropout_rate_Layer_2': 0.23186173745234273, 'dropout_rate_Layer_3': 0.0687761701003876, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.042594123815731e-05, 'l1_Layer_2': 1.3239690861573763e-05, 'l1_Layer_3': 4.1813920320326466e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 280, 'n_units_Layer_3': 185}. Best is trial 881 with value: 4.329528562301975.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 14.53% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.95 | sMAPE for Test Set is: 20.97% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:50:04,680]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:50:09,294]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:50:12,406]\u001b[0m Trial 931 finished with value: 4.27843157554916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016855286149513656, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08011704837580011, 'dropout_rate_Layer_2': 0.017898510155918434, 'dropout_rate_Layer_3': 0.029939945849437287, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012141090194961373, 'l1_Layer_2': 0.005834526554564187, 'l1_Layer_3': 2.4950683844335796e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 295, 'n_units_Layer_3': 265}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 13.87% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 19.18% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:50:18,151]\u001b[0m Trial 929 finished with value: 4.4475682168756405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005014446483343574, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11568066306375162, 'dropout_rate_Layer_2': 0.13770573667794886, 'dropout_rate_Layer_3': 0.09338728689000948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.588200951851101e-05, 'l1_Layer_2': 0.00023343974956682424, 'l1_Layer_3': 0.0004980962807619579, 'n_units_Layer_1': 250, 'n_units_Layer_2': 75, 'n_units_Layer_3': 120}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 19.16% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:50:22,745]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:50:34,964]\u001b[0m Trial 930 finished with value: 4.357980293160377 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007074292633391341, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024624223396671027, 'dropout_rate_Layer_2': 0.027127816947680475, 'dropout_rate_Layer_3': 0.3126545808662608, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002929892349067935, 'l1_Layer_2': 0.00616987107374938, 'l1_Layer_3': 2.5325464694157302e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 14.03% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.73 | sMAPE for Test Set is: 20.00% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:50:44,999]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:50:59,968]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:51:08,162]\u001b[0m Trial 934 finished with value: 4.405304614472823 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005003745318737922, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0533519215395376, 'dropout_rate_Layer_2': 0.2349257785011095, 'dropout_rate_Layer_3': 0.068058832710743, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.443892994183727e-05, 'l1_Layer_2': 1.1850206511350965e-05, 'l1_Layer_3': 4.0137842466161745e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 280, 'n_units_Layer_3': 185}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 21.06% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:51:10,980]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:51:16,366]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:51:21,102]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:51:22,738]\u001b[0m Trial 933 finished with value: 4.359063445871118 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011781891373676523, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047637327065739365, 'dropout_rate_Layer_2': 0.025242542394704484, 'dropout_rate_Layer_3': 0.003255544865501201, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029654607117162715, 'l1_Layer_2': 0.0025399664309798914, 'l1_Layer_3': 2.5441377961450077e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 14.43% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 22.36% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:51:24,682]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:51:27,395]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:51:32,434]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:51:35,783]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:51:39,663]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:51:54,521]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:52:13,525]\u001b[0m Trial 945 finished with value: 4.506110874950553 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005063067147932744, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09820769983205815, 'dropout_rate_Layer_2': 0.1401319816860496, 'dropout_rate_Layer_3': 0.09352932764177156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.490806675787502e-05, 'l1_Layer_2': 0.00017740882823609775, 'l1_Layer_3': 0.0005147846267522032, 'n_units_Layer_1': 255, 'n_units_Layer_2': 85, 'n_units_Layer_3': 135}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 14.68% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 19.45% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:52:21,565]\u001b[0m Trial 938 finished with value: 4.342615502663997 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006997390259193912, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025409598534842502, 'dropout_rate_Layer_2': 0.005945456928499078, 'dropout_rate_Layer_3': 0.28396437918924755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011163170517377349, 'l1_Layer_2': 0.006883417267271028, 'l1_Layer_3': 2.4670541336565414e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 285, 'n_units_Layer_3': 265}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 14.06% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 19.18% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:52:29,782]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:52:40,474]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:53:05,231]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:53:08,028]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:53:09,810]\u001b[0m Trial 951 finished with value: 4.580012701796419 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005026182329947345, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07932899076664081, 'dropout_rate_Layer_2': 0.22626553222224113, 'dropout_rate_Layer_3': 0.06267243631475976, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.365623564241835e-05, 'l1_Layer_2': 1.2769520393188854e-05, 'l1_Layer_3': 9.058886474615216e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 275, 'n_units_Layer_3': 195}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 21.74% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:53:12,299]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:53:21,014]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:53:29,355]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:53:31,211]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:53:36,007]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:53:37,662]\u001b[0m Trial 950 finished with value: 4.457496316564483 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005006327753807064, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08898109193880817, 'dropout_rate_Layer_2': 0.1370653967930296, 'dropout_rate_Layer_3': 0.09019614821265357, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.21182750281455e-05, 'l1_Layer_2': 0.00018343181169818763, 'l1_Layer_3': 0.0004805911428565774, 'n_units_Layer_1': 260, 'n_units_Layer_2': 75, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 18.82% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:53:39,138]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:53:44,116]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:53:45,592]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:53:50,437]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:54:12,431]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:54:30,850]\u001b[0m Trial 963 finished with value: 4.522263871752128 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005194908869803925, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08285023192855918, 'dropout_rate_Layer_2': 0.21441299302160444, 'dropout_rate_Layer_3': 0.062452882301110554, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.55261861648621e-05, 'l1_Layer_2': 1.1667756401136623e-05, 'l1_Layer_3': 7.758095247715566e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 285, 'n_units_Layer_3': 190}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 22.85% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:54:41,585]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:55:19,709]\u001b[0m Trial 965 finished with value: 4.490882622468627 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006387004269328782, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10032086874996453, 'dropout_rate_Layer_2': 0.15491386566415272, 'dropout_rate_Layer_3': 0.10255887812906134, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2323667335403263e-05, 'l1_Layer_2': 0.0002227422375768387, 'l1_Layer_3': 0.00039076637772057787, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 130}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 20.18% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:55:28,622]\u001b[0m Trial 967 finished with value: 4.4499103240444 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005641333058286539, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09689252276508287, 'dropout_rate_Layer_2': 0.12987675301706267, 'dropout_rate_Layer_3': 0.07525605583381595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0422364349529925e-05, 'l1_Layer_2': 0.00021540150045723205, 'l1_Layer_3': 0.000707718357164764, 'n_units_Layer_1': 250, 'n_units_Layer_2': 85, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 19.03% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:55:33,164]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:55:37,920]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:55:40,652]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:55:45,704]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:56:00,929]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:56:23,722]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:56:26,315]\u001b[0m Trial 968 finished with value: 4.4397296538122095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005589332554076483, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09523358546861806, 'dropout_rate_Layer_2': 0.1297425906963352, 'dropout_rate_Layer_3': 0.07686051083663019, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0016039703422977e-05, 'l1_Layer_2': 0.00021609272110129055, 'l1_Layer_3': 0.0003806909190805068, 'n_units_Layer_1': 250, 'n_units_Layer_2': 85, 'n_units_Layer_3': 135}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 20.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:56:38,629]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:56:44,976]\u001b[0m Trial 971 finished with value: 4.44229495382481 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006631011843722497, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09684112467016798, 'dropout_rate_Layer_2': 0.14236413213611082, 'dropout_rate_Layer_3': 0.06914868067904234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.177453073929866e-05, 'l1_Layer_2': 0.00020703193490318557, 'l1_Layer_3': 0.00039700777717612565, 'n_units_Layer_1': 270, 'n_units_Layer_2': 75, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 19.86% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:56:45,285]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:56:53,460]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:56:55,374]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:57:32,058]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:57:53,027]\u001b[0m Trial 984 finished with value: 4.418666090925868 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006403553992588893, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0936870479934545, 'dropout_rate_Layer_2': 0.14341738348931307, 'dropout_rate_Layer_3': 0.05894351510694489, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.692102886045367e-05, 'l1_Layer_2': 0.00033908881165490917, 'l1_Layer_3': 0.0006080474130057718, 'n_units_Layer_1': 270, 'n_units_Layer_2': 70, 'n_units_Layer_3': 120}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 14.33% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 18.93% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:58:19,250]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:58:27,998]\u001b[0m Trial 985 finished with value: 4.438947427510327 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006351257706394905, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11679164928522368, 'dropout_rate_Layer_2': 0.14330472998472704, 'dropout_rate_Layer_3': 0.0614710567606089, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5732256520887995e-05, 'l1_Layer_2': 0.0002540923375078277, 'l1_Layer_3': 0.00037410976635105295, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 120}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.44% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:58:37,405]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:58:40,621]\u001b[0m Trial 986 finished with value: 4.452154616868363 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006327450023685386, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09793730656700658, 'dropout_rate_Layer_2': 0.14219971492926164, 'dropout_rate_Layer_3': 0.052900804843489684, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6476113950247146e-05, 'l1_Layer_2': 0.0003789535834439054, 'l1_Layer_3': 0.0003902758731385198, 'n_units_Layer_1': 270, 'n_units_Layer_2': 70, 'n_units_Layer_3': 120}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 19.37% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:58:46,317]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:58:55,675]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:59:00,451]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:59:05,476]\u001b[0m Trial 979 finished with value: 4.446362357835668 and parameters: {'n_hidden': 3, 'learning_rate': 0.000557427390052189, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09083034593871842, 'dropout_rate_Layer_2': 0.13169089640572929, 'dropout_rate_Layer_3': 0.06712124460861363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1635149795450864e-05, 'l1_Layer_2': 0.00025892308572163654, 'l1_Layer_3': 0.0003409971121250998, 'n_units_Layer_1': 270, 'n_units_Layer_2': 75, 'n_units_Layer_3': 135}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 21.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:59:13,627]\u001b[0m Trial 987 finished with value: 4.413653077804856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006627611767300589, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09126762954264056, 'dropout_rate_Layer_2': 0.1329814908629085, 'dropout_rate_Layer_3': 0.06049337795904826, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.234420094840861e-05, 'l1_Layer_2': 0.0003611149377748939, 'l1_Layer_3': 0.0003765772043997305, 'n_units_Layer_1': 270, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.52% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 21.17% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:59:16,517]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:59:24,812]\u001b[0m Trial 991 finished with value: 4.387763029024338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006604930632403932, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040770143185196096, 'dropout_rate_Layer_2': 0.06632550482417131, 'dropout_rate_Layer_3': 0.30170923014470286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000130069577670825, 'l1_Layer_2': 0.0008008835054568363, 'l1_Layer_3': 7.438436324959822e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 14.30% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 20.39% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:59:35,918]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:59:41,775]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:59:43,456]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:59:46,234]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:59:46,967]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:59:50,676]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:59:57,080]\u001b[0m Trial 994 finished with value: 4.4611720722664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007259185580145314, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0908129226841361, 'dropout_rate_Layer_2': 0.1263567019867255, 'dropout_rate_Layer_3': 0.05110446214497015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.232140584028479e-05, 'l1_Layer_2': 0.0003830492977673, 'l1_Layer_3': 0.0003493923483178283, 'n_units_Layer_1': 275, 'n_units_Layer_2': 65, 'n_units_Layer_3': 130}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.43% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 19.27% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:00:00,191]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:00:03,128]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:00:07,228]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:00:15,528]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:00:19,060]\u001b[0m Trial 995 finished with value: 4.456949091145294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006628155998467529, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08761663678516914, 'dropout_rate_Layer_2': 0.1251328376677618, 'dropout_rate_Layer_3': 0.05030343944056169, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2948642674351614e-05, 'l1_Layer_2': 0.00034134464088148963, 'l1_Layer_3': 0.0003239894756262232, 'n_units_Layer_1': 270, 'n_units_Layer_2': 60, 'n_units_Layer_3': 115}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 21.12% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:00:28,115]\u001b[0m Trial 1005 finished with value: 4.379846160124772 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006922806884987361, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005529863814680013, 'dropout_rate_Layer_2': 0.062245573727573514, 'dropout_rate_Layer_3': 0.29814951004968615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000143185678033569, 'l1_Layer_2': 0.0002679449414066237, 'l1_Layer_3': 0.00011442303982219085, 'n_units_Layer_1': 220, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 14.29% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 21.77% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:00:31,867]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:00:35,761]\u001b[0m Trial 1002 finished with value: 4.384891997934276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006871504702436477, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0001102591781566506, 'dropout_rate_Layer_2': 0.0645952305888643, 'dropout_rate_Layer_3': 0.29703857504150843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011792942753740957, 'l1_Layer_2': 0.0004827650551338521, 'l1_Layer_3': 0.00019594505310754478, 'n_units_Layer_1': 165, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 14.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 20.92% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:00:44,069]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:01:28,610]\u001b[0m Trial 1008 finished with value: 4.409547689194397 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006438457628660383, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08044338514185174, 'dropout_rate_Layer_2': 0.12383184397482824, 'dropout_rate_Layer_3': 0.043246425014836457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1950162524573527e-05, 'l1_Layer_2': 0.0004230769049559188, 'l1_Layer_3': 0.0005491762692678938, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 18.79% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:01:49,824]\u001b[0m Trial 1009 finished with value: 4.307260021841504 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007167253770695285, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016980889367080313, 'dropout_rate_Layer_2': 0.010174480133351347, 'dropout_rate_Layer_3': 0.22996060666727505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022728604651399897, 'l1_Layer_2': 0.007631074997658148, 'l1_Layer_3': 1.0187694173857647e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 270}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 13.90% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 19.36% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:01:54,518]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:01:57,731]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:01:58,071]\u001b[0m Trial 1013 finished with value: 4.3572921418470765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007027011888543685, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017702812984909062, 'dropout_rate_Layer_2': 0.009051385529746265, 'dropout_rate_Layer_3': 0.36904703485629603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023100311803569263, 'l1_Layer_2': 0.0019631922622332753, 'l1_Layer_3': 1.0082812848986756e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 270}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 14.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 20.36% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:02:12,932]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:02:17,264]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:02:22,954]\u001b[0m Trial 1011 finished with value: 4.3371593234625605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007968246168450729, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017981035740886497, 'dropout_rate_Layer_2': 0.007914665942450695, 'dropout_rate_Layer_3': 0.3371602368164611, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002327551150699791, 'l1_Layer_2': 0.007119042618833369, 'l1_Layer_3': 2.0564088773144467e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 280, 'n_units_Layer_3': 270}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 13.95% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 20.02% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:02:35,897]\u001b[0m Trial 1017 finished with value: 4.463937734554711 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008523820610698402, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0007502495310849622, 'dropout_rate_Layer_2': 0.10473881482843847, 'dropout_rate_Layer_3': 0.29805432475626736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025026328176290277, 'l1_Layer_2': 0.00047498947789830913, 'l1_Layer_3': 0.00019085852025514554, 'n_units_Layer_1': 170, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 21.05% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:02:37,566]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:02:40,671]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:02:42,678]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:02:47,563]\u001b[0m Trial 1014 finished with value: 4.40673348422601 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005568010206711583, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015978946578365565, 'dropout_rate_Layer_2': 0.009000593466448558, 'dropout_rate_Layer_3': 0.3446139217193043, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022584429143322188, 'l1_Layer_2': 0.006992007866655146, 'l1_Layer_3': 1.940401948565283e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 270}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.70 | sMAPE for Test Set is: 19.78% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:02:49,410]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:02:59,545]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:03:00,580]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:03:11,951]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:03:16,013]\u001b[0m Trial 1020 finished with value: 4.435853229713396 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006704674832113733, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0919054291198651, 'dropout_rate_Layer_2': 0.14182802924328936, 'dropout_rate_Layer_3': 0.0580746545501956, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.537230595682431e-05, 'l1_Layer_2': 0.0003066792371809426, 'l1_Layer_3': 0.0003937553812236081, 'n_units_Layer_1': 285, 'n_units_Layer_2': 65, 'n_units_Layer_3': 110}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 20.44% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:03:20,967]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:03:34,112]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:03:40,469]\u001b[0m Trial 1024 finished with value: 4.412464638182294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006421576460243922, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08033359479739946, 'dropout_rate_Layer_2': 0.12547049862402554, 'dropout_rate_Layer_3': 0.04198903362660012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0291729040511928e-05, 'l1_Layer_2': 0.0002946537701772151, 'l1_Layer_3': 0.00035056489566401115, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 120}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 20.12% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:03:40,639]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:03:54,642]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:03:57,910]\u001b[0m Trial 1028 finished with value: 4.533539897016419 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006040742557597784, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07570954427680321, 'dropout_rate_Layer_2': 0.10272302938248197, 'dropout_rate_Layer_3': 0.05434434867823043, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.272010954074692e-05, 'l1_Layer_2': 1.9925039872769186e-05, 'l1_Layer_3': 9.058337417502321e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 14.83% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.31 | sMAPE for Test Set is: 22.55% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:04:03,137]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:04:06,969]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:04:41,135]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:04:45,887]\u001b[0m Trial 1037 finished with value: 4.478218276139966 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006780439870744544, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08207324147777108, 'dropout_rate_Layer_2': 0.11764606872437705, 'dropout_rate_Layer_3': 0.05814826403173902, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1257264915136154e-05, 'l1_Layer_2': 0.0003777121947058816, 'l1_Layer_3': 0.00036432267721907464, 'n_units_Layer_1': 300, 'n_units_Layer_2': 55, 'n_units_Layer_3': 115}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 19.12% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:04:49,995]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:04:50,553]\u001b[0m Trial 1039 finished with value: 4.413850283908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008722580988557853, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005612546917596588, 'dropout_rate_Layer_2': 0.12406059849758852, 'dropout_rate_Layer_3': 0.29279431891578767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029384033011522473, 'l1_Layer_2': 0.0004323065023568304, 'l1_Layer_3': 0.00027315631449232664, 'n_units_Layer_1': 165, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.31% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.37 | sMAPE for Test Set is: 19.43% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:04:52,930]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:04:54,003]\u001b[0m Trial 1036 finished with value: 4.4754551568638465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005008021133657944, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024369378904022434, 'dropout_rate_Layer_2': 0.2390718855314465, 'dropout_rate_Layer_3': 0.04377275810743973, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7986968596841566e-05, 'l1_Layer_2': 1.6004187863898196e-05, 'l1_Layer_3': 6.835904257947804e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 295, 'n_units_Layer_3': 195}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 14.52% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.85 | sMAPE for Test Set is: 21.19% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:05:00,553]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:05:19,969]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:05:38,815]\u001b[0m Trial 1045 finished with value: 4.453758186186826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008475727202160511, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010754528648274732, 'dropout_rate_Layer_2': 0.10677285380448527, 'dropout_rate_Layer_3': 0.3012482402819485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0038304138124374797, 'l1_Layer_2': 0.0005021679254446857, 'l1_Layer_3': 0.000294255938800715, 'n_units_Layer_1': 165, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 19.99% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:05:49,258]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:05:54,022]\u001b[0m Trial 1047 finished with value: 4.576654703261078 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005097504204548871, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02013695551289788, 'dropout_rate_Layer_2': 0.24105586117799804, 'dropout_rate_Layer_3': 0.04091207360897403, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.784868043394854e-05, 'l1_Layer_2': 1.9841841346398385e-05, 'l1_Layer_3': 8.344568492582099e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 295, 'n_units_Layer_3': 200}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 21.19% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:06:27,834]\u001b[0m Trial 1044 finished with value: 4.3731063999232855 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005518533670445308, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013194837317340453, 'dropout_rate_Layer_2': 0.007534309291346697, 'dropout_rate_Layer_3': 0.34984887165989836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022237141268417686, 'l1_Layer_2': 0.006440305448045679, 'l1_Layer_3': 1.9718878013120217e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 270}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 14.09% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 19.48% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:06:31,120]\u001b[0m Trial 1049 finished with value: 4.53040864742002 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005017065860211094, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020015955037956387, 'dropout_rate_Layer_2': 0.23227934546518503, 'dropout_rate_Layer_3': 0.039598720203492074, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7277819301989357e-05, 'l1_Layer_2': 1.799479395485783e-05, 'l1_Layer_3': 8.358828966301089e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 295, 'n_units_Layer_3': 200}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 21.22% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:06:36,231]\u001b[0m Trial 1050 finished with value: 4.524038684512983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005555786331616013, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023495191589997622, 'dropout_rate_Layer_2': 0.2435740317303908, 'dropout_rate_Layer_3': 0.04237660366410169, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8500140726875633e-05, 'l1_Layer_2': 1.791618065479931e-05, 'l1_Layer_3': 8.161916748642445e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 295, 'n_units_Layer_3': 200}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 20.36% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:06:41,911]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:06:46,951]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:06:50,401]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:06:52,136]\u001b[0m Trial 1048 finished with value: 4.425553722205941 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006158270524228845, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09256471871996763, 'dropout_rate_Layer_2': 0.13140984819048127, 'dropout_rate_Layer_3': 0.06521217925232041, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4320040368012139e-05, 'l1_Layer_2': 0.0004261596686266873, 'l1_Layer_3': 0.00043992499323878577, 'n_units_Layer_1': 285, 'n_units_Layer_2': 70, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:06:55,317]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:07:14,259]\u001b[0m Trial 1053 finished with value: 4.517945860273568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005030377923070852, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03438962672673146, 'dropout_rate_Layer_2': 0.24595212167205044, 'dropout_rate_Layer_3': 0.039826418237471156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8365990199359635e-05, 'l1_Layer_2': 1.989931831119772e-05, 'l1_Layer_3': 7.59220417652116e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 205}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 14.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 21.57% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:07:26,536]\u001b[0m Trial 1051 finished with value: 4.530010766217857 and parameters: {'n_hidden': 3, 'learning_rate': 0.000509357522730004, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01807771194813751, 'dropout_rate_Layer_2': 0.2448178252162277, 'dropout_rate_Layer_3': 0.04050488748657671, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.050555337310457e-05, 'l1_Layer_2': 1.9687908687004226e-05, 'l1_Layer_3': 8.095024000338071e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 295, 'n_units_Layer_3': 205}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 21.98% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:07:35,331]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:07:51,795]\u001b[0m Trial 1057 finished with value: 4.481648557788833 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006629581676889557, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09876045868354331, 'dropout_rate_Layer_2': 0.13397098772100835, 'dropout_rate_Layer_3': 0.06661063840837272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3208637987353234e-05, 'l1_Layer_2': 0.00043321495367796577, 'l1_Layer_3': 0.0004779540508393919, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 14.68% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 21.71% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:07:55,989]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:08:00,853]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:08:06,702]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:08:09,197]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:08:13,377]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:08:21,668]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:08:24,707]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:08:28,978]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:08:32,217]\u001b[0m Trial 1060 finished with value: 4.450310123548383 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006720020508641551, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08822857531231582, 'dropout_rate_Layer_2': 0.128581664769057, 'dropout_rate_Layer_3': 0.05481915246372632, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3066672158252905e-05, 'l1_Layer_2': 0.0004057630225199395, 'l1_Layer_3': 0.00045622317887831647, 'n_units_Layer_1': 290, 'n_units_Layer_2': 70, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 19.00% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:08:42,412]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:08:43,130]\u001b[0m Trial 1058 finished with value: 4.4218243123500764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006474463851849663, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08810945008342339, 'dropout_rate_Layer_2': 0.12727341429693656, 'dropout_rate_Layer_3': 0.07086997102820772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2493477190778186e-05, 'l1_Layer_2': 0.0004961585491654871, 'l1_Layer_3': 0.00046947606065226314, 'n_units_Layer_1': 285, 'n_units_Layer_2': 70, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 19.14% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:08:49,130]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:08:51,062]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:08:55,128]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:08:55,163]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:01,780]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:08,460]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:14,013]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:22,445]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:25,006]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:28,863]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:28,968]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:36,909]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:41,909]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:42,214]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:42,472]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:51,922]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:53,921]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:58,184]\u001b[0m Trial 1070 finished with value: 4.443008554069052 and parameters: {'n_hidden': 3, 'learning_rate': 0.000678550670526853, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10484121785784223, 'dropout_rate_Layer_2': 0.11988174839048421, 'dropout_rate_Layer_3': 0.0612147348778382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8463684065660432e-05, 'l1_Layer_2': 0.0002595474436016642, 'l1_Layer_3': 0.00034259453604314926, 'n_units_Layer_1': 275, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:09:58,403]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:10:00,630]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:10:01,741]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:10:06,424]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:10:08,350]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:10:11,692]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:10:24,176]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:10:27,810]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:10:28,170]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:10:39,157]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:11:06,802]\u001b[0m Trial 1099 finished with value: 4.532246371263454 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005530335089244659, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07416758705037937, 'dropout_rate_Layer_2': 0.25066164999836954, 'dropout_rate_Layer_3': 0.05428575045827439, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.901292531666502e-05, 'l1_Layer_2': 1.3112339420807113e-05, 'l1_Layer_3': 6.457510365348546e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 295, 'n_units_Layer_3': 210}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 14.66% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.09 | sMAPE for Test Set is: 21.64% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:11:10,469]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:11:19,489]\u001b[0m Trial 1098 finished with value: 4.456553813335616 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006727253526807457, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09570025661649957, 'dropout_rate_Layer_2': 0.12175725945547552, 'dropout_rate_Layer_3': 0.05481717948473762, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4520497044848096e-05, 'l1_Layer_2': 0.00036305374768020454, 'l1_Layer_3': 0.0004596983983667395, 'n_units_Layer_1': 290, 'n_units_Layer_2': 60, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 21.06% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:11:27,374]\u001b[0m Trial 1101 finished with value: 4.51687543290121 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005583930748814446, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034447895040282346, 'dropout_rate_Layer_2': 0.25175346768342793, 'dropout_rate_Layer_3': 0.034585390371155975, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.881112523140825e-05, 'l1_Layer_2': 1.3519874035707448e-05, 'l1_Layer_3': 5.9585080636781973e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 295, 'n_units_Layer_3': 210}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 21.24% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:11:32,629]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:11:32,823]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:11:40,482]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:11:44,377]\u001b[0m Trial 1092 finished with value: 4.385775882360045 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006844200916713458, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034185772885415355, 'dropout_rate_Layer_2': 0.0067055870114006875, 'dropout_rate_Layer_3': 0.2373660482590661, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035046246128450355, 'l1_Layer_2': 0.006275755423430353, 'l1_Layer_3': 2.7311392860389717e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 300, 'n_units_Layer_3': 270}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 14.12% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:11:53,935]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:11:59,192]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:12:02,391]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:12:32,642]\u001b[0m Trial 1107 finished with value: 4.462537735084443 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006447651346684727, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13642035400065047, 'dropout_rate_Layer_2': 0.11069307833224007, 'dropout_rate_Layer_3': 0.04526961684011579, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.460983350392976e-05, 'l1_Layer_2': 0.00033922232484103203, 'l1_Layer_3': 0.00038652469448498207, 'n_units_Layer_1': 290, 'n_units_Layer_2': 55, 'n_units_Layer_3': 120}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 20.30% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:12:35,848]\u001b[0m Trial 1106 finished with value: 4.59453153701128 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005825323771570905, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03095851141740911, 'dropout_rate_Layer_2': 0.2529429234890431, 'dropout_rate_Layer_3': 0.030855782222317538, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.711362548989993e-05, 'l1_Layer_2': 1.557447567682088e-05, 'l1_Layer_3': 9.69211040375834e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 295, 'n_units_Layer_3': 210}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 14.99% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 22.69% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:12:38,427]\u001b[0m Trial 1108 finished with value: 4.452153418344936 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008365474459078657, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13538340644496807, 'dropout_rate_Layer_2': 0.10778223684796191, 'dropout_rate_Layer_3': 0.043647426273572446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0638095909954977e-05, 'l1_Layer_2': 0.0003700793499572035, 'l1_Layer_3': 0.0003580860942628756, 'n_units_Layer_1': 290, 'n_units_Layer_2': 55, 'n_units_Layer_3': 120}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 21.01% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:12:38,580]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:12:44,193]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:12:48,826]\u001b[0m Trial 1112 finished with value: 4.465334907045112 and parameters: {'n_hidden': 3, 'learning_rate': 0.000615620893241798, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08885520882791245, 'dropout_rate_Layer_2': 0.12469486686377668, 'dropout_rate_Layer_3': 0.05051913951452769, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9832459346070244e-05, 'l1_Layer_2': 0.0003186277424909074, 'l1_Layer_3': 0.0003772065763018876, 'n_units_Layer_1': 300, 'n_units_Layer_2': 65, 'n_units_Layer_3': 115}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 20.17% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:12:50,359]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:12:55,018]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:13:00,394]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:13:02,295]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:13:08,005]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:13:09,837]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:13:13,938]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:13:16,195]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:13:19,375]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:13:21,631]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:13:25,517]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:13:40,634]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:04,941]\u001b[0m Trial 1114 finished with value: 4.321586735473887 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007291261147914977, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04779731670526202, 'dropout_rate_Layer_2': 0.00746084667979733, 'dropout_rate_Layer_3': 0.2315172663947671, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035518003613636823, 'l1_Layer_2': 0.004298505307223997, 'l1_Layer_3': 1.6818614451466196e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 13.92% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 19.98% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:14:18,554]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:22,684]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:23,752]\u001b[0m Trial 1129 finished with value: 4.432942994689808 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006771280762049711, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02332380534395649, 'dropout_rate_Layer_2': 0.09645011367939284, 'dropout_rate_Layer_3': 0.32981137960943213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002493189125283094, 'l1_Layer_2': 0.00026091654180942733, 'l1_Layer_3': 0.00032883568402375423, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 235}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 19.37% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:14:24,396]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:28,117]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:31,531]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:32,221]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:35,660]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:37,379]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:38,841]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:40,574]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:44,980]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:48,619]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:49,415]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:52,072]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:54,598]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:56,686]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:59,394]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:59,769]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:00,338]\u001b[0m Trial 1130 finished with value: 4.400789619084843 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006596917437904491, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025118279718080314, 'dropout_rate_Layer_2': 0.1012760708937737, 'dropout_rate_Layer_3': 0.32911912967827645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016655482589512732, 'l1_Layer_2': 0.0006606275803097973, 'l1_Layer_3': 0.0003968387654262922, 'n_units_Layer_1': 150, 'n_units_Layer_2': 60, 'n_units_Layer_3': 230}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 14.28% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:15:06,886]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:07,221]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:13,311]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:13,887]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:20,294]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:24,612]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:33,570]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:34,566]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:38,044]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:51,074]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:53,647]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:55,370]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:15:55,444]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:16:00,159]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:16:01,886]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:16:02,798]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:16:03,787]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:16:04,705]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:16:19,319]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:16:23,087]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:16:27,159]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:16:30,366]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:00,663]\u001b[0m Trial 1168 finished with value: 4.4990914505478035 and parameters: {'n_hidden': 3, 'learning_rate': 0.000675857648276472, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09472296564122708, 'dropout_rate_Layer_2': 0.11145619606656183, 'dropout_rate_Layer_3': 0.050015122933046795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.998341796677822e-05, 'l1_Layer_2': 0.00015527499760517398, 'l1_Layer_3': 0.000738812164244228, 'n_units_Layer_1': 290, 'n_units_Layer_2': 55, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 19.54% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:17:04,541]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:08,218]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:11,809]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:15,170]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:17,870]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:21,121]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:24,831]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:28,706]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:33,668]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:38,827]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:46,376]\u001b[0m Trial 1172 finished with value: 4.429714409715359 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007394975074484922, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13615269832646032, 'dropout_rate_Layer_2': 0.1114516029185125, 'dropout_rate_Layer_3': 0.05640644802988678, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.644599036901615e-05, 'l1_Layer_2': 0.0005647639699043263, 'l1_Layer_3': 0.0002718504600946223, 'n_units_Layer_1': 240, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 21.04% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:17:49,669]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:52,552]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:17:57,467]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:18:02,968]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:18:06,935]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:18:10,845]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:18:24,381]\u001b[0m Trial 1178 finished with value: 4.510894061215292 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005538336974341623, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06713921594587687, 'dropout_rate_Layer_2': 0.2625647045736001, 'dropout_rate_Layer_3': 0.05840348228268907, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.334793325894865e-05, 'l1_Layer_2': 1.0035753746456004e-05, 'l1_Layer_3': 9.09546429548556e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 300, 'n_units_Layer_3': 215}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 21.28% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:18:31,392]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:18:34,071]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:18:41,842]\u001b[0m Trial 1179 finished with value: 4.398021352437344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005489493445943706, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07803870374003978, 'dropout_rate_Layer_2': 0.09818170514820918, 'dropout_rate_Layer_3': 0.06809442685766692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.66093142232425e-05, 'l1_Layer_2': 0.0002065495912853324, 'l1_Layer_3': 0.00045183890212104804, 'n_units_Layer_1': 260, 'n_units_Layer_2': 80, 'n_units_Layer_3': 115}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 14.35% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 20.04% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:18:45,180]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:18:50,030]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:18:54,303]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:19:09,008]\u001b[0m Trial 1184 finished with value: 4.402387972519746 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005435162673833806, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02600165633850639, 'dropout_rate_Layer_2': 0.03470867574232558, 'dropout_rate_Layer_3': 0.3274778440185036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006501899386699331, 'l1_Layer_2': 0.0016493754629836456, 'l1_Layer_3': 1.7095358883461216e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 20.05% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:19:22,953]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:19:27,071]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:19:48,975]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:19:53,146]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:19:59,029]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:02,352]\u001b[0m Trial 1199 finished with value: 4.437299739951043 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005623422528310508, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0739377817511793, 'dropout_rate_Layer_2': 0.09216069191047101, 'dropout_rate_Layer_3': 0.04988579627407551, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4775252967469844e-05, 'l1_Layer_2': 0.00024824333393468946, 'l1_Layer_3': 0.0003670229475382103, 'n_units_Layer_1': 260, 'n_units_Layer_2': 85, 'n_units_Layer_3': 115}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 20.56% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:20:11,298]\u001b[0m Trial 1193 finished with value: 4.399479424499905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005466037316408465, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13198363476410563, 'dropout_rate_Layer_2': 0.13853105170709565, 'dropout_rate_Layer_3': 0.07669884179110364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4011397955933667e-05, 'l1_Layer_2': 0.00043344160051607476, 'l1_Layer_3': 0.0003881923186906226, 'n_units_Layer_1': 260, 'n_units_Layer_2': 80, 'n_units_Layer_3': 135}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:20:13,168]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:14,826]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:18,821]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:21,996]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:30,683]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:30,972]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:37,230]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:40,306]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:41,177]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:45,329]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:46,887]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:48,901]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:51,496]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:52,034]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:53,173]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:20:59,319]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:01,543]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:02,554]\u001b[0m Trial 1198 finished with value: 4.410875917725973 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005588980516822115, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07591445619138412, 'dropout_rate_Layer_2': 0.10496739843104372, 'dropout_rate_Layer_3': 0.04830198421702961, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.567287130016783e-05, 'l1_Layer_2': 0.0008523516350343557, 'l1_Layer_3': 0.00039568539351691096, 'n_units_Layer_1': 260, 'n_units_Layer_2': 85, 'n_units_Layer_3': 110}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 20.13% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:21:05,659]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:08,907]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:12,950]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:14,791]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:18,266]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:19,892]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:24,179]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:24,336]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:29,277]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:32,462]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:40,577]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:44,120]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:53,431]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:21:56,984]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:22:01,751]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:22:25,874]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:22:26,806]\u001b[0m Trial 1235 finished with value: 4.453653448286225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005965701592612252, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06615532916942943, 'dropout_rate_Layer_2': 0.11335014458099554, 'dropout_rate_Layer_3': 0.07291411402290172, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0123236444540533e-05, 'l1_Layer_2': 0.00020076887073569778, 'l1_Layer_3': 0.00024288310941630476, 'n_units_Layer_1': 260, 'n_units_Layer_2': 75, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 19.41% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:22:36,570]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:22:45,766]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:22:50,245]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:22:50,759]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:22:52,731]\u001b[0m Trial 1222 finished with value: 4.3248565120170905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007119995453074064, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05182001913711794, 'dropout_rate_Layer_2': 0.017568443704509933, 'dropout_rate_Layer_3': 0.19005077438939866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020610407582198886, 'l1_Layer_2': 0.0052018827366143465, 'l1_Layer_3': 3.3233323426530036e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 14.17% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 19.55% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:22:56,581]\u001b[0m Trial 1225 finished with value: 4.400884929614027 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005794887201834063, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06404385669599866, 'dropout_rate_Layer_2': 0.11929364183497346, 'dropout_rate_Layer_3': 0.053788268295166225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4461480442304898e-05, 'l1_Layer_2': 0.000679425659802745, 'l1_Layer_3': 0.000809078366158542, 'n_units_Layer_1': 265, 'n_units_Layer_2': 95, 'n_units_Layer_3': 100}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.47 | sMAPE for Test Set is: 20.19% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:23:01,030]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:23:02,879]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:23:06,846]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:23:29,281]\u001b[0m Trial 1244 finished with value: 4.4072451474972665 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011511110330068737, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031327948229042, 'dropout_rate_Layer_2': 0.06251724246257717, 'dropout_rate_Layer_3': 0.2728375596412405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001026953721536822, 'l1_Layer_2': 0.0002639792874057097, 'l1_Layer_3': 0.00023055286934089032, 'n_units_Layer_1': 165, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 23.58% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:23:32,276]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:23:35,734]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:23:37,971]\u001b[0m Trial 1250 finished with value: 4.449522208283885 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010988155727490836, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031749611894426794, 'dropout_rate_Layer_2': 0.06389222056103969, 'dropout_rate_Layer_3': 0.30293923234010406, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002150247892528927, 'l1_Layer_2': 0.000262724386516582, 'l1_Layer_3': 0.00013257779324652623, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 21.21% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:23:40,735]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:23:45,785]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:23:47,908]\u001b[0m Trial 1249 finished with value: 4.474057046526582 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006258364237369756, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013086474264552447, 'dropout_rate_Layer_2': 0.26412648545663137, 'dropout_rate_Layer_3': 0.03155764211108298, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.036621760930213e-05, 'l1_Layer_2': 1.913431335197114e-05, 'l1_Layer_3': 4.569837528159526e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 200}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 21.67% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:23:55,328]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:24:00,190]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:24:06,054]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:24:18,723]\u001b[0m Trial 1245 finished with value: 4.337613690781583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007648361201088242, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01598481492257287, 'dropout_rate_Layer_2': 0.02396930988054667, 'dropout_rate_Layer_3': 0.20212402096431137, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002023909624332819, 'l1_Layer_2': 0.004252738291217444, 'l1_Layer_3': 3.728976954942098e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 285, 'n_units_Layer_3': 245}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.55 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:24:23,229]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:24:28,006]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:24:33,308]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:24:44,245]\u001b[0m Trial 1254 finished with value: 4.484733212104612 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006158147517772869, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07819274384235372, 'dropout_rate_Layer_2': 0.2773375778474285, 'dropout_rate_Layer_3': 0.00922790538949148, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0249846484800214e-05, 'l1_Layer_2': 1.9282736011796868e-05, 'l1_Layer_3': 4.563744151864912e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 200}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 14.43% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 23.31% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:24:50,873]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:24:56,180]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:05,204]\u001b[0m Trial 1260 finished with value: 4.428070878163535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006237140608753285, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05729478265668018, 'dropout_rate_Layer_2': 0.11524424307148796, 'dropout_rate_Layer_3': 0.04731358192198193, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2843784110687266e-05, 'l1_Layer_2': 0.00018192973508592385, 'l1_Layer_3': 0.0007296233018840206, 'n_units_Layer_1': 245, 'n_units_Layer_2': 80, 'n_units_Layer_3': 115}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 14.31% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:25:08,855]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:12,436]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:16,669]\u001b[0m Trial 1257 finished with value: 4.445468026002248 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005915051794859763, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014749804418204936, 'dropout_rate_Layer_2': 0.2592532164317109, 'dropout_rate_Layer_3': 0.029813323558908283, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.871154589353352e-05, 'l1_Layer_2': 2.0987717412070337e-05, 'l1_Layer_3': 0.0012176628988741541, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 205}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.25 | sMAPE for Test Set is: 22.01% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:25:20,935]\u001b[0m Trial 1266 finished with value: 4.364852882714412 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011490243440866537, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03196397967687626, 'dropout_rate_Layer_2': 0.06344398705327634, 'dropout_rate_Layer_3': 0.3227629568663541, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010674575995161847, 'l1_Layer_2': 0.00027163573793091754, 'l1_Layer_3': 7.330469412977986e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 185, 'n_units_Layer_3': 225}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 21.82% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:25:21,484]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:23,153]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:27,935]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:32,870]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:41,934]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:42,489]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:47,838]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:48,204]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:56,574]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:57,320]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:25:57,348]\u001b[0m Trial 1267 finished with value: 4.51937023905902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005001956002021445, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009729481884113288, 'dropout_rate_Layer_2': 0.2768582207422487, 'dropout_rate_Layer_3': 0.015992989569162994, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.045125767648054e-05, 'l1_Layer_2': 2.0193156424843135e-05, 'l1_Layer_3': 4.034277314913275e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 285, 'n_units_Layer_3': 195}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 14.68% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 23.21% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:26:04,664]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:05,248]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:05,501]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:05,671]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:13,647]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:13,976]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:19,230]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:19,526]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:19,645]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:26,278]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:26,806]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:28,687]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:31,283]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:36,074]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:36,177]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:39,681]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:42,914]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:46,261]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:48,447]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:51,818]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:52,723]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:56,814]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:26:58,844]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:27:05,133]\u001b[0m Trial 1297 finished with value: 4.356410513567692 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011356352373000185, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018821425025733526, 'dropout_rate_Layer_2': 0.04482510164119833, 'dropout_rate_Layer_3': 0.32281769510092034, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007493455873494355, 'l1_Layer_2': 0.00019579831259961908, 'l1_Layer_3': 0.00013037928869060603, 'n_units_Layer_1': 115, 'n_units_Layer_2': 195, 'n_units_Layer_3': 225}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 14.12% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 19.75% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:27:08,863]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:27:12,287]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:27:16,338]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:27:52,079]\u001b[0m Trial 1310 finished with value: 4.565393601512777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006978570724243469, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038946973034369815, 'dropout_rate_Layer_2': 0.26154967121778144, 'dropout_rate_Layer_3': 0.014344073419835929, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.281031066927767e-05, 'l1_Layer_2': 1.6678973137355906e-05, 'l1_Layer_3': 4.3650518391578176e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 290, 'n_units_Layer_3': 50}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 14.76% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 21.49% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:27:59,225]\u001b[0m Trial 1307 finished with value: 4.473360542193249 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007790833707244224, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08446544357885798, 'dropout_rate_Layer_2': 0.16414766022630561, 'dropout_rate_Layer_3': 0.07817628755449763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.578528212309752e-05, 'l1_Layer_2': 0.00041380782774363414, 'l1_Layer_3': 0.0003945348386957966, 'n_units_Layer_1': 270, 'n_units_Layer_2': 60, 'n_units_Layer_3': 95}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.60 | sMAPE for Test Set is: 19.97% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:28:00,625]\u001b[0m Trial 1296 finished with value: 4.374406784563578 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005682071965392425, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010017524636959887, 'dropout_rate_Layer_2': 0.014713116646877305, 'dropout_rate_Layer_3': 0.16332953897070304, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002023431254561451, 'l1_Layer_2': 0.00531846844025461, 'l1_Layer_3': 2.0406358025528702e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 285, 'n_units_Layer_3': 250}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 20.77% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:28:11,904]\u001b[0m Trial 1305 finished with value: 4.455875339958283 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007098158564495871, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06178481993683297, 'dropout_rate_Layer_2': 0.09832976854046094, 'dropout_rate_Layer_3': 0.03804566742807466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9346648120645725e-05, 'l1_Layer_2': 0.0004048010796032314, 'l1_Layer_3': 0.00023351582884514893, 'n_units_Layer_1': 270, 'n_units_Layer_2': 60, 'n_units_Layer_3': 100}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.62% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 20.38% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:28:12,757]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:28:18,438]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:28:18,877]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:28:22,916]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:28:36,458]\u001b[0m Trial 1317 finished with value: 4.499263108565821 and parameters: {'n_hidden': 3, 'learning_rate': 0.000504366246479239, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01681466970087485, 'dropout_rate_Layer_2': 0.06132298572062918, 'dropout_rate_Layer_3': 0.2773911490260332, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009103044343876049, 'l1_Layer_2': 0.00038681848179235637, 'l1_Layer_3': 0.00013559500901217273, 'n_units_Layer_1': 115, 'n_units_Layer_2': 195, 'n_units_Layer_3': 220}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:28:40,095]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:28:43,017]\u001b[0m Trial 1311 finished with value: 4.315296809591034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015143659043477683, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014226025141740282, 'dropout_rate_Layer_2': 0.03708639356062184, 'dropout_rate_Layer_3': 0.30531716765862266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008917393028548304, 'l1_Layer_2': 9.602490014697359e-05, 'l1_Layer_3': 0.0001256864977316383, 'n_units_Layer_1': 110, 'n_units_Layer_2': 195, 'n_units_Layer_3': 220}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 14.10% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.38 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:28:45,041]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:28:48,258]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:28:51,288]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:28:52,945]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:28:56,409]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:28:56,731]\u001b[0m Trial 1312 finished with value: 4.474649601023457 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005842618986878843, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10935083390852204, 'dropout_rate_Layer_2': 0.14480781617988195, 'dropout_rate_Layer_3': 0.06438055333793885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4114541294779575e-05, 'l1_Layer_2': 0.00027907394725583905, 'l1_Layer_3': 0.0002903914411126863, 'n_units_Layer_1': 245, 'n_units_Layer_2': 70, 'n_units_Layer_3': 120}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 14.53% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 19.68% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:28:56,842]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:03,744]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:07,418]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:10,963]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:11,398]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:14,862]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:18,402]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:20,153]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:22,971]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:29,614]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:33,528]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:40,373]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:42,659]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:45,117]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:47,245]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:48,152]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:53,857]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:29:57,622]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:30:01,802]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:30:05,637]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:30:17,844]\u001b[0m Trial 1328 finished with value: 4.325788465713809 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007358490450616946, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04399718947094707, 'dropout_rate_Layer_2': 0.026782903224871778, 'dropout_rate_Layer_3': 0.18990591861337952, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001067878720439011, 'l1_Layer_2': 0.0030026123327324466, 'l1_Layer_3': 3.1381384744855824e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 290, 'n_units_Layer_3': 240}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 20.57% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:30:21,794]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:30:26,800]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:31:11,413]\u001b[0m Trial 1350 finished with value: 4.519995144195508 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005012264789930771, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0625430323943909, 'dropout_rate_Layer_2': 0.26049391603569455, 'dropout_rate_Layer_3': 0.04073123198032434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.40218802246953e-05, 'l1_Layer_2': 2.1185889570195993e-05, 'l1_Layer_3': 2.6229997606254274e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 300, 'n_units_Layer_3': 200}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 14.98% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 22.75% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:31:15,182]\u001b[0m Trial 1342 finished with value: 4.45024220495601 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005387266421326036, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008936421013891329, 'dropout_rate_Layer_2': 0.014787156536009451, 'dropout_rate_Layer_3': 0.20193247785115986, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019996533563388348, 'l1_Layer_2': 0.005383266785409849, 'l1_Layer_3': 2.069169941815813e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 250}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.52% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 20.50% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:31:18,300]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:31:20,447]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:31:27,430]\u001b[0m Trial 1347 finished with value: 4.367642197719042 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005744125614138198, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017625481361384063, 'dropout_rate_Layer_2': 0.01373545908179931, 'dropout_rate_Layer_3': 0.20440280944595063, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019817533556795844, 'l1_Layer_2': 0.005859847709699617, 'l1_Layer_3': 2.1710326054551482e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 14.05% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 20.04% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:31:35,797]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:31:39,478]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:31:42,181]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:31:48,627]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:31:51,792]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:31:57,966]\u001b[0m Trial 1354 finished with value: 4.417271672947614 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011078832743397435, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04990892722640016, 'dropout_rate_Layer_2': 0.03176117526723965, 'dropout_rate_Layer_3': 0.30660894427054236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011171321690761494, 'l1_Layer_2': 7.367790305236156e-05, 'l1_Layer_3': 7.096498805237124e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 210, 'n_units_Layer_3': 235}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 21.02% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:32:00,152]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:02,235]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:06,280]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:09,871]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:12,053]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:13,827]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:17,394]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:20,347]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:22,909]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:23,039]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:27,615]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:30,737]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:41,433]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:42,299]\u001b[0m Trial 1371 finished with value: 4.4373289150947945 and parameters: {'n_hidden': 3, 'learning_rate': 0.002037876575463005, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05318429844771142, 'dropout_rate_Layer_2': 0.022119887953695967, 'dropout_rate_Layer_3': 0.28855594552999503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000753016443758651, 'l1_Layer_2': 3.815946739347023e-05, 'l1_Layer_3': 8.36999205591329e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 230}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.35% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 20.19% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:32:42,510]\u001b[0m Trial 1348 finished with value: 4.449521847513524 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007211132015272423, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08246144567637509, 'dropout_rate_Layer_2': 0.12595346024160664, 'dropout_rate_Layer_3': 0.08440387409707419, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.007334544170263e-05, 'l1_Layer_2': 0.00012000985315774879, 'l1_Layer_3': 0.0010354116168932073, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:32:48,663]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:49,106]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:52,526]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:53,221]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:55,171]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:00,135]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:02,858]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:05,771]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:06,689]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:07,093]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:10,942]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:13,974]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:14,199]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:15,496]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:20,221]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:22,258]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:25,157]\u001b[0m Trial 1377 finished with value: 4.409192056961953 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017023554814684792, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0661355333571788, 'dropout_rate_Layer_2': 0.08454011792255543, 'dropout_rate_Layer_3': 0.3244271663191457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013726995918283066, 'l1_Layer_2': 3.440076903141761e-05, 'l1_Layer_3': 0.00010940181406574468, 'n_units_Layer_1': 110, 'n_units_Layer_2': 220, 'n_units_Layer_3': 280}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 20.76% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:33:29,044]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:32,525]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:36,111]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:40,086]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:43,739]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:46,055]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:55,748]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:58,595]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:59,030]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:33:59,242]\u001b[0m Trial 1388 finished with value: 4.556108389252613 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005519349838188686, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0571275526782161, 'dropout_rate_Layer_2': 0.2464573075106256, 'dropout_rate_Layer_3': 0.042018892924618204, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.919267615430122e-05, 'l1_Layer_2': 1.522732983801463e-05, 'l1_Layer_3': 6.103533566320266e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 290, 'n_units_Layer_3': 205}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 14.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 21.56% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:34:07,029]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:09,634]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:15,506]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:15,834]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:16,034]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:22,843]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:25,629]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:27,597]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:28,501]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:29,731]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:34,797]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:37,556]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:40,268]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:42,663]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:44,935]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:45,169]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:46,496]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:46,786]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:51,729]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:52,849]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:53,479]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:34:55,245]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:35:01,131]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:35:01,346]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:35:05,712]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:35:12,391]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:35:16,687]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:35:32,702]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:35:42,036]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:35:45,482]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:35:53,839]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:36:02,045]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:36:06,854]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:36:11,816]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:36:18,488]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:36:22,401]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:36:26,589]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:36:34,238]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:37:11,873]\u001b[0m Trial 1427 finished with value: 4.455656481220264 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007676599207195357, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06376823564151435, 'dropout_rate_Layer_2': 0.09550683458093931, 'dropout_rate_Layer_3': 0.03468146632893042, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.490534826725981e-05, 'l1_Layer_2': 0.0003152039316139473, 'l1_Layer_3': 0.00032760801520917264, 'n_units_Layer_1': 265, 'n_units_Layer_2': 60, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.89% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 21.78% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:37:16,304]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:37:25,729]\u001b[0m Trial 1424 finished with value: 4.447361542646335 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006094753792330866, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09877465319971568, 'dropout_rate_Layer_2': 0.09483109278130389, 'dropout_rate_Layer_3': 0.11473627321914683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1419725739189648e-05, 'l1_Layer_2': 0.0001862025077526215, 'l1_Layer_3': 0.00046878975963927656, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 110}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.51% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 19.50% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:37:30,804]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:37:34,901]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:37:35,852]\u001b[0m Trial 1433 finished with value: 4.470720783979866 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005832222355721438, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09282474130750858, 'dropout_rate_Layer_2': 0.12685951145173371, 'dropout_rate_Layer_3': 0.10948488498215349, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.153854428990801e-05, 'l1_Layer_2': 0.00016745066538390287, 'l1_Layer_3': 0.0004648747628173549, 'n_units_Layer_1': 265, 'n_units_Layer_2': 90, 'n_units_Layer_3': 125}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 19.18% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:37:36,237]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:37:38,982]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:37:39,087]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:37:45,895]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:37:46,456]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:37:51,336]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:37:53,238]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:37:55,520]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:37:59,683]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:01,604]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:02,354]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:08,989]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:11,403]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:12,758]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:12,938]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:19,750]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:23,815]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:24,351]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:28,986]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:32,111]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:34,216]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:36,400]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:37,721]\u001b[0m Trial 1457 finished with value: 4.369361722420631 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013207629224219713, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02277725125568863, 'dropout_rate_Layer_2': 0.07076102731265169, 'dropout_rate_Layer_3': 0.3311673145031692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016473753135691279, 'l1_Layer_2': 3.089167681475227e-05, 'l1_Layer_3': 0.0002193927291396911, 'n_units_Layer_1': 80, 'n_units_Layer_2': 205, 'n_units_Layer_3': 265}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 14.17% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 20.89% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:38:38,644]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:46,957]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:47,479]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:51,670]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:55,100]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:57,749]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:38:57,914]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:39:05,181]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:39:05,366]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:39:12,558]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:39:12,685]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:39:18,538]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:39:27,310]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:39:31,802]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:39:46,074]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:40:02,632]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:40:06,856]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:40:16,272]\u001b[0m Trial 1481 finished with value: 4.353663640459878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008207902565483465, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050412002740090785, 'dropout_rate_Layer_2': 0.016220533129423176, 'dropout_rate_Layer_3': 0.0014989187687223747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002088031628979933, 'l1_Layer_2': 0.005411548271941713, 'l1_Layer_3': 1.0085873551235726e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:40:24,775]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:41:06,750]\u001b[0m Trial 1478 finished with value: 4.399938507926975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005543937703077458, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05081345578855802, 'dropout_rate_Layer_2': 0.09191744693955568, 'dropout_rate_Layer_3': 0.006976951838371159, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.377640862206737e-05, 'l1_Layer_2': 0.000211012503324321, 'l1_Layer_3': 0.0007133784289488092, 'n_units_Layer_1': 270, 'n_units_Layer_2': 80, 'n_units_Layer_3': 120}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 19.94% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:41:10,716]\u001b[0m Trial 1484 finished with value: 4.448766431036497 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005577171316472161, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04517548563624558, 'dropout_rate_Layer_2': 0.18266127286547137, 'dropout_rate_Layer_3': 0.061213648445848506, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6317487003152242e-05, 'l1_Layer_2': 0.00025800123513199113, 'l1_Layer_3': 0.0007514464944052119, 'n_units_Layer_1': 270, 'n_units_Layer_2': 90, 'n_units_Layer_3': 115}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 19.43% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:41:13,967]\u001b[0m Trial 1489 finished with value: 4.413539265907843 and parameters: {'n_hidden': 3, 'learning_rate': 0.000906695156195251, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10904751511118542, 'dropout_rate_Layer_2': 0.10514377382584034, 'dropout_rate_Layer_3': 0.06354313184811586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3140838875460693e-05, 'l1_Layer_2': 0.0003591463266978711, 'l1_Layer_3': 0.0005415248167742984, 'n_units_Layer_1': 280, 'n_units_Layer_2': 70, 'n_units_Layer_3': 130}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 19.70% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:41:14,320]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:41:14,507]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:41:15,013]\u001b[0m Trial 1487 finished with value: 4.397738911739275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007985520522295871, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05044922378182713, 'dropout_rate_Layer_2': 0.017227887874505146, 'dropout_rate_Layer_3': 0.3500911406382257, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022746989472925203, 'l1_Layer_2': 0.005914870058916219, 'l1_Layer_3': 2.03291442196987e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255}. Best is trial 931 with value: 4.27843157554916.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 18.91% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:41:24,600]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:41:29,285]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:41:29,832]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:41:35,131]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:41:38,832]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:41:39,027]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:41:52,333]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:41:56,243]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-01-01, MAE is:7.56 & sMAPE is:24.64% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 24.64% & 0.37\n",
      "for 2020-01-02, MAE is:2.71 & sMAPE is:7.29% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 15.96% & 0.28\n",
      "for 2020-01-03, MAE is:2.64 & sMAPE is:7.54% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 13.15% & 0.38\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E9085A5B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2020-01-04, MAE is:2.97 & sMAPE is:9.01% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 12.12% & 0.52\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E81CCCA040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2020-01-05, MAE is:6.52 & sMAPE is:20.21% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 13.74% & 0.68\n",
      "for 2020-01-06, MAE is:4.93 & sMAPE is:12.01% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 13.45% & 0.75\n",
      "for 2020-01-07, MAE is:5.63 & sMAPE is:13.82% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.50% & 0.79\n",
      "for 2020-01-08, MAE is:5.59 & sMAPE is:14.75% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 13.66% & 0.76\n",
      "for 2020-01-09, MAE is:5.33 & sMAPE is:13.72% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 13.66% & 0.81\n",
      "for 2020-01-10, MAE is:5.74 & sMAPE is:15.83% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 13.88% & 0.91\n",
      "for 2020-01-11, MAE is:3.96 & sMAPE is:11.93% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 13.70% & 1.03\n",
      "for 2020-01-12, MAE is:3.67 & sMAPE is:12.55% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.61% & 0.99\n",
      "for 2020-01-13, MAE is:5.51 & sMAPE is:14.78% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 13.70% & 1.00\n",
      "for 2020-01-14, MAE is:4.28 & sMAPE is:18.29% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 14.03% & 0.95\n",
      "for 2020-01-15, MAE is:5.12 & sMAPE is:18.66% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 14.33% & 0.93\n",
      "for 2020-01-16, MAE is:4.84 & sMAPE is:13.43% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 14.28% & 1.03\n",
      "for 2020-01-17, MAE is:2.86 & sMAPE is:8.00% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.91% & 1.04\n",
      "for 2020-01-18, MAE is:3.81 & sMAPE is:11.80% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 13.79% & 1.07\n",
      "for 2020-01-19, MAE is:2.32 & sMAPE is:6.91% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 13.43% & 1.05\n",
      "for 2020-01-20, MAE is:4.29 & sMAPE is:9.59% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 13.24% & 1.02\n",
      "for 2020-01-21, MAE is:4.29 & sMAPE is:9.22% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 13.05% & 0.99\n",
      "for 2020-01-22, MAE is:3.96 & sMAPE is:8.02% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 12.82% & 0.95\n",
      "for 2020-01-23, MAE is:5.17 & sMAPE is:9.90% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 12.69% & 0.93\n",
      "for 2020-01-24, MAE is:5.44 & sMAPE is:10.49% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 12.60% & 0.90\n",
      "for 2020-01-25, MAE is:2.79 & sMAPE is:6.86% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 12.37% & 0.89\n",
      "for 2020-01-26, MAE is:3.20 & sMAPE is:9.00% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 12.24% & 0.89\n",
      "for 2020-01-27, MAE is:4.10 & sMAPE is:10.74% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 12.18% & 0.88\n",
      "for 2020-01-28, MAE is:5.72 & sMAPE is:15.65% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 12.31% & 0.86\n",
      "for 2020-01-29, MAE is:3.12 & sMAPE is:8.97% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 12.19% & 0.84\n",
      "for 2020-01-30, MAE is:3.42 & sMAPE is:9.68% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 12.11% & 0.82\n",
      "for 2020-01-31, MAE is:4.75 & sMAPE is:17.36% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 12.28% & 0.80\n",
      "for 2020-02-01, MAE is:7.10 & sMAPE is:46.58% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 13.35% & 0.79\n",
      "for 2020-02-02, MAE is:5.31 & sMAPE is:29.14% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 13.83% & 0.77\n",
      "for 2020-02-03, MAE is:5.41 & sMAPE is:18.80% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 13.97% & 0.76\n",
      "for 2020-02-04, MAE is:5.84 & sMAPE is:21.12% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 14.18% & 0.77\n",
      "for 2020-02-05, MAE is:4.10 & sMAPE is:11.52% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 14.10% & 0.79\n",
      "for 2020-02-06, MAE is:3.30 & sMAPE is:9.36% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 13.98% & 0.80\n",
      "for 2020-02-07, MAE is:5.30 & sMAPE is:14.32% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 13.99% & 0.81\n",
      "for 2020-02-08, MAE is:3.60 & sMAPE is:11.81% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 13.93% & 0.79\n",
      "for 2020-02-09, MAE is:7.46 & sMAPE is:46.70% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 14.75% & 0.80\n",
      "for 2020-02-10, MAE is:10.24 & sMAPE is:48.88% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 15.58% & 0.82\n",
      "for 2020-02-11, MAE is:3.10 & sMAPE is:14.34% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 15.55% & 0.82\n",
      "for 2020-02-12, MAE is:5.30 & sMAPE is:18.06% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 15.61% & 0.82\n",
      "for 2020-02-13, MAE is:4.02 & sMAPE is:12.64% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 15.54% & 0.81\n",
      "for 2020-02-14, MAE is:3.14 & sMAPE is:10.17% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 15.42% & 0.81\n",
      "for 2020-02-15, MAE is:5.45 & sMAPE is:24.62% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 15.62% & 0.81\n",
      "for 2020-02-16, MAE is:6.19 & sMAPE is:71.26% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 16.81% & 0.81\n",
      "for 2020-02-17, MAE is:3.76 & sMAPE is:21.49% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 16.90% & 0.81\n",
      "for 2020-02-18, MAE is:5.42 & sMAPE is:21.08% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 16.99% & 0.83\n",
      "for 2020-02-19, MAE is:3.56 & sMAPE is:11.80% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 16.89% & 0.84\n",
      "for 2020-02-20, MAE is:4.19 & sMAPE is:12.97% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 16.81% & 0.86\n",
      "for 2020-02-21, MAE is:3.19 & sMAPE is:10.16% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 16.68% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-02-22, MAE is:4.37 & sMAPE is:17.78% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 16.70% & 0.87\n",
      "for 2020-02-23, MAE is:3.79 & sMAPE is:19.94% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 16.76% & 0.86\n",
      "for 2020-02-24, MAE is:6.86 & sMAPE is:23.75% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 16.89% & 0.86\n",
      "for 2020-02-25, MAE is:4.77 & sMAPE is:19.17% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 16.93% & 0.88\n",
      "for 2020-02-26, MAE is:3.32 & sMAPE is:9.67% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 16.80% & 0.89\n",
      "for 2020-02-27, MAE is:2.51 & sMAPE is:7.05% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 16.63% & 0.89\n",
      "for 2020-02-28, MAE is:5.53 & sMAPE is:16.76% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 16.64% & 0.90\n",
      "for 2020-02-29, MAE is:8.03 & sMAPE is:41.94% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 17.06% & 0.90\n",
      "for 2020-03-01, MAE is:5.59 & sMAPE is:36.07% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 17.37% & 0.91\n",
      "for 2020-03-02, MAE is:4.44 & sMAPE is:14.05% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 17.32% & 0.90\n",
      "for 2020-03-03, MAE is:4.76 & sMAPE is:12.56% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 17.24% & 0.90\n",
      "for 2020-03-04, MAE is:5.43 & sMAPE is:13.11% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 17.18% & 0.89\n",
      "for 2020-03-05, MAE is:5.14 & sMAPE is:15.12% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 17.14% & 0.90\n",
      "for 2020-03-06, MAE is:2.94 & sMAPE is:9.49% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 17.03% & 0.89\n",
      "for 2020-03-07, MAE is:3.31 & sMAPE is:11.58% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 16.95% & 0.88\n",
      "for 2020-03-08, MAE is:8.77 & sMAPE is:46.98% & rMAE is:2.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 17.39% & 0.91\n",
      "for 2020-03-09, MAE is:5.03 & sMAPE is:14.22% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 17.34% & 0.92\n",
      "for 2020-03-10, MAE is:7.19 & sMAPE is:25.02% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 17.45% & 0.91\n",
      "for 2020-03-11, MAE is:5.67 & sMAPE is:22.86% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 17.53% & 0.91\n",
      "for 2020-03-12, MAE is:6.75 & sMAPE is:34.32% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 17.76% & 0.90\n",
      "for 2020-03-13, MAE is:4.89 & sMAPE is:17.73% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 17.76% & 0.91\n",
      "for 2020-03-14, MAE is:4.70 & sMAPE is:16.08% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 17.74% & 0.92\n",
      "for 2020-03-15, MAE is:9.36 & sMAPE is:67.20% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 18.40% & 0.94\n",
      "for 2020-03-16, MAE is:8.88 & sMAPE is:34.60% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 18.61% & 0.94\n",
      "for 2020-03-17, MAE is:3.56 & sMAPE is:12.75% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 18.54% & 0.94\n",
      "for 2020-03-18, MAE is:4.42 & sMAPE is:16.24% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 18.51% & 0.94\n",
      "for 2020-03-19, MAE is:3.20 & sMAPE is:12.51% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 18.43% & 0.93\n",
      "for 2020-03-20, MAE is:4.88 & sMAPE is:20.91% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 18.46% & 0.93\n",
      "for 2020-03-21, MAE is:6.47 & sMAPE is:47.96% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 18.83% & 0.92\n",
      "for 2020-03-22, MAE is:8.54 & sMAPE is:84.99% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 19.63% & 0.92\n",
      "for 2020-03-23, MAE is:5.50 & sMAPE is:36.02% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 19.83% & 0.92\n",
      "for 2020-03-24, MAE is:4.82 & sMAPE is:22.86% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 19.87% & 0.91\n",
      "for 2020-03-25, MAE is:3.87 & sMAPE is:16.29% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 19.82% & 0.92\n",
      "for 2020-03-26, MAE is:2.97 & sMAPE is:13.19% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 19.75% & 0.91\n",
      "for 2020-03-27, MAE is:3.28 & sMAPE is:15.93% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 19.70% & 0.92\n",
      "for 2020-03-28, MAE is:5.93 & sMAPE is:50.21% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 20.05% & 0.92\n",
      "for 2020-03-29, MAE is:3.89 & sMAPE is:73.87% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 20.65% & 0.92\n",
      "for 2020-03-30, MAE is:3.51 & sMAPE is:18.08% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 20.63% & 0.91\n",
      "for 2020-03-31, MAE is:2.79 & sMAPE is:11.80% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 20.53% & 0.91\n",
      "for 2020-04-01, MAE is:2.63 & sMAPE is:12.80% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 20.44% & 0.92\n",
      "for 2020-04-02, MAE is:2.77 & sMAPE is:12.60% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 20.36% & 0.92\n",
      "for 2020-04-03, MAE is:2.34 & sMAPE is:11.45% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 20.27% & 0.92\n",
      "for 2020-04-04, MAE is:4.76 & sMAPE is:25.77% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 20.32% & 0.93\n",
      "for 2020-04-05, MAE is:7.73 & sMAPE is:90.27% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 21.05% & 0.94\n",
      "for 2020-04-06, MAE is:3.53 & sMAPE is:42.19% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 21.27% & 0.93\n",
      "for 2020-04-07, MAE is:4.13 & sMAPE is:28.87% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 21.35% & 0.93\n",
      "for 2020-04-08, MAE is:3.16 & sMAPE is:22.61% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 21.36% & 0.92\n",
      "for 2020-04-09, MAE is:4.60 & sMAPE is:26.62% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 21.41% & 0.92\n",
      "for 2020-04-10, MAE is:2.82 & sMAPE is:18.57% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 21.38% & 0.92\n",
      "for 2020-04-11, MAE is:5.38 & sMAPE is:52.43% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 21.69% & 0.92\n",
      "for 2020-04-12, MAE is:5.46 & sMAPE is:64.53% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 22.10% & 0.92\n",
      "for 2020-04-13, MAE is:14.77 & sMAPE is:136.65% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 23.21% & 0.92\n",
      "for 2020-04-14, MAE is:6.83 & sMAPE is:65.48% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 23.61% & 0.92\n",
      "for 2020-04-15, MAE is:3.26 & sMAPE is:22.84% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 23.60% & 0.93\n",
      "for 2020-04-16, MAE is:2.67 & sMAPE is:19.82% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 23.57% & 0.93\n",
      "for 2020-04-17, MAE is:2.79 & sMAPE is:22.17% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 23.55% & 0.93\n",
      "for 2020-04-18, MAE is:3.70 & sMAPE is:30.68% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 23.62% & 0.93\n",
      "for 2020-04-19, MAE is:6.45 & sMAPE is:64.32% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 23.99% & 0.93\n",
      "for 2020-04-20, MAE is:11.71 & sMAPE is:101.62% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 24.69% & 0.93\n",
      "for 2020-04-21, MAE is:7.88 & sMAPE is:100.13% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 25.36% & 0.94\n",
      "for 2020-04-22, MAE is:6.41 & sMAPE is:68.75% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 25.75% & 0.94\n",
      "for 2020-04-23, MAE is:3.50 & sMAPE is:23.55% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 25.73% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-04-24, MAE is:3.63 & sMAPE is:22.43% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 25.70% & 0.93\n",
      "for 2020-04-25, MAE is:2.60 & sMAPE is:21.34% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 25.66% & 0.93\n",
      "for 2020-04-26, MAE is:2.48 & sMAPE is:20.78% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 25.62% & 0.93\n",
      "for 2020-04-27, MAE is:3.49 & sMAPE is:20.14% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 25.57% & 0.92\n",
      "for 2020-04-28, MAE is:3.19 & sMAPE is:15.50% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 25.49% & 0.91\n",
      "for 2020-04-29, MAE is:6.38 & sMAPE is:39.67% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 25.61% & 0.92\n",
      "for 2020-04-30, MAE is:9.43 & sMAPE is:73.00% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 26.00% & 0.92\n",
      "for 2020-05-01, MAE is:5.91 & sMAPE is:80.46% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 26.44% & 0.91\n",
      "for 2020-05-02, MAE is:4.37 & sMAPE is:35.16% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 26.51% & 0.91\n",
      "for 2020-05-03, MAE is:2.08 & sMAPE is:20.89% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 26.47% & 0.91\n",
      "for 2020-05-04, MAE is:3.24 & sMAPE is:21.91% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 26.43% & 0.91\n",
      "for 2020-05-05, MAE is:2.54 & sMAPE is:13.59% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 26.33% & 0.91\n",
      "for 2020-05-06, MAE is:3.55 & sMAPE is:19.86% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 26.28% & 0.91\n",
      "for 2020-05-07, MAE is:3.73 & sMAPE is:20.59% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 26.24% & 0.90\n",
      "for 2020-05-08, MAE is:4.23 & sMAPE is:29.12% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 26.26% & 0.90\n",
      "for 2020-05-09, MAE is:3.01 & sMAPE is:17.00% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 26.19% & 0.90\n",
      "for 2020-05-10, MAE is:3.79 & sMAPE is:38.72% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 26.28% & 0.90\n",
      "for 2020-05-11, MAE is:7.73 & sMAPE is:81.97% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 26.70% & 0.90\n",
      "for 2020-05-12, MAE is:3.19 & sMAPE is:16.92% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 26.63% & 0.90\n",
      "for 2020-05-13, MAE is:3.54 & sMAPE is:14.94% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 26.54% & 0.90\n",
      "for 2020-05-14, MAE is:4.61 & sMAPE is:22.37% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 26.51% & 0.90\n",
      "for 2020-05-15, MAE is:4.15 & sMAPE is:19.74% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 26.46% & 0.91\n",
      "for 2020-05-16, MAE is:2.95 & sMAPE is:21.69% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 26.43% & 0.91\n",
      "for 2020-05-17, MAE is:6.63 & sMAPE is:66.96% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 26.72% & 0.91\n",
      "for 2020-05-18, MAE is:5.21 & sMAPE is:25.63% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 26.71% & 0.91\n",
      "for 2020-05-19, MAE is:3.26 & sMAPE is:15.13% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 26.63% & 0.91\n",
      "for 2020-05-20, MAE is:4.33 & sMAPE is:19.93% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 26.58% & 0.91\n",
      "for 2020-05-21, MAE is:3.45 & sMAPE is:22.71% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 26.56% & 0.91\n",
      "for 2020-05-22, MAE is:6.49 & sMAPE is:37.51% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 26.63% & 0.92\n",
      "for 2020-05-23, MAE is:4.99 & sMAPE is:36.01% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 26.70% & 0.92\n",
      "for 2020-05-24, MAE is:22.34 & sMAPE is:157.32% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 27.60% & 0.92\n",
      "for 2020-05-25, MAE is:6.68 & sMAPE is:45.09% & rMAE is:3.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 27.72% & 0.94\n",
      "for 2020-05-26, MAE is:3.32 & sMAPE is:18.92% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 27.66% & 0.94\n",
      "for 2020-05-27, MAE is:2.54 & sMAPE is:12.80% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 27.56% & 0.94\n",
      "for 2020-05-28, MAE is:3.58 & sMAPE is:18.79% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 27.50% & 0.94\n",
      "for 2020-05-29, MAE is:2.69 & sMAPE is:16.30% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 27.42% & 0.94\n",
      "for 2020-05-30, MAE is:3.36 & sMAPE is:33.75% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 27.47% & 0.94\n",
      "for 2020-05-31, MAE is:10.24 & sMAPE is:92.04% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 27.89% & 0.93\n",
      "for 2020-06-01, MAE is:6.46 & sMAPE is:68.37% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 28.16% & 0.93\n",
      "for 2020-06-02, MAE is:2.89 & sMAPE is:15.91% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 28.08% & 0.93\n",
      "for 2020-06-03, MAE is:2.58 & sMAPE is:10.06% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 27.96% & 0.93\n",
      "for 2020-06-04, MAE is:3.30 & sMAPE is:14.55% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 27.87% & 0.93\n",
      "for 2020-06-05, MAE is:5.28 & sMAPE is:30.63% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 27.89% & 0.93\n",
      "for 2020-06-06, MAE is:9.28 & sMAPE is:113.27% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 28.43% & 0.93\n",
      "for 2020-06-07, MAE is:3.74 & sMAPE is:23.11% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 28.40% & 0.93\n",
      "for 2020-06-08, MAE is:3.53 & sMAPE is:12.94% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 28.30% & 0.92\n",
      "for 2020-06-09, MAE is:3.22 & sMAPE is:11.76% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 28.20% & 0.92\n",
      "for 2020-06-10, MAE is:2.82 & sMAPE is:9.59% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 28.08% & 0.92\n",
      "for 2020-06-11, MAE is:8.40 & sMAPE is:28.99% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 28.09% & 0.92\n",
      "for 2020-06-12, MAE is:4.47 & sMAPE is:18.62% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 28.03% & 0.93\n",
      "for 2020-06-13, MAE is:2.38 & sMAPE is:12.05% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 27.94% & 0.92\n",
      "for 2020-06-14, MAE is:1.76 & sMAPE is:9.28% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 27.82% & 0.92\n",
      "for 2020-06-15, MAE is:5.20 & sMAPE is:17.61% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 27.76% & 0.93\n",
      "for 2020-06-16, MAE is:2.01 & sMAPE is:6.01% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 27.63% & 0.92\n",
      "for 2020-06-17, MAE is:2.62 & sMAPE is:7.92% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 27.52% & 0.92\n",
      "for 2020-06-18, MAE is:2.17 & sMAPE is:7.01% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 27.39% & 0.92\n",
      "for 2020-06-19, MAE is:2.27 & sMAPE is:7.79% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 27.28% & 0.91\n",
      "for 2020-06-20, MAE is:2.84 & sMAPE is:11.93% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 27.19% & 0.91\n",
      "for 2020-06-21, MAE is:6.15 & sMAPE is:33.25% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 27.23% & 0.92\n",
      "for 2020-06-22, MAE is:3.33 & sMAPE is:11.23% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 27.13% & 0.92\n",
      "for 2020-06-23, MAE is:3.75 & sMAPE is:11.77% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 27.05% & 0.92\n",
      "for 2020-06-24, MAE is:2.79 & sMAPE is:7.87% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 26.94% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-06-25, MAE is:2.56 & sMAPE is:7.21% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 26.83% & 0.93\n",
      "for 2020-06-26, MAE is:2.80 & sMAPE is:8.02% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 26.72% & 0.92\n",
      "for 2020-06-27, MAE is:5.47 & sMAPE is:19.41% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 26.68% & 0.93\n",
      "for 2020-06-28, MAE is:7.97 & sMAPE is:45.41% & rMAE is:2.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 26.78% & 0.94\n",
      "for 2020-06-29, MAE is:3.74 & sMAPE is:12.69% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 26.71% & 0.94\n",
      "for 2020-06-30, MAE is:4.87 & sMAPE is:14.77% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 26.64% & 0.94\n",
      "for 2020-07-01, MAE is:2.41 & sMAPE is:7.35% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 26.53% & 0.94\n",
      "for 2020-07-02, MAE is:3.94 & sMAPE is:10.52% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 26.45% & 0.94\n",
      "for 2020-07-03, MAE is:5.42 & sMAPE is:14.02% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 26.38% & 0.95\n",
      "for 2020-07-04, MAE is:6.15 & sMAPE is:27.03% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 26.38% & 0.95\n",
      "for 2020-07-05, MAE is:17.72 & sMAPE is:134.76% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 26.96% & 0.95\n",
      "for 2020-07-06, MAE is:3.24 & sMAPE is:13.46% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 26.89% & 0.95\n",
      "for 2020-07-07, MAE is:2.99 & sMAPE is:9.30% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 26.80% & 0.95\n",
      "for 2020-07-08, MAE is:3.50 & sMAPE is:8.45% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 26.70% & 0.95\n",
      "for 2020-07-09, MAE is:2.12 & sMAPE is:5.21% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 26.59% & 0.95\n",
      "for 2020-07-10, MAE is:4.35 & sMAPE is:10.54% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 26.51% & 0.95\n",
      "for 2020-07-11, MAE is:1.95 & sMAPE is:6.59% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 26.40% & 0.94\n",
      "for 2020-07-12, MAE is:4.28 & sMAPE is:18.32% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 26.36% & 0.94\n",
      "for 2020-07-13, MAE is:3.40 & sMAPE is:9.80% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 26.28% & 0.94\n",
      "for 2020-07-14, MAE is:3.91 & sMAPE is:11.05% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 26.20% & 0.94\n",
      "for 2020-07-15, MAE is:4.12 & sMAPE is:10.82% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 26.12% & 0.95\n",
      "for 2020-07-16, MAE is:2.06 & sMAPE is:4.93% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 26.01% & 0.94\n",
      "for 2020-07-17, MAE is:2.49 & sMAPE is:6.59% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 25.92% & 0.95\n",
      "for 2020-07-18, MAE is:2.77 & sMAPE is:9.00% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 25.83% & 0.95\n",
      "for 2020-07-19, MAE is:3.70 & sMAPE is:13.07% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 25.77% & 0.95\n",
      "for 2020-07-20, MAE is:2.45 & sMAPE is:7.17% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 25.68% & 0.96\n",
      "for 2020-07-21, MAE is:4.56 & sMAPE is:11.86% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 25.61% & 0.96\n",
      "for 2020-07-22, MAE is:2.38 & sMAPE is:6.54% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 25.51% & 0.96\n",
      "for 2020-07-23, MAE is:2.91 & sMAPE is:7.47% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 25.43% & 0.96\n",
      "for 2020-07-24, MAE is:6.66 & sMAPE is:17.44% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 25.39% & 0.97\n",
      "for 2020-07-25, MAE is:2.56 & sMAPE is:9.16% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 25.31% & 0.97\n",
      "for 2020-07-26, MAE is:7.74 & sMAPE is:39.09% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 25.37% & 0.97\n",
      "for 2020-07-27, MAE is:4.35 & sMAPE is:12.08% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 25.31% & 0.97\n",
      "for 2020-07-28, MAE is:3.57 & sMAPE is:12.54% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 25.25% & 0.97\n",
      "for 2020-07-29, MAE is:2.51 & sMAPE is:6.83% & rMAE is:2.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 25.16% & 0.98\n",
      "for 2020-07-30, MAE is:3.43 & sMAPE is:8.35% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 25.08% & 0.98\n",
      "for 2020-07-31, MAE is:3.02 & sMAPE is:7.36% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 25.00% & 0.98\n",
      "for 2020-08-01, MAE is:5.14 & sMAPE is:14.38% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 24.95% & 0.98\n",
      "for 2020-08-02, MAE is:2.97 & sMAPE is:9.83% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 24.88% & 0.97\n",
      "for 2020-08-03, MAE is:4.27 & sMAPE is:12.37% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 24.82% & 0.98\n",
      "for 2020-08-04, MAE is:2.81 & sMAPE is:8.22% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 24.75% & 0.98\n",
      "for 2020-08-05, MAE is:3.17 & sMAPE is:9.77% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 24.68% & 0.98\n",
      "for 2020-08-06, MAE is:3.21 & sMAPE is:8.44% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 24.60% & 0.98\n",
      "for 2020-08-07, MAE is:3.13 & sMAPE is:8.05% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 24.53% & 0.97\n",
      "for 2020-08-08, MAE is:3.77 & sMAPE is:10.81% & rMAE is:3.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 24.47% & 0.98\n",
      "for 2020-08-09, MAE is:2.78 & sMAPE is:9.08% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 24.40% & 0.98\n",
      "for 2020-08-10, MAE is:2.69 & sMAPE is:7.17% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 24.32% & 0.99\n",
      "for 2020-08-11, MAE is:2.59 & sMAPE is:6.97% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 24.24% & 0.98\n",
      "for 2020-08-12, MAE is:2.47 & sMAPE is:5.87% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 24.16% & 0.98\n",
      "for 2020-08-13, MAE is:3.63 & sMAPE is:8.89% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 24.09% & 0.98\n",
      "for 2020-08-14, MAE is:3.01 & sMAPE is:7.46% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 24.02% & 0.98\n",
      "for 2020-08-15, MAE is:2.15 & sMAPE is:6.79% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 23.94% & 0.98\n",
      "for 2020-08-16, MAE is:3.80 & sMAPE is:13.32% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 23.90% & 0.99\n",
      "for 2020-08-17, MAE is:6.01 & sMAPE is:15.33% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 23.86% & 0.99\n",
      "for 2020-08-18, MAE is:3.61 & sMAPE is:8.50% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 23.79% & 1.00\n",
      "for 2020-08-19, MAE is:4.14 & sMAPE is:10.46% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 23.74% & 1.00\n",
      "for 2020-08-20, MAE is:4.31 & sMAPE is:11.05% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 23.68% & 1.00\n",
      "for 2020-08-21, MAE is:7.60 & sMAPE is:20.82% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 23.67% & 1.00\n",
      "for 2020-08-22, MAE is:6.33 & sMAPE is:26.40% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 23.68% & 1.00\n",
      "for 2020-08-23, MAE is:5.00 & sMAPE is:25.94% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 23.69% & 1.00\n",
      "for 2020-08-24, MAE is:10.27 & sMAPE is:25.90% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 23.70% & 1.00\n",
      "for 2020-08-25, MAE is:6.61 & sMAPE is:15.10% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 23.66% & 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-08-26, MAE is:7.17 & sMAPE is:23.34% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 23.66% & 1.00\n",
      "for 2020-08-27, MAE is:8.58 & sMAPE is:16.19% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 23.63% & 1.00\n",
      "for 2020-08-28, MAE is:9.07 & sMAPE is:18.76% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 23.61% & 1.00\n",
      "for 2020-08-29, MAE is:3.83 & sMAPE is:10.96% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 23.56% & 1.00\n",
      "for 2020-08-30, MAE is:2.19 & sMAPE is:6.80% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 23.49% & 1.00\n",
      "for 2020-08-31, MAE is:14.16 & sMAPE is:27.42% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 23.51% & 1.00\n",
      "for 2020-09-01, MAE is:4.57 & sMAPE is:9.23% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 23.45% & 1.00\n",
      "for 2020-09-02, MAE is:6.01 & sMAPE is:12.36% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 23.40% & 0.99\n",
      "for 2020-09-03, MAE is:4.04 & sMAPE is:8.70% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 23.34% & 0.99\n",
      "for 2020-09-04, MAE is:4.14 & sMAPE is:9.25% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 23.29% & 0.99\n",
      "for 2020-09-05, MAE is:2.35 & sMAPE is:6.58% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 23.22% & 1.00\n",
      "for 2020-09-06, MAE is:3.81 & sMAPE is:11.32% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 23.17% & 1.00\n",
      "for 2020-09-07, MAE is:5.85 & sMAPE is:13.89% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 23.13% & 1.00\n",
      "for 2020-09-08, MAE is:4.64 & sMAPE is:9.74% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 23.08% & 1.00\n",
      "for 2020-09-09, MAE is:3.66 & sMAPE is:7.56% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 23.02% & 1.00\n",
      "for 2020-09-10, MAE is:4.75 & sMAPE is:8.69% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 22.96% & 1.00\n",
      "for 2020-09-11, MAE is:6.45 & sMAPE is:12.76% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 22.92% & 0.99\n",
      "for 2020-09-12, MAE is:3.32 & sMAPE is:8.13% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 22.87% & 0.99\n",
      "for 2020-09-13, MAE is:2.34 & sMAPE is:6.41% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 22.80% & 1.00\n",
      "for 2020-09-14, MAE is:12.06 & sMAPE is:20.72% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 22.79% & 1.00\n",
      "for 2020-09-15, MAE is:16.74 & sMAPE is:19.58% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 22.78% & 1.00\n",
      "for 2020-09-16, MAE is:16.46 & sMAPE is:24.62% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 22.79% & 1.00\n",
      "for 2020-09-17, MAE is:4.71 & sMAPE is:9.09% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 22.74% & 1.00\n",
      "for 2020-09-18, MAE is:6.78 & sMAPE is:14.24% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 22.70% & 1.00\n",
      "for 2020-09-19, MAE is:2.46 & sMAPE is:6.05% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 22.64% & 1.00\n",
      "for 2020-09-20, MAE is:2.88 & sMAPE is:7.76% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 22.58% & 1.00\n",
      "for 2020-09-21, MAE is:18.36 & sMAPE is:26.05% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 22.60% & 1.01\n",
      "for 2020-09-22, MAE is:8.21 & sMAPE is:14.10% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 22.57% & 1.00\n",
      "for 2020-09-23, MAE is:3.65 & sMAPE is:7.47% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 22.51% & 1.00\n",
      "for 2020-09-24, MAE is:4.30 & sMAPE is:9.97% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 22.46% & 1.00\n",
      "for 2020-09-25, MAE is:5.03 & sMAPE is:12.12% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 22.42% & 1.00\n",
      "for 2020-09-26, MAE is:2.87 & sMAPE is:8.51% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 22.37% & 1.00\n",
      "for 2020-09-27, MAE is:6.23 & sMAPE is:22.62% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 22.37% & 1.00\n",
      "for 2020-09-28, MAE is:7.43 & sMAPE is:18.56% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 22.36% & 1.00\n",
      "for 2020-09-29, MAE is:12.74 & sMAPE is:21.14% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 22.35% & 1.00\n",
      "for 2020-09-30, MAE is:6.82 & sMAPE is:13.60% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 22.32% & 1.00\n",
      "for 2020-10-01, MAE is:4.09 & sMAPE is:9.52% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 22.28% & 1.00\n",
      "for 2020-10-02, MAE is:4.91 & sMAPE is:13.60% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 22.24% & 1.00\n",
      "for 2020-10-03, MAE is:4.43 & sMAPE is:16.41% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 22.22% & 1.01\n",
      "for 2020-10-04, MAE is:12.08 & sMAPE is:66.94% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 22.38% & 1.01\n",
      "for 2020-10-05, MAE is:6.19 & sMAPE is:26.68% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 22.40% & 1.00\n",
      "for 2020-10-06, MAE is:4.31 & sMAPE is:14.37% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 22.37% & 1.00\n",
      "for 2020-10-07, MAE is:5.06 & sMAPE is:13.70% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 22.34% & 1.00\n",
      "for 2020-10-08, MAE is:4.84 & sMAPE is:12.93% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 22.31% & 1.00\n",
      "for 2020-10-09, MAE is:5.00 & sMAPE is:11.89% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 22.27% & 1.00\n",
      "for 2020-10-10, MAE is:2.94 & sMAPE is:8.94% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 22.22% & 1.00\n",
      "for 2020-10-11, MAE is:2.85 & sMAPE is:8.58% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 22.18% & 0.99\n",
      "for 2020-10-12, MAE is:6.59 & sMAPE is:13.95% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 22.15% & 0.99\n",
      "for 2020-10-13, MAE is:5.31 & sMAPE is:11.41% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 22.11% & 0.99\n",
      "for 2020-10-14, MAE is:5.29 & sMAPE is:12.07% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 22.07% & 0.99\n",
      "for 2020-10-15, MAE is:2.94 & sMAPE is:7.16% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 22.02% & 0.99\n",
      "for 2020-10-16, MAE is:4.80 & sMAPE is:9.90% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 21.98% & 0.99\n",
      "for 2020-10-17, MAE is:3.71 & sMAPE is:9.55% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 21.94% & 0.99\n",
      "for 2020-10-18, MAE is:3.85 & sMAPE is:10.61% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 21.90% & 0.98\n",
      "for 2020-10-19, MAE is:6.53 & sMAPE is:14.39% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 21.87% & 0.98\n",
      "for 2020-10-20, MAE is:3.56 & sMAPE is:9.21% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 21.83% & 0.98\n",
      "for 2020-10-21, MAE is:4.87 & sMAPE is:12.58% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 21.80% & 0.98\n",
      "for 2020-10-22, MAE is:3.34 & sMAPE is:8.47% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 21.75% & 0.98\n",
      "for 2020-10-23, MAE is:4.93 & sMAPE is:10.95% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 21.72% & 0.99\n",
      "for 2020-10-24, MAE is:5.40 & sMAPE is:17.39% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 21.70% & 0.98\n",
      "for 2020-10-25, MAE is:11.07 & sMAPE is:81.02% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 21.90% & 0.98\n",
      "for 2020-10-26, MAE is:4.83 & sMAPE is:14.55% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 21.88% & 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-10-27, MAE is:4.02 & sMAPE is:10.67% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 21.84% & 0.98\n",
      "for 2020-10-28, MAE is:5.62 & sMAPE is:15.65% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 21.82% & 0.98\n",
      "for 2020-10-29, MAE is:6.50 & sMAPE is:21.56% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 21.82% & 0.98\n",
      "for 2020-10-30, MAE is:6.04 & sMAPE is:26.32% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 21.83% & 0.98\n",
      "for 2020-10-31, MAE is:4.88 & sMAPE is:16.08% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 21.81% & 0.98\n",
      "for 2020-11-01, MAE is:6.60 & sMAPE is:43.83% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 21.89% & 0.98\n",
      "for 2020-11-02, MAE is:7.35 & sMAPE is:58.06% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 22.00% & 0.98\n",
      "for 2020-11-03, MAE is:3.75 & sMAPE is:11.18% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 21.97% & 0.98\n",
      "for 2020-11-04, MAE is:4.72 & sMAPE is:11.51% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 21.94% & 0.98\n",
      "for 2020-11-05, MAE is:4.05 & sMAPE is:10.31% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 21.90% & 0.98\n",
      "for 2020-11-06, MAE is:4.91 & sMAPE is:12.87% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 21.87% & 0.98\n",
      "for 2020-11-07, MAE is:5.44 & sMAPE is:16.61% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 21.85% & 0.98\n",
      "for 2020-11-08, MAE is:3.01 & sMAPE is:9.03% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 21.81% & 0.97\n",
      "for 2020-11-09, MAE is:5.27 & sMAPE is:13.96% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 21.79% & 0.97\n",
      "for 2020-11-10, MAE is:5.97 & sMAPE is:13.41% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 21.76% & 0.97\n",
      "for 2020-11-11, MAE is:4.68 & sMAPE is:12.35% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 21.73% & 0.97\n",
      "for 2020-11-12, MAE is:4.61 & sMAPE is:12.15% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 21.70% & 0.97\n",
      "for 2020-11-13, MAE is:4.85 & sMAPE is:12.31% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 21.67% & 0.98\n",
      "for 2020-11-14, MAE is:6.23 & sMAPE is:18.25% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 21.66% & 0.98\n",
      "for 2020-11-15, MAE is:12.11 & sMAPE is:82.85% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 21.85% & 0.98\n",
      "for 2020-11-16, MAE is:10.59 & sMAPE is:67.42% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 21.99% & 0.98\n",
      "for 2020-11-17, MAE is:7.30 & sMAPE is:20.47% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 21.99% & 0.98\n",
      "for 2020-11-18, MAE is:3.97 & sMAPE is:10.04% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 21.95% & 0.98\n",
      "for 2020-11-19, MAE is:6.51 & sMAPE is:26.52% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 21.96% & 0.98\n",
      "for 2020-11-20, MAE is:5.52 & sMAPE is:13.56% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 21.94% & 0.98\n",
      "for 2020-11-21, MAE is:2.42 & sMAPE is:6.20% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 21.89% & 0.98\n",
      "for 2020-11-22, MAE is:3.37 & sMAPE is:9.23% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 21.85% & 0.97\n",
      "for 2020-11-23, MAE is:4.89 & sMAPE is:10.98% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 21.82% & 0.97\n",
      "for 2020-11-24, MAE is:3.59 & sMAPE is:7.47% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 21.77% & 0.97\n",
      "for 2020-11-25, MAE is:4.42 & sMAPE is:9.74% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 21.74% & 0.97\n",
      "for 2020-11-26, MAE is:9.38 & sMAPE is:17.76% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 21.73% & 0.97\n",
      "for 2020-11-27, MAE is:8.62 & sMAPE is:14.48% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 21.70% & 0.97\n",
      "for 2020-11-28, MAE is:3.88 & sMAPE is:8.71% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 21.67% & 0.97\n",
      "for 2020-11-29, MAE is:2.80 & sMAPE is:6.31% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 21.62% & 0.96\n",
      "for 2020-11-30, MAE is:5.82 & sMAPE is:10.55% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 21.59% & 0.96\n",
      "for 2020-12-01, MAE is:5.62 & sMAPE is:9.87% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 21.55% & 0.96\n",
      "for 2020-12-02, MAE is:19.74 & sMAPE is:26.81% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 21.57% & 0.96\n",
      "for 2020-12-03, MAE is:9.32 & sMAPE is:16.08% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 21.55% & 0.96\n",
      "for 2020-12-04, MAE is:5.67 & sMAPE is:12.13% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 21.52% & 0.96\n",
      "for 2020-12-05, MAE is:3.43 & sMAPE is:6.71% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 21.48% & 0.96\n",
      "for 2020-12-06, MAE is:3.36 & sMAPE is:7.33% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 21.44% & 0.96\n",
      "for 2020-12-07, MAE is:9.48 & sMAPE is:15.76% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 21.42% & 0.96\n",
      "for 2020-12-08, MAE is:11.44 & sMAPE is:16.59% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 21.41% & 0.96\n",
      "for 2020-12-09, MAE is:22.85 & sMAPE is:29.66% & rMAE is:3.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 21.43% & 0.97\n",
      "for 2020-12-10, MAE is:16.37 & sMAPE is:23.02% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 21.44% & 0.97\n",
      "for 2020-12-11, MAE is:3.62 & sMAPE is:7.37% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 21.40% & 0.97\n",
      "for 2020-12-12, MAE is:2.67 & sMAPE is:5.72% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 21.35% & 0.97\n",
      "for 2020-12-13, MAE is:2.56 & sMAPE is:6.04% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 21.31% & 0.97\n",
      "for 2020-12-14, MAE is:3.59 & sMAPE is:8.50% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 21.27% & 0.96\n",
      "for 2020-12-15, MAE is:4.46 & sMAPE is:8.89% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 21.23% & 0.96\n",
      "for 2020-12-16, MAE is:3.86 & sMAPE is:7.18% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 21.19% & 0.96\n",
      "for 2020-12-17, MAE is:3.60 & sMAPE is:6.78% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 21.15% & 0.96\n",
      "for 2020-12-18, MAE is:6.63 & sMAPE is:13.00% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 21.13% & 0.96\n",
      "for 2020-12-19, MAE is:4.40 & sMAPE is:11.19% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 21.10% & 0.96\n",
      "for 2020-12-20, MAE is:2.14 & sMAPE is:5.18% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 21.06% & 0.96\n",
      "for 2020-12-21, MAE is:4.25 & sMAPE is:10.38% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 21.03% & 0.96\n",
      "for 2020-12-22, MAE is:8.76 & sMAPE is:44.52% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 21.09% & 0.95\n",
      "for 2020-12-23, MAE is:8.60 & sMAPE is:23.46% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 21.10% & 0.95\n",
      "for 2020-12-24, MAE is:7.69 & sMAPE is:44.11% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 21.16% & 0.95\n",
      "for 2020-12-25, MAE is:8.72 & sMAPE is:35.11% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 21.20% & 0.95\n",
      "for 2020-12-26, MAE is:10.07 & sMAPE is:29.00% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 21.22% & 0.95\n",
      "for 2020-12-27, MAE is:12.15 & sMAPE is:75.82% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 21.37% & 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-12-28, MAE is:10.12 & sMAPE is:27.33% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 21.39% & 0.95\n",
      "for 2020-12-29, MAE is:5.66 & sMAPE is:12.66% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 21.37% & 0.95\n",
      "for 2020-12-30, MAE is:3.79 & sMAPE is:7.87% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 21.33% & 0.95\n",
      "for 2020-12-31, MAE is:3.43 & sMAPE is:7.25% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 21.29% & 0.95\n",
      "CPU times: total: 10h 42min 29s\n",
      "Wall time: 4h 29min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "large_scale_predictor(zone, first_year=2020, last_year=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
