{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = ['BE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.2 - (Calib Year = 3)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:51:09,695]\u001b[0m A new study created in RDB with name: BE_2018\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:51:43,025]\u001b[0m Trial 1 finished with value: 7.048610935659604 and parameters: {'n_hidden': 3, 'learning_rate': 0.009089717644687741, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3281140275713411, 'dropout_rate_Layer_2': 0.11954337480945938, 'dropout_rate_Layer_3': 0.364032043955859, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6232904320459115e-05, 'l1_Layer_2': 5.044382570423294e-05, 'l1_Layer_3': 0.0011756062598454135, 'n_units_Layer_1': 120, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125}. Best is trial 1 with value: 7.048610935659604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 16.03% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 9.86 | sMAPE for Test Set is: 17.91% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:51:48,643]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:51:53,221]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:51:56,780]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.67 | sMAPE for Validation Set is: 17.19% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 11.85 | sMAPE for Test Set is: 21.84% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:52:01,058]\u001b[0m Trial 3 finished with value: 7.66769261146169 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016896405106379294, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03141304395958451, 'dropout_rate_Layer_2': 0.3918227104817411, 'dropout_rate_Layer_3': 0.04246646896914639, 'dropout_rate_Layer_4': 0.3536696633578362, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.0899650404583778e-05, 'l1_Layer_2': 0.006110646083293594, 'l1_Layer_3': 3.811757261995904e-05, 'l1_Layer_4': 0.0006735796052906772, 'n_units_Layer_1': 240, 'n_units_Layer_2': 225, 'n_units_Layer_3': 100, 'n_units_Layer_4': 245}. Best is trial 1 with value: 7.048610935659604.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:52:04,410]\u001b[0m Trial 0 finished with value: 8.010888421371218 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006172842214264547, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20887591460687413, 'dropout_rate_Layer_2': 0.27398368205752904, 'dropout_rate_Layer_3': 0.15077197342364937, 'dropout_rate_Layer_4': 0.18503303320326517, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.024158647172266776, 'l1_Layer_2': 0.015241457387238647, 'l1_Layer_3': 0.00019183095303908457, 'l1_Layer_4': 1.72016337252878e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 245, 'n_units_Layer_3': 240, 'n_units_Layer_4': 115}. Best is trial 1 with value: 7.048610935659604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.01 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 10.35 | sMAPE for Test Set is: 18.69% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:52:04,844]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:52:10,869]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:52:13,552]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:52:15,539]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:52:19,736]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:52:22,111]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:52:24,646]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:52:29,407]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:52:45,024]\u001b[0m Trial 2 finished with value: 7.882459298441087 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005848756019786946, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015678532173751283, 'dropout_rate_Layer_2': 0.329698728362234, 'dropout_rate_Layer_3': 0.2066298947389419, 'dropout_rate_Layer_4': 0.013524925278382628, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0833892210292573e-05, 'l1_Layer_2': 0.06226355005341182, 'l1_Layer_3': 0.019810251069614232, 'l1_Layer_4': 2.1053460299710955e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 70, 'n_units_Layer_3': 120, 'n_units_Layer_4': 230}. Best is trial 1 with value: 7.048610935659604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.88 | sMAPE for Validation Set is: 17.03% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 10.51 | sMAPE for Test Set is: 19.09% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:52:45,798]\u001b[0m Trial 7 finished with value: 6.847159621755504 and parameters: {'n_hidden': 4, 'learning_rate': 0.003823167191732905, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2054366390019375, 'dropout_rate_Layer_2': 0.12593248588778302, 'dropout_rate_Layer_3': 0.2251740637328964, 'dropout_rate_Layer_4': 0.19481124485077334, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.093442977163231e-05, 'l1_Layer_2': 0.0001235009529238578, 'l1_Layer_3': 0.0013431897663375208, 'l1_Layer_4': 6.157025518856549e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 240, 'n_units_Layer_3': 85, 'n_units_Layer_4': 65}. Best is trial 7 with value: 6.847159621755504.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 15.21% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 9.78 | sMAPE for Test Set is: 17.98% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:52:52,029]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:52:54,579]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:52:58,228]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:04,211]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:04,521]\u001b[0m Trial 19 finished with value: 11.846761193142259 and parameters: {'n_hidden': 4, 'learning_rate': 0.049482669322545234, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02903275015387794, 'dropout_rate_Layer_2': 0.21882997069050292, 'dropout_rate_Layer_3': 0.019456888089238823, 'dropout_rate_Layer_4': 0.23061805423226125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.3941089090994618e-05, 'l1_Layer_2': 0.017171860676653068, 'l1_Layer_3': 0.0031315801687061716, 'l1_Layer_4': 0.007924515936794838, 'n_units_Layer_1': 120, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125, 'n_units_Layer_4': 245}. Best is trial 7 with value: 6.847159621755504.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.85 | sMAPE for Validation Set is: 25.67% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 19.19 | sMAPE for Test Set is: 37.71% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:53:09,789]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:10,428]\u001b[0m Trial 15 finished with value: 6.666401457950833 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008457083889752528, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23119757643142935, 'dropout_rate_Layer_2': 0.28438693055038083, 'dropout_rate_Layer_3': 0.343477123911774, 'dropout_rate_Layer_4': 0.05878107573928455, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003049952228981279, 'l1_Layer_2': 6.883045377565426e-05, 'l1_Layer_3': 0.00010356922646846995, 'l1_Layer_4': 0.019471315185353198, 'n_units_Layer_1': 150, 'n_units_Layer_2': 215, 'n_units_Layer_3': 240, 'n_units_Layer_4': 140}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 15.13% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.73 | sMAPE for Test Set is: 15.99% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:53:16,976]\u001b[0m Trial 21 finished with value: 8.213464350118763 and parameters: {'n_hidden': 3, 'learning_rate': 0.08875441070027465, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029930956449807634, 'dropout_rate_Layer_2': 0.056208488475314726, 'dropout_rate_Layer_3': 0.18739135646113386, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0010245313966112805, 'l1_Layer_2': 0.0006113370410226696, 'l1_Layer_3': 4.256803502958629e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 85, 'n_units_Layer_3': 295}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.21 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 11.14 | sMAPE for Test Set is: 20.08% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:53:18,441]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:19,544]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:21,849]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:28,957]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:33,866]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:34,935]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.75 | sMAPE for Validation Set is: 27.50% | rMAE for Validation Set is: 1.31\n",
      "MAE for Test Set is: 19.31 | sMAPE for Test Set is: 37.48% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:53:37,915]\u001b[0m Trial 27 finished with value: 12.753254501442226 and parameters: {'n_hidden': 4, 'learning_rate': 0.03469783774437372, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23118804618860325, 'dropout_rate_Layer_2': 0.10025239444210428, 'dropout_rate_Layer_3': 0.1957180282657122, 'dropout_rate_Layer_4': 0.25668668505677944, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00021823819212175502, 'l1_Layer_2': 1.6194675202597383e-05, 'l1_Layer_3': 0.0032549776375827883, 'l1_Layer_4': 0.00384007212825218, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230, 'n_units_Layer_4': 80}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:40,062]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:45,150]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:48,373]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:50,803]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:53:54,177]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:54:00,350]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:54:10,220]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:54:15,601]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:54:15,968]\u001b[0m Trial 39 finished with value: 12.79466653331032 and parameters: {'n_hidden': 3, 'learning_rate': 0.011773251803356491, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3414311420415289, 'dropout_rate_Layer_2': 0.23644657553595183, 'dropout_rate_Layer_3': 0.1936818655688589, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.013485910070938266, 'l1_Layer_2': 0.006967485265171115, 'l1_Layer_3': 0.0775110945786844, 'n_units_Layer_1': 255, 'n_units_Layer_2': 165, 'n_units_Layer_3': 85}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.79 | sMAPE for Validation Set is: 27.67% | rMAE for Validation Set is: 1.31\n",
      "MAE for Test Set is: 19.73 | sMAPE for Test Set is: 38.55% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:54:22,491]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:54:22,927]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.36 | sMAPE for Validation Set is: 16.39% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 9.15 | sMAPE for Test Set is: 16.74% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:54:25,719]\u001b[0m Trial 33 finished with value: 7.357280811473202 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012470065665025755, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09602144309524925, 'dropout_rate_Layer_2': 0.17884651960725995, 'dropout_rate_Layer_3': 0.16825710132990146, 'dropout_rate_Layer_4': 0.21477005271990054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008830178298475663, 'l1_Layer_2': 1.6264482402079958e-05, 'l1_Layer_3': 0.07789030056782646, 'l1_Layer_4': 2.8225229921172245e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 190, 'n_units_Layer_3': 280, 'n_units_Layer_4': 110}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:54:37,830]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:54:43,223]\u001b[0m Trial 28 finished with value: 6.894354237719843 and parameters: {'n_hidden': 4, 'learning_rate': 0.006533655771482822, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17810734208834075, 'dropout_rate_Layer_2': 0.3107334774103086, 'dropout_rate_Layer_3': 0.058015774104333895, 'dropout_rate_Layer_4': 0.04070354587432323, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008625595137344143, 'l1_Layer_2': 0.0001341302954073568, 'l1_Layer_3': 0.0002756742630988881, 'l1_Layer_4': 0.0003532243693783085, 'n_units_Layer_1': 90, 'n_units_Layer_2': 140, 'n_units_Layer_3': 215, 'n_units_Layer_4': 60}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 15.36% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.08 | sMAPE for Test Set is: 18.50% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:54:47,904]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:54:58,963]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:03,555]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:08,465]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:12,550]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:17,044]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:17,691]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:23,852]\u001b[0m Trial 44 finished with value: 7.018154458964115 and parameters: {'n_hidden': 3, 'learning_rate': 0.022913843944688428, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39729497012226006, 'dropout_rate_Layer_2': 0.10554330967543013, 'dropout_rate_Layer_3': 0.14383875880532063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022824272972153847, 'l1_Layer_2': 0.001649599001666412, 'l1_Layer_3': 1.3217060931604213e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 235, 'n_units_Layer_3': 250}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.02 | sMAPE for Validation Set is: 15.52% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 9.94 | sMAPE for Test Set is: 18.12% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:55:27,871]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:35,608]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:39,202]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:40,689]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:48,982]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:52,867]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:53,193]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:59,027]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:55:59,563]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:03,730]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:07,876]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:10,121]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:10,924]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:15,847]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:19,724]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:23,831]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:26,788]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:27,494]\u001b[0m Trial 56 finished with value: 6.682992508948627 and parameters: {'n_hidden': 4, 'learning_rate': 0.002039182588491349, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3767485451707619, 'dropout_rate_Layer_2': 0.0404598766572867, 'dropout_rate_Layer_3': 0.3038150524299095, 'dropout_rate_Layer_4': 0.14216970752082192, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002602439142934865, 'l1_Layer_2': 2.2476790899256297e-05, 'l1_Layer_3': 1.985770673707796e-05, 'l1_Layer_4': 0.016365617058790822, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 125, 'n_units_Layer_4': 115}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.68 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.45 | sMAPE for Test Set is: 15.52% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:56:27,916]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:27,947]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:32,551]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:37,135]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:40,030]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:41,592]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:48,796]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:48,910]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:49,065]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:56:53,238]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:01,394]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:03,118]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:08,048]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:10,148]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:12,011]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:17,613]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:17,802]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:37,364]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:42,323]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:47,120]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:53,529]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:54,030]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:57:59,626]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:58:05,669]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:58:13,195]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:58:19,374]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:58:21,378]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:58:28,786]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:58:34,563]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:58:37,758]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:58:44,869]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:58:49,009]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:59:14,424]\u001b[0m Trial 106 finished with value: 6.833528331471556 and parameters: {'n_hidden': 4, 'learning_rate': 0.007541466880133171, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0388739684485048, 'dropout_rate_Layer_2': 0.1597184785332207, 'dropout_rate_Layer_3': 0.38019779594672964, 'dropout_rate_Layer_4': 0.24231660899851204, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.28703530326351e-05, 'l1_Layer_2': 3.688883758411532e-05, 'l1_Layer_3': 0.010032935278390592, 'l1_Layer_4': 0.0007924822616381404, 'n_units_Layer_1': 110, 'n_units_Layer_2': 150, 'n_units_Layer_3': 160, 'n_units_Layer_4': 225}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 15.71% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 9.20 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:59:22,783]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:59:28,226]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:59:29,074]\u001b[0m Trial 91 finished with value: 6.80587809798882 and parameters: {'n_hidden': 4, 'learning_rate': 0.006488366160394323, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1693672299215906, 'dropout_rate_Layer_2': 0.20800221585162584, 'dropout_rate_Layer_3': 0.15032544591248312, 'dropout_rate_Layer_4': 0.17084203127299588, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.374376917691241e-05, 'l1_Layer_2': 0.0012736101087577737, 'l1_Layer_3': 0.0006101850317274589, 'l1_Layer_4': 0.00035384393714311464, 'n_units_Layer_1': 150, 'n_units_Layer_2': 160, 'n_units_Layer_3': 125, 'n_units_Layer_4': 190}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 15.30% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 9.33 | sMAPE for Test Set is: 17.15% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 18:59:34,205]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:59:38,386]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:59:42,476]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:59:43,726]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:59:48,460]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:59:53,036]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 18:59:57,323]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:02,811]\u001b[0m Trial 88 finished with value: 7.067372156903286 and parameters: {'n_hidden': 3, 'learning_rate': 0.003170138522405455, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20863439275639517, 'dropout_rate_Layer_2': 0.10075628007622175, 'dropout_rate_Layer_3': 0.22454924860067205, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0183031176918113e-05, 'l1_Layer_2': 0.00019647326736518282, 'l1_Layer_3': 0.00043279793885714037, 'n_units_Layer_1': 190, 'n_units_Layer_2': 225, 'n_units_Layer_3': 150}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:02,838]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.07 | sMAPE for Validation Set is: 15.85% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 9.20 | sMAPE for Test Set is: 16.71% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:00:13,202]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:20,253]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:24,345]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:24,760]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:33,948]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:38,091]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:38,520]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:38,632]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:44,517]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:46,233]\u001b[0m Trial 114 finished with value: 6.762086187403518 and parameters: {'n_hidden': 3, 'learning_rate': 0.006667697967771413, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2572578866330581, 'dropout_rate_Layer_2': 0.10946676729354682, 'dropout_rate_Layer_3': 0.17714303620284003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00017499948475048908, 'l1_Layer_2': 0.000518668269645184, 'l1_Layer_3': 1.5688699397220165e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 250, 'n_units_Layer_3': 125}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 15.15% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.63 | sMAPE for Test Set is: 17.78% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:00:51,215]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:53,760]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:54,947]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:57,289]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:00:58,062]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:01:06,240]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:01:07,332]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:01:10,901]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:01:16,396]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:01:23,334]\u001b[0m Trial 133 finished with value: 12.680868038882535 and parameters: {'n_hidden': 4, 'learning_rate': 0.005487616362425039, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19191093153573655, 'dropout_rate_Layer_2': 0.2630118640797604, 'dropout_rate_Layer_3': 0.2465716362935635, 'dropout_rate_Layer_4': 0.08943658324692438, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0041636044523906054, 'l1_Layer_2': 0.08493718991241107, 'l1_Layer_3': 3.558786022815172e-05, 'l1_Layer_4': 0.0005329698014842792, 'n_units_Layer_1': 255, 'n_units_Layer_2': 75, 'n_units_Layer_3': 285, 'n_units_Layer_4': 180}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.68 | sMAPE for Validation Set is: 27.22% | rMAE for Validation Set is: 1.30\n",
      "MAE for Test Set is: 18.92 | sMAPE for Test Set is: 36.41% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:01:27,060]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:01:32,257]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:01:41,656]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:01:43,631]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:01:46,724]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:01:52,824]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:01:54,519]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:01:59,475]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:02:03,881]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:02:08,337]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:02:13,548]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:02:18,697]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:02:24,852]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:02:31,021]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:02:34,690]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:02:38,772]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:02:43,333]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:02:46,295]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:02:49,458]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:02:58,275]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:01,192]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:06,333]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:13,572]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:17,024]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:17,106]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:19,529]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:23,666]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:25,567]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:28,140]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:40,656]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:47,571]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:50,766]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:57,318]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:03:57,679]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:04:02,948]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:04:10,173]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:04:39,714]\u001b[0m Trial 174 finished with value: 7.948285131356793 and parameters: {'n_hidden': 3, 'learning_rate': 0.03322650370383919, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39985080764648206, 'dropout_rate_Layer_2': 0.05756343600670439, 'dropout_rate_Layer_3': 0.15713266714615362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021899278251412513, 'l1_Layer_2': 0.0013380428914133975, 'l1_Layer_3': 1.083818493888649e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 195, 'n_units_Layer_3': 220}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.95 | sMAPE for Validation Set is: 17.21% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 10.11 | sMAPE for Test Set is: 18.25% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:04:39,889]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:04:40,412]\u001b[0m Trial 164 finished with value: 7.373404339847174 and parameters: {'n_hidden': 4, 'learning_rate': 0.008297159510230342, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3515704937004503, 'dropout_rate_Layer_2': 0.2001203347648305, 'dropout_rate_Layer_3': 0.10011109326428715, 'dropout_rate_Layer_4': 0.09424911603222826, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.7265721505597385e-05, 'l1_Layer_2': 8.994628829266959e-05, 'l1_Layer_3': 0.023029940924082632, 'l1_Layer_4': 0.001457835386694839, 'n_units_Layer_1': 255, 'n_units_Layer_2': 195, 'n_units_Layer_3': 105, 'n_units_Layer_4': 70}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.37 | sMAPE for Validation Set is: 16.13% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 10.31 | sMAPE for Test Set is: 18.80% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:05:00,469]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:05:04,964]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:05:05,151]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:05:13,026]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:05:15,026]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:05:16,879]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:05:22,011]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:05:29,436]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:05:33,837]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:05:37,549]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:05:41,090]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:05:44,239]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:05:52,066]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:06:01,624]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:06:05,205]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:06:11,211]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:06:17,929]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:06:23,742]\u001b[0m Trial 189 finished with value: 7.7270582468682845 and parameters: {'n_hidden': 4, 'learning_rate': 0.018168561503969095, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3988765926862524, 'dropout_rate_Layer_2': 0.2961868220350761, 'dropout_rate_Layer_3': 0.33745132621719026, 'dropout_rate_Layer_4': 0.08924592932813774, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00019346133326410308, 'l1_Layer_2': 2.5814751983929374e-05, 'l1_Layer_3': 0.012946723986474389, 'l1_Layer_4': 0.004942162312206707, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 240, 'n_units_Layer_4': 75}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.73 | sMAPE for Validation Set is: 16.82% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 19.41% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:06:33,087]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:06:37,426]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:06:42,733]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:06:55,060]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:06:55,277]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:07:02,888]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:07:03,020]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:07:13,368]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:07:24,306]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:07:30,878]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:07:37,571]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:07:39,815]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:07:47,210]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:07:52,844]\u001b[0m Trial 208 finished with value: 12.977701449403106 and parameters: {'n_hidden': 3, 'learning_rate': 0.04921729190105717, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2138487406321255, 'dropout_rate_Layer_2': 0.24054869755739783, 'dropout_rate_Layer_3': 0.2177321327437114, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0017981607781482733, 'l1_Layer_2': 0.0003664641617232549, 'l1_Layer_3': 6.300464353071467e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 220, 'n_units_Layer_3': 65}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.98 | sMAPE for Validation Set is: 28.30% | rMAE for Validation Set is: 1.33\n",
      "MAE for Test Set is: 20.71 | sMAPE for Test Set is: 41.10% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:07:54,605]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:08:02,418]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:08:08,989]\u001b[0m Trial 198 finished with value: 7.089175896791107 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006411573138755111, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24366476483379484, 'dropout_rate_Layer_2': 0.037033147342316, 'dropout_rate_Layer_3': 0.025831276336356873, 'dropout_rate_Layer_4': 0.10250264551531987, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.3180668946381996e-05, 'l1_Layer_2': 9.663191811795864e-05, 'l1_Layer_3': 0.00021867215406658384, 'l1_Layer_4': 3.1314169552141314e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 220, 'n_units_Layer_3': 105, 'n_units_Layer_4': 95}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 15.64% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 19.39% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:08:11,207]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:08:15,180]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:08:18,109]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:08:30,417]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:08:33,758]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:08:38,550]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:08:48,312]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:08:58,343]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:09:01,327]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:09:01,475]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:09:10,274]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:09:14,083]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:09:14,137]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:09:21,435]\u001b[0m Trial 205 finished with value: 6.8929712807532795 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005487079321776589, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2236540729573267, 'dropout_rate_Layer_2': 0.015169705370074182, 'dropout_rate_Layer_3': 0.11371540123446494, 'dropout_rate_Layer_4': 0.2133724784177314, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.2360894080056338e-05, 'l1_Layer_2': 7.56365244865466e-05, 'l1_Layer_3': 7.534884086590354e-05, 'l1_Layer_4': 1.2419238759802828e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 210, 'n_units_Layer_3': 105, 'n_units_Layer_4': 95}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 15.55% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.10 | sMAPE for Test Set is: 18.73% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:09:27,470]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:09:27,981]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:09:40,997]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:09:41,511]\u001b[0m Trial 227 finished with value: 8.354787980440165 and parameters: {'n_hidden': 4, 'learning_rate': 0.01952530500129241, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02135814984337196, 'dropout_rate_Layer_2': 0.06489802554805124, 'dropout_rate_Layer_3': 0.0003527334701564633, 'dropout_rate_Layer_4': 0.036221551313844455, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006105494389901997, 'l1_Layer_2': 0.0007569792806381608, 'l1_Layer_3': 3.0014450284719485e-05, 'l1_Layer_4': 0.0001808838116342671, 'n_units_Layer_1': 55, 'n_units_Layer_2': 200, 'n_units_Layer_3': 100, 'n_units_Layer_4': 215}. Best is trial 15 with value: 6.666401457950833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 10.98 | sMAPE for Test Set is: 20.28% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:09:48,227]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:09:53,551]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:10:08,242]\u001b[0m Trial 224 finished with value: 6.40148307949471 and parameters: {'n_hidden': 3, 'learning_rate': 0.0068693209501517775, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13434231262887986, 'dropout_rate_Layer_2': 0.2684420264059764, 'dropout_rate_Layer_3': 0.10448015619715903, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.91517152801263e-05, 'l1_Layer_2': 0.0006453303855659384, 'l1_Layer_3': 0.00030225264918655855, 'n_units_Layer_1': 170, 'n_units_Layer_2': 230, 'n_units_Layer_3': 140}. Best is trial 224 with value: 6.40148307949471.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.92 | sMAPE for Test Set is: 16.42% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:10:14,519]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:10:25,308]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:10:27,939]\u001b[0m Trial 235 finished with value: 8.127224144473866 and parameters: {'n_hidden': 4, 'learning_rate': 0.030991875087652318, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3672285249402971, 'dropout_rate_Layer_2': 0.3256592586784769, 'dropout_rate_Layer_3': 0.27818441472450484, 'dropout_rate_Layer_4': 0.021994198192533537, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.940482205141605e-05, 'l1_Layer_2': 6.611079480402722e-05, 'l1_Layer_3': 0.004387009148870011, 'l1_Layer_4': 0.00034676975570562506, 'n_units_Layer_1': 255, 'n_units_Layer_2': 230, 'n_units_Layer_3': 200, 'n_units_Layer_4': 190}. Best is trial 224 with value: 6.40148307949471.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.13 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 10.68 | sMAPE for Test Set is: 19.38% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:10:31,276]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:10:32,225]\u001b[0m Trial 232 finished with value: 6.383628461396451 and parameters: {'n_hidden': 3, 'learning_rate': 0.006425087109384647, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0022514479961156797, 'dropout_rate_Layer_2': 0.2647658509885075, 'dropout_rate_Layer_3': 0.21757531024016674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.512589368403017e-05, 'l1_Layer_2': 0.0006654852415928531, 'l1_Layer_3': 0.00033290655496936083, 'n_units_Layer_1': 85, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 232 with value: 6.383628461396451.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.73 | sMAPE for Test Set is: 15.89% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:10:33,685]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:10:42,422]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:10:45,153]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:10:45,241]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:10:54,175]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:10:54,379]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:11:06,956]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:11:07,182]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.43 | sMAPE for Test Set is: 15.50% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:11:13,465]\u001b[0m Trial 241 finished with value: 6.322800703634762 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034870012564894195, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08848976898650068, 'dropout_rate_Layer_2': 0.14428028191924652, 'dropout_rate_Layer_3': 0.32491009939670606, 'dropout_rate_Layer_4': 0.2630015401584023, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.276416166118424e-05, 'l1_Layer_2': 3.6523779143853245e-05, 'l1_Layer_3': 0.001663511787228869, 'l1_Layer_4': 1.812420562561888e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 195, 'n_units_Layer_4': 240}. Best is trial 241 with value: 6.322800703634762.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:11:17,677]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:11:18,311]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:11:20,940]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:11:30,702]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:11:34,469]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:11:43,614]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:11:50,859]\u001b[0m Trial 250 finished with value: 6.381951024399124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024807354195447422, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052309752281860813, 'dropout_rate_Layer_2': 0.3550652517153425, 'dropout_rate_Layer_3': 0.04033155633384286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.350873286131996e-05, 'l1_Layer_2': 0.0005652645998857425, 'l1_Layer_3': 0.0019326336287687786, 'n_units_Layer_1': 245, 'n_units_Layer_2': 220, 'n_units_Layer_3': 140}. Best is trial 241 with value: 6.322800703634762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.94 | sMAPE for Test Set is: 14.47% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:12:00,207]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:12:03,081]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:12:05,060]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:12:09,899]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:12:09,974]\u001b[0m Trial 249 finished with value: 6.6948006774016156 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010812181706205887, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16648801109987052, 'dropout_rate_Layer_2': 0.009419249497565924, 'dropout_rate_Layer_3': 0.13289666546285886, 'dropout_rate_Layer_4': 0.14044493830031848, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4259529513351164e-05, 'l1_Layer_2': 0.00012911289685969815, 'l1_Layer_3': 0.00022403514554679083, 'l1_Layer_4': 0.0001127963129501334, 'n_units_Layer_1': 215, 'n_units_Layer_2': 205, 'n_units_Layer_3': 130, 'n_units_Layer_4': 55}. Best is trial 241 with value: 6.322800703634762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.69 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.09 | sMAPE for Test Set is: 14.93% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:12:18,782]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:12:23,586]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:12:24,492]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:12:30,017]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:12:31,626]\u001b[0m Trial 257 finished with value: 6.6708724109198565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028845023769264095, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09232973126843776, 'dropout_rate_Layer_2': 0.13935785160007888, 'dropout_rate_Layer_3': 0.26867996722880993, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.019938496400883344, 'l1_Layer_2': 0.00306259220879649, 'l1_Layer_3': 0.00034518103376756867, 'n_units_Layer_1': 285, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200}. Best is trial 241 with value: 6.322800703634762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 14.92% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.75 | sMAPE for Test Set is: 15.72% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:12:33,532]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:12:57,126]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:02,055]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:07,231]\u001b[0m Trial 266 finished with value: 6.302874020815341 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021146327562246007, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.046792569511213924, 'dropout_rate_Layer_2': 0.36179993252820986, 'dropout_rate_Layer_3': 0.06455469230536126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.679168221875907e-05, 'l1_Layer_2': 0.00021736863512481435, 'l1_Layer_3': 0.0025563874057233584, 'n_units_Layer_1': 235, 'n_units_Layer_2': 215, 'n_units_Layer_3': 145}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 14.03% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.98 | sMAPE for Test Set is: 14.54% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:13:14,436]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:21,473]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:24,656]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:25,182]\u001b[0m Trial 264 finished with value: 6.971457995569241 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020529636716945694, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10408236849402415, 'dropout_rate_Layer_2': 0.15654206975834106, 'dropout_rate_Layer_3': 0.376691489266726, 'dropout_rate_Layer_4': 0.0014443091135832643, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015557976784526927, 'l1_Layer_2': 0.0005211290454918226, 'l1_Layer_3': 0.022614731621582958, 'l1_Layer_4': 3.120790222983511e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 295, 'n_units_Layer_3': 125, 'n_units_Layer_4': 75}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.97 | sMAPE for Validation Set is: 15.37% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.42 | sMAPE for Test Set is: 19.37% | rMAE for Test Set is: 0.81\n",
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.02 | sMAPE for Test Set is: 14.61% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:13:29,418]\u001b[0m Trial 265 finished with value: 6.390304009501494 and parameters: {'n_hidden': 3, 'learning_rate': 0.002467955271415252, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04950814017085714, 'dropout_rate_Layer_2': 0.3492354739575989, 'dropout_rate_Layer_3': 0.036817257138889885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.280795952804785e-05, 'l1_Layer_2': 0.0002441888793048565, 'l1_Layer_3': 0.002530507168423296, 'n_units_Layer_1': 240, 'n_units_Layer_2': 215, 'n_units_Layer_3': 140}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:33,021]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:35,270]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:40,014]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:40,372]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:46,709]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:51,728]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:51,937]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:13:58,350]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:14:02,953]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:14:06,646]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:14:30,036]\u001b[0m Trial 280 finished with value: 6.392835638722894 and parameters: {'n_hidden': 3, 'learning_rate': 0.002509820193405107, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020438549840212438, 'dropout_rate_Layer_2': 0.35301739868996196, 'dropout_rate_Layer_3': 0.034479231521640674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.030054301806905e-05, 'l1_Layer_2': 0.00020747735110247868, 'l1_Layer_3': 0.002430329319756534, 'n_units_Layer_1': 245, 'n_units_Layer_2': 210, 'n_units_Layer_3': 140}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.94 | sMAPE for Test Set is: 14.44% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:14:36,008]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:14:53,715]\u001b[0m Trial 271 finished with value: 12.71689591276357 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019366897299887907, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2984350918376458, 'dropout_rate_Layer_2': 0.30090899638078517, 'dropout_rate_Layer_3': 0.037769101827008815, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.04702752296578919, 'l1_Layer_2': 4.0852093592271324e-05, 'l1_Layer_3': 0.018346755627257415, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 65}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.72 | sMAPE for Validation Set is: 27.36% | rMAE for Validation Set is: 1.31\n",
      "MAE for Test Set is: 19.14 | sMAPE for Test Set is: 37.00% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:14:58,129]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:15:00,390]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:15:05,272]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:15:12,024]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:15:19,026]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:15:23,551]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:15:27,132]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:15:34,009]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:15:50,854]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.24% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 14.30% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:15:54,448]\u001b[0m Trial 286 finished with value: 6.395587900186605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012733254808766049, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.054018949835973024, 'dropout_rate_Layer_2': 0.34544987339319905, 'dropout_rate_Layer_3': 0.01782052994835895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8572295539152322e-05, 'l1_Layer_2': 0.00022442931685405043, 'l1_Layer_3': 0.007529270549471115, 'n_units_Layer_1': 225, 'n_units_Layer_2': 220, 'n_units_Layer_3': 110}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:16:00,830]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:16:04,533]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:16:11,239]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:16:15,338]\u001b[0m Trial 289 finished with value: 8.29064802549849 and parameters: {'n_hidden': 4, 'learning_rate': 0.021555502498697757, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35978627282067444, 'dropout_rate_Layer_2': 0.3418860274437749, 'dropout_rate_Layer_3': 0.19246028082150335, 'dropout_rate_Layer_4': 0.10366694907780517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.7982628175452208e-05, 'l1_Layer_2': 0.00010453874318637105, 'l1_Layer_3': 0.05740185480064705, 'l1_Layer_4': 0.0018497711103318101, 'n_units_Layer_1': 290, 'n_units_Layer_2': 215, 'n_units_Layer_3': 55, 'n_units_Layer_4': 215}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.29 | sMAPE for Validation Set is: 17.58% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 11.84 | sMAPE for Test Set is: 21.27% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:16:19,364]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:16:23,597]\u001b[0m Trial 293 finished with value: 6.385211836821095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014837481605875465, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04605142834083805, 'dropout_rate_Layer_2': 0.34046036332775687, 'dropout_rate_Layer_3': 0.000393987153070402, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1627980551278527e-05, 'l1_Layer_2': 0.0002793842112015872, 'l1_Layer_3': 0.006654001064097371, 'n_units_Layer_1': 225, 'n_units_Layer_2': 220, 'n_units_Layer_3': 110}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 14.28% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.08 | sMAPE for Test Set is: 14.65% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:16:28,143]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:16:34,176]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:16:36,822]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:16:41,944]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:16:44,828]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:16:47,739]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:16:51,481]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:17:00,745]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:17:06,695]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:17:16,971]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:17:17,253]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:17:24,379]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:17:38,751]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:17:43,626]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:17:46,104]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:17:52,469]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:17:58,471]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:18:02,404]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:18:05,927]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:18:10,542]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:18:18,412]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:18:19,050]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:18:30,184]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:18:39,292]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:18:42,222]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:18:45,567]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:18:49,882]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:18:56,822]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:19:00,004]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:19:02,947]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:19:10,023]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:19:20,887]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:20:06,552]\u001b[0m Trial 304 finished with value: 6.967745476346221 and parameters: {'n_hidden': 4, 'learning_rate': 0.002306200553528166, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12937580006914623, 'dropout_rate_Layer_2': 0.11143397716454809, 'dropout_rate_Layer_3': 0.38373042581453287, 'dropout_rate_Layer_4': 0.010860575216473128, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.182738566878146e-05, 'l1_Layer_2': 0.00015527586528989087, 'l1_Layer_3': 0.002723717852585952, 'l1_Layer_4': 0.00015892048667737202, 'n_units_Layer_1': 300, 'n_units_Layer_2': 295, 'n_units_Layer_3': 130, 'n_units_Layer_4': 60}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.97 | sMAPE for Validation Set is: 15.54% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.46 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:20:13,250]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:20:22,975]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:20:53,383]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:21:06,223]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:21:11,705]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:21:19,523]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:21:24,530]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:21:28,674]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:21:41,195]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:21:53,084]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:21:53,658]\u001b[0m Trial 332 finished with value: 6.989049996752537 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027005358230723915, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1185296283250834, 'dropout_rate_Layer_2': 0.11507439253594838, 'dropout_rate_Layer_3': 0.3927203105799022, 'dropout_rate_Layer_4': 0.029430153384916447, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.516855438017003e-05, 'l1_Layer_2': 0.000132204404496049, 'l1_Layer_3': 0.0017007930253261348, 'l1_Layer_4': 0.0002880618885823064, 'n_units_Layer_1': 300, 'n_units_Layer_2': 290, 'n_units_Layer_3': 130, 'n_units_Layer_4': 55}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.99 | sMAPE for Validation Set is: 15.68% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 9.96 | sMAPE for Test Set is: 18.48% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:22:01,077]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:09,430]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:17,265]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:22,820]\u001b[0m Trial 335 finished with value: 7.015929671577015 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027058245960020723, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11007953907123721, 'dropout_rate_Layer_2': 0.10355826436155986, 'dropout_rate_Layer_3': 0.372679601755182, 'dropout_rate_Layer_4': 0.027060807007962772, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.0755695636528e-05, 'l1_Layer_2': 0.00017457821526024975, 'l1_Layer_3': 0.0027210005143141086, 'l1_Layer_4': 0.00013081637603006274, 'n_units_Layer_1': 295, 'n_units_Layer_2': 290, 'n_units_Layer_3': 125, 'n_units_Layer_4': 290}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:22,883]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.02 | sMAPE for Validation Set is: 15.59% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 20.02% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:22:25,217]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:34,795]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:35,337]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:38,589]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:42,463]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:45,115]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:46,711]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:50,306]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:54,249]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:56,354]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:57,270]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:22:58,847]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:07,283]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:07,490]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:08,316]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:20,586]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.19 | sMAPE for Test Set is: 14.98% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:23:22,465]\u001b[0m Trial 356 finished with value: 6.599425956190632 and parameters: {'n_hidden': 3, 'learning_rate': 0.004301194424053135, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09970922390018344, 'dropout_rate_Layer_2': 0.2905312237761174, 'dropout_rate_Layer_3': 0.03820823063063751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.432748003775588e-05, 'l1_Layer_2': 0.0007615719062618976, 'l1_Layer_3': 0.015059900661940937, 'n_units_Layer_1': 215, 'n_units_Layer_2': 200, 'n_units_Layer_3': 80}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:27,666]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:32,641]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:35,187]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:35,226]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:36,885]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:45,176]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:46,631]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:47,810]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:48,449]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:54,652]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:23:58,524]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:24:00,585]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:24:05,513]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:24:11,330]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:24:13,500]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:24:42,454]\u001b[0m Trial 384 finished with value: 6.34718481207693 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015071731030764758, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11600498002805956, 'dropout_rate_Layer_2': 0.3208241220689597, 'dropout_rate_Layer_3': 0.053940067435977145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.307792080650214e-05, 'l1_Layer_2': 5.695048795033849e-05, 'l1_Layer_3': 0.0016033730656244707, 'n_units_Layer_1': 270, 'n_units_Layer_2': 275, 'n_units_Layer_3': 170}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 14.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.09 | sMAPE for Test Set is: 14.73% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:24:54,573]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:00,943]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:02,784]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:08,399]\u001b[0m Trial 378 finished with value: 7.049229061492553 and parameters: {'n_hidden': 4, 'learning_rate': 0.014651605629781213, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2670249701502019, 'dropout_rate_Layer_2': 0.006864143467038508, 'dropout_rate_Layer_3': 0.09659147318322743, 'dropout_rate_Layer_4': 0.14065894637732806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00020062103436976176, 'l1_Layer_2': 0.0025549875832048016, 'l1_Layer_3': 0.0006580264457834336, 'l1_Layer_4': 0.0019803032136352086, 'n_units_Layer_1': 75, 'n_units_Layer_2': 255, 'n_units_Layer_3': 185, 'n_units_Layer_4': 130}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 15.99% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 9.77 | sMAPE for Test Set is: 18.12% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:25:11,751]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:19,638]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:20,324]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:25,430]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:29,462]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:34,425]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:38,184]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:43,386]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:47,037]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:53,425]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:25:54,352]\u001b[0m Trial 383 finished with value: 6.510500624250878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007102245109583762, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.110778516275535, 'dropout_rate_Layer_2': 0.320253884129629, 'dropout_rate_Layer_3': 0.062161764577704275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.117786585028821e-05, 'l1_Layer_2': 0.00013738495323336808, 'l1_Layer_3': 0.024824750203179955, 'n_units_Layer_1': 200, 'n_units_Layer_2': 275, 'n_units_Layer_3': 170}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.15 | sMAPE for Test Set is: 14.81% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:25:58,520]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:26:02,965]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:26:08,315]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:26:08,365]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:26:13,970]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:26:15,914]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:26:19,432]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:26:24,830]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:26:25,327]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:26:29,354]\u001b[0m Trial 400 finished with value: 6.71326456232444 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032804629117800556, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09364483997775304, 'dropout_rate_Layer_2': 0.14081419548261964, 'dropout_rate_Layer_3': 0.2604796653184417, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018826836899773585, 'l1_Layer_2': 0.001885177527674317, 'l1_Layer_3': 0.0003011916227671486, 'n_units_Layer_1': 300, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.71 | sMAPE for Validation Set is: 15.00% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.41 | sMAPE for Test Set is: 15.28% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:26:39,213]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:26:39,762]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:26:49,254]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:26:56,977]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:02,864]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:05,633]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:06,329]\u001b[0m Trial 408 finished with value: 6.477832959794909 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013715228786932918, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028767485134232485, 'dropout_rate_Layer_2': 0.28989371371339606, 'dropout_rate_Layer_3': 0.0008750873495358066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.00308545371333e-05, 'l1_Layer_2': 0.002641442347169188, 'l1_Layer_3': 0.0008157146885611926, 'n_units_Layer_1': 295, 'n_units_Layer_2': 230, 'n_units_Layer_3': 150}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.48 | sMAPE for Validation Set is: 14.33% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.00 | sMAPE for Test Set is: 14.51% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:27:14,180]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:20,588]\u001b[0m Trial 409 finished with value: 6.3660456457217975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015911671557851316, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03308273634240798, 'dropout_rate_Layer_2': 0.2860363059595679, 'dropout_rate_Layer_3': 0.08095867559135776, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.862885778219169e-05, 'l1_Layer_2': 0.00013267414092413062, 'l1_Layer_3': 0.0005838873741311553, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 145}. Best is trial 266 with value: 6.302874020815341.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:20,671]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.15 | sMAPE for Test Set is: 14.97% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:27:29,503]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:30,439]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:35,929]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:39,984]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:43,221]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:47,275]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:48,033]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:50,479]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:27:59,788]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:03,033]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:03,943]\u001b[0m Trial 417 finished with value: 6.142767457842159 and parameters: {'n_hidden': 3, 'learning_rate': 0.001998750098569233, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11654897780405837, 'dropout_rate_Layer_2': 0.056910639786644304, 'dropout_rate_Layer_3': 0.3269152969130369, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.164375381549444e-05, 'l1_Layer_2': 0.00038908866279618057, 'l1_Layer_3': 0.0023709524028560037, 'n_units_Layer_1': 265, 'n_units_Layer_2': 50, 'n_units_Layer_3': 270}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.65 | sMAPE for Test Set is: 18.17% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:28:10,041]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:10,096]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:10,788]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:11,369]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:23,020]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:24,256]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:30,234]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:30,545]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:32,376]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:37,718]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:44,161]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:50,106]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:50,896]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:28:54,356]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:01,796]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:05,358]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:08,715]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:12,501]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:23,547]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:27,830]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:28,689]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:30,838]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:36,018]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:37,937]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:43,582]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:49,215]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:49,365]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:59,036]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:29:59,342]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:05,911]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:06,546]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:15,670]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:20,158]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:23,630]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:29,209]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:29,775]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:38,270]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:43,087]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:47,176]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:47,888]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:51,883]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:54,911]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:56,316]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:57,047]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:30:58,097]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:07,414]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:07,979]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:11,824]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:13,818]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:18,910]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:19,180]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:19,810]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:30,706]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:31,091]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:39,416]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:45,685]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:50,007]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:50,031]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:31:50,562]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 14.35% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.07 | sMAPE for Test Set is: 14.66% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:31:55,316]\u001b[0m Trial 479 finished with value: 6.412288007327742 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015128239518192577, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03928725648880214, 'dropout_rate_Layer_2': 0.38006101384408514, 'dropout_rate_Layer_3': 0.04041694682439569, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.638265565190847e-05, 'l1_Layer_2': 2.181439868493845e-05, 'l1_Layer_3': 0.004411244067983714, 'n_units_Layer_1': 270, 'n_units_Layer_2': 220, 'n_units_Layer_3': 100}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:32:07,658]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:32:14,556]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:32:20,478]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:32:42,900]\u001b[0m Trial 489 finished with value: 6.538201543836398 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005458418618296238, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16129754753640957, 'dropout_rate_Layer_2': 0.05328091301480462, 'dropout_rate_Layer_3': 0.30649421440645747, 'dropout_rate_Layer_4': 0.2562399552017019, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3672744116181976e-05, 'l1_Layer_2': 6.0299547787320705e-05, 'l1_Layer_3': 0.0006596816643816004, 'l1_Layer_4': 8.38846566260913e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 250, 'n_units_Layer_3': 95, 'n_units_Layer_4': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 14.67% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.14 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:32:49,461]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:32:58,046]\u001b[0m Trial 490 finished with value: 6.682118637304288 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006723990812584506, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24508139735325485, 'dropout_rate_Layer_2': 0.05284104750781081, 'dropout_rate_Layer_3': 0.30949208251895904, 'dropout_rate_Layer_4': 0.26765895218908053, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1989326218626178e-05, 'l1_Layer_2': 5.87169849228723e-05, 'l1_Layer_3': 0.00041170775162353883, 'l1_Layer_4': 0.002457863066084476, 'n_units_Layer_1': 190, 'n_units_Layer_2': 250, 'n_units_Layer_3': 175, 'n_units_Layer_4': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.68 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.67 | sMAPE for Test Set is: 17.80% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:33:03,824]\u001b[0m Trial 488 finished with value: 6.67109434601537 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005308495491326474, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1531186199452326, 'dropout_rate_Layer_2': 0.04909948430640115, 'dropout_rate_Layer_3': 0.306027081105996, 'dropout_rate_Layer_4': 0.2653254363263274, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3386854981565121e-05, 'l1_Layer_2': 4.3887552495793516e-05, 'l1_Layer_3': 0.00046264447407946726, 'l1_Layer_4': 0.0023360008306492026, 'n_units_Layer_1': 195, 'n_units_Layer_2': 250, 'n_units_Layer_3': 95, 'n_units_Layer_4': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 14.97% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 18.10% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:33:08,014]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:14,200]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:15,006]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:21,729]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:22,268]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:30,082]\u001b[0m Trial 494 finished with value: 6.72571384065422 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007619396752821381, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16103439819037899, 'dropout_rate_Layer_2': 0.04715927829971134, 'dropout_rate_Layer_3': 0.30756515651625027, 'dropout_rate_Layer_4': 0.25679945965131634, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0967958481816956e-05, 'l1_Layer_2': 4.910137252136738e-05, 'l1_Layer_3': 0.0005279407116510462, 'l1_Layer_4': 0.002046694047091938, 'n_units_Layer_1': 195, 'n_units_Layer_2': 250, 'n_units_Layer_3': 90, 'n_units_Layer_4': 230}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.73 | sMAPE for Validation Set is: 15.08% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.61 | sMAPE for Test Set is: 17.63% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:33:30,505]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:31,136]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:38,414]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:41,278]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:43,439]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:45,537]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:50,907]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:51,229]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:51,880]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:33:52,770]\u001b[0m Trial 496 finished with value: 6.291041913254522 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011134682104675321, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019070396447364205, 'dropout_rate_Layer_2': 0.29891777874798087, 'dropout_rate_Layer_3': 0.05980812555998197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.885410751364192e-05, 'l1_Layer_2': 0.001114096873902229, 'l1_Layer_3': 0.0007443175183886296, 'n_units_Layer_1': 235, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 14.04% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.98 | sMAPE for Test Set is: 14.52% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:34:01,101]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:34:01,808]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:34:11,647]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:34:18,502]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:34:25,836]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:34:30,966]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:34:34,299]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:34:37,398]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:34:41,067]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:34:49,787]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:34:58,009]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:35:03,112]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:35:09,757]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:35:18,801]\u001b[0m Trial 516 finished with value: 7.240219706041631 and parameters: {'n_hidden': 4, 'learning_rate': 0.015949490353065903, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3512754800624065, 'dropout_rate_Layer_2': 0.3140707545601625, 'dropout_rate_Layer_3': 0.20304605731198905, 'dropout_rate_Layer_4': 0.062337485241397234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00014676750895236423, 'l1_Layer_2': 0.00020294818697376917, 'l1_Layer_3': 0.005529258448890609, 'l1_Layer_4': 1.4468790923734351e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 220, 'n_units_Layer_3': 95, 'n_units_Layer_4': 240}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.24 | sMAPE for Validation Set is: 15.95% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 9.73 | sMAPE for Test Set is: 17.62% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:35:28,802]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:35:36,711]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:36:09,081]\u001b[0m Trial 514 finished with value: 6.732911640319078 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005075363922235603, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24661901046573753, 'dropout_rate_Layer_2': 0.16077880312899878, 'dropout_rate_Layer_3': 0.0777183409975812, 'dropout_rate_Layer_4': 0.14228208847256413, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.884680073099729e-05, 'l1_Layer_2': 0.0001209013427670949, 'l1_Layer_3': 0.00016952592497081277, 'l1_Layer_4': 3.136641351567819e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 200, 'n_units_Layer_3': 105, 'n_units_Layer_4': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.73 | sMAPE for Validation Set is: 14.99% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.32 | sMAPE for Test Set is: 17.08% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:36:15,431]\u001b[0m Trial 525 finished with value: 6.2487245478265985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009346071646972091, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06648964128237107, 'dropout_rate_Layer_2': 0.25824121473144673, 'dropout_rate_Layer_3': 0.20035766967861085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010657692814426234, 'l1_Layer_2': 0.0008792736431384679, 'l1_Layer_3': 0.0007199338818124947, 'n_units_Layer_1': 290, 'n_units_Layer_2': 265, 'n_units_Layer_3': 185}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 14.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:36:16,062]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:36:25,211]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:36:27,336]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:36:34,337]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:36:37,626]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:36:41,834]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:36:48,644]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:36:53,044]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:02,025]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:02,392]\u001b[0m Trial 528 finished with value: 6.34032693786106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005541090011138928, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06596676499192401, 'dropout_rate_Layer_2': 0.2575325948024578, 'dropout_rate_Layer_3': 0.19645717181616676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010042501997266269, 'l1_Layer_2': 0.0009157318082904607, 'l1_Layer_3': 0.000736866402185353, 'n_units_Layer_1': 290, 'n_units_Layer_2': 265, 'n_units_Layer_3': 165}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 14.08% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.03 | sMAPE for Test Set is: 14.42% | rMAE for Test Set is: 0.62\n",
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 13.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 14.41% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:37:02,641]\u001b[0m Trial 530 finished with value: 6.267198021456294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008623826476270211, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02146177979768041, 'dropout_rate_Layer_2': 0.25109311758876673, 'dropout_rate_Layer_3': 0.05647393444223099, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010549174663448324, 'l1_Layer_2': 0.001795298573478295, 'l1_Layer_3': 0.0006667114341107988, 'n_units_Layer_1': 290, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:11,763]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:15,445]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:20,515]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:20,746]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:20,893]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:26,283]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:32,434]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:32,568]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:32,804]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:46,038]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:53,767]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:57,299]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:58,027]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:37:58,196]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:00,735]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:06,573]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:12,493]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:15,253]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:16,399]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:20,417]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:28,399]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:32,811]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:34,100]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:37,937]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:42,382]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:47,770]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:50,036]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:54,563]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:55,002]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:38:56,751]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:39:00,396]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:39:05,964]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:39:08,985]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:39:10,273]\u001b[0m Trial 562 finished with value: 6.380590666095192 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006336975044587543, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03509279513368655, 'dropout_rate_Layer_2': 0.21031885418001856, 'dropout_rate_Layer_3': 0.20308824797170183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.3754328367279834e-05, 'l1_Layer_2': 0.0012896752472439123, 'l1_Layer_3': 9.903688775537115e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 245, 'n_units_Layer_3': 190}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.09% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.92 | sMAPE for Test Set is: 14.35% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:39:17,556]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:39:23,694]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:39:24,126]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:39:31,382]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:39:31,966]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:39:38,733]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:39:40,521]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:39:41,479]\u001b[0m Trial 575 finished with value: 6.412650647811605 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015911828950384973, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04127267582097277, 'dropout_rate_Layer_2': 0.04117720704809671, 'dropout_rate_Layer_3': 0.28013713970538395, 'dropout_rate_Layer_4': 0.34322671231168367, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003497978435356901, 'l1_Layer_2': 3.475456408169911e-05, 'l1_Layer_3': 0.004521349245345438, 'l1_Layer_4': 1.040191377985048e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 50, 'n_units_Layer_3': 190, 'n_units_Layer_4': 300}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.04 | sMAPE for Test Set is: 16.48% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:39:42,959]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:39:53,763]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:40:15,461]\u001b[0m Trial 572 finished with value: 6.713167164800776 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005412415810722818, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2530578031932582, 'dropout_rate_Layer_2': 0.056950456081532146, 'dropout_rate_Layer_3': 0.28317975665740425, 'dropout_rate_Layer_4': 0.2994875212097138, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0470517846710303e-05, 'l1_Layer_2': 4.451447142455677e-05, 'l1_Layer_3': 0.0002713441128839521, 'l1_Layer_4': 0.006813887727282704, 'n_units_Layer_1': 125, 'n_units_Layer_2': 265, 'n_units_Layer_3': 170, 'n_units_Layer_4': 150}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.71 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.45 | sMAPE for Test Set is: 17.42% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:40:21,309]\u001b[0m Trial 585 finished with value: 6.4175530775743255 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014820758545890337, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034789886843396844, 'dropout_rate_Layer_2': 0.07640419268480034, 'dropout_rate_Layer_3': 0.2744771585221931, 'dropout_rate_Layer_4': 0.3988683515103886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004099014409712321, 'l1_Layer_2': 1.1678423027807486e-05, 'l1_Layer_3': 0.0033656139074837626, 'l1_Layer_4': 1.1062107223090863e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220, 'n_units_Layer_4': 300}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.08 | sMAPE for Test Set is: 16.67% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:40:33,800]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:40:42,365]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:40:48,082]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:40:55,860]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:41:04,533]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:41:11,468]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:41:16,083]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:41:22,687]\u001b[0m Trial 587 finished with value: 7.020496299515446 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006234454435428772, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29202492683577375, 'dropout_rate_Layer_2': 0.01880123278610843, 'dropout_rate_Layer_3': 0.027577226490640778, 'dropout_rate_Layer_4': 0.03365289570423364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.515940806744011e-05, 'l1_Layer_2': 7.975304880691347e-05, 'l1_Layer_3': 0.0001607546499620863, 'l1_Layer_4': 1.64753211274448e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 115, 'n_units_Layer_3': 105, 'n_units_Layer_4': 85}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.02 | sMAPE for Validation Set is: 15.41% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.12 | sMAPE for Test Set is: 18.56% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:41:28,801]\u001b[0m Trial 594 finished with value: 6.7258062727358086 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011169888839080678, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.003421864124609611, 'dropout_rate_Layer_2': 0.04204326598918649, 'dropout_rate_Layer_3': 0.22779326650031334, 'dropout_rate_Layer_4': 0.3381277560496048, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005270853728189805, 'l1_Layer_2': 1.1090175157789413e-05, 'l1_Layer_3': 0.0013825544570089396, 'l1_Layer_4': 1.023830887323512e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225, 'n_units_Layer_4': 300}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.73 | sMAPE for Validation Set is: 15.15% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.23 | sMAPE for Test Set is: 16.96% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:41:29,369]\u001b[0m Trial 586 finished with value: 6.697350834108598 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005253890406476874, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23997745341195006, 'dropout_rate_Layer_2': 0.0601156054882456, 'dropout_rate_Layer_3': 0.29135973986722996, 'dropout_rate_Layer_4': 0.28805649130263844, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1076597475662997e-05, 'l1_Layer_2': 3.539156246541951e-05, 'l1_Layer_3': 0.00024221544340424775, 'l1_Layer_4': 0.007845840652252453, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 180, 'n_units_Layer_4': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.70 | sMAPE for Validation Set is: 15.11% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.49 | sMAPE for Test Set is: 17.51% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:41:36,654]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:41:38,816]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:41:45,651]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:41:50,410]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:41:59,145]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:42:01,451]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:42:11,302]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:42:14,581]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:42:22,496]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:42:23,328]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:42:49,955]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:42:55,910]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:43:12,865]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:43:21,228]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:43:27,718]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:43:36,591]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:43:41,283]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:43:45,930]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:43:51,610]\u001b[0m Trial 601 finished with value: 6.962671565720934 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005515217280521019, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3066959543296405, 'dropout_rate_Layer_2': 0.01585452367141944, 'dropout_rate_Layer_3': 0.03673551047240896, 'dropout_rate_Layer_4': 0.02203701574575224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.4218399671301095e-05, 'l1_Layer_2': 0.00012754417802789825, 'l1_Layer_3': 0.0001122431616753201, 'l1_Layer_4': 1.343149370077039e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 135, 'n_units_Layer_4': 90}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.96 | sMAPE for Validation Set is: 15.62% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.30 | sMAPE for Test Set is: 18.85% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:44:05,170]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:44:16,003]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:44:25,626]\u001b[0m Trial 608 finished with value: 6.7980952793437455 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006994069804291819, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2564558783441143, 'dropout_rate_Layer_2': 0.020077670552606786, 'dropout_rate_Layer_3': 0.04579055091330119, 'dropout_rate_Layer_4': 0.06563815363149023, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.923340032973372e-05, 'l1_Layer_2': 6.910009485491692e-05, 'l1_Layer_3': 0.00022530847064750094, 'l1_Layer_4': 1.8462483708373886e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 145, 'n_units_Layer_4': 80}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 15.21% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.32 | sMAPE for Test Set is: 19.15% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:44:32,305]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:44:37,345]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:44:41,439]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:44:46,629]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:44:52,523]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:44:55,116]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:45:02,038]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:45:12,386]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:45:17,700]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:45:25,448]\u001b[0m Trial 621 finished with value: 6.869741335798686 and parameters: {'n_hidden': 4, 'learning_rate': 0.001122336138336615, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30802811022139864, 'dropout_rate_Layer_2': 0.028698681053624244, 'dropout_rate_Layer_3': 0.32923058805789546, 'dropout_rate_Layer_4': 0.34515106472457113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001076968468753863, 'l1_Layer_2': 7.841744548393019e-05, 'l1_Layer_3': 0.000534488308297285, 'l1_Layer_4': 0.0019858008250756244, 'n_units_Layer_1': 205, 'n_units_Layer_2': 210, 'n_units_Layer_3': 215, 'n_units_Layer_4': 175}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 15.33% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 19.76% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:45:30,473]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:45:40,804]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:45:45,219]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:45:48,535]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:45:51,856]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:45:59,367]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:46:09,791]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:46:23,492]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:46:28,212]\u001b[0m Trial 626 finished with value: 6.954679005518972 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005557293091897412, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31129389146229847, 'dropout_rate_Layer_2': 0.01300185324486038, 'dropout_rate_Layer_3': 0.025444128455871524, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.627346688695434e-05, 'l1_Layer_2': 5.2994817031690934e-05, 'l1_Layer_3': 7.944935719165991e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 180, 'n_units_Layer_3': 135}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.95 | sMAPE for Validation Set is: 15.53% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.27 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:46:32,251]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:46:36,393]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:46:37,421]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:46:43,524]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:46:45,294]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:46:57,034]\u001b[0m Trial 641 finished with value: 6.757272641929611 and parameters: {'n_hidden': 3, 'learning_rate': 0.006195169914158022, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30409827028171427, 'dropout_rate_Layer_2': 0.1998671222705773, 'dropout_rate_Layer_3': 0.028054827345503134, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8936297384502162e-05, 'l1_Layer_2': 3.731229671938682e-05, 'l1_Layer_3': 8.171882072089639e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 180, 'n_units_Layer_3': 160}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.83 | sMAPE for Test Set is: 16.07% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:47:02,852]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:06,427]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:07,873]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:09,259]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:14,796]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:18,123]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:19,692]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:25,193]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:29,309]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:35,243]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:38,276]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:48,610]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:52,810]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:47:56,526]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:48:03,050]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:48:06,469]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:48:12,749]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:48:15,524]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.70 | sMAPE for Validation Set is: 15.16% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.63 | sMAPE for Test Set is: 17.75% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:48:16,950]\u001b[0m Trial 632 finished with value: 6.703906156714846 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006364943812030458, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2670818863854756, 'dropout_rate_Layer_2': 0.010681511619191683, 'dropout_rate_Layer_3': 0.0270092554524825, 'dropout_rate_Layer_4': 0.03238850634933477, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.59122635182427e-05, 'l1_Layer_2': 0.00010549375185457293, 'l1_Layer_3': 0.0001202801921732312, 'l1_Layer_4': 1.6621558952385396e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 195, 'n_units_Layer_3': 155, 'n_units_Layer_4': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:48:23,499]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:48:24,177]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:48:27,290]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:48:32,449]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:48:33,756]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:48:41,875]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:48:49,742]\u001b[0m Trial 665 finished with value: 6.484562552401473 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009409541037244207, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12193025457449788, 'dropout_rate_Layer_2': 0.18115761982559547, 'dropout_rate_Layer_3': 0.23920144773023777, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.16570759713604e-05, 'l1_Layer_2': 0.00017366548585789364, 'l1_Layer_3': 0.0012209471913558678, 'n_units_Layer_1': 165, 'n_units_Layer_2': 245, 'n_units_Layer_3': 165}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.48 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 15.26% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:49:00,175]\u001b[0m Trial 671 finished with value: 6.3828434549186035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009327281353773506, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12168409059196514, 'dropout_rate_Layer_2': 0.2642167269062991, 'dropout_rate_Layer_3': 0.08082082531570034, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.344571844602492e-05, 'l1_Layer_2': 9.325821284326315e-05, 'l1_Layer_3': 0.001142503373726591, 'n_units_Layer_1': 265, 'n_units_Layer_2': 245, 'n_units_Layer_3': 165}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.17% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.09 | sMAPE for Test Set is: 14.73% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:49:00,806]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:49:05,600]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:49:07,742]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:49:12,819]\u001b[0m Trial 668 finished with value: 6.5188923335474955 and parameters: {'n_hidden': 4, 'learning_rate': 0.002471658666515438, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05202302345202857, 'dropout_rate_Layer_2': 0.0898299022999238, 'dropout_rate_Layer_3': 0.3639084901391819, 'dropout_rate_Layer_4': 0.31809490731053597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00013959140227897253, 'l1_Layer_2': 4.310181326913171e-05, 'l1_Layer_3': 0.0011124622273133817, 'l1_Layer_4': 1.0015281155773308e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 80, 'n_units_Layer_3': 250, 'n_units_Layer_4': 285}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 14.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.51 | sMAPE for Test Set is: 15.36% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:49:13,635]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:49:20,074]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:49:26,026]\u001b[0m Trial 669 finished with value: 7.0754927283469975 and parameters: {'n_hidden': 4, 'learning_rate': 0.008849537275305838, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3410990903265873, 'dropout_rate_Layer_2': 0.3025141073142416, 'dropout_rate_Layer_3': 0.18747988967426837, 'dropout_rate_Layer_4': 0.05727502712444443, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001824294511106833, 'l1_Layer_2': 0.00014766833450924872, 'l1_Layer_3': 0.012406096380164705, 'l1_Layer_4': 0.004052383801542852, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 210, 'n_units_Layer_4': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.08 | sMAPE for Validation Set is: 16.03% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 9.71 | sMAPE for Test Set is: 17.95% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:49:30,937]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:49:35,699]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:49:44,166]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:49:52,176]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:49:56,862]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:50:00,880]\u001b[0m Trial 679 finished with value: 6.703324273644879 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022477390763845527, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06079787192742249, 'dropout_rate_Layer_2': 0.09277622960444, 'dropout_rate_Layer_3': 0.3618730459066007, 'dropout_rate_Layer_4': 0.3254094805637906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001432705259525176, 'l1_Layer_2': 4.031495705421359e-05, 'l1_Layer_3': 0.001103144276346984, 'l1_Layer_4': 1.0152398410077055e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 75, 'n_units_Layer_3': 255, 'n_units_Layer_4': 280}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.70 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.14 | sMAPE for Test Set is: 16.30% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:50:01,403]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:50:05,821]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:50:06,637]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:50:10,736]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:50:14,124]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:50:16,666]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:50:19,411]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:50:19,867]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:50:22,261]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:50:27,934]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:50:31,568]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:50:40,704]\u001b[0m Trial 675 finished with value: 6.998100204627607 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008145294763892616, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2692836158972254, 'dropout_rate_Layer_2': 0.21809657996604304, 'dropout_rate_Layer_3': 0.05420093562918912, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.4051373946160206e-05, 'l1_Layer_2': 3.564494518354414e-05, 'l1_Layer_3': 0.00011499378033951157, 'n_units_Layer_1': 160, 'n_units_Layer_2': 175, 'n_units_Layer_3': 150}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.00 | sMAPE for Validation Set is: 15.37% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 9.39 | sMAPE for Test Set is: 17.18% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:50:41,204]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:51:00,295]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:51:35,387]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:51:39,223]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:51:57,238]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:52:02,696]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:52:08,708]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:52:11,444]\u001b[0m Trial 698 finished with value: 7.222422162745031 and parameters: {'n_hidden': 4, 'learning_rate': 0.007840269006468526, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3353967489618314, 'dropout_rate_Layer_2': 0.3101212240269568, 'dropout_rate_Layer_3': 0.1954290929956996, 'dropout_rate_Layer_4': 0.043967769712995534, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8542536334032023e-05, 'l1_Layer_2': 0.00014170884192982416, 'l1_Layer_3': 0.014335725141351242, 'l1_Layer_4': 0.00493294941090274, 'n_units_Layer_1': 300, 'n_units_Layer_2': 70, 'n_units_Layer_3': 205, 'n_units_Layer_4': 80}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 16.20% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 9.22 | sMAPE for Test Set is: 16.83% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:52:24,242]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:52:30,162]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:52:38,585]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:52:49,614]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:52:54,304]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:52:54,930]\u001b[0m Trial 696 finished with value: 7.186538597804873 and parameters: {'n_hidden': 4, 'learning_rate': 0.009081920459653173, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35120579336736135, 'dropout_rate_Layer_2': 0.31232778886108625, 'dropout_rate_Layer_3': 0.18773712143831994, 'dropout_rate_Layer_4': 0.04616412929603983, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011578398024959886, 'l1_Layer_2': 0.00014211651890240316, 'l1_Layer_3': 0.013548817833499975, 'l1_Layer_4': 4.6184035953544385e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 80}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 16.02% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 10.22 | sMAPE for Test Set is: 18.79% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:53:01,278]\u001b[0m Trial 693 finished with value: 7.144396978880884 and parameters: {'n_hidden': 4, 'learning_rate': 0.007718986736276665, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11402611989137565, 'dropout_rate_Layer_2': 0.309300848196929, 'dropout_rate_Layer_3': 0.10486757189282009, 'dropout_rate_Layer_4': 0.04344455968391927, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.315366660278925e-05, 'l1_Layer_2': 0.00014831204073620719, 'l1_Layer_3': 0.005561573054963851, 'l1_Layer_4': 0.005207015557358613, 'n_units_Layer_1': 300, 'n_units_Layer_2': 120, 'n_units_Layer_3': 210, 'n_units_Layer_4': 80}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.14 | sMAPE for Validation Set is: 15.84% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 9.49 | sMAPE for Test Set is: 17.33% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:53:11,944]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:53:16,673]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:53:24,704]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:53:37,613]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:53:45,951]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:53:53,764]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:53:57,395]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:54:01,258]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:54:10,814]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:54:15,708]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:54:20,421]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:54:34,838]\u001b[0m Trial 720 finished with value: 36.36734689814196 and parameters: {'n_hidden': 4, 'learning_rate': 0.09098950617528498, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11265672350163954, 'dropout_rate_Layer_2': 0.07890689105018409, 'dropout_rate_Layer_3': 0.2897977351715078, 'dropout_rate_Layer_4': 0.37356390374760884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00041174486248284336, 'l1_Layer_2': 1.763533056688438e-05, 'l1_Layer_3': 0.002889785417961046, 'l1_Layer_4': 2.2938674354908343e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 65, 'n_units_Layer_3': 245, 'n_units_Layer_4': 285}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.37 | sMAPE for Validation Set is: 131.01% | rMAE for Validation Set is: 3.74\n",
      "MAE for Test Set is: 47.80 | sMAPE for Test Set is: 144.03% | rMAE for Test Set is: 3.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:54:46,829]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:54:55,838]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:55:00,496]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:55:14,835]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:55:19,746]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:55:22,829]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:55:33,160]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:55:38,992]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:55:42,223]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:55:46,291]\u001b[0m Trial 715 finished with value: 6.492382407867709 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013120484133065204, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11015875573797616, 'dropout_rate_Layer_2': 0.0534432055998072, 'dropout_rate_Layer_3': 0.2909088195088536, 'dropout_rate_Layer_4': 0.28104920547437534, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004084418200405661, 'l1_Layer_2': 1.5480546798933844e-05, 'l1_Layer_3': 0.0025307461631174245, 'l1_Layer_4': 2.508506125150116e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 65, 'n_units_Layer_3': 215, 'n_units_Layer_4': 280}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 14.53% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.56 | sMAPE for Test Set is: 15.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:55:46,977]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:55:47,996]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:56:07,638]\u001b[0m Trial 713 finished with value: 6.508407449784447 and parameters: {'n_hidden': 4, 'learning_rate': 0.001419609086347243, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 4.072412122973351e-05, 'dropout_rate_Layer_2': 0.05523781676815355, 'dropout_rate_Layer_3': 0.28814539927945687, 'dropout_rate_Layer_4': 0.28308879190263525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00044618660337627765, 'l1_Layer_2': 1.7406379913715537e-05, 'l1_Layer_3': 0.002138244919614908, 'l1_Layer_4': 2.383492001010557e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 65, 'n_units_Layer_3': 245, 'n_units_Layer_4': 285}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 14.52% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.87 | sMAPE for Test Set is: 16.17% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:56:24,712]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:56:35,289]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:56:35,345]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:56:38,640]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:56:47,671]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:56:48,875]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:57:03,893]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:57:14,590]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:57:22,524]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:57:34,613]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:57:43,056]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:57:48,569]\u001b[0m Trial 735 finished with value: 6.401335913540042 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013317745838223908, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022722391965056935, 'dropout_rate_Layer_2': 0.05220805390153965, 'dropout_rate_Layer_3': 0.24768614281504467, 'dropout_rate_Layer_4': 0.2750836294095435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0010805309146765215, 'l1_Layer_2': 1.556214157264703e-05, 'l1_Layer_3': 0.007810249295452346, 'l1_Layer_4': 5.080510229667771e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 215, 'n_units_Layer_4': 245}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.17% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.42 | sMAPE for Test Set is: 15.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 19:57:51,402]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:57:56,830]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:58:08,256]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:58:15,798]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:58:25,896]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:58:38,038]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:58:45,922]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:58:57,874]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:59:08,242]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:59:22,045]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 19:59:51,642]\u001b[0m Trial 740 finished with value: 6.585884955888353 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005735657816956205, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2354792514518792, 'dropout_rate_Layer_2': 0.17546728390123367, 'dropout_rate_Layer_3': 0.06093764282535211, 'dropout_rate_Layer_4': 0.041830213386620345, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004223873854442988, 'l1_Layer_2': 3.891903386050763e-05, 'l1_Layer_3': 0.00010332311427018796, 'l1_Layer_4': 1.2620635945509428e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 145, 'n_units_Layer_3': 165, 'n_units_Layer_4': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 17.49% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:00:01,470]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:00:06,585]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:00:16,052]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:00:38,048]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:01:03,045]\u001b[0m Trial 760 finished with value: 7.112494592759863 and parameters: {'n_hidden': 4, 'learning_rate': 0.007888523748167328, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06566194506693443, 'dropout_rate_Layer_2': 0.3049492756076777, 'dropout_rate_Layer_3': 0.09286348157229428, 'dropout_rate_Layer_4': 0.04768445288627712, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.159881300486005e-05, 'l1_Layer_2': 0.00012046199268686524, 'l1_Layer_3': 0.006116641552199941, 'l1_Layer_4': 3.46702937381373e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190, 'n_units_Layer_4': 90}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 16.00% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 9.67 | sMAPE for Test Set is: 17.76% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:01:28,006]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:01:34,603]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:01:52,379]\u001b[0m Trial 751 finished with value: 6.434999999156434 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005022594499382296, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23057205254920168, 'dropout_rate_Layer_2': 0.16613080427267848, 'dropout_rate_Layer_3': 0.032594701298556024, 'dropout_rate_Layer_4': 0.03618802218686389, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005702929026276083, 'l1_Layer_2': 5.118204395014544e-05, 'l1_Layer_3': 0.00010950194682465192, 'l1_Layer_4': 2.1228698479753925e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 150, 'n_units_Layer_3': 130, 'n_units_Layer_4': 50}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 15.65% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:02:46,501]\u001b[0m Trial 765 finished with value: 6.360947515089862 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005580607615499836, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23934274759764493, 'dropout_rate_Layer_2': 0.16860046556749406, 'dropout_rate_Layer_3': 0.02629241399429812, 'dropout_rate_Layer_4': 0.0428586714557888, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00030561314622768663, 'l1_Layer_2': 2.48995190376385e-05, 'l1_Layer_3': 0.00011047029819782789, 'l1_Layer_4': 1.2221661287407593e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 150, 'n_units_Layer_3': 125, 'n_units_Layer_4': 50}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 14.52% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.22 | sMAPE for Test Set is: 15.00% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:02:52,858]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:03:47,721]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:03:55,477]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:04:03,325]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:04:06,145]\u001b[0m Trial 769 finished with value: 6.686957341670102 and parameters: {'n_hidden': 4, 'learning_rate': 0.007694875100809257, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004138865702053837, 'dropout_rate_Layer_2': 0.3371864831023381, 'dropout_rate_Layer_3': 0.1229404619659537, 'dropout_rate_Layer_4': 0.053327853490980494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0161077695399632e-05, 'l1_Layer_2': 0.00018080602669864638, 'l1_Layer_3': 0.008564319534342177, 'l1_Layer_4': 0.0001178142112309375, 'n_units_Layer_1': 290, 'n_units_Layer_2': 90, 'n_units_Layer_3': 210, 'n_units_Layer_4': 155}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.69 | sMAPE for Validation Set is: 15.04% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.93 | sMAPE for Test Set is: 16.07% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:04:14,150]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:04:20,155]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:04:26,088]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:04:31,391]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:04:37,815]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:04:50,996]\u001b[0m Trial 766 finished with value: 6.45445834948364 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005491144309601309, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2380638756436398, 'dropout_rate_Layer_2': 0.16421308338663546, 'dropout_rate_Layer_3': 0.02232638435744515, 'dropout_rate_Layer_4': 0.05414079897746914, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0023168807267936386, 'l1_Layer_2': 2.4360720150339048e-05, 'l1_Layer_3': 0.00010829452863228801, 'l1_Layer_4': 1.2613178833985426e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 150, 'n_units_Layer_3': 125, 'n_units_Layer_4': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 14.51% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.43 | sMAPE for Test Set is: 15.39% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:06:22,612]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:06:22,930]\u001b[0m Trial 768 finished with value: 6.297671224369462 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005790831160170769, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24101802165199662, 'dropout_rate_Layer_2': 0.17880744100221393, 'dropout_rate_Layer_3': 0.023167327410734597, 'dropout_rate_Layer_4': 0.04428113123426558, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0028296492592064858, 'l1_Layer_2': 2.448119554293504e-05, 'l1_Layer_3': 6.161105711605363e-05, 'l1_Layer_4': 1.2639074075354871e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 175, 'n_units_Layer_4': 50}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.24 | sMAPE for Test Set is: 15.06% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.52 | sMAPE for Test Set is: 15.56% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:06:29,332]\u001b[0m Trial 778 finished with value: 6.488643165078687 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005642883793678934, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24680692926679382, 'dropout_rate_Layer_2': 0.1512082633304008, 'dropout_rate_Layer_3': 0.029441722819513478, 'dropout_rate_Layer_4': 0.05333719844282042, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.010067978885851989, 'l1_Layer_2': 3.686191657829196e-05, 'l1_Layer_3': 5.6814355189291006e-05, 'l1_Layer_4': 1.5123333312434655e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 115, 'n_units_Layer_4': 60}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:06:45,449]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:06:47,185]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:07:01,614]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:07:25,636]\u001b[0m Trial 780 finished with value: 7.169014297179892 and parameters: {'n_hidden': 4, 'learning_rate': 0.011818060083404157, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023531639568883843, 'dropout_rate_Layer_2': 0.32106622349141817, 'dropout_rate_Layer_3': 0.10188004177933273, 'dropout_rate_Layer_4': 0.06947717882853592, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.024418247932888e-05, 'l1_Layer_2': 0.000153562086793691, 'l1_Layer_3': 0.006665402943920054, 'l1_Layer_4': 0.00014116967819563283, 'n_units_Layer_1': 285, 'n_units_Layer_2': 75, 'n_units_Layer_3': 200, 'n_units_Layer_4': 155}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 15.52% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 9.12 | sMAPE for Test Set is: 16.55% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:07:29,900]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:07:39,686]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:08:33,659]\u001b[0m Trial 783 finished with value: 6.806874027496387 and parameters: {'n_hidden': 4, 'learning_rate': 0.0101882070679804, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04726602291978966, 'dropout_rate_Layer_2': 0.3194594017515077, 'dropout_rate_Layer_3': 0.11531166950711821, 'dropout_rate_Layer_4': 0.0358186606267135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0133140930274579e-05, 'l1_Layer_2': 0.00014099496519742505, 'l1_Layer_3': 0.009959194486789646, 'l1_Layer_4': 0.0002212938099885212, 'n_units_Layer_1': 295, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180, 'n_units_Layer_4': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 14.85% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.47 | sMAPE for Test Set is: 15.35% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:08:43,141]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:09:26,233]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:09:48,500]\u001b[0m Trial 789 finished with value: 6.816355244056695 and parameters: {'n_hidden': 4, 'learning_rate': 0.010023506078247727, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03570678882297857, 'dropout_rate_Layer_2': 0.3206075604732241, 'dropout_rate_Layer_3': 0.11317768755633927, 'dropout_rate_Layer_4': 0.07049846741410179, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.1744201675045737e-05, 'l1_Layer_2': 0.00015367060108229975, 'l1_Layer_3': 0.006779651546201129, 'l1_Layer_4': 0.00013210760047896743, 'n_units_Layer_1': 295, 'n_units_Layer_2': 70, 'n_units_Layer_3': 220, 'n_units_Layer_4': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 14.95% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.82 | sMAPE for Test Set is: 16.01% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:10:03,683]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:10:09,651]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:10:20,928]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:10:41,292]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:11:52,411]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:12:02,478]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:12:29,290]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:12:38,138]\u001b[0m Trial 800 finished with value: 6.4710696355368595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010229822042063569, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16528953002323254, 'dropout_rate_Layer_2': 0.2617742590571666, 'dropout_rate_Layer_3': 0.0829333526936804, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.722728895206473e-05, 'l1_Layer_2': 9.7742059605603e-05, 'l1_Layer_3': 0.001056701118349221, 'n_units_Layer_1': 270, 'n_units_Layer_2': 250, 'n_units_Layer_3': 165}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.14 | sMAPE for Test Set is: 14.95% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:12:43,083]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:12:59,941]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:13:05,824]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:13:20,900]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:14:05,025]\u001b[0m Trial 798 finished with value: 6.8720151643824074 and parameters: {'n_hidden': 4, 'learning_rate': 0.010566728103888368, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05407598182064177, 'dropout_rate_Layer_2': 0.32642347859089166, 'dropout_rate_Layer_3': 0.11402673881178327, 'dropout_rate_Layer_4': 0.037205729884194266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5000896502032555e-05, 'l1_Layer_2': 0.00015710628211382298, 'l1_Layer_3': 0.007479162881976082, 'l1_Layer_4': 0.00014797403082595948, 'n_units_Layer_1': 295, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180, 'n_units_Layer_4': 150}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.49 | sMAPE for Test Set is: 15.38% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:14:28,942]\u001b[0m Trial 794 finished with value: 6.9416761711012285 and parameters: {'n_hidden': 4, 'learning_rate': 0.011120592137059019, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.050026667141422634, 'dropout_rate_Layer_2': 0.32027204765535017, 'dropout_rate_Layer_3': 0.115172145509275, 'dropout_rate_Layer_4': 0.03447798456216225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0437763263936714e-05, 'l1_Layer_2': 0.00015663188744334842, 'l1_Layer_3': 0.0067788923894274, 'l1_Layer_4': 0.00013715880027497646, 'n_units_Layer_1': 295, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180, 'n_units_Layer_4': 150}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.94 | sMAPE for Validation Set is: 15.86% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.79 | sMAPE for Test Set is: 16.03% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:14:35,178]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:14:42,051]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:14:43,038]\u001b[0m Trial 807 finished with value: 6.6068612472216275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009009410599317226, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06642004554865198, 'dropout_rate_Layer_2': 0.2929144427060432, 'dropout_rate_Layer_3': 0.09044420141188325, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4597010777899485e-05, 'l1_Layer_2': 8.78440610292896e-05, 'l1_Layer_3': 0.0007048561925228412, 'n_units_Layer_1': 265, 'n_units_Layer_2': 260, 'n_units_Layer_3': 175}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 15.08% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 15.85% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:14:48,714]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:14:58,598]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:15:03,121]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:15:06,487]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:15:10,922]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:15:17,170]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:15:21,998]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:15:24,288]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:15:30,052]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:15:59,040]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:16:16,944]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:17:22,876]\u001b[0m Trial 820 finished with value: 6.977199424387578 and parameters: {'n_hidden': 4, 'learning_rate': 0.008468639479276438, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.058878156739239365, 'dropout_rate_Layer_2': 0.3147785764250745, 'dropout_rate_Layer_3': 0.11953401096936078, 'dropout_rate_Layer_4': 0.040774216864144286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.287754562047622e-05, 'l1_Layer_2': 0.00012938533523062414, 'l1_Layer_3': 0.006879618389691514, 'l1_Layer_4': 0.00014484142923074046, 'n_units_Layer_1': 290, 'n_units_Layer_2': 80, 'n_units_Layer_3': 170, 'n_units_Layer_4': 140}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.98 | sMAPE for Validation Set is: 15.41% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 9.46 | sMAPE for Test Set is: 16.87% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:17:28,143]\u001b[0m Trial 810 finished with value: 6.903386568734544 and parameters: {'n_hidden': 4, 'learning_rate': 0.012340714791850243, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.035258636507123395, 'dropout_rate_Layer_2': 0.3058499132889223, 'dropout_rate_Layer_3': 0.10325001035710701, 'dropout_rate_Layer_4': 0.04036366348107433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.4701918958036991e-05, 'l1_Layer_2': 0.00026972215105336596, 'l1_Layer_3': 0.007984933208487673, 'l1_Layer_4': 0.00016994308043339257, 'n_units_Layer_1': 285, 'n_units_Layer_2': 80, 'n_units_Layer_3': 180, 'n_units_Layer_4': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.90 | sMAPE for Validation Set is: 15.27% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.50 | sMAPE for Test Set is: 15.41% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:18:08,257]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:18:11,225]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:18:13,700]\u001b[0m Trial 822 finished with value: 6.375647250398354 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005027001304095299, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1029393417046621, 'dropout_rate_Layer_2': 0.15441237602814373, 'dropout_rate_Layer_3': 0.0012980749971427848, 'dropout_rate_Layer_4': 0.07015404373918335, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003754956732989375, 'l1_Layer_2': 1.4207819438402129e-05, 'l1_Layer_3': 0.00012184524915120064, 'l1_Layer_4': 1.6510030734452993e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 155, 'n_units_Layer_3': 105, 'n_units_Layer_4': 60}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.38 | sMAPE for Test Set is: 15.14% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:18:20,825]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:18:22,149]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:19:01,394]\u001b[0m Trial 828 finished with value: 6.740504678965057 and parameters: {'n_hidden': 4, 'learning_rate': 0.001086038008803793, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10243597166810646, 'dropout_rate_Layer_2': 0.05734025290374925, 'dropout_rate_Layer_3': 0.2750710766499593, 'dropout_rate_Layer_4': 0.2766310745580408, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.124860941818967e-05, 'l1_Layer_2': 1.4494961029457313e-05, 'l1_Layer_3': 0.0007575967379457797, 'l1_Layer_4': 3.7072863737637206e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 210, 'n_units_Layer_4': 265}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.74 | sMAPE for Test Set is: 15.97% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:19:13,184]\u001b[0m Trial 823 finished with value: 7.113409269783973 and parameters: {'n_hidden': 4, 'learning_rate': 0.007173821588278928, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06389828426882935, 'dropout_rate_Layer_2': 0.2972973023376363, 'dropout_rate_Layer_3': 0.13970781927332926, 'dropout_rate_Layer_4': 0.019052102273503364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.7432826636078407e-05, 'l1_Layer_2': 0.00018865203627370763, 'l1_Layer_3': 0.0052530210239028355, 'l1_Layer_4': 0.00015137996104651002, 'n_units_Layer_1': 280, 'n_units_Layer_2': 75, 'n_units_Layer_3': 175, 'n_units_Layer_4': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 15.58% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 8.84 | sMAPE for Test Set is: 15.91% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:19:17,500]\u001b[0m Trial 827 finished with value: 6.633227679210003 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013745073163728204, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12853373682734268, 'dropout_rate_Layer_2': 0.05514059852720263, 'dropout_rate_Layer_3': 0.2730521720527265, 'dropout_rate_Layer_4': 0.2811376828624759, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.645604777222554e-05, 'l1_Layer_2': 1.1404974255643689e-05, 'l1_Layer_3': 0.0025929223472473486, 'l1_Layer_4': 3.375792997812037e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 210, 'n_units_Layer_4': 265}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.63 | sMAPE for Validation Set is: 14.84% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 16.06% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:19:26,761]\u001b[0m Trial 830 finished with value: 8.163632898153097 and parameters: {'n_hidden': 4, 'learning_rate': 0.03199490291078721, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17307570861485985, 'dropout_rate_Layer_2': 0.08633770403303556, 'dropout_rate_Layer_3': 0.3110991050264418, 'dropout_rate_Layer_4': 0.2188380001897, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005109240262148966, 'l1_Layer_2': 2.6040010936895363e-05, 'l1_Layer_3': 0.0004083558386698646, 'l1_Layer_4': 0.023639282354708576, 'n_units_Layer_1': 135, 'n_units_Layer_2': 195, 'n_units_Layer_3': 110, 'n_units_Layer_4': 255}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.16 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 11.17 | sMAPE for Test Set is: 20.39% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:19:40,074]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:19:51,005]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:20:14,525]\u001b[0m Trial 829 finished with value: 6.771449411550269 and parameters: {'n_hidden': 4, 'learning_rate': 0.013877309395913345, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07473740270561423, 'dropout_rate_Layer_2': 0.299453425655212, 'dropout_rate_Layer_3': 0.14039405799978488, 'dropout_rate_Layer_4': 0.02021524945424449, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8490758418814083e-05, 'l1_Layer_2': 0.00018554915327372148, 'l1_Layer_3': 0.005199132984497134, 'l1_Layer_4': 0.00014509180238924483, 'n_units_Layer_1': 300, 'n_units_Layer_2': 80, 'n_units_Layer_3': 180, 'n_units_Layer_4': 140}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.77 | sMAPE for Validation Set is: 15.06% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 16.19% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:21:58,301]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:22:02,817]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:22:07,889]\u001b[0m Trial 833 finished with value: 6.609296656742664 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005730964716087094, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10131771278672622, 'dropout_rate_Layer_2': 0.14898167530297796, 'dropout_rate_Layer_3': 0.0022506134429946837, 'dropout_rate_Layer_4': 0.08335968716036934, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005214595333578911, 'l1_Layer_2': 1.0942511111777928e-05, 'l1_Layer_3': 0.00011162998116442332, 'l1_Layer_4': 1.5025959510705523e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 155, 'n_units_Layer_3': 100, 'n_units_Layer_4': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 15.05% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.94 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:22:08,274]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:22:18,989]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:22:24,713]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:22:30,977]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:22:36,913]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:22:46,842]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:22:52,856]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:22:59,178]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:23:00,039]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:23:12,141]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:23:30,678]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:23:43,277]\u001b[0m Trial 836 finished with value: 6.392391804947311 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005509531311872956, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12998383947607467, 'dropout_rate_Layer_2': 0.14004894178153415, 'dropout_rate_Layer_3': 0.014156798316709358, 'dropout_rate_Layer_4': 0.0677652703253733, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00972181143754091, 'l1_Layer_2': 1.8515365070146908e-05, 'l1_Layer_3': 0.00010508013309289611, 'l1_Layer_4': 0.0072883127672893015, 'n_units_Layer_1': 90, 'n_units_Layer_2': 160, 'n_units_Layer_3': 100, 'n_units_Layer_4': 60}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.40 | sMAPE for Test Set is: 15.33% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:23:51,854]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:24:13,505]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:24:22,335]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:25:12,220]\u001b[0m Trial 850 finished with value: 6.739607121735756 and parameters: {'n_hidden': 4, 'learning_rate': 0.007604392837781401, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0557475764119102, 'dropout_rate_Layer_2': 0.31371688499317246, 'dropout_rate_Layer_3': 0.14083817315818065, 'dropout_rate_Layer_4': 0.0013589327019542623, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.211671596827796e-05, 'l1_Layer_2': 0.00031541399610926144, 'l1_Layer_3': 0.005087987797286944, 'l1_Layer_4': 0.00016774750933352178, 'n_units_Layer_1': 300, 'n_units_Layer_2': 80, 'n_units_Layer_3': 175, 'n_units_Layer_4': 130}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 15.10% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 16.08% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:25:23,701]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:25:51,729]\u001b[0m Trial 854 finished with value: 6.655063746210806 and parameters: {'n_hidden': 4, 'learning_rate': 0.000550042036417096, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26866455614298673, 'dropout_rate_Layer_2': 0.037682510305390535, 'dropout_rate_Layer_3': 0.2953030851488669, 'dropout_rate_Layer_4': 0.3120829452184703, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.0340273818896754e-05, 'l1_Layer_2': 6.769540085298566e-05, 'l1_Layer_3': 0.0001918604787694064, 'l1_Layer_4': 0.006607538306402403, 'n_units_Layer_1': 145, 'n_units_Layer_2': 235, 'n_units_Layer_3': 180, 'n_units_Layer_4': 150}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.50 | sMAPE for Test Set is: 17.58% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:25:58,213]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:26:03,098]\u001b[0m Trial 848 finished with value: 7.037766230918844 and parameters: {'n_hidden': 4, 'learning_rate': 0.007533777778723691, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07144687958137702, 'dropout_rate_Layer_2': 0.3003382886948933, 'dropout_rate_Layer_3': 0.14908408125860723, 'dropout_rate_Layer_4': 0.02290496304129564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.6058340001634446e-05, 'l1_Layer_2': 0.00018757516291519736, 'l1_Layer_3': 0.0034440789091681047, 'l1_Layer_4': 0.00030382633763303285, 'n_units_Layer_1': 300, 'n_units_Layer_2': 85, 'n_units_Layer_3': 175, 'n_units_Layer_4': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 15.44% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 8.80 | sMAPE for Test Set is: 16.00% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:26:05,195]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:26:55,934]\u001b[0m Trial 851 finished with value: 7.001700247444032 and parameters: {'n_hidden': 4, 'learning_rate': 0.007502946433887415, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05683495766725017, 'dropout_rate_Layer_2': 0.3319867474749493, 'dropout_rate_Layer_3': 0.1437274212336635, 'dropout_rate_Layer_4': 0.027058619608793594, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.190844736824309e-05, 'l1_Layer_2': 0.00029197659144000065, 'l1_Layer_3': 0.005339495796422743, 'l1_Layer_4': 0.00030896931490282997, 'n_units_Layer_1': 300, 'n_units_Layer_2': 80, 'n_units_Layer_3': 175, 'n_units_Layer_4': 130}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.00 | sMAPE for Validation Set is: 15.32% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 8.73 | sMAPE for Test Set is: 15.78% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:27:04,507]\u001b[0m Trial 856 finished with value: 6.665799890146133 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005003431556839138, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23085922934783518, 'dropout_rate_Layer_2': 0.036638455738790474, 'dropout_rate_Layer_3': 0.28882603533066215, 'dropout_rate_Layer_4': 0.30773200590595734, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8068997418346406e-05, 'l1_Layer_2': 2.8063439749746653e-05, 'l1_Layer_3': 0.00015332529001846874, 'l1_Layer_4': 0.005242781782762284, 'n_units_Layer_1': 140, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175, 'n_units_Layer_4': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 14.92% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 17.65% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:27:07,277]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:27:26,925]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:27:57,987]\u001b[0m Trial 859 finished with value: 6.992517627728497 and parameters: {'n_hidden': 4, 'learning_rate': 0.007451401931778935, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.055737842880629294, 'dropout_rate_Layer_2': 0.3138676986181161, 'dropout_rate_Layer_3': 0.15423993442628806, 'dropout_rate_Layer_4': 0.002562661902729968, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1965475407260176e-05, 'l1_Layer_2': 0.0003244339319749664, 'l1_Layer_3': 0.004844394777000327, 'l1_Layer_4': 0.000286998011876941, 'n_units_Layer_1': 300, 'n_units_Layer_2': 90, 'n_units_Layer_3': 180, 'n_units_Layer_4': 160}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.99 | sMAPE for Validation Set is: 15.35% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 8.71 | sMAPE for Test Set is: 15.76% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:28:04,873]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:28:16,837]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:28:20,239]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:28:30,672]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:28:40,820]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:29:00,076]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:29:09,116]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:29:15,471]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:29:21,695]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:29:32,497]\u001b[0m Trial 860 finished with value: 6.924990830998625 and parameters: {'n_hidden': 4, 'learning_rate': 0.007506624298371816, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.053493441290783594, 'dropout_rate_Layer_2': 0.3117419062228046, 'dropout_rate_Layer_3': 0.13135278233220127, 'dropout_rate_Layer_4': 0.001408032541543809, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1879010109003628e-05, 'l1_Layer_2': 0.0003712155160901742, 'l1_Layer_3': 0.007285580906273996, 'l1_Layer_4': 0.00027150577822154245, 'n_units_Layer_1': 300, 'n_units_Layer_2': 90, 'n_units_Layer_3': 175, 'n_units_Layer_4': 130}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 15.14% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 9.09 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:29:52,991]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:29:57,779]\u001b[0m Trial 869 finished with value: 6.8103522625271395 and parameters: {'n_hidden': 4, 'learning_rate': 0.003941089744084695, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21503459969570832, 'dropout_rate_Layer_2': 0.029444665075413722, 'dropout_rate_Layer_3': 0.2705590365586151, 'dropout_rate_Layer_4': 0.33164383061728514, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.442152784181164e-05, 'l1_Layer_2': 9.514788246618157e-05, 'l1_Layer_3': 0.00011560456673305579, 'l1_Layer_4': 0.005010129653589649, 'n_units_Layer_1': 145, 'n_units_Layer_2': 240, 'n_units_Layer_3': 200, 'n_units_Layer_4': 165}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 15.38% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 19.89% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:30:07,309]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:30:10,002]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:30:31,351]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:30:37,534]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:30:58,832]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:31:04,359]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:31:10,735]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:31:19,419]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:31:25,373]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:31:31,200]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:31:34,396]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:31:43,361]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:31:43,786]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:31:44,558]\u001b[0m Trial 865 finished with value: 6.314015486129391 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006539970870322249, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10589158425798825, 'dropout_rate_Layer_2': 0.17011181270255143, 'dropout_rate_Layer_3': 0.015625318262025838, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002599777916840586, 'l1_Layer_2': 1.8227421358154297e-05, 'l1_Layer_3': 0.00013954065369373102, 'n_units_Layer_1': 95, 'n_units_Layer_2': 155, 'n_units_Layer_3': 110}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 14.31% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.08 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:31:54,947]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:31:58,633]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:31:58,791]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:32:07,864]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:32:10,805]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:32:20,966]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:32:30,239]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:32:44,944]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:33:31,162]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:33:55,246]\u001b[0m Trial 897 finished with value: 6.406114352504189 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005988045733763818, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10385359372234976, 'dropout_rate_Layer_2': 0.14402208979599296, 'dropout_rate_Layer_3': 0.035027547509404566, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019367366388916473, 'l1_Layer_2': 2.1885235511092224e-05, 'l1_Layer_3': 8.96240989980054e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 155, 'n_units_Layer_3': 115}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 14.67% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.01 | sMAPE for Test Set is: 16.67% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:34:18,305]\u001b[0m Trial 901 finished with value: 6.257344181448832 and parameters: {'n_hidden': 4, 'learning_rate': 0.001202818358115952, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07574469859915668, 'dropout_rate_Layer_2': 0.014685380697600718, 'dropout_rate_Layer_3': 0.29906400966142044, 'dropout_rate_Layer_4': 0.2020271983986276, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006838559679514316, 'l1_Layer_2': 3.415135760718717e-05, 'l1_Layer_3': 0.0026872274294982975, 'l1_Layer_4': 4.392612246377142e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 195, 'n_units_Layer_3': 170, 'n_units_Layer_4': 240}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 14.18% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.36 | sMAPE for Test Set is: 15.51% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:34:22,555]\u001b[0m Trial 898 finished with value: 7.170984714173294 and parameters: {'n_hidden': 4, 'learning_rate': 0.007855592502502631, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09717578653176796, 'dropout_rate_Layer_2': 0.3135192629043959, 'dropout_rate_Layer_3': 0.12037132692182981, 'dropout_rate_Layer_4': 0.04115684310322186, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.7761460803692538e-05, 'l1_Layer_2': 0.0006857945214635696, 'l1_Layer_3': 0.008124490334053595, 'l1_Layer_4': 0.00014648682117506066, 'n_units_Layer_1': 290, 'n_units_Layer_2': 75, 'n_units_Layer_3': 170, 'n_units_Layer_4': 140}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 15.71% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 8.65 | sMAPE for Test Set is: 15.62% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:34:28,380]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:34:33,296]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:34:41,878]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:34:42,240]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:34:49,862]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:34:54,920]\u001b[0m Trial 895 finished with value: 6.28164201133522 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006146193297418209, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10355320958574758, 'dropout_rate_Layer_2': 0.14654261511765165, 'dropout_rate_Layer_3': 0.03511016315244122, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002375743761557672, 'l1_Layer_2': 2.126149129837756e-05, 'l1_Layer_3': 9.058524430501346e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 155, 'n_units_Layer_3': 115}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.47 | sMAPE for Test Set is: 15.44% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:34:59,305]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:35:02,717]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:35:22,008]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.47 | sMAPE for Test Set is: 17.54% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:35:24,253]\u001b[0m Trial 900 finished with value: 6.411478384575585 and parameters: {'n_hidden': 3, 'learning_rate': 0.000552325191772469, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10183711036524896, 'dropout_rate_Layer_2': 0.14238286228920768, 'dropout_rate_Layer_3': 0.013155390209674364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020469616372416062, 'l1_Layer_2': 1.426084933954543e-05, 'l1_Layer_3': 3.575882483110845e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 100, 'n_units_Layer_3': 100}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:35:43,710]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:36:33,525]\u001b[0m Trial 911 finished with value: 6.452793664386152 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005942847405591878, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10477556161904955, 'dropout_rate_Layer_2': 0.14488174831796682, 'dropout_rate_Layer_3': 0.02772348572138304, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016844111423050168, 'l1_Layer_2': 2.3979610216460802e-05, 'l1_Layer_3': 6.806523918610653e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 155, 'n_units_Layer_3': 105}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.47 | sMAPE for Test Set is: 17.51% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:36:46,172]\u001b[0m Trial 907 finished with value: 6.434934179418801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006929540767245823, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10364969359594661, 'dropout_rate_Layer_2': 0.14747555029686366, 'dropout_rate_Layer_3': 0.03732616826930943, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024490932884401687, 'l1_Layer_2': 1.6246317433340925e-05, 'l1_Layer_3': 5.757209915852327e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 160, 'n_units_Layer_3': 120}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.60 | sMAPE for Test Set is: 17.86% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:37:11,919]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:37:22,284]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:37:32,584]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:37:37,188]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:37:42,686]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:37:54,905]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:38:03,160]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:38:08,370]\u001b[0m Trial 914 finished with value: 6.467164201740889 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005489486669625893, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11092695175692584, 'dropout_rate_Layer_2': 0.14690952016324058, 'dropout_rate_Layer_3': 0.00026777039050699704, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018639144642323074, 'l1_Layer_2': 1.311169846687621e-05, 'l1_Layer_3': 3.494757049505741e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 100, 'n_units_Layer_3': 110}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 16.20% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:38:20,526]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:38:31,967]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:38:56,212]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:39:00,273]\u001b[0m Trial 918 finished with value: 6.435578069864481 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005505705618606553, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09305973635344382, 'dropout_rate_Layer_2': 0.1456522426314328, 'dropout_rate_Layer_3': 0.014833414761039882, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013538991057814715, 'l1_Layer_2': 1.4359946285731949e-05, 'l1_Layer_3': 3.228348681048057e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 95}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 14.67% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.89 | sMAPE for Test Set is: 16.39% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:39:08,308]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:39:17,741]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:39:21,200]\u001b[0m Trial 921 finished with value: 6.492282285761344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007007762655143238, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11428890929134886, 'dropout_rate_Layer_2': 0.1448507564508701, 'dropout_rate_Layer_3': 0.0443319063691425, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017430557068825203, 'l1_Layer_2': 1.2008961323723568e-05, 'l1_Layer_3': 6.183371390394655e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 160, 'n_units_Layer_3': 85}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 14.77% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.81 | sMAPE for Test Set is: 16.19% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:39:24,465]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:39:29,157]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:40:56,708]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:41:00,318]\u001b[0m Trial 928 finished with value: 6.463539731535832 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005508725238350926, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09561807335625506, 'dropout_rate_Layer_2': 0.1453101587417693, 'dropout_rate_Layer_3': 0.003148508177261984, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001721682483388542, 'l1_Layer_2': 1.518930311546167e-05, 'l1_Layer_3': 2.5855387805297216e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 155, 'n_units_Layer_3': 90}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 14.68% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.87 | sMAPE for Test Set is: 18.47% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:41:03,622]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:41:06,427]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:41:09,486]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:41:09,994]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:41:49,703]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:41:54,822]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:42:01,679]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:42:33,352]\u001b[0m Trial 939 finished with value: 6.350373025750758 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006813843507419523, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09023393312270858, 'dropout_rate_Layer_2': 0.1342670173958507, 'dropout_rate_Layer_3': 0.0012923020893140062, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014081465237604664, 'l1_Layer_2': 1.3155218099044835e-05, 'l1_Layer_3': 3.0061872264227392e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 160, 'n_units_Layer_3': 90}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 14.26% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.53 | sMAPE for Test Set is: 15.46% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:42:45,483]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:42:55,213]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:43:26,141]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:43:38,846]\u001b[0m Trial 938 finished with value: 7.030101982854599 and parameters: {'n_hidden': 4, 'learning_rate': 0.007961501793705427, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028913248226390548, 'dropout_rate_Layer_2': 0.3125686021497218, 'dropout_rate_Layer_3': 0.12188720382627302, 'dropout_rate_Layer_4': 0.018832612113681556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.0401289181460658e-05, 'l1_Layer_2': 0.00014988670725184198, 'l1_Layer_3': 0.006794333148016845, 'l1_Layer_4': 0.0001406537161514413, 'n_units_Layer_1': 300, 'n_units_Layer_2': 90, 'n_units_Layer_3': 165, 'n_units_Layer_4': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.03 | sMAPE for Validation Set is: 15.32% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 8.84 | sMAPE for Test Set is: 16.04% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:44:22,609]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:44:33,681]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:44:56,617]\u001b[0m Trial 946 finished with value: 6.482769837219621 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005839423721435039, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08452436000674413, 'dropout_rate_Layer_2': 0.14625775523458268, 'dropout_rate_Layer_3': 0.008424128270495351, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017418072864360863, 'l1_Layer_2': 1.5904833820699476e-05, 'l1_Layer_3': 2.9277083044643273e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 155, 'n_units_Layer_3': 90}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.48 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.96 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:45:06,071]\u001b[0m Trial 945 finished with value: 6.38696095968758 and parameters: {'n_hidden': 3, 'learning_rate': 0.00060583911157712, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11028259085517061, 'dropout_rate_Layer_2': 0.11893181636370792, 'dropout_rate_Layer_3': 0.00020909434571625939, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016116590208004096, 'l1_Layer_2': 1.4405960749828394e-05, 'l1_Layer_3': 2.9772697862593114e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 160, 'n_units_Layer_3': 85}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.99 | sMAPE for Test Set is: 16.84% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:45:16,453]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:45:23,928]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:45:43,226]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:46:14,209]\u001b[0m Trial 949 finished with value: 6.369478746082085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005517727571618903, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08187274254498572, 'dropout_rate_Layer_2': 0.14586230197980882, 'dropout_rate_Layer_3': 0.00985920767333222, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001966126591084006, 'l1_Layer_2': 1.5807531904283337e-05, 'l1_Layer_3': 2.107329557820359e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 160, 'n_units_Layer_3': 90}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 14.35% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.49 | sMAPE for Test Set is: 15.63% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:46:37,196]\u001b[0m Trial 950 finished with value: 6.486242552669354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005482893341215932, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08501845016164626, 'dropout_rate_Layer_2': 0.1451015249668699, 'dropout_rate_Layer_3': 0.010817462292280377, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018161169563403565, 'l1_Layer_2': 1.728362227440313e-05, 'l1_Layer_3': 2.4746145885476517e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 155, 'n_units_Layer_3': 90}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 14.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.01 | sMAPE for Test Set is: 16.77% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:46:41,988]\u001b[0m Trial 951 finished with value: 6.411675993930028 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006894663861993856, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07910216513795569, 'dropout_rate_Layer_2': 0.142803205946633, 'dropout_rate_Layer_3': 0.00855323985014406, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019731293552504258, 'l1_Layer_2': 1.6479724033968054e-05, 'l1_Layer_3': 2.2333338749402943e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 160, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.78 | sMAPE for Test Set is: 15.90% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:46:55,359]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:46:59,080]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:47:03,543]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:47:20,501]\u001b[0m Trial 954 finished with value: 6.503297962942601 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007219110683552794, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08257126220138913, 'dropout_rate_Layer_2': 0.14342536171882536, 'dropout_rate_Layer_3': 0.007214911297237981, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001808034297112265, 'l1_Layer_2': 1.4985205411230195e-05, 'l1_Layer_3': 2.8652269564571897e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 160, 'n_units_Layer_3': 90}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.81 | sMAPE for Test Set is: 18.25% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:47:24,000]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:47:36,084]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:47:47,739]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:48:25,255]\u001b[0m Trial 957 finished with value: 6.321131667118498 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005510553630817813, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08200573862138673, 'dropout_rate_Layer_2': 0.1245488493380337, 'dropout_rate_Layer_3': 0.008449096686222995, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000180810102008305, 'l1_Layer_2': 1.5410431057771332e-05, 'l1_Layer_3': 1.821522592887749e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:48:32,911]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:48:53,017]\u001b[0m Trial 959 finished with value: 7.190965280914661 and parameters: {'n_hidden': 4, 'learning_rate': 0.011850526465684358, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05072085781438639, 'dropout_rate_Layer_2': 0.3095248488575421, 'dropout_rate_Layer_3': 0.12583388570635265, 'dropout_rate_Layer_4': 0.04999359600425195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8615592809717348e-05, 'l1_Layer_2': 0.00019731229106482114, 'l1_Layer_3': 0.004450529310406874, 'l1_Layer_4': 9.05919683957384e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 80, 'n_units_Layer_3': 170, 'n_units_Layer_4': 130}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 15.62% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 8.98 | sMAPE for Test Set is: 16.22% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:48:57,412]\u001b[0m Trial 961 finished with value: 6.376946768711843 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006812319054519286, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07150422271171408, 'dropout_rate_Layer_2': 0.12997983650154601, 'dropout_rate_Layer_3': 0.010820371504106141, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001287357194357122, 'l1_Layer_2': 1.7700128489915552e-05, 'l1_Layer_3': 2.7693607067405657e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 80}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 16.55% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:49:10,279]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:49:19,886]\u001b[0m Trial 967 finished with value: 8.239540440840871 and parameters: {'n_hidden': 3, 'learning_rate': 0.009551787437975493, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2181640840510155, 'dropout_rate_Layer_2': 0.08455266646757803, 'dropout_rate_Layer_3': 0.21462506714529378, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 7.07140422288649e-05, 'l1_Layer_2': 0.08613227124443941, 'l1_Layer_3': 0.0013847722634168828, 'n_units_Layer_1': 85, 'n_units_Layer_2': 235, 'n_units_Layer_3': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.24 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 21.63% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:49:31,156]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:49:33,867]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:49:43,379]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:49:51,989]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.00 | sMAPE for Test Set is: 16.48% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:49:53,415]\u001b[0m Trial 964 finished with value: 6.398139858327986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007082333490747784, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06411159809340822, 'dropout_rate_Layer_2': 0.12712241736787896, 'dropout_rate_Layer_3': 0.01400283508567832, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016748716160868983, 'l1_Layer_2': 1.540927117376402e-05, 'l1_Layer_3': 2.992595872973681e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 85}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:49:54,768]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:50:11,681]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:50:12,060]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:50:16,483]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:50:31,448]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:50:40,573]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:51:05,428]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:51:16,719]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:51:22,286]\u001b[0m Trial 981 finished with value: 6.370469044822111 and parameters: {'n_hidden': 4, 'learning_rate': 0.002814528981402084, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10328616447034561, 'dropout_rate_Layer_2': 0.04862987110019974, 'dropout_rate_Layer_3': 0.3061223152064134, 'dropout_rate_Layer_4': 8.969440025119457e-05, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00036074042731128425, 'l1_Layer_2': 1.4747245008074794e-05, 'l1_Layer_3': 0.002450689918551255, 'l1_Layer_4': 0.0018633528575876931, 'n_units_Layer_1': 120, 'n_units_Layer_2': 215, 'n_units_Layer_3': 290, 'n_units_Layer_4': 270}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 14.53% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.15 | sMAPE for Test Set is: 17.04% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:51:26,815]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:51:31,641]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:51:38,285]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:51:38,856]\u001b[0m Trial 975 finished with value: 6.312322548594554 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005008383568541509, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09110845922629685, 'dropout_rate_Layer_2': 0.12033135131553742, 'dropout_rate_Layer_3': 0.008562790558794922, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024059672029589136, 'l1_Layer_2': 1.677702042101035e-05, 'l1_Layer_3': 3.013882553844278e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 14.43% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 15.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:51:48,733]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:51:48,955]\u001b[0m Trial 978 finished with value: 6.418320042412152 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005514305437151286, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052998393247837235, 'dropout_rate_Layer_2': 0.11994983103354277, 'dropout_rate_Layer_3': 0.009605808099010316, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022510685896881677, 'l1_Layer_2': 1.6787509923171332e-05, 'l1_Layer_3': 3.7686950370806084e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.02 | sMAPE for Test Set is: 16.74% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:51:49,368]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:52:09,824]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:52:12,830]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:52:13,645]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:52:23,684]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:52:31,304]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:52:36,364]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:52:43,025]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:53:17,667]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:53:21,866]\u001b[0m Trial 987 finished with value: 6.304265753241668 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007271838545770641, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052564943955307225, 'dropout_rate_Layer_2': 0.10230523859289481, 'dropout_rate_Layer_3': 0.006196359973387041, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000266267793509721, 'l1_Layer_2': 1.2237035300539738e-05, 'l1_Layer_3': 2.4535858041951548e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 170, 'n_units_Layer_3': 80}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 14.30% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.93 | sMAPE for Test Set is: 16.54% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:53:25,431]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:53:52,994]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:53:58,082]\u001b[0m Trial 998 finished with value: 6.923139510252401 and parameters: {'n_hidden': 4, 'learning_rate': 0.011439167425705108, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07617273754694123, 'dropout_rate_Layer_2': 0.31034541105716656, 'dropout_rate_Layer_3': 0.11606242198659723, 'dropout_rate_Layer_4': 0.029338047610827048, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.287790126958389e-05, 'l1_Layer_2': 0.00015412827376639986, 'l1_Layer_3': 0.009364930075474445, 'l1_Layer_4': 0.00020373756120980392, 'n_units_Layer_1': 295, 'n_units_Layer_2': 80, 'n_units_Layer_3': 175, 'n_units_Layer_4': 160}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 15.72% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 9.79 | sMAPE for Test Set is: 17.73% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:54:01,926]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:54:08,311]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:54:13,288]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:54:22,165]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 14.62% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.70 | sMAPE for Test Set is: 16.13% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:54:24,908]\u001b[0m Trial 994 finished with value: 6.4617584203652605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006247150575570126, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06417943467158388, 'dropout_rate_Layer_2': 0.1017951141610893, 'dropout_rate_Layer_3': 0.017902326868077804, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015879372280703152, 'l1_Layer_2': 1.498919568668242e-05, 'l1_Layer_3': 3.0551070385448676e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:54:28,203]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:54:33,827]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:54:36,860]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:54:39,673]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:54:48,972]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:54:58,131]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:56:11,556]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:56:23,234]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:56:48,559]\u001b[0m Trial 1010 finished with value: 6.312257189488721 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007518641960962933, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04807262148131156, 'dropout_rate_Layer_2': 0.0932665014718119, 'dropout_rate_Layer_3': 0.01737081277116769, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00028045470791611047, 'l1_Layer_2': 2.0022513139606767e-05, 'l1_Layer_3': 1.9539230823006966e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 170, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.35 | sMAPE for Test Set is: 17.31% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:58:49,656]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:59:00,032]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:59:07,716]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 20:59:29,155]\u001b[0m Trial 1014 finished with value: 6.8110181119011335 and parameters: {'n_hidden': 4, 'learning_rate': 0.011235407435154273, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07294608782176075, 'dropout_rate_Layer_2': 0.33204784243751023, 'dropout_rate_Layer_3': 0.13160039072323262, 'dropout_rate_Layer_4': 0.04212030342955468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.599034709179608e-05, 'l1_Layer_2': 0.00014302797842896044, 'l1_Layer_3': 0.0023328688004013074, 'l1_Layer_4': 0.00014097058117835108, 'n_units_Layer_1': 285, 'n_units_Layer_2': 75, 'n_units_Layer_3': 180, 'n_units_Layer_4': 165}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 15.31% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.62 | sMAPE for Test Set is: 15.64% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 20:59:40,447]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:00:05,646]\u001b[0m Trial 1017 finished with value: 6.9401452709887055 and parameters: {'n_hidden': 4, 'learning_rate': 0.009313743238839035, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0711271047854782, 'dropout_rate_Layer_2': 0.3067681832821135, 'dropout_rate_Layer_3': 0.1296397453093457, 'dropout_rate_Layer_4': 0.014358366120099764, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0040330908453285e-05, 'l1_Layer_2': 0.0004473146417204283, 'l1_Layer_3': 0.007845893105867854, 'l1_Layer_4': 0.00010463818215361565, 'n_units_Layer_1': 295, 'n_units_Layer_2': 65, 'n_units_Layer_3': 160, 'n_units_Layer_4': 155}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.94 | sMAPE for Validation Set is: 15.35% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.67 | sMAPE for Test Set is: 15.71% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:00:15,604]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:00:21,931]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:00:28,631]\u001b[0m Trial 1019 finished with value: 6.407055766826677 and parameters: {'n_hidden': 3, 'learning_rate': 0.00076893160480821, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06637924695581934, 'dropout_rate_Layer_2': 0.098660542847177, 'dropout_rate_Layer_3': 0.017504271266936752, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003076172186679184, 'l1_Layer_2': 2.1770962013554124e-05, 'l1_Layer_3': 2.0819702816601383e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 175, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 14.43% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.47 | sMAPE for Test Set is: 15.59% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:00:32,942]\u001b[0m Trial 1020 finished with value: 6.547759867695679 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006225942779834605, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2354157509439428, 'dropout_rate_Layer_2': 0.062021237509354746, 'dropout_rate_Layer_3': 0.31911947386518347, 'dropout_rate_Layer_4': 0.26800653780219663, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0466543898324173e-05, 'l1_Layer_2': 6.704869808419073e-05, 'l1_Layer_3': 0.0003196023264533453, 'l1_Layer_4': 0.0011247982251084588, 'n_units_Layer_1': 190, 'n_units_Layer_2': 230, 'n_units_Layer_3': 170, 'n_units_Layer_4': 140}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 14.87% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.62 | sMAPE for Test Set is: 17.77% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:00:35,599]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:00:47,046]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:00:57,717]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:01:06,085]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:01:14,163]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:01:46,827]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:01:47,212]\u001b[0m Trial 1028 finished with value: 6.7595062399976085 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009925274900215754, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1923632819050026, 'dropout_rate_Layer_2': 0.06787662602359784, 'dropout_rate_Layer_3': 0.31426761906451056, 'dropout_rate_Layer_4': 0.27066028341726944, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.8434435773241936e-05, 'l1_Layer_2': 8.990864318949951e-05, 'l1_Layer_3': 0.000780331713834482, 'l1_Layer_4': 0.001098225059030206, 'n_units_Layer_1': 140, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160, 'n_units_Layer_4': 135}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.14 | sMAPE for Test Set is: 18.59% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:01:56,037]\u001b[0m Trial 1023 finished with value: 6.608554343688866 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006278802364807991, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2356492075275862, 'dropout_rate_Layer_2': 0.06637818302233248, 'dropout_rate_Layer_3': 0.31787243047890607, 'dropout_rate_Layer_4': 0.2750738898731965, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0308791289673475e-05, 'l1_Layer_2': 6.444660303893243e-05, 'l1_Layer_3': 0.0003549235435607345, 'l1_Layer_4': 0.003973393086658358, 'n_units_Layer_1': 115, 'n_units_Layer_2': 235, 'n_units_Layer_3': 170, 'n_units_Layer_4': 140}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 14.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.99 | sMAPE for Test Set is: 18.45% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:01:58,832]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:01:59,653]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:02:06,662]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:02:12,596]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:02:21,946]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:02:34,044]\u001b[0m Trial 1027 finished with value: 6.405509690261641 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007894650621395001, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052178072070646245, 'dropout_rate_Layer_2': 0.12266626000986952, 'dropout_rate_Layer_3': 0.010883288708154863, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00038135325559940787, 'l1_Layer_2': 2.286940804237819e-05, 'l1_Layer_3': 1.341161340047157e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 65}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.95 | sMAPE for Test Set is: 16.61% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:02:52,082]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:02:54,124]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:03:20,986]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:03:21,493]\u001b[0m Trial 1038 finished with value: 6.449851730868802 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006713976194769876, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09067229873649428, 'dropout_rate_Layer_2': 0.12020509468341643, 'dropout_rate_Layer_3': 0.00776038693855487, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011946618879827253, 'l1_Layer_2': 1.807860184082304e-05, 'l1_Layer_3': 3.218076644593213e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 170, 'n_units_Layer_3': 80}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.53 | sMAPE for Test Set is: 15.69% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:03:30,576]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:03:39,965]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:03:48,620]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:03:54,068]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:04:03,627]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:04:24,206]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:04:24,359]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:04:55,781]\u001b[0m Trial 1042 finished with value: 6.593197787762577 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006509425697183342, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28350616840563064, 'dropout_rate_Layer_2': 0.017195875823931665, 'dropout_rate_Layer_3': 0.3279651139190818, 'dropout_rate_Layer_4': 0.3105418958862264, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.729821735346721e-05, 'l1_Layer_2': 0.000712239924124024, 'l1_Layer_3': 0.00021153425027128073, 'l1_Layer_4': 0.0003459875366703356, 'n_units_Layer_1': 120, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185, 'n_units_Layer_4': 190}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 14.83% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.60 | sMAPE for Test Set is: 17.72% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:05:07,469]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:05:10,387]\u001b[0m Trial 1044 finished with value: 6.4562445827302986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008593857748239967, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05477748993899974, 'dropout_rate_Layer_2': 0.12209502356933082, 'dropout_rate_Layer_3': 0.007253602015930612, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00028224302744710736, 'l1_Layer_2': 1.6900358468242297e-05, 'l1_Layer_3': 1.0009378039747415e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 65}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.29 | sMAPE for Test Set is: 17.09% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:05:19,305]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:05:22,231]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:05:22,654]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:05:28,034]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:05:32,113]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:05:47,329]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:05:56,840]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:06:01,807]\u001b[0m Trial 1060 finished with value: 6.532670087778814 and parameters: {'n_hidden': 3, 'learning_rate': 0.005705554423573832, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12059757441964622, 'dropout_rate_Layer_2': 0.10549456253733008, 'dropout_rate_Layer_3': 0.3836072478724927, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.654387844507959e-05, 'l1_Layer_2': 0.0002365928920498591, 'l1_Layer_3': 0.0022469953894086537, 'n_units_Layer_1': 65, 'n_units_Layer_2': 235, 'n_units_Layer_3': 240}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 14.76% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 15.11% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:06:14,852]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:06:36,724]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:07:22,176]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:07:29,746]\u001b[0m Trial 1063 finished with value: 6.373783125109289 and parameters: {'n_hidden': 3, 'learning_rate': 0.000815958495306103, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04581899705200885, 'dropout_rate_Layer_2': 0.098327045408945, 'dropout_rate_Layer_3': 0.00036480001072773053, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.64368435983904e-05, 'l1_Layer_2': 1.1166141310157167e-05, 'l1_Layer_3': 2.4239073796066588e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 14.21% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.34 | sMAPE for Test Set is: 17.15% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:07:49,738]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:07:59,097]\u001b[0m Trial 1065 finished with value: 6.483231386201563 and parameters: {'n_hidden': 3, 'learning_rate': 0.00064411079084005, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04596453732401551, 'dropout_rate_Layer_2': 0.1110909284034394, 'dropout_rate_Layer_3': 0.014524497017735522, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023682528531563044, 'l1_Layer_2': 1.1476093031849876e-05, 'l1_Layer_3': 1.748439008486081e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 165, 'n_units_Layer_3': 85}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.48 | sMAPE for Validation Set is: 14.90% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.29 | sMAPE for Test Set is: 17.35% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:08:45,236]\u001b[0m Trial 1054 finished with value: 6.557938463723414 and parameters: {'n_hidden': 4, 'learning_rate': 0.0067189445655216435, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02672876355979397, 'dropout_rate_Layer_2': 0.31749104591845395, 'dropout_rate_Layer_3': 0.12517319571179908, 'dropout_rate_Layer_4': 0.010690528021142846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.7086868769027582e-05, 'l1_Layer_2': 0.00022212942885537206, 'l1_Layer_3': 0.003102690823832532, 'l1_Layer_4': 8.667410155169188e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 75, 'n_units_Layer_3': 170, 'n_units_Layer_4': 145}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 14.76% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.13 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:09:13,220]\u001b[0m Trial 1066 finished with value: 6.401960063420193 and parameters: {'n_hidden': 3, 'learning_rate': 0.000651481916585065, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.048614508441991396, 'dropout_rate_Layer_2': 0.11033280206513864, 'dropout_rate_Layer_3': 0.0004999448265476884, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010622669007137794, 'l1_Layer_2': 1.1025936984858393e-05, 'l1_Layer_3': 2.3514940977857908e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 165, 'n_units_Layer_3': 85}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.81 | sMAPE for Test Set is: 16.30% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:09:18,917]\u001b[0m Trial 1069 finished with value: 6.304521371416983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008786320578712153, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024961239258465388, 'dropout_rate_Layer_2': 0.0819186776212911, 'dropout_rate_Layer_3': 0.0024966367562983794, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019461386638223337, 'l1_Layer_2': 1.0779860165843419e-05, 'l1_Layer_3': 2.513765643777701e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 14.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.64 | sMAPE for Test Set is: 15.92% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:09:25,333]\u001b[0m Trial 1068 finished with value: 6.322955958496924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008663900542757173, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045803355901214045, 'dropout_rate_Layer_2': 0.09791785161177645, 'dropout_rate_Layer_3': 0.0010821287600326947, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023897713148043136, 'l1_Layer_2': 1.1122154350835386e-05, 'l1_Layer_3': 1.7136647951734293e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 165, 'n_units_Layer_3': 60}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 16.37% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:09:35,865]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:09:48,796]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:10:04,569]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:10:23,017]\u001b[0m Trial 1070 finished with value: 6.306958843689389 and parameters: {'n_hidden': 3, 'learning_rate': 0.000880206740610728, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.036255082661450666, 'dropout_rate_Layer_2': 0.08492551231745925, 'dropout_rate_Layer_3': 0.004766325521052337, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010300088917030361, 'l1_Layer_2': 1.0919697865346487e-05, 'l1_Layer_3': 2.3657650680672927e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 14.25% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 16.04% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:10:33,662]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:10:37,471]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:10:45,408]\u001b[0m Trial 1072 finished with value: 6.436738221845147 and parameters: {'n_hidden': 3, 'learning_rate': 0.000949076471847134, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.059657585497459156, 'dropout_rate_Layer_2': 0.07822385711593653, 'dropout_rate_Layer_3': 0.0006530617917574685, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003237165609264136, 'l1_Layer_2': 1.1056125055298033e-05, 'l1_Layer_3': 2.323786063398369e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.44 | sMAPE for Test Set is: 15.52% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:10:56,277]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:11:31,092]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:11:37,490]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:12:05,128]\u001b[0m Trial 1076 finished with value: 6.361050232961856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008817624221551478, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03138204003001691, 'dropout_rate_Layer_2': 0.07664868788168512, 'dropout_rate_Layer_3': 0.0022844050066818953, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.704311584385536e-05, 'l1_Layer_2': 1.071942689052264e-05, 'l1_Layer_3': 1.4635303379897745e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 14.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.96 | sMAPE for Test Set is: 16.30% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:12:34,796]\u001b[0m Trial 1078 finished with value: 6.288499232799203 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010329499680510534, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.043279098695475096, 'dropout_rate_Layer_2': 0.08298415004371718, 'dropout_rate_Layer_3': 0.0018878923641538203, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.382177550963669e-05, 'l1_Layer_2': 1.1932401893735e-05, 'l1_Layer_3': 2.2553817399333196e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 175, 'n_units_Layer_3': 50}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.49 | sMAPE for Test Set is: 17.58% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:12:37,485]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:12:44,332]\u001b[0m Trial 1084 finished with value: 9.301209844131042 and parameters: {'n_hidden': 4, 'learning_rate': 0.09659911013046521, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35522986800753487, 'dropout_rate_Layer_2': 0.1304416493275667, 'dropout_rate_Layer_3': 0.39867097011458524, 'dropout_rate_Layer_4': 0.23267008279789034, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.424957679150583e-05, 'l1_Layer_2': 0.0002652186491160386, 'l1_Layer_3': 0.00021608427934100835, 'l1_Layer_4': 0.0003896964247381786, 'n_units_Layer_1': 115, 'n_units_Layer_2': 185, 'n_units_Layer_3': 145, 'n_units_Layer_4': 185}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.30 | sMAPE for Validation Set is: 20.37% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 10.35 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:12:50,923]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:12:51,310]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:12:58,191]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:13:13,845]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:13:17,997]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:13:22,209]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:13:30,540]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:14:14,189]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:14:27,808]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:14:35,244]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:15:00,306]\u001b[0m Trial 1089 finished with value: 6.357117215681342 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010364587439399664, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.033545412884929536, 'dropout_rate_Layer_2': 0.07094638997655545, 'dropout_rate_Layer_3': 0.00021036194142032326, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.157900721868696e-05, 'l1_Layer_2': 1.0060104227436013e-05, 'l1_Layer_3': 1.2576401933914223e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 180, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.03 | sMAPE for Test Set is: 15.89% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:16:00,081]\u001b[0m Trial 1098 finished with value: 6.4905448616549934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010128207723741943, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025929322376218696, 'dropout_rate_Layer_2': 0.07506096175450087, 'dropout_rate_Layer_3': 0.0014562500524040612, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.96895783097724e-05, 'l1_Layer_2': 1.2014611853609874e-05, 'l1_Layer_3': 1.1363236321355357e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 180, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 14.83% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.44 | sMAPE for Test Set is: 17.62% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:16:18,619]\u001b[0m Trial 1096 finished with value: 6.299537143405367 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009087976449854771, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04039111845823318, 'dropout_rate_Layer_2': 0.07660468436564298, 'dropout_rate_Layer_3': 0.0006840626429087445, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010801106166368724, 'l1_Layer_2': 1.1731684527428146e-05, 'l1_Layer_3': 1.637980657030489e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 180, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 14.29% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.79 | sMAPE for Test Set is: 18.38% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:16:22,071]\u001b[0m Trial 1097 finished with value: 6.487592108160868 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009908307221776005, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024072811814295707, 'dropout_rate_Layer_2': 0.08111659826093233, 'dropout_rate_Layer_3': 0.0002628920430515309, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010569707616445896, 'l1_Layer_2': 1.2259825944982068e-05, 'l1_Layer_3': 1.854298833710483e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 180, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 14.53% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.82 | sMAPE for Test Set is: 16.11% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:16:28,859]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:16:43,413]\u001b[0m Trial 1093 finished with value: 6.585196682993925 and parameters: {'n_hidden': 4, 'learning_rate': 0.006457984664072748, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07943939365156445, 'dropout_rate_Layer_2': 0.31454605724263085, 'dropout_rate_Layer_3': 0.13083824127737123, 'dropout_rate_Layer_4': 0.037553740327034464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.198877681598047e-05, 'l1_Layer_2': 0.00014426582746789767, 'l1_Layer_3': 0.00821973386508917, 'l1_Layer_4': 0.00020109565035875306, 'n_units_Layer_1': 285, 'n_units_Layer_2': 95, 'n_units_Layer_3': 175, 'n_units_Layer_4': 150}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 14.93% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 15.92% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:16:49,255]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:17:06,733]\u001b[0m Trial 1101 finished with value: 6.407140522646948 and parameters: {'n_hidden': 4, 'learning_rate': 0.00157684861505959, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11597137314916638, 'dropout_rate_Layer_2': 0.052321792514068946, 'dropout_rate_Layer_3': 0.2890228612312141, 'dropout_rate_Layer_4': 0.24847714929841644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00034163568186158425, 'l1_Layer_2': 1.3945488900813588e-05, 'l1_Layer_3': 0.0030190953232964173, 'l1_Layer_4': 2.086954351282875e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 55, 'n_units_Layer_3': 205, 'n_units_Layer_4': 280}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.21 | sMAPE for Test Set is: 14.79% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:17:07,023]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:17:20,239]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:17:26,129]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:17:37,571]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:18:02,374]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:18:23,274]\u001b[0m Trial 1102 finished with value: 6.34438811224932 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011032904260953593, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00985732765835079, 'dropout_rate_Layer_2': 0.08552298104262265, 'dropout_rate_Layer_3': 0.007699109346487585, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.44603992827765e-05, 'l1_Layer_2': 1.021026685345171e-05, 'l1_Layer_3': 1.5580598227828213e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 185, 'n_units_Layer_3': 60}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 14.18% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.33 | sMAPE for Test Set is: 15.05% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:18:26,975]\u001b[0m Trial 1106 finished with value: 6.42130904776202 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010296136201396141, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.033218393086702915, 'dropout_rate_Layer_2': 0.09293359302376587, 'dropout_rate_Layer_3': 0.007309848519229591, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.374411182578872e-05, 'l1_Layer_2': 1.0005910731111832e-05, 'l1_Layer_3': 1.709748985810585e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 60}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.65 | sMAPE for Test Set is: 15.86% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:19:26,739]\u001b[0m Trial 1110 finished with value: 6.330554045423226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008958267633443737, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009396161884989946, 'dropout_rate_Layer_2': 0.06433549584076084, 'dropout_rate_Layer_3': 0.008633206467945458, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.834603617199897e-05, 'l1_Layer_2': 1.0006194027698734e-05, 'l1_Layer_3': 2.4726754747660058e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 175, 'n_units_Layer_3': 65}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 14.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.34 | sMAPE for Test Set is: 15.25% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:19:50,983]\u001b[0m Trial 1111 finished with value: 6.326620948483378 and parameters: {'n_hidden': 3, 'learning_rate': 0.00107617919146664, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010953361224724786, 'dropout_rate_Layer_2': 0.06371970765332322, 'dropout_rate_Layer_3': 0.008727054194826032, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.672143361549041e-05, 'l1_Layer_2': 1.0117481651007557e-05, 'l1_Layer_3': 2.331514283455268e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.41 | sMAPE for Test Set is: 15.15% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:20:04,319]\u001b[0m Trial 1103 finished with value: 6.882063722335204 and parameters: {'n_hidden': 4, 'learning_rate': 0.005580160144739691, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08933520417451306, 'dropout_rate_Layer_2': 0.2903479386655397, 'dropout_rate_Layer_3': 0.13389873368225957, 'dropout_rate_Layer_4': 0.018944404186530577, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3911885257897535e-05, 'l1_Layer_2': 0.00017892395259391772, 'l1_Layer_3': 0.0091832907683668, 'l1_Layer_4': 0.0001567100117157162, 'n_units_Layer_1': 280, 'n_units_Layer_2': 90, 'n_units_Layer_3': 160, 'n_units_Layer_4': 160}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 15.09% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.85 | sMAPE for Test Set is: 16.13% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:20:11,152]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:20:51,972]\u001b[0m Trial 1113 finished with value: 6.401568193466747 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009562968448744754, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01938676763420661, 'dropout_rate_Layer_2': 0.06739607523318383, 'dropout_rate_Layer_3': 0.011842397600360616, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.770423585370645e-05, 'l1_Layer_2': 1.2994656656496165e-05, 'l1_Layer_3': 2.411257132420951e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.12 | sMAPE for Test Set is: 18.78% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:21:05,871]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:21:15,748]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:21:22,636]\u001b[0m Trial 1116 finished with value: 6.42517050359946 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012769196926566968, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0052343087770690445, 'dropout_rate_Layer_2': 0.0724761235401728, 'dropout_rate_Layer_3': 0.007659743808294678, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.066101064014201e-05, 'l1_Layer_2': 1.299530357117802e-05, 'l1_Layer_3': 2.0655881313335032e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 185, 'n_units_Layer_3': 50}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.72 | sMAPE for Test Set is: 15.79% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:21:35,401]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:21:41,291]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:22:11,258]\u001b[0m Trial 1112 finished with value: 6.715999346534187 and parameters: {'n_hidden': 4, 'learning_rate': 0.006156938666576655, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08702371226022057, 'dropout_rate_Layer_2': 0.2994866909945672, 'dropout_rate_Layer_3': 0.16174054163349794, 'dropout_rate_Layer_4': 0.02897314205604351, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3386669196978854e-05, 'l1_Layer_2': 0.00018275834101936646, 'l1_Layer_3': 0.009376138102086465, 'l1_Layer_4': 0.000246934430758833, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 170, 'n_units_Layer_4': 135}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.72 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.05 | sMAPE for Test Set is: 16.48% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:22:17,700]\u001b[0m Trial 1115 finished with value: 6.376155711334732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011526535348327855, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010136155369547243, 'dropout_rate_Layer_2': 0.06489118968390883, 'dropout_rate_Layer_3': 0.007860234804207493, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.545640253608502e-05, 'l1_Layer_2': 1.010076106214695e-05, 'l1_Layer_3': 2.0290905357349976e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.43% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.18 | sMAPE for Test Set is: 21.16% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:22:31,132]\u001b[0m Trial 1123 finished with value: 8.433028260467218 and parameters: {'n_hidden': 3, 'learning_rate': 0.026641093270920686, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2594889786703406, 'dropout_rate_Layer_2': 0.17708234892645106, 'dropout_rate_Layer_3': 0.04717673589910873, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.009146874025643e-05, 'l1_Layer_2': 0.025052181284269677, 'l1_Layer_3': 0.0019080415553400392, 'n_units_Layer_1': 85, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.43 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 12.21 | sMAPE for Test Set is: 22.14% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:23:26,178]\u001b[0m Trial 1122 finished with value: 6.335567975914455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010630648609468226, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015450147350899314, 'dropout_rate_Layer_2': 0.08652633747371692, 'dropout_rate_Layer_3': 0.014318214215315282, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011177181118798362, 'l1_Layer_2': 1.2467690501266631e-05, 'l1_Layer_3': 1.563599900472588e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 14.35% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.47 | sMAPE for Test Set is: 17.52% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:23:34,782]\u001b[0m Trial 1124 finished with value: 6.430252268309921 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011273792279342392, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00914500837105624, 'dropout_rate_Layer_2': 0.0638806047085647, 'dropout_rate_Layer_3': 0.008089658673635598, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011864862409546203, 'l1_Layer_2': 1.2251091738935066e-05, 'l1_Layer_3': 1.4906877810945044e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 14.43% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.73 | sMAPE for Test Set is: 15.96% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:23:44,514]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:23:45,962]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:23:47,289]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:23:48,243]\u001b[0m Trial 1125 finished with value: 6.442381235718504 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011263389659138556, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010168953543934052, 'dropout_rate_Layer_2': 0.05742032338612384, 'dropout_rate_Layer_3': 0.0007454352951443623, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011768104585819028, 'l1_Layer_2': 1.0126603381978751e-05, 'l1_Layer_3': 1.6022823023999413e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 14.28% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.57 | sMAPE for Test Set is: 15.33% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:23:56,586]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:24:00,509]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:24:10,362]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:24:12,992]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:24:13,781]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:24:17,937]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:24:27,495]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:24:38,210]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:24:50,750]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:25:01,089]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:25:09,792]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:25:12,678]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:25:29,318]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:25:40,759]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:25:49,502]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:25:59,431]\u001b[0m Trial 1137 finished with value: 6.445437359712199 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012415262056151668, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029459933701728003, 'dropout_rate_Layer_2': 0.06848342154327712, 'dropout_rate_Layer_3': 0.008186716005416237, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.917567688498121e-05, 'l1_Layer_2': 1.0034801298941641e-05, 'l1_Layer_3': 1.888287547841622e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.64 | sMAPE for Test Set is: 15.80% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:26:10,787]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:26:14,723]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:26:22,330]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:26:22,510]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:26:42,737]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.22 | sMAPE for Test Set is: 15.09% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:26:45,006]\u001b[0m Trial 1149 finished with value: 6.329913952781279 and parameters: {'n_hidden': 4, 'learning_rate': 0.002131553274692212, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08262976965757793, 'dropout_rate_Layer_2': 0.06369402886257022, 'dropout_rate_Layer_3': 0.2670322022132614, 'dropout_rate_Layer_4': 0.22646843284686094, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.000880551878784453, 'l1_Layer_2': 1.9544718154706243e-05, 'l1_Layer_3': 0.0013596426017354341, 'l1_Layer_4': 3.647287798126881e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 55, 'n_units_Layer_3': 195, 'n_units_Layer_4': 255}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:26:51,531]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:26:57,344]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:26:58,640]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:27:05,966]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:27:10,750]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:27:28,943]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:27:47,212]\u001b[0m Trial 1150 finished with value: 6.392529603160736 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011046864489038595, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010019260093680314, 'dropout_rate_Layer_2': 0.08590675225529044, 'dropout_rate_Layer_3': 0.01943127977246569, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.467443565237069e-05, 'l1_Layer_2': 1.1598609260302148e-05, 'l1_Layer_3': 1.5494134593778022e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.72 | sMAPE for Test Set is: 16.01% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:27:50,973]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:27:57,406]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:28:01,322]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:28:19,264]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:28:28,287]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 14.30% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.66 | sMAPE for Test Set is: 15.74% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:28:34,484]\u001b[0m Trial 1157 finished with value: 6.413990008675629 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008941517709091057, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015244107290209367, 'dropout_rate_Layer_2': 0.07746456516113195, 'dropout_rate_Layer_3': 0.015299326272983579, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.528622151607211e-05, 'l1_Layer_2': 1.4596332166811464e-05, 'l1_Layer_3': 1.732078737589714e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 190, 'n_units_Layer_3': 60}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:28:48,718]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:29:04,414]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:29:05,281]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:29:24,816]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:29:27,972]\u001b[0m Trial 1159 finished with value: 6.416470860582488 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009138564679268109, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004422303436587266, 'dropout_rate_Layer_2': 0.10017640951400675, 'dropout_rate_Layer_3': 0.013456694414616605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.990904819814163e-05, 'l1_Layer_2': 1.0198174509516827e-05, 'l1_Layer_3': 1.4549410265295543e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 180, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 16.23% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:29:36,204]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:29:47,280]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:29:52,733]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:29:55,222]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:29:59,117]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:30:02,922]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:30:10,384]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:30:12,482]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:30:25,485]\u001b[0m Trial 1178 finished with value: 6.487063819793794 and parameters: {'n_hidden': 3, 'learning_rate': 0.001787360911273365, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024533453839050673, 'dropout_rate_Layer_2': 0.2991646104552447, 'dropout_rate_Layer_3': 0.04803233067467243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.9634241961780634e-05, 'l1_Layer_2': 0.0002572723453943324, 'l1_Layer_3': 0.0005073499387851189, 'n_units_Layer_1': 245, 'n_units_Layer_2': 215, 'n_units_Layer_3': 125}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 14.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.36 | sMAPE for Test Set is: 15.04% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:30:30,244]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:30:36,637]\u001b[0m Trial 1166 finished with value: 6.401745233910932 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012031714481415374, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022120131315749317, 'dropout_rate_Layer_2': 0.05924783726966926, 'dropout_rate_Layer_3': 0.0004645876650608402, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013986173318868858, 'l1_Layer_2': 1.2069718806065245e-05, 'l1_Layer_3': 2.3756935215693706e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.65 | sMAPE for Test Set is: 15.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:30:41,141]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:30:55,241]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:30:58,569]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:31:09,766]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:31:17,685]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:31:23,814]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:31:27,468]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:31:39,146]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:31:39,417]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:31:50,475]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:31:55,317]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:31:57,670]\u001b[0m Trial 1175 finished with value: 6.368608568851286 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008456244277803989, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021515329578904417, 'dropout_rate_Layer_2': 0.09276225877260975, 'dropout_rate_Layer_3': 0.024674331197786892, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013666266649108196, 'l1_Layer_2': 1.5512343188990365e-05, 'l1_Layer_3': 1.9798276166594244e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 180, 'n_units_Layer_3': 65}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 14.27% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.42 | sMAPE for Test Set is: 15.32% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:32:10,384]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:32:15,254]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:32:21,275]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:32:34,888]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:33:14,761]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:33:25,492]\u001b[0m Trial 1194 finished with value: 6.377190472287171 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009509675472849317, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007298657172968126, 'dropout_rate_Layer_2': 0.09949609224186468, 'dropout_rate_Layer_3': 0.023136700735079174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.628826791349692e-05, 'l1_Layer_2': 1.0089011390515385e-05, 'l1_Layer_3': 1.8028081311760846e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.22% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.97 | sMAPE for Test Set is: 16.49% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:33:44,330]\u001b[0m Trial 1197 finished with value: 6.381723347460533 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009353409466711338, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01892459162912072, 'dropout_rate_Layer_2': 0.09552639896431087, 'dropout_rate_Layer_3': 0.02022369215935235, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011470129944849478, 'l1_Layer_2': 1.2258300000756208e-05, 'l1_Layer_3': 1.8162364679332786e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.87 | sMAPE for Test Set is: 16.24% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:33:46,358]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:33:50,620]\u001b[0m Trial 1198 finished with value: 6.400688252444595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008299472747919972, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03466603422058847, 'dropout_rate_Layer_2': 0.09414810871891945, 'dropout_rate_Layer_3': 0.024282699974239166, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011077009988756466, 'l1_Layer_2': 1.3892012337584288e-05, 'l1_Layer_3': 1.587894974571713e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.28% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.63 | sMAPE for Test Set is: 15.87% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:33:55,352]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:34:05,199]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:34:23,924]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:34:29,767]\u001b[0m Trial 1199 finished with value: 6.741715839206617 and parameters: {'n_hidden': 4, 'learning_rate': 0.005197581690605459, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.043871811193808875, 'dropout_rate_Layer_2': 0.28532267780091347, 'dropout_rate_Layer_3': 0.12730254970723612, 'dropout_rate_Layer_4': 0.021492130079426287, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.5301893370462524e-05, 'l1_Layer_2': 0.0001287145084737094, 'l1_Layer_3': 0.007757135971402094, 'l1_Layer_4': 0.0004151601274701458, 'n_units_Layer_1': 300, 'n_units_Layer_2': 100, 'n_units_Layer_3': 155, 'n_units_Layer_4': 155}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 15.25% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.97 | sMAPE for Test Set is: 16.34% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:34:40,069]\u001b[0m Trial 1207 finished with value: 12.554047714931338 and parameters: {'n_hidden': 4, 'learning_rate': 0.047634828441810134, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09037756353787252, 'dropout_rate_Layer_2': 0.15322619321998088, 'dropout_rate_Layer_3': 0.28278782854830786, 'dropout_rate_Layer_4': 0.21653520202693782, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.05445527388845744, 'l1_Layer_2': 4.269033272400153e-05, 'l1_Layer_3': 0.004805290360847269, 'l1_Layer_4': 0.03283696511840336, 'n_units_Layer_1': 215, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180, 'n_units_Layer_4': 235}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.55 | sMAPE for Validation Set is: 27.14% | rMAE for Validation Set is: 1.29\n",
      "MAE for Test Set is: 20.36 | sMAPE for Test Set is: 40.00% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:34:48,807]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:35:01,152]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:35:23,846]\u001b[0m Trial 1203 finished with value: 6.460517989767774 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010866192873944709, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024861498941651516, 'dropout_rate_Layer_2': 0.08322988830035355, 'dropout_rate_Layer_3': 0.007190737810053287, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001680993986921087, 'l1_Layer_2': 1.007075180806518e-05, 'l1_Layer_3': 2.231065915211732e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.28 | sMAPE for Test Set is: 17.14% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:35:43,916]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:35:53,378]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:36:02,887]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:36:12,126]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:36:12,811]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:36:21,736]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:36:29,648]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:36:32,548]\u001b[0m Trial 1206 finished with value: 6.699343723589259 and parameters: {'n_hidden': 4, 'learning_rate': 0.006311623982979389, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19808204778366206, 'dropout_rate_Layer_2': 0.3268192864762017, 'dropout_rate_Layer_3': 0.15154086070214662, 'dropout_rate_Layer_4': 0.021860442252835073, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.412630610243275e-05, 'l1_Layer_2': 0.0001294004217698515, 'l1_Layer_3': 0.012202069854242763, 'l1_Layer_4': 0.0001423815118003703, 'n_units_Layer_1': 300, 'n_units_Layer_2': 65, 'n_units_Layer_3': 170, 'n_units_Layer_4': 155}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.70 | sMAPE for Validation Set is: 14.85% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.20 | sMAPE for Test Set is: 16.32% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:36:54,111]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:37:05,056]\u001b[0m Trial 1210 finished with value: 6.706893676144229 and parameters: {'n_hidden': 4, 'learning_rate': 0.005224018927639995, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04068525961629583, 'dropout_rate_Layer_2': 0.28570328826878705, 'dropout_rate_Layer_3': 0.15114342694540314, 'dropout_rate_Layer_4': 0.012638106460476847, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.287570189390608e-05, 'l1_Layer_2': 0.0001274738471412171, 'l1_Layer_3': 0.007805229184575949, 'l1_Layer_4': 0.00039801144710936145, 'n_units_Layer_1': 300, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155, 'n_units_Layer_4': 155}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.71 | sMAPE for Validation Set is: 14.87% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.60 | sMAPE for Test Set is: 15.63% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:37:35,534]\u001b[0m Trial 1215 finished with value: 7.319572180533986 and parameters: {'n_hidden': 4, 'learning_rate': 0.0037807941237059475, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03926213205796506, 'dropout_rate_Layer_2': 0.29155689114464917, 'dropout_rate_Layer_3': 0.1508948304058056, 'dropout_rate_Layer_4': 0.018330651790003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.127277691841456e-05, 'l1_Layer_2': 0.00032910132513786443, 'l1_Layer_3': 0.008095283306347076, 'l1_Layer_4': 0.00031312119828253376, 'n_units_Layer_1': 290, 'n_units_Layer_2': 95, 'n_units_Layer_3': 150, 'n_units_Layer_4': 125}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.32 | sMAPE for Validation Set is: 16.01% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 16.01% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:37:44,478]\u001b[0m Trial 1220 finished with value: 6.550253312174834 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008883398872119453, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22738192912827135, 'dropout_rate_Layer_2': 0.04134827462268261, 'dropout_rate_Layer_3': 0.27844270810401467, 'dropout_rate_Layer_4': 0.31051426849910285, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.4411455310757837e-05, 'l1_Layer_2': 5.7134845012367186e-05, 'l1_Layer_3': 3.9553364067920456e-05, 'l1_Layer_4': 0.0002500137777307529, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 180, 'n_units_Layer_4': 215}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.83 | sMAPE for Test Set is: 16.09% | rMAE for Test Set is: 0.68\n",
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.25 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:37:46,664]\u001b[0m Trial 1219 finished with value: 6.6635487126993285 and parameters: {'n_hidden': 4, 'learning_rate': 0.000988321261469764, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22668504324234678, 'dropout_rate_Layer_2': 0.04046160857579816, 'dropout_rate_Layer_3': 0.2694294763395189, 'dropout_rate_Layer_4': 0.31021497921467595, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.2629414320957588e-05, 'l1_Layer_2': 5.856697865916764e-05, 'l1_Layer_3': 0.0006355316594121711, 'l1_Layer_4': 2.663433063497251e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 220, 'n_units_Layer_3': 185, 'n_units_Layer_4': 90}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:37:55,698]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:37:56,493]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:38:02,769]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:38:20,962]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:38:22,447]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:38:24,150]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:38:33,549]\u001b[0m Trial 1221 finished with value: 6.3774750655057035 and parameters: {'n_hidden': 3, 'learning_rate': 0.001223326663641795, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01835938455413908, 'dropout_rate_Layer_2': 0.07302334679698363, 'dropout_rate_Layer_3': 0.006616512711068195, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011919982310445267, 'l1_Layer_2': 1.6734907924468683e-05, 'l1_Layer_3': 1.7943200248792338e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 150, 'n_units_Layer_3': 50}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.79 | sMAPE for Test Set is: 16.10% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:38:40,247]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:39:16,648]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:40:11,612]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:40:17,841]\u001b[0m Trial 1229 finished with value: 6.327642099699716 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008250986261779843, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04393303969406173, 'dropout_rate_Layer_2': 0.08443794106957894, 'dropout_rate_Layer_3': 0.006838306400673496, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001872711416819401, 'l1_Layer_2': 1.4541741830914751e-05, 'l1_Layer_3': 1.55176296764023e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 180, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 14.28% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.19 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:40:34,440]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.79 | sMAPE for Validation Set is: 15.05% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.82 | sMAPE for Test Set is: 15.99% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:40:38,779]\u001b[0m Trial 1228 finished with value: 6.7868194541718045 and parameters: {'n_hidden': 4, 'learning_rate': 0.0056741005490808655, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03442124988340785, 'dropout_rate_Layer_2': 0.33936681470901503, 'dropout_rate_Layer_3': 0.1579287419713729, 'dropout_rate_Layer_4': 0.0282654509459453, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.6715472236952295e-05, 'l1_Layer_2': 0.00016440078505793957, 'l1_Layer_3': 0.009991803911056618, 'l1_Layer_4': 0.00038117057754126645, 'n_units_Layer_1': 295, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145, 'n_units_Layer_4': 160}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:40:41,318]\u001b[0m Trial 1232 finished with value: 6.774114402019777 and parameters: {'n_hidden': 4, 'learning_rate': 0.005815104655663358, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03549919967118187, 'dropout_rate_Layer_2': 0.27488038893005234, 'dropout_rate_Layer_3': 0.13621480225962662, 'dropout_rate_Layer_4': 0.026905991475469564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.7551606722407176e-05, 'l1_Layer_2': 0.00016758762197888164, 'l1_Layer_3': 0.00970692983550374, 'l1_Layer_4': 7.953098426196062e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 100, 'n_units_Layer_3': 165, 'n_units_Layer_4': 160}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.77 | sMAPE for Validation Set is: 15.21% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.88 | sMAPE for Test Set is: 15.96% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:40:45,926]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:40:54,699]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:41:37,990]\u001b[0m Trial 1234 finished with value: 6.442888304809839 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008299328373601931, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03202037703501599, 'dropout_rate_Layer_2': 0.07988617427105082, 'dropout_rate_Layer_3': 0.014418567058245952, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.901656767113604e-05, 'l1_Layer_2': 1.012673406943437e-05, 'l1_Layer_3': 3.103475324283143e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 140, 'n_units_Layer_3': 65}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 16.07% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:41:56,276]\u001b[0m Trial 1240 finished with value: 6.821476628338601 and parameters: {'n_hidden': 4, 'learning_rate': 0.004610389403004692, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018712294525509213, 'dropout_rate_Layer_2': 0.28066518335241497, 'dropout_rate_Layer_3': 0.12323885254256152, 'dropout_rate_Layer_4': 0.01373156718654247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.8897762162883154e-05, 'l1_Layer_2': 0.00010371936426970103, 'l1_Layer_3': 0.010250015967915093, 'l1_Layer_4': 0.0001240233713494388, 'n_units_Layer_1': 140, 'n_units_Layer_2': 100, 'n_units_Layer_3': 140, 'n_units_Layer_4': 155}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 15.40% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 9.12 | sMAPE for Test Set is: 16.48% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:41:57,600]\u001b[0m Trial 1236 finished with value: 6.3951642483550515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008232345336659275, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05059744356641569, 'dropout_rate_Layer_2': 0.08484341460771291, 'dropout_rate_Layer_3': 0.014879200064131301, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002500338921774343, 'l1_Layer_2': 1.8941124851979396e-05, 'l1_Layer_3': 1.3553489640644059e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.28% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.49 | sMAPE for Test Set is: 17.53% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:42:04,051]\u001b[0m Trial 1238 finished with value: 6.343930332713953 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008232703520504933, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05083623885235964, 'dropout_rate_Layer_2': 0.08469655673962945, 'dropout_rate_Layer_3': 0.01600602685618776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025006361708826457, 'l1_Layer_2': 1.782215222625656e-05, 'l1_Layer_3': 1.3069238587065362e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.04 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:42:09,241]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:42:13,424]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:42:18,944]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:42:23,226]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:42:28,286]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:42:38,166]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:42:42,952]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:42:46,902]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:42:53,717]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:43:01,735]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:43:04,677]\u001b[0m Trial 1241 finished with value: 6.40661191122048 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007962276090965976, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05061739183123672, 'dropout_rate_Layer_2': 0.09024840671823403, 'dropout_rate_Layer_3': 0.00014042206388064686, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026303311928556263, 'l1_Layer_2': 1.9284283091903272e-05, 'l1_Layer_3': 1.0551979619335637e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 14.31% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.40 | sMAPE for Test Set is: 17.42% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:43:24,449]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:43:27,749]\u001b[0m Trial 1243 finished with value: 6.506034234080679 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009089519284926813, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05495594267932263, 'dropout_rate_Layer_2': 0.09145247017154011, 'dropout_rate_Layer_3': 0.02634933426613367, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017751965621354244, 'l1_Layer_2': 1.4477760989831619e-05, 'l1_Layer_3': 1.1310908994153237e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 14.67% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.00 | sMAPE for Test Set is: 16.63% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:43:34,194]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:43:34,783]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:43:43,511]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:43:44,174]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:43:52,246]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:44:47,529]\u001b[0m Trial 1259 finished with value: 6.419775704200927 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007944351923087962, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03908158504202911, 'dropout_rate_Layer_2': 0.10661382820457928, 'dropout_rate_Layer_3': 0.01595602324201415, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022926332079205102, 'l1_Layer_2': 1.3183242550334126e-05, 'l1_Layer_3': 1.4323661895079234e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 170, 'n_units_Layer_3': 65}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 14.34% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.61 | sMAPE for Test Set is: 15.76% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:45:18,765]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:45:23,214]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:45:30,851]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:45:45,034]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:45:51,506]\u001b[0m Trial 1260 finished with value: 6.268214111630033 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007908565408265508, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031213746535582256, 'dropout_rate_Layer_2': 0.09549688461326732, 'dropout_rate_Layer_3': 0.013921897310794896, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003080020077605684, 'l1_Layer_2': 1.9832891816835975e-05, 'l1_Layer_3': 1.578554441922167e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 14.10% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.32 | sMAPE for Test Set is: 15.08% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:46:11,094]\u001b[0m Trial 1266 finished with value: 6.489245042201527 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014925317763140127, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03798191003088924, 'dropout_rate_Layer_2': 0.07241015495947704, 'dropout_rate_Layer_3': 0.2770864684255551, 'dropout_rate_Layer_4': 0.3369015443395778, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007226587164520904, 'l1_Layer_2': 1.1082778138635504e-05, 'l1_Layer_3': 0.002616947238653494, 'l1_Layer_4': 2.4780659381006244e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 205, 'n_units_Layer_4': 290}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.11 | sMAPE for Test Set is: 16.56% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:47:04,103]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:47:13,456]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:47:28,457]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:47:38,203]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:47:42,786]\u001b[0m Trial 1267 finished with value: 6.420206760192493 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008048585816194657, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030092945910000796, 'dropout_rate_Layer_2': 0.07411872313381088, 'dropout_rate_Layer_3': 0.014035076687046108, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017555717493793064, 'l1_Layer_2': 1.1940828852303868e-05, 'l1_Layer_3': 3.931309231606987e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 160, 'n_units_Layer_3': 60}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.64 | sMAPE for Test Set is: 17.80% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:47:52,906]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:48:00,121]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:48:12,432]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:48:44,114]\u001b[0m Trial 1268 finished with value: 6.751826502735166 and parameters: {'n_hidden': 4, 'learning_rate': 0.004599433804891985, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019989849690511274, 'dropout_rate_Layer_2': 0.28154841748034914, 'dropout_rate_Layer_3': 0.1532503921302073, 'dropout_rate_Layer_4': 0.012394534264642758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.477588738328771e-05, 'l1_Layer_2': 0.00026942746831939176, 'l1_Layer_3': 0.011463969614330403, 'l1_Layer_4': 0.00011030994737146733, 'n_units_Layer_1': 130, 'n_units_Layer_2': 110, 'n_units_Layer_3': 140, 'n_units_Layer_4': 160}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.75 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.06 | sMAPE for Test Set is: 16.21% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:49:08,853]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:49:16,975]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:49:29,113]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:49:36,844]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:49:46,624]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:50:04,344]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:50:08,055]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:50:31,808]\u001b[0m Trial 1281 finished with value: 7.120939844280649 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006349145317847212, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21096223705425104, 'dropout_rate_Layer_2': 0.015417441587207953, 'dropout_rate_Layer_3': 0.302011309996897, 'dropout_rate_Layer_4': 0.25155909852777436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00016110773854230182, 'l1_Layer_2': 5.703045150380321e-05, 'l1_Layer_3': 3.168744904625611e-05, 'l1_Layer_4': 9.599343393554169e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 280, 'n_units_Layer_3': 300, 'n_units_Layer_4': 240}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 16.10% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 10.35 | sMAPE for Test Set is: 18.84% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:50:44,242]\u001b[0m Trial 1261 finished with value: 6.716161971629442 and parameters: {'n_hidden': 4, 'learning_rate': 0.0041706757166391235, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016795615386545424, 'dropout_rate_Layer_2': 0.3327477377773169, 'dropout_rate_Layer_3': 0.14019979378303202, 'dropout_rate_Layer_4': 0.030299871351522806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.6757132189089307e-05, 'l1_Layer_2': 0.00010267621503174021, 'l1_Layer_3': 0.009503424546001605, 'l1_Layer_4': 7.367208532098889e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 100, 'n_units_Layer_3': 155, 'n_units_Layer_4': 155}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.72 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.63 | sMAPE for Test Set is: 15.64% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:50:57,037]\u001b[0m Trial 1278 finished with value: 6.442853080316183 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008948231757577033, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04701820669553621, 'dropout_rate_Layer_2': 0.09191165029355829, 'dropout_rate_Layer_3': 0.01702805308398659, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002886145049064815, 'l1_Layer_2': 2.6968707094229336e-05, 'l1_Layer_3': 1.5671029610985304e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 165, 'n_units_Layer_3': 65}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 16.04% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:51:03,991]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:51:04,700]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:51:15,524]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:51:16,315]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:51:23,346]\u001b[0m Trial 1286 finished with value: 6.373319066636388 and parameters: {'n_hidden': 4, 'learning_rate': 0.001270529815720013, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11897825004830326, 'dropout_rate_Layer_2': 0.033569302894908046, 'dropout_rate_Layer_3': 0.3353918996571973, 'dropout_rate_Layer_4': 0.26471205047662627, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004164621182890023, 'l1_Layer_2': 0.006443164550017087, 'l1_Layer_3': 0.0012665739736907266, 'l1_Layer_4': 1.820526794398914e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195, 'n_units_Layer_4': 280}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.66 | sMAPE for Test Set is: 15.78% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:51:27,462]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:51:28,280]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:51:31,296]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:51:59,334]\u001b[0m Trial 1292 finished with value: 6.659399635880575 and parameters: {'n_hidden': 4, 'learning_rate': 0.001259415024695131, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18265368880023586, 'dropout_rate_Layer_2': 0.06678157415917009, 'dropout_rate_Layer_3': 0.32415241286564994, 'dropout_rate_Layer_4': 0.33890880419697805, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.420158080754825e-05, 'l1_Layer_2': 0.00040152681995670386, 'l1_Layer_3': 4.3409702890295546e-05, 'l1_Layer_4': 0.0002865735532193262, 'n_units_Layer_1': 275, 'n_units_Layer_2': 285, 'n_units_Layer_3': 165, 'n_units_Layer_4': 205}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 14.95% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.29 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:52:52,850]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:52:57,301]\u001b[0m Trial 1296 finished with value: 6.381097119982236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007620339135190875, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03445783024385736, 'dropout_rate_Layer_2': 0.08162209003880526, 'dropout_rate_Layer_3': 0.02793380991728455, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023938281975552361, 'l1_Layer_2': 1.3767460195846307e-05, 'l1_Layer_3': 1.8506847404777756e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 160, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 16.12% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:53:02,953]\u001b[0m Trial 1295 finished with value: 6.416234786093123 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007662520125038664, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007884008117800753, 'dropout_rate_Layer_2': 0.08337279847030854, 'dropout_rate_Layer_3': 0.032650928370908786, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001517865433089352, 'l1_Layer_2': 1.3721772850766021e-05, 'l1_Layer_3': 1.8848648702485974e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 160, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.36 | sMAPE for Test Set is: 17.50% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:53:05,548]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:53:09,942]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:53:21,794]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:53:29,775]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:53:32,416]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:54:08,307]\u001b[0m Trial 1298 finished with value: 6.4042663578170185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008464322320593578, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005629309733778742, 'dropout_rate_Layer_2': 0.10398070521359333, 'dropout_rate_Layer_3': 0.01454315646281071, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002411895947240624, 'l1_Layer_2': 1.1786190757466242e-05, 'l1_Layer_3': 3.36171028517853e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.27% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 16.34% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:55:01,268]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.14 | sMAPE for Test Set is: 21.06% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:55:32,626]\u001b[0m Trial 1305 finished with value: 6.4152189474887225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008384860906911988, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01855253774961535, 'dropout_rate_Layer_2': 0.08955658018919645, 'dropout_rate_Layer_3': 0.008544947737792515, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011112690725759738, 'l1_Layer_2': 1.1860872585883784e-05, 'l1_Layer_3': 2.7926540093751897e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 170, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:55:39,399]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:55:56,992]\u001b[0m Trial 1304 finished with value: 6.3231803042551205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009613091135614036, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018319027706867396, 'dropout_rate_Layer_2': 0.09540686627595488, 'dropout_rate_Layer_3': 0.009338300860955745, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018409186107327667, 'l1_Layer_2': 1.5426735718844243e-05, 'l1_Layer_3': 2.4789492048872858e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 170, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 14.28% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.20 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:56:03,249]\u001b[0m Trial 1294 finished with value: 6.88320716837043 and parameters: {'n_hidden': 4, 'learning_rate': 0.004100064368242842, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01825693733625964, 'dropout_rate_Layer_2': 0.271527132152383, 'dropout_rate_Layer_3': 0.13005541675298832, 'dropout_rate_Layer_4': 0.03421618767783883, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.68537704051248e-05, 'l1_Layer_2': 8.874151358859171e-05, 'l1_Layer_3': 0.014390556710179823, 'l1_Layer_4': 7.483551689203532e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 130, 'n_units_Layer_4': 155}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 15.09% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.53 | sMAPE for Test Set is: 15.54% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:56:16,223]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:56:33,557]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:56:38,660]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:57:30,831]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:57:38,329]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:57:49,934]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:58:24,243]\u001b[0m Trial 1314 finished with value: 6.358295168148516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009371710415517662, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03064208396511188, 'dropout_rate_Layer_2': 0.10903156333490727, 'dropout_rate_Layer_3': 0.007346332275246991, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013657543331776115, 'l1_Layer_2': 2.0977488267573094e-05, 'l1_Layer_3': 4.1380548476637575e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.40 | sMAPE for Test Set is: 17.29% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:58:29,462]\u001b[0m Trial 1313 finished with value: 6.481030581197259 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009970670658357276, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029252788022410298, 'dropout_rate_Layer_2': 0.11368795852063543, 'dropout_rate_Layer_3': 0.006571539277543165, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001363207246334878, 'l1_Layer_2': 2.111820709115244e-05, 'l1_Layer_3': 4.2846637319895395e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.48 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.01 | sMAPE for Test Set is: 16.69% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 21:58:41,949]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:58:49,178]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:58:58,126]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:59:03,494]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 21:59:40,626]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:00:02,941]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:00:12,552]\u001b[0m Trial 1318 finished with value: 6.4342673247886095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010019529678660492, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03580964799241788, 'dropout_rate_Layer_2': 0.11102994483056763, 'dropout_rate_Layer_3': 6.416063640017362e-05, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004172894743050518, 'l1_Layer_2': 2.120219356107709e-05, 'l1_Layer_3': 4.160564908625367e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.53 | sMAPE for Test Set is: 15.70% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:00:21,459]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:00:30,674]\u001b[0m Trial 1320 finished with value: 6.396221435141075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011232417010940442, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03841014113421529, 'dropout_rate_Layer_2': 0.11202974343674496, 'dropout_rate_Layer_3': 0.014231349363817227, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000252427392000451, 'l1_Layer_2': 1.000172385478127e-05, 'l1_Layer_3': 4.3176166868758606e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 170, 'n_units_Layer_3': 60}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.44% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.89 | sMAPE for Test Set is: 20.32% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:00:30,835]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:00:41,796]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:00:53,294]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:01:03,831]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:01:26,017]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:01:33,578]\u001b[0m Trial 1325 finished with value: 6.328259491796156 and parameters: {'n_hidden': 3, 'learning_rate': 0.001248886663312374, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0486082075882593, 'dropout_rate_Layer_2': 0.09869937428173654, 'dropout_rate_Layer_3': 0.0003269130056633169, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000178801992678808, 'l1_Layer_2': 1.821991998393102e-05, 'l1_Layer_3': 3.181071280014934e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 80}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 14.17% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 16.26% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:01:37,685]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:01:42,514]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:01:45,855]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:01:46,266]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:01:54,956]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:01:57,939]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:02:02,490]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:02:04,986]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:02:18,825]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:02:23,859]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:02:40,285]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:02:44,778]\u001b[0m Trial 1309 finished with value: 6.801642232838067 and parameters: {'n_hidden': 4, 'learning_rate': 0.0040085694570322575, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006206554456771135, 'dropout_rate_Layer_2': 0.3361805683140837, 'dropout_rate_Layer_3': 0.12901299106229702, 'dropout_rate_Layer_4': 0.029939725856146432, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.637677492190795e-05, 'l1_Layer_2': 9.706726057566995e-05, 'l1_Layer_3': 0.015227995152513545, 'l1_Layer_4': 8.605338709392303e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 110, 'n_units_Layer_3': 140, 'n_units_Layer_4': 165}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 14.97% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.73 | sMAPE for Test Set is: 15.89% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:03:02,540]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:03:07,571]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:03:13,670]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:03:20,329]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:03:26,671]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:03:38,049]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:04:37,789]\u001b[0m Trial 1348 finished with value: 6.42866114108034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009482746504434627, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05055455732245527, 'dropout_rate_Layer_2': 0.09645804603256898, 'dropout_rate_Layer_3': 0.0081631296692584, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001543518003645754, 'l1_Layer_2': 1.8422737565575365e-05, 'l1_Layer_3': 2.9922160851466043e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 160, 'n_units_Layer_3': 50}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.62 | sMAPE for Test Set is: 15.70% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:05:14,483]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:06:19,089]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:06:55,132]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 15.24% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.47 | sMAPE for Test Set is: 15.38% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:06:58,006]\u001b[0m Trial 1344 finished with value: 6.866591632992196 and parameters: {'n_hidden': 4, 'learning_rate': 0.004437068815007871, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022491643456029466, 'dropout_rate_Layer_2': 0.274734311952989, 'dropout_rate_Layer_3': 0.13878449266879006, 'dropout_rate_Layer_4': 0.029589956610648505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.312988165527165e-05, 'l1_Layer_2': 0.00019845457954581987, 'l1_Layer_3': 0.010235549693808216, 'l1_Layer_4': 6.81237085226546e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 110, 'n_units_Layer_3': 150, 'n_units_Layer_4': 155}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:07:02,895]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:07:04,673]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:07:12,348]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:07:20,493]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.68 | sMAPE for Validation Set is: 16.46% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 10.64 | sMAPE for Test Set is: 19.14% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:07:22,150]\u001b[0m Trial 1355 finished with value: 7.6810676560766 and parameters: {'n_hidden': 4, 'learning_rate': 0.006609930164638017, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3128264402821357, 'dropout_rate_Layer_2': 0.05446549697889817, 'dropout_rate_Layer_3': 0.20171976086471424, 'dropout_rate_Layer_4': 0.37317336848574106, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0006675227449531254, 'l1_Layer_2': 0.0001290541083263662, 'l1_Layer_3': 0.00254006987998345, 'l1_Layer_4': 0.001300301505754193, 'n_units_Layer_1': 155, 'n_units_Layer_2': 260, 'n_units_Layer_3': 180, 'n_units_Layer_4': 260}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:07:55,725]\u001b[0m Trial 1351 finished with value: 6.735233330944173 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031181535601782343, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0017538404754967292, 'dropout_rate_Layer_2': 0.267081009157229, 'dropout_rate_Layer_3': 0.13847493608630548, 'dropout_rate_Layer_4': 0.02926576609232802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.6142038663677505e-05, 'l1_Layer_2': 7.866625039972395e-05, 'l1_Layer_3': 0.01698483308457434, 'l1_Layer_4': 7.568673754226528e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 110, 'n_units_Layer_3': 135, 'n_units_Layer_4': 170}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 15.25% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.85 | sMAPE for Test Set is: 16.02% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:08:16,621]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:08:16,957]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:08:38,144]\u001b[0m Trial 1360 finished with value: 6.3509517576619 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010644502049668662, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.040443160704199094, 'dropout_rate_Layer_2': 0.06895901935619927, 'dropout_rate_Layer_3': 0.008513829289930093, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001283357901625316, 'l1_Layer_2': 1.3338893883255984e-05, 'l1_Layer_3': 2.1053375569307394e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 165, 'n_units_Layer_3': 85}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 14.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 16.29% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:08:46,581]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:08:52,768]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:08:56,029]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:08:59,888]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:09:02,574]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:09:08,252]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:09:13,701]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:09:52,214]\u001b[0m Trial 1365 finished with value: 6.334417536742637 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009330129599802345, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018827912244343506, 'dropout_rate_Layer_2': 0.06932645013175463, 'dropout_rate_Layer_3': 0.017394705655007257, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003883920405921133, 'l1_Layer_2': 2.4380828686568358e-05, 'l1_Layer_3': 1.6282806112910985e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 14.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.65 | sMAPE for Test Set is: 15.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:10:02,515]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:10:13,770]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:10:27,909]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:10:43,636]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:10:49,723]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:10:58,816]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:11:05,066]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:11:08,347]\u001b[0m Trial 1373 finished with value: 6.394618296973976 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009351630281424484, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021401798207925985, 'dropout_rate_Layer_2': 0.06223047206109558, 'dropout_rate_Layer_3': 0.01846034921369761, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012331809988060875, 'l1_Layer_2': 1.7055694539652944e-05, 'l1_Layer_3': 2.6254356394819536e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.83 | sMAPE for Test Set is: 16.28% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:11:08,704]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:11:16,664]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:11:16,983]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:11:27,301]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:11:27,638]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:11:34,134]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:11:50,652]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:11:55,965]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:12:20,348]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:12:41,732]\u001b[0m Trial 1389 finished with value: 6.543079923060577 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011960534982284829, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1804939271955178, 'dropout_rate_Layer_2': 0.07000931104068217, 'dropout_rate_Layer_3': 0.2742821412690754, 'dropout_rate_Layer_4': 0.34039423473621605, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3291706349317178e-05, 'l1_Layer_2': 0.00045268665336778636, 'l1_Layer_3': 3.9716271102964016e-05, 'l1_Layer_4': 0.0002888127992113585, 'n_units_Layer_1': 240, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165, 'n_units_Layer_4': 210}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 14.84% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.03 | sMAPE for Test Set is: 18.52% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:12:57,660]\u001b[0m Trial 1387 finished with value: 6.377976408129076 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010490576478292492, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03870451979679687, 'dropout_rate_Layer_2': 0.0541549469343882, 'dropout_rate_Layer_3': 0.007614687190036852, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017466714107309582, 'l1_Layer_2': 1.8934943511795835e-05, 'l1_Layer_3': 1.2584937350404725e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 65}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.42 | sMAPE for Test Set is: 15.45% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:13:05,787]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:13:28,240]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:13:44,695]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:13:52,038]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:14:38,522]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:14:47,709]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:14:48,400]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:14:58,828]\u001b[0m Trial 1393 finished with value: 6.349261373923034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007497162083138867, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06747470576795925, 'dropout_rate_Layer_2': 0.08748506958337275, 'dropout_rate_Layer_3': 0.005604173653758615, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00037040696456080665, 'l1_Layer_2': 1.1694260884557672e-05, 'l1_Layer_3': 2.2400653667656362e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 180, 'n_units_Layer_3': 90}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.50 | sMAPE for Test Set is: 15.55% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:15:02,037]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:15:17,500]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:15:20,922]\u001b[0m Trial 1397 finished with value: 6.376344286902657 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012080295621351592, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05208593867979379, 'dropout_rate_Layer_2': 0.08574381517968814, 'dropout_rate_Layer_3': 0.0005991701248158828, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00038704819747639377, 'l1_Layer_2': 1.4710491231935422e-05, 'l1_Layer_3': 2.3409928169089797e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 180, 'n_units_Layer_3': 75}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 14.31% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.33 | sMAPE for Test Set is: 15.30% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:15:27,483]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:15:49,694]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:16:18,025]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:16:19,078]\u001b[0m Trial 1399 finished with value: 6.4646098508337575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007793313583121811, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02772953301033164, 'dropout_rate_Layer_2': 0.07339760662595093, 'dropout_rate_Layer_3': 0.03179401378873663, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00034149664921947614, 'l1_Layer_2': 1.2024830884732316e-05, 'l1_Layer_3': 2.1724545564520573e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 155, 'n_units_Layer_3': 205}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.46 | sMAPE for Test Set is: 15.48% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:16:40,149]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:16:44,631]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:16:50,994]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:16:51,482]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:17:11,727]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:17:17,077]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:18:31,622]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:18:32,400]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:18:40,855]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:19:16,469]\u001b[0m Trial 1414 finished with value: 6.420043183229931 and parameters: {'n_hidden': 3, 'learning_rate': 0.000922766404685208, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08764617370385931, 'dropout_rate_Layer_2': 0.0899252167459055, 'dropout_rate_Layer_3': 0.020382002498393167, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002703401612898982, 'l1_Layer_2': 1.1487124538957904e-05, 'l1_Layer_3': 2.037426108557462e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 14.44% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.68 | sMAPE for Test Set is: 17.90% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:19:26,908]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:19:33,243]\u001b[0m Trial 1403 finished with value: 6.81101236134268 and parameters: {'n_hidden': 4, 'learning_rate': 0.005527321021571893, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012511347874623012, 'dropout_rate_Layer_2': 0.34462308696428956, 'dropout_rate_Layer_3': 0.13669990861922757, 'dropout_rate_Layer_4': 0.04654723228106691, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.611098540722543e-05, 'l1_Layer_2': 0.00013464671705599497, 'l1_Layer_3': 0.014790657215067156, 'l1_Layer_4': 7.592374054916866e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 100, 'n_units_Layer_3': 155, 'n_units_Layer_4': 150}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 15.16% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 16.09% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:19:38,068]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:19:47,239]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:19:55,495]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:20:00,240]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:20:03,654]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:20:07,370]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:20:31,843]\u001b[0m Trial 1415 finished with value: 6.401422825037213 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009169981103580068, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07154629772463791, 'dropout_rate_Layer_2': 0.08051396059384316, 'dropout_rate_Layer_3': 0.00020871121977086328, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026437564235623094, 'l1_Layer_2': 1.1963294495942535e-05, 'l1_Layer_3': 2.00303459104654e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.57 | sMAPE for Test Set is: 17.94% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:20:52,192]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:20:57,835]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:21:02,243]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:21:15,084]\u001b[0m Trial 1418 finished with value: 6.803278698330708 and parameters: {'n_hidden': 4, 'learning_rate': 0.004203215234099441, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010154572546092103, 'dropout_rate_Layer_2': 0.2558937296974692, 'dropout_rate_Layer_3': 0.12062096002643108, 'dropout_rate_Layer_4': 0.04817421934597531, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.10552780937435e-05, 'l1_Layer_2': 0.00016303703885156117, 'l1_Layer_3': 0.011411231237369163, 'l1_Layer_4': 0.00013041983441891542, 'n_units_Layer_1': 135, 'n_units_Layer_2': 110, 'n_units_Layer_3': 120, 'n_units_Layer_4': 150}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 15.19% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.76 | sMAPE for Test Set is: 15.95% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:21:22,231]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:21:40,721]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:21:45,195]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:21:54,652]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:21:57,043]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:22:40,875]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:24:00,471]\u001b[0m Trial 1437 finished with value: 6.74065695390577 and parameters: {'n_hidden': 4, 'learning_rate': 0.004184369367768923, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028663029386014446, 'dropout_rate_Layer_2': 0.23051341403161554, 'dropout_rate_Layer_3': 0.13042937151402362, 'dropout_rate_Layer_4': 0.05009680671553694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.0922751197262574e-05, 'l1_Layer_2': 0.00016888741280015953, 'l1_Layer_3': 0.0012401410880205506, 'l1_Layer_4': 0.00011819456676749794, 'n_units_Layer_1': 145, 'n_units_Layer_2': 100, 'n_units_Layer_3': 145, 'n_units_Layer_4': 160}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 15.00% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.80 | sMAPE for Test Set is: 16.06% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:24:07,347]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:24:55,953]\u001b[0m Trial 1439 finished with value: 6.591424542219279 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011632292938179853, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2031280929151395, 'dropout_rate_Layer_2': 0.11609239509269945, 'dropout_rate_Layer_3': 0.256272025133653, 'dropout_rate_Layer_4': 0.3001009610050047, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4484215575002121e-05, 'l1_Layer_2': 0.0009231978341103087, 'l1_Layer_3': 4.657472548528317e-05, 'l1_Layer_4': 0.00031096103681597313, 'n_units_Layer_1': 240, 'n_units_Layer_2': 245, 'n_units_Layer_3': 210, 'n_units_Layer_4': 205}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 14.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.71 | sMAPE for Test Set is: 17.75% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:25:20,501]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:25:35,489]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:25:39,399]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:26:06,588]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:26:36,798]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:26:42,420]\u001b[0m Trial 1436 finished with value: 6.778934607239409 and parameters: {'n_hidden': 4, 'learning_rate': 0.004120339375611906, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009237983334825369, 'dropout_rate_Layer_2': 0.2507656571248931, 'dropout_rate_Layer_3': 0.13213462579242657, 'dropout_rate_Layer_4': 0.04910668642965197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.406817890439209e-05, 'l1_Layer_2': 0.00017263954680200047, 'l1_Layer_3': 0.012124987251242598, 'l1_Layer_4': 0.00011789040895646515, 'n_units_Layer_1': 125, 'n_units_Layer_2': 110, 'n_units_Layer_3': 125, 'n_units_Layer_4': 150}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 15.70% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:26:50,328]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:27:06,661]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:27:07,025]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:27:18,434]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:27:27,757]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:27:34,544]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:27:47,874]\u001b[0m Trial 1443 finished with value: 6.620095794640439 and parameters: {'n_hidden': 4, 'learning_rate': 0.005734443062033825, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030140326318416216, 'dropout_rate_Layer_2': 0.23863413038554188, 'dropout_rate_Layer_3': 0.13514609058600158, 'dropout_rate_Layer_4': 0.05656027006338869, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.0701267082249126e-05, 'l1_Layer_2': 0.00016135324423197217, 'l1_Layer_3': 0.002033073662507768, 'l1_Layer_4': 0.00012419020106114973, 'n_units_Layer_1': 145, 'n_units_Layer_2': 95, 'n_units_Layer_3': 150, 'n_units_Layer_4': 170}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 14.91% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.55 | sMAPE for Test Set is: 15.55% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:27:52,499]\u001b[0m Trial 1447 finished with value: 6.205946385309905 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017862405892153008, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12246901085878144, 'dropout_rate_Layer_2': 0.0007042930038321862, 'dropout_rate_Layer_3': 0.30252100435112445, 'dropout_rate_Layer_4': 0.15896598660899322, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002669664676826873, 'l1_Layer_2': 0.0067357578027925, 'l1_Layer_3': 0.000848370653291462, 'l1_Layer_4': 9.918214771994919e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 130, 'n_units_Layer_3': 210, 'n_units_Layer_4': 225}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.42 | sMAPE for Test Set is: 15.50% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:28:03,097]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:28:35,441]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:28:43,341]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:28:55,198]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:29:07,545]\u001b[0m Trial 1450 finished with value: 6.687243836392237 and parameters: {'n_hidden': 4, 'learning_rate': 0.004793981009608771, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00024626322591376473, 'dropout_rate_Layer_2': 0.24956432889806388, 'dropout_rate_Layer_3': 0.14108375336257037, 'dropout_rate_Layer_4': 0.04546472903070575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.8466679771046525e-05, 'l1_Layer_2': 0.000142171469841597, 'l1_Layer_3': 0.001414180980128571, 'l1_Layer_4': 0.0001314021647406088, 'n_units_Layer_1': 125, 'n_units_Layer_2': 105, 'n_units_Layer_3': 135, 'n_units_Layer_4': 155}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.69 | sMAPE for Validation Set is: 14.92% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.62 | sMAPE for Test Set is: 15.60% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:29:11,991]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:29:16,788]\u001b[0m Trial 1455 finished with value: 6.20421212828137 and parameters: {'n_hidden': 4, 'learning_rate': 0.001824948751375235, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1161137361680255, 'dropout_rate_Layer_2': 0.00209654753398806, 'dropout_rate_Layer_3': 0.286234924229993, 'dropout_rate_Layer_4': 0.16844305819102498, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002717012964647796, 'l1_Layer_2': 0.012220158777307897, 'l1_Layer_3': 0.0009664270117745904, 'l1_Layer_4': 8.392150110531365e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 110, 'n_units_Layer_3': 205, 'n_units_Layer_4': 225}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 14.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.10 | sMAPE for Test Set is: 16.92% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:29:20,032]\u001b[0m Trial 1453 finished with value: 6.445356375032297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011428827371256587, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020858005341676665, 'dropout_rate_Layer_2': 0.09501572852052027, 'dropout_rate_Layer_3': 0.008261906339516772, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022605565645767833, 'l1_Layer_2': 1.0056802634237052e-05, 'l1_Layer_3': 1.7538698745130767e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.89 | sMAPE for Test Set is: 16.33% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:29:22,866]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:29:27,817]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:29:29,503]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:29:30,921]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:29:34,698]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:29:39,101]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:29:43,490]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:29:56,222]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:30:01,910]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:30:06,991]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:30:34,716]\u001b[0m Trial 1468 finished with value: 6.186062275577522 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018155030509480292, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12263891372635473, 'dropout_rate_Layer_2': 0.023160729978530917, 'dropout_rate_Layer_3': 0.3016068003204253, 'dropout_rate_Layer_4': 0.161239548632145, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006141107272095162, 'l1_Layer_2': 0.005904364487861001, 'l1_Layer_3': 0.0006688182840222635, 'l1_Layer_4': 8.788520919701174e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210, 'n_units_Layer_4': 225}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 14.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.46 | sMAPE for Test Set is: 15.53% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:30:50,319]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:30:54,097]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:30:58,386]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:31:02,936]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:31:09,222]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:31:09,610]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:31:21,185]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:31:26,004]\u001b[0m Trial 1466 finished with value: 6.545877406339628 and parameters: {'n_hidden': 4, 'learning_rate': 0.005965171317491028, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0004029267825895157, 'dropout_rate_Layer_2': 0.24884608756215598, 'dropout_rate_Layer_3': 0.12454647425508598, 'dropout_rate_Layer_4': 0.04755539184082753, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.816140094867982e-05, 'l1_Layer_2': 0.0001490010209804211, 'l1_Layer_3': 0.0011857931184363687, 'l1_Layer_4': 0.00012554887118144782, 'n_units_Layer_1': 140, 'n_units_Layer_2': 95, 'n_units_Layer_3': 135, 'n_units_Layer_4': 165}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 14.62% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.65 | sMAPE for Test Set is: 15.69% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:31:31,525]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:31:32,278]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:31:42,635]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:31:43,932]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:31:56,691]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:32:04,899]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:32:12,296]\u001b[0m Trial 1474 finished with value: 6.207492428296548 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018714684924423313, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1270331368923469, 'dropout_rate_Layer_2': 0.0033627605256461267, 'dropout_rate_Layer_3': 0.3142150631042928, 'dropout_rate_Layer_4': 0.17505862943445305, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012197147504485716, 'l1_Layer_2': 0.005427096810134671, 'l1_Layer_3': 0.00024447736828480445, 'l1_Layer_4': 0.00018557641895794837, 'n_units_Layer_1': 220, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210, 'n_units_Layer_4': 225}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.19 | sMAPE for Test Set is: 14.89% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:32:18,426]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:32:22,905]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:32:23,106]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:32:24,822]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:32:34,544]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:32:38,859]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:32:42,849]\u001b[0m Trial 1479 finished with value: 6.362476588494284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007842957481228462, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0301665015526698, 'dropout_rate_Layer_2': 0.08696220189184031, 'dropout_rate_Layer_3': 0.035506488714643944, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001283552710630437, 'l1_Layer_2': 1.4850316411648135e-05, 'l1_Layer_3': 2.6187230336660202e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 165, 'n_units_Layer_3': 80}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.84 | sMAPE for Test Set is: 16.34% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:32:53,378]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:32:58,753]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:33:03,869]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:33:06,994]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:33:14,441]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:33:19,744]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 22:33:33,772]\u001b[0m Trial 1490 finished with value: 6.417027885567542 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007924642125868627, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03824541892804781, 'dropout_rate_Layer_2': 0.07140721465337772, 'dropout_rate_Layer_3': 0.0069126342037531575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00033226716259224985, 'l1_Layer_2': 1.6115048181555775e-05, 'l1_Layer_3': 2.3668221828724712e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 190, 'n_units_Layer_3': 60}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 16.08% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 22:33:34,316]\u001b[0m Trial 1499 finished with value: 6.656616764810053 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010211394923010804, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24890020094200865, 'dropout_rate_Layer_2': 0.08103447264242769, 'dropout_rate_Layer_3': 0.24006711157005542, 'dropout_rate_Layer_4': 0.07804564741851815, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.761653472168835e-05, 'l1_Layer_2': 0.0032024198547540763, 'l1_Layer_3': 4.895799360053641e-05, 'l1_Layer_4': 0.00011394944789178977, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 250, 'n_units_Layer_4': 220}. Best is trial 417 with value: 6.142767457842159.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 15.18% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.41 | sMAPE for Test Set is: 17.42% | rMAE for Test Set is: 0.73\n",
      "for 2018-01-01, MAE is:15.26 & sMAPE is:105.41% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :15.26 & 105.41% & 0.59\n",
      "for 2018-01-02, MAE is:6.55 & sMAPE is:34.02% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :10.90 & 69.72% & 0.57\n",
      "for 2018-01-03, MAE is:16.56 & sMAPE is:59.64% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :12.79 & 66.36% & 0.72\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DE1677D550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:8.44 & sMAPE is:27.92% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :11.70 & 56.75% & 0.77\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DDF755D670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:7.31 & sMAPE is:30.57% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :10.82 & 51.51% & 0.74\n",
      "for 2018-01-06, MAE is:5.26 & sMAPE is:15.49% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :9.89 & 45.51% & 0.69\n",
      "for 2018-01-07, MAE is:7.11 & sMAPE is:30.05% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 43.30% & 0.76\n",
      "for 2018-01-08, MAE is:6.42 & sMAPE is:19.85% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 40.37% & 0.69\n",
      "for 2018-01-09, MAE is:7.60 & sMAPE is:15.38% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.94 & 37.59% & 0.66\n",
      "for 2018-01-10, MAE is:2.21 & sMAPE is:5.67% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 34.40% & 0.60\n",
      "for 2018-01-11, MAE is:4.93 & sMAPE is:10.69% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 32.25% & 0.58\n",
      "for 2018-01-12, MAE is:3.29 & sMAPE is:6.65% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 30.11% & 0.56\n",
      "for 2018-01-13, MAE is:5.14 & sMAPE is:12.30% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 28.74% & 0.58\n",
      "for 2018-01-14, MAE is:5.38 & sMAPE is:14.07% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 27.70% & 0.56\n",
      "for 2018-01-15, MAE is:7.40 & sMAPE is:15.55% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 26.89% & 0.57\n",
      "for 2018-01-16, MAE is:7.47 & sMAPE is:22.08% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 26.59% & 0.57\n",
      "for 2018-01-17, MAE is:3.50 & sMAPE is:10.05% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 25.61% & 0.58\n",
      "for 2018-01-18, MAE is:5.03 & sMAPE is:16.63% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 25.11% & 0.57\n",
      "for 2018-01-19, MAE is:2.16 & sMAPE is:5.51% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 24.08% & 0.56\n",
      "for 2018-01-20, MAE is:5.39 & sMAPE is:15.02% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 23.63% & 0.58\n",
      "for 2018-01-21, MAE is:2.85 & sMAPE is:8.07% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 22.89% & 0.58\n",
      "for 2018-01-22, MAE is:4.28 & sMAPE is:13.09% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 22.44% & 0.59\n",
      "for 2018-01-23, MAE is:3.93 & sMAPE is:10.88% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 21.94% & 0.59\n",
      "for 2018-01-24, MAE is:4.90 & sMAPE is:16.20% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 21.70% & 0.61\n",
      "for 2018-01-25, MAE is:5.99 & sMAPE is:19.77% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 21.62% & 0.64\n",
      "for 2018-01-26, MAE is:9.06 & sMAPE is:23.15% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 21.68% & 0.69\n",
      "for 2018-01-27, MAE is:4.54 & sMAPE is:13.34% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 21.37% & 0.70\n",
      "for 2018-01-28, MAE is:4.82 & sMAPE is:21.34% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 21.37% & 0.69\n",
      "for 2018-01-29, MAE is:3.82 & sMAPE is:12.38% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 21.06% & 0.69\n",
      "for 2018-01-30, MAE is:5.43 & sMAPE is:13.78% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 20.82% & 0.70\n",
      "for 2018-01-31, MAE is:5.18 & sMAPE is:13.86% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 20.59% & 0.70\n",
      "for 2018-02-01, MAE is:2.13 & sMAPE is:5.35% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 20.12% & 0.69\n",
      "for 2018-02-02, MAE is:2.47 & sMAPE is:5.78% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 19.68% & 0.69\n",
      "for 2018-02-03, MAE is:3.15 & sMAPE is:8.12% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 19.34% & 0.69\n",
      "for 2018-02-04, MAE is:5.78 & sMAPE is:16.55% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 19.26% & 0.68\n",
      "for 2018-02-05, MAE is:2.78 & sMAPE is:6.13% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 18.90% & 0.67\n",
      "for 2018-02-06, MAE is:5.38 & sMAPE is:10.93% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 18.68% & 0.67\n",
      "for 2018-02-07, MAE is:2.68 & sMAPE is:5.28% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 18.33% & 0.66\n",
      "for 2018-02-08, MAE is:3.33 & sMAPE is:6.57% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 18.03% & 0.64\n",
      "for 2018-02-09, MAE is:8.06 & sMAPE is:15.44% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 17.96% & 0.67\n",
      "for 2018-02-10, MAE is:3.73 & sMAPE is:8.86% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 17.74% & 0.68\n",
      "for 2018-02-11, MAE is:6.71 & sMAPE is:25.92% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 17.94% & 0.68\n",
      "for 2018-02-12, MAE is:11.36 & sMAPE is:25.93% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 18.12% & 0.71\n",
      "for 2018-02-13, MAE is:4.15 & sMAPE is:9.11% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 17.92% & 0.70\n",
      "for 2018-02-14, MAE is:4.55 & sMAPE is:10.21% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 17.75% & 0.70\n",
      "for 2018-02-15, MAE is:2.79 & sMAPE is:6.97% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 17.51% & 0.69\n",
      "for 2018-02-16, MAE is:1.74 & sMAPE is:4.03% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 17.23% & 0.69\n",
      "for 2018-02-17, MAE is:1.98 & sMAPE is:4.99% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 16.97% & 0.68\n",
      "for 2018-02-18, MAE is:2.73 & sMAPE is:7.58% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 16.78% & 0.67\n",
      "for 2018-02-19, MAE is:5.49 & sMAPE is:11.05% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 16.66% & 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-20, MAE is:2.11 & sMAPE is:4.44% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 16.42% & 0.68\n",
      "for 2018-02-21, MAE is:2.95 & sMAPE is:6.36% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 16.23% & 0.67\n",
      "for 2018-02-22, MAE is:3.21 & sMAPE is:6.70% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 16.05% & 0.67\n",
      "for 2018-02-23, MAE is:4.36 & sMAPE is:8.72% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 15.92% & 0.66\n",
      "for 2018-02-24, MAE is:7.80 & sMAPE is:16.59% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 15.93% & 0.67\n",
      "for 2018-02-25, MAE is:3.73 & sMAPE is:7.87% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 15.78% & 0.67\n",
      "for 2018-02-26, MAE is:5.28 & sMAPE is:8.82% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 15.66% & 0.67\n",
      "for 2018-02-27, MAE is:9.53 & sMAPE is:13.24% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 15.62% & 0.66\n",
      "for 2018-02-28, MAE is:11.08 & sMAPE is:16.66% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 15.64% & 0.66\n",
      "for 2018-03-01, MAE is:23.20 & sMAPE is:29.59% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 15.87% & 0.66\n",
      "for 2018-03-02, MAE is:35.24 & sMAPE is:38.87% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 16.25% & 0.66\n",
      "for 2018-03-03, MAE is:8.05 & sMAPE is:14.55% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 16.22% & 0.67\n",
      "for 2018-03-04, MAE is:4.53 & sMAPE is:9.05% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 16.11% & 0.67\n",
      "for 2018-03-05, MAE is:6.74 & sMAPE is:12.27% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 16.05% & 0.67\n",
      "for 2018-03-06, MAE is:2.80 & sMAPE is:5.43% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 15.88% & 0.67\n",
      "for 2018-03-07, MAE is:1.95 & sMAPE is:4.22% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.71% & 0.66\n",
      "for 2018-03-08, MAE is:4.22 & sMAPE is:8.77% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.60% & 0.65\n",
      "for 2018-03-09, MAE is:3.03 & sMAPE is:6.98% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 15.48% & 0.64\n",
      "for 2018-03-10, MAE is:2.26 & sMAPE is:6.24% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 15.34% & 0.63\n",
      "for 2018-03-11, MAE is:3.79 & sMAPE is:12.99% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 15.31% & 0.63\n",
      "for 2018-03-12, MAE is:8.72 & sMAPE is:20.67% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 15.38% & 0.63\n",
      "for 2018-03-13, MAE is:9.30 & sMAPE is:16.88% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 15.40% & 0.64\n",
      "for 2018-03-14, MAE is:6.16 & sMAPE is:12.47% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 15.36% & 0.64\n",
      "for 2018-03-15, MAE is:11.74 & sMAPE is:30.45% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.57% & 0.65\n",
      "for 2018-03-16, MAE is:4.93 & sMAPE is:9.58% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.49% & 0.65\n",
      "for 2018-03-17, MAE is:9.27 & sMAPE is:18.51% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 15.53% & 0.64\n",
      "for 2018-03-18, MAE is:7.17 & sMAPE is:20.00% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 15.59% & 0.64\n",
      "for 2018-03-19, MAE is:4.71 & sMAPE is:8.01% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 15.49% & 0.64\n",
      "for 2018-03-20, MAE is:10.31 & sMAPE is:20.04% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 15.55% & 0.65\n",
      "for 2018-03-21, MAE is:8.61 & sMAPE is:15.29% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 15.54% & 0.65\n",
      "for 2018-03-22, MAE is:5.46 & sMAPE is:9.39% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 15.47% & 0.65\n",
      "for 2018-03-23, MAE is:7.83 & sMAPE is:13.47% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 15.44% & 0.66\n",
      "for 2018-03-24, MAE is:5.73 & sMAPE is:11.62% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 15.40% & 0.66\n",
      "for 2018-03-25, MAE is:5.97 & sMAPE is:14.64% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 15.39% & 0.66\n",
      "for 2018-03-26, MAE is:4.49 & sMAPE is:7.80% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 15.30% & 0.67\n",
      "for 2018-03-27, MAE is:6.60 & sMAPE is:13.17% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 15.27% & 0.67\n",
      "for 2018-03-28, MAE is:4.14 & sMAPE is:9.00% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 15.20% & 0.66\n",
      "for 2018-03-29, MAE is:5.30 & sMAPE is:10.62% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 15.15% & 0.66\n",
      "for 2018-03-30, MAE is:2.84 & sMAPE is:6.18% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 15.05% & 0.66\n",
      "for 2018-03-31, MAE is:3.23 & sMAPE is:8.77% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 14.98% & 0.65\n",
      "for 2018-04-01, MAE is:5.76 & sMAPE is:20.88% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.04% & 0.65\n",
      "for 2018-04-02, MAE is:6.74 & sMAPE is:21.22% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.11% & 0.65\n",
      "for 2018-04-03, MAE is:8.08 & sMAPE is:23.53% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 15.20% & 0.65\n",
      "for 2018-04-04, MAE is:3.22 & sMAPE is:10.20% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.15% & 0.65\n",
      "for 2018-04-05, MAE is:3.37 & sMAPE is:8.84% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.08% & 0.64\n",
      "for 2018-04-06, MAE is:7.41 & sMAPE is:18.47% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.12% & 0.65\n",
      "for 2018-04-07, MAE is:5.50 & sMAPE is:20.97% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.18% & 0.65\n",
      "for 2018-04-08, MAE is:5.30 & sMAPE is:22.87% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.26% & 0.65\n",
      "for 2018-04-09, MAE is:11.16 & sMAPE is:28.12% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 15.39% & 0.65\n",
      "for 2018-04-10, MAE is:3.86 & sMAPE is:8.49% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.32% & 0.65\n",
      "for 2018-04-11, MAE is:7.58 & sMAPE is:17.53% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.34% & 0.65\n",
      "for 2018-04-12, MAE is:7.09 & sMAPE is:15.84% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 15.34% & 0.65\n",
      "for 2018-04-13, MAE is:5.87 & sMAPE is:11.65% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 15.31% & 0.65\n",
      "for 2018-04-14, MAE is:3.35 & sMAPE is:8.78% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.25% & 0.65\n",
      "for 2018-04-15, MAE is:9.59 & sMAPE is:24.19% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 15.33% & 0.65\n",
      "for 2018-04-16, MAE is:3.82 & sMAPE is:7.78% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.26% & 0.66\n",
      "for 2018-04-17, MAE is:4.17 & sMAPE is:9.81% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.21% & 0.66\n",
      "for 2018-04-18, MAE is:4.09 & sMAPE is:9.89% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.16% & 0.66\n",
      "for 2018-04-19, MAE is:4.62 & sMAPE is:10.64% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 15.12% & 0.65\n",
      "for 2018-04-20, MAE is:2.87 & sMAPE is:6.90% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 15.04% & 0.65\n",
      "for 2018-04-21, MAE is:10.40 & sMAPE is:25.53% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.14% & 0.65\n",
      "for 2018-04-22, MAE is:15.99 & sMAPE is:67.03% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 15.60% & 0.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-23, MAE is:3.91 & sMAPE is:14.98% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 15.60% & 0.65\n",
      "for 2018-04-24, MAE is:2.98 & sMAPE is:7.71% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.53% & 0.65\n",
      "for 2018-04-25, MAE is:7.22 & sMAPE is:19.95% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 15.56% & 0.65\n",
      "for 2018-04-26, MAE is:4.52 & sMAPE is:13.15% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.54% & 0.65\n",
      "for 2018-04-27, MAE is:6.47 & sMAPE is:15.70% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.54% & 0.66\n",
      "for 2018-04-28, MAE is:9.52 & sMAPE is:25.30% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 15.63% & 0.66\n",
      "for 2018-04-29, MAE is:11.90 & sMAPE is:34.85% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 15.79% & 0.66\n",
      "for 2018-04-30, MAE is:10.85 & sMAPE is:48.19% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 16.06% & 0.66\n",
      "for 2018-05-01, MAE is:8.47 & sMAPE is:33.95% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 16.21% & 0.66\n",
      "for 2018-05-02, MAE is:6.77 & sMAPE is:17.78% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 16.22% & 0.66\n",
      "for 2018-05-03, MAE is:7.51 & sMAPE is:15.10% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 16.21% & 0.66\n",
      "for 2018-05-04, MAE is:7.31 & sMAPE is:15.42% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 16.20% & 0.67\n",
      "for 2018-05-05, MAE is:13.19 & sMAPE is:31.26% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 16.32% & 0.67\n",
      "for 2018-05-06, MAE is:10.31 & sMAPE is:33.57% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 16.46% & 0.67\n",
      "for 2018-05-07, MAE is:6.57 & sMAPE is:14.40% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 16.45% & 0.66\n",
      "for 2018-05-08, MAE is:7.81 & sMAPE is:16.47% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 16.45% & 0.66\n",
      "for 2018-05-09, MAE is:6.83 & sMAPE is:14.59% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 16.43% & 0.66\n",
      "for 2018-05-10, MAE is:10.63 & sMAPE is:30.52% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 16.54% & 0.67\n",
      "for 2018-05-11, MAE is:7.12 & sMAPE is:15.44% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 16.53% & 0.67\n",
      "for 2018-05-12, MAE is:8.77 & sMAPE is:22.42% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 16.58% & 0.67\n",
      "for 2018-05-13, MAE is:15.73 & sMAPE is:43.88% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.78% & 0.67\n",
      "for 2018-05-14, MAE is:10.25 & sMAPE is:28.10% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.87% & 0.67\n",
      "for 2018-05-15, MAE is:5.26 & sMAPE is:11.82% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.83% & 0.67\n",
      "for 2018-05-16, MAE is:8.37 & sMAPE is:18.29% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.84% & 0.67\n",
      "for 2018-05-17, MAE is:2.75 & sMAPE is:8.16% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.78% & 0.67\n",
      "for 2018-05-18, MAE is:11.18 & sMAPE is:24.35% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.83% & 0.68\n",
      "for 2018-05-19, MAE is:18.10 & sMAPE is:35.02% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 16.96% & 0.68\n",
      "for 2018-05-20, MAE is:17.72 & sMAPE is:75.98% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 17.38% & 0.68\n",
      "for 2018-05-21, MAE is:17.35 & sMAPE is:72.73% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.78% & 0.68\n",
      "for 2018-05-22, MAE is:8.61 & sMAPE is:19.49% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 17.79% & 0.69\n",
      "for 2018-05-23, MAE is:5.63 & sMAPE is:12.11% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 17.75% & 0.69\n",
      "for 2018-05-24, MAE is:3.93 & sMAPE is:8.49% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 17.68% & 0.68\n",
      "for 2018-05-25, MAE is:4.73 & sMAPE is:10.02% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 17.63% & 0.68\n",
      "for 2018-05-26, MAE is:6.04 & sMAPE is:14.65% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 17.61% & 0.68\n",
      "for 2018-05-27, MAE is:6.19 & sMAPE is:14.47% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 17.59% & 0.68\n",
      "for 2018-05-28, MAE is:16.09 & sMAPE is:26.98% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 17.65% & 0.68\n",
      "for 2018-05-29, MAE is:6.78 & sMAPE is:11.50% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 17.61% & 0.68\n",
      "for 2018-05-30, MAE is:14.08 & sMAPE is:22.40% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 17.64% & 0.68\n",
      "for 2018-05-31, MAE is:7.66 & sMAPE is:11.88% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 17.60% & 0.68\n",
      "for 2018-06-01, MAE is:10.54 & sMAPE is:17.02% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 17.60% & 0.68\n",
      "for 2018-06-02, MAE is:19.83 & sMAPE is:38.49% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 17.74% & 0.68\n",
      "for 2018-06-03, MAE is:16.71 & sMAPE is:32.27% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 17.83% & 0.68\n",
      "for 2018-06-04, MAE is:7.40 & sMAPE is:13.06% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 17.80% & 0.68\n",
      "for 2018-06-05, MAE is:3.89 & sMAPE is:6.92% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 17.73% & 0.68\n",
      "for 2018-06-06, MAE is:3.08 & sMAPE is:6.01% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 17.66% & 0.68\n",
      "for 2018-06-07, MAE is:3.98 & sMAPE is:7.39% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 17.59% & 0.68\n",
      "for 2018-06-08, MAE is:7.23 & sMAPE is:13.41% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 17.57% & 0.68\n",
      "for 2018-06-09, MAE is:14.59 & sMAPE is:31.78% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 17.65% & 0.68\n",
      "for 2018-06-10, MAE is:10.33 & sMAPE is:25.18% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 17.70% & 0.68\n",
      "for 2018-06-11, MAE is:7.79 & sMAPE is:15.45% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 17.69% & 0.69\n",
      "for 2018-06-12, MAE is:3.49 & sMAPE is:7.15% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 17.62% & 0.69\n",
      "for 2018-06-13, MAE is:2.81 & sMAPE is:6.06% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 17.55% & 0.68\n",
      "for 2018-06-14, MAE is:5.29 & sMAPE is:10.67% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 17.51% & 0.68\n",
      "for 2018-06-15, MAE is:6.06 & sMAPE is:11.41% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 17.47% & 0.69\n",
      "for 2018-06-16, MAE is:3.68 & sMAPE is:8.68% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 17.42% & 0.69\n",
      "for 2018-06-17, MAE is:10.51 & sMAPE is:40.61% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 17.56% & 0.68\n",
      "for 2018-06-18, MAE is:2.88 & sMAPE is:6.20% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.49% & 0.68\n",
      "for 2018-06-19, MAE is:6.46 & sMAPE is:11.83% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.46% & 0.68\n",
      "for 2018-06-20, MAE is:6.01 & sMAPE is:12.06% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 17.43% & 0.69\n",
      "for 2018-06-21, MAE is:9.55 & sMAPE is:20.71% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 17.45% & 0.69\n",
      "for 2018-06-22, MAE is:11.77 & sMAPE is:33.37% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 17.54% & 0.69\n",
      "for 2018-06-23, MAE is:5.18 & sMAPE is:14.65% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 17.52% & 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-24, MAE is:3.49 & sMAPE is:9.47% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 17.48% & 0.69\n",
      "for 2018-06-25, MAE is:6.16 & sMAPE is:12.86% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.45% & 0.69\n",
      "for 2018-06-26, MAE is:7.98 & sMAPE is:14.69% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 17.43% & 0.69\n",
      "for 2018-06-27, MAE is:4.03 & sMAPE is:8.31% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 17.38% & 0.70\n",
      "for 2018-06-28, MAE is:4.22 & sMAPE is:8.52% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 17.33% & 0.69\n",
      "for 2018-06-29, MAE is:4.37 & sMAPE is:8.46% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 17.28% & 0.69\n",
      "for 2018-06-30, MAE is:7.14 & sMAPE is:17.70% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 17.29% & 0.69\n",
      "for 2018-07-01, MAE is:6.98 & sMAPE is:22.84% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 17.32% & 0.69\n",
      "for 2018-07-02, MAE is:9.37 & sMAPE is:17.63% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 17.32% & 0.70\n",
      "for 2018-07-03, MAE is:11.35 & sMAPE is:19.83% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.33% & 0.70\n",
      "for 2018-07-04, MAE is:4.11 & sMAPE is:6.67% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 17.27% & 0.70\n",
      "for 2018-07-05, MAE is:3.65 & sMAPE is:6.15% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 17.21% & 0.70\n",
      "for 2018-07-06, MAE is:3.26 & sMAPE is:5.65% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 17.15% & 0.69\n",
      "for 2018-07-07, MAE is:10.93 & sMAPE is:20.80% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 17.17% & 0.70\n",
      "for 2018-07-08, MAE is:5.62 & sMAPE is:13.76% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 17.15% & 0.70\n",
      "for 2018-07-09, MAE is:5.92 & sMAPE is:10.67% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 17.12% & 0.70\n",
      "for 2018-07-10, MAE is:3.23 & sMAPE is:6.69% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 17.07% & 0.70\n",
      "for 2018-07-11, MAE is:4.00 & sMAPE is:8.59% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 17.02% & 0.70\n",
      "for 2018-07-12, MAE is:5.87 & sMAPE is:12.47% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 17.00% & 0.70\n",
      "for 2018-07-13, MAE is:4.23 & sMAPE is:8.95% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 16.96% & 0.70\n",
      "for 2018-07-14, MAE is:5.42 & sMAPE is:11.41% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 16.93% & 0.70\n",
      "for 2018-07-15, MAE is:5.60 & sMAPE is:13.13% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 16.91% & 0.70\n",
      "for 2018-07-16, MAE is:3.05 & sMAPE is:5.93% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 16.85% & 0.70\n",
      "for 2018-07-17, MAE is:2.67 & sMAPE is:5.44% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 16.79% & 0.70\n",
      "for 2018-07-18, MAE is:2.83 & sMAPE is:5.71% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 16.74% & 0.70\n",
      "for 2018-07-19, MAE is:2.78 & sMAPE is:5.53% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.68% & 0.71\n",
      "for 2018-07-20, MAE is:3.27 & sMAPE is:6.82% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.63% & 0.71\n",
      "for 2018-07-21, MAE is:12.66 & sMAPE is:29.35% & rMAE is:3.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 16.70% & 0.72\n",
      "for 2018-07-22, MAE is:10.00 & sMAPE is:24.23% & rMAE is:5.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 16.73% & 0.75\n",
      "for 2018-07-23, MAE is:2.80 & sMAPE is:5.42% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.68% & 0.75\n",
      "for 2018-07-24, MAE is:4.35 & sMAPE is:7.82% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.64% & 0.75\n",
      "for 2018-07-25, MAE is:6.80 & sMAPE is:12.31% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.61% & 0.76\n",
      "for 2018-07-26, MAE is:9.63 & sMAPE is:15.86% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 16.61% & 0.76\n",
      "for 2018-07-27, MAE is:3.00 & sMAPE is:5.06% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.56% & 0.75\n",
      "for 2018-07-28, MAE is:8.12 & sMAPE is:18.69% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.57% & 0.76\n",
      "for 2018-07-29, MAE is:8.83 & sMAPE is:22.62% & rMAE is:3.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.59% & 0.77\n",
      "for 2018-07-30, MAE is:5.74 & sMAPE is:11.78% & rMAE is:3.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.57% & 0.79\n",
      "for 2018-07-31, MAE is:3.67 & sMAPE is:6.71% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.52% & 0.79\n",
      "for 2018-08-01, MAE is:7.58 & sMAPE is:14.57% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.52% & 0.79\n",
      "for 2018-08-02, MAE is:5.96 & sMAPE is:10.73% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.49% & 0.80\n",
      "for 2018-08-03, MAE is:9.28 & sMAPE is:15.37% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.48% & 0.80\n",
      "for 2018-08-04, MAE is:5.74 & sMAPE is:12.21% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.46% & 0.80\n",
      "for 2018-08-05, MAE is:9.71 & sMAPE is:21.76% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 16.49% & 0.81\n",
      "for 2018-08-06, MAE is:5.67 & sMAPE is:8.55% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.45% & 0.81\n",
      "for 2018-08-07, MAE is:3.67 & sMAPE is:5.41% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.40% & 0.81\n",
      "for 2018-08-08, MAE is:4.86 & sMAPE is:8.20% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.36% & 0.81\n",
      "for 2018-08-09, MAE is:5.95 & sMAPE is:10.77% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 16.34% & 0.81\n",
      "for 2018-08-10, MAE is:4.42 & sMAPE is:8.87% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 16.31% & 0.81\n",
      "for 2018-08-11, MAE is:6.48 & sMAPE is:14.43% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 16.30% & 0.81\n",
      "for 2018-08-12, MAE is:9.97 & sMAPE is:25.13% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.34% & 0.81\n",
      "for 2018-08-13, MAE is:3.58 & sMAPE is:6.87% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 16.29% & 0.81\n",
      "for 2018-08-14, MAE is:4.73 & sMAPE is:9.49% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 16.26% & 0.81\n",
      "for 2018-08-15, MAE is:8.25 & sMAPE is:16.54% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 16.27% & 0.82\n",
      "for 2018-08-16, MAE is:4.66 & sMAPE is:8.81% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 16.23% & 0.81\n",
      "for 2018-08-17, MAE is:3.01 & sMAPE is:5.11% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 16.18% & 0.81\n",
      "for 2018-08-18, MAE is:12.51 & sMAPE is:25.96% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 16.23% & 0.82\n",
      "for 2018-08-19, MAE is:10.37 & sMAPE is:24.08% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.26% & 0.82\n",
      "for 2018-08-20, MAE is:6.47 & sMAPE is:10.45% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.24% & 0.82\n",
      "for 2018-08-21, MAE is:5.67 & sMAPE is:8.63% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 16.20% & 0.82\n",
      "for 2018-08-22, MAE is:13.42 & sMAPE is:21.25% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.22% & 0.82\n",
      "for 2018-08-23, MAE is:7.29 & sMAPE is:11.12% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.20% & 0.82\n",
      "for 2018-08-24, MAE is:9.09 & sMAPE is:14.71% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 16.20% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-25, MAE is:21.80 & sMAPE is:40.03% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 16.30% & 0.82\n",
      "for 2018-08-26, MAE is:14.18 & sMAPE is:30.39% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 16.36% & 0.83\n",
      "for 2018-08-27, MAE is:17.56 & sMAPE is:25.05% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 16.39% & 0.83\n",
      "for 2018-08-28, MAE is:7.37 & sMAPE is:9.99% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 16.37% & 0.83\n",
      "for 2018-08-29, MAE is:10.35 & sMAPE is:13.52% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 16.35% & 0.84\n",
      "for 2018-08-30, MAE is:16.13 & sMAPE is:21.41% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 16.37% & 0.84\n",
      "for 2018-08-31, MAE is:3.81 & sMAPE is:5.67% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 16.33% & 0.84\n",
      "for 2018-09-01, MAE is:17.53 & sMAPE is:31.72% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 16.39% & 0.84\n",
      "for 2018-09-02, MAE is:10.42 & sMAPE is:21.07% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 16.41% & 0.85\n",
      "for 2018-09-03, MAE is:7.34 & sMAPE is:10.60% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 16.39% & 0.85\n",
      "for 2018-09-04, MAE is:3.59 & sMAPE is:5.61% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 16.35% & 0.85\n",
      "for 2018-09-05, MAE is:4.42 & sMAPE is:6.54% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 16.31% & 0.85\n",
      "for 2018-09-06, MAE is:4.48 & sMAPE is:6.96% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 16.27% & 0.85\n",
      "for 2018-09-07, MAE is:6.35 & sMAPE is:9.82% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 16.24% & 0.85\n",
      "for 2018-09-08, MAE is:16.51 & sMAPE is:27.20% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 16.29% & 0.86\n",
      "for 2018-09-09, MAE is:5.81 & sMAPE is:11.00% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 16.27% & 0.86\n",
      "for 2018-09-10, MAE is:3.67 & sMAPE is:5.84% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 16.22% & 0.86\n",
      "for 2018-09-11, MAE is:4.49 & sMAPE is:6.29% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 16.19% & 0.86\n",
      "for 2018-09-12, MAE is:4.55 & sMAPE is:6.00% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 16.15% & 0.86\n",
      "for 2018-09-13, MAE is:6.24 & sMAPE is:9.54% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 16.12% & 0.86\n",
      "for 2018-09-14, MAE is:6.56 & sMAPE is:9.47% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 16.09% & 0.87\n",
      "for 2018-09-15, MAE is:5.40 & sMAPE is:9.65% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 16.07% & 0.87\n",
      "for 2018-09-16, MAE is:6.89 & sMAPE is:13.83% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 16.06% & 0.87\n",
      "for 2018-09-17, MAE is:3.71 & sMAPE is:5.41% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 16.02% & 0.87\n",
      "for 2018-09-18, MAE is:7.03 & sMAPE is:10.03% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 16.00% & 0.87\n",
      "for 2018-09-19, MAE is:5.86 & sMAPE is:8.42% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 15.97% & 0.87\n",
      "for 2018-09-20, MAE is:4.60 & sMAPE is:7.18% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 15.93% & 0.87\n",
      "for 2018-09-21, MAE is:8.76 & sMAPE is:14.99% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 15.93% & 0.87\n",
      "for 2018-09-22, MAE is:23.24 & sMAPE is:34.07% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 16.00% & 0.87\n",
      "for 2018-09-23, MAE is:11.80 & sMAPE is:20.00% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 16.01% & 0.87\n",
      "for 2018-09-24, MAE is:40.27 & sMAPE is:32.79% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 16.08% & 0.87\n",
      "for 2018-09-25, MAE is:24.42 & sMAPE is:30.39% & rMAE is:2.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 16.13% & 0.88\n",
      "for 2018-09-26, MAE is:11.67 & sMAPE is:14.72% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 16.12% & 0.88\n",
      "for 2018-09-27, MAE is:11.69 & sMAPE is:14.38% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 16.12% & 0.88\n",
      "for 2018-09-28, MAE is:8.20 & sMAPE is:11.66% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 16.10% & 0.88\n",
      "for 2018-09-29, MAE is:24.68 & sMAPE is:40.08% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 16.19% & 0.88\n",
      "for 2018-09-30, MAE is:18.49 & sMAPE is:31.98% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 16.25% & 0.88\n",
      "for 2018-10-01, MAE is:11.95 & sMAPE is:18.80% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 16.26% & 0.88\n",
      "for 2018-10-02, MAE is:14.45 & sMAPE is:16.15% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 16.26% & 0.88\n",
      "for 2018-10-03, MAE is:21.65 & sMAPE is:22.36% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 16.28% & 0.88\n",
      "for 2018-10-04, MAE is:9.76 & sMAPE is:12.77% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 16.27% & 0.88\n",
      "for 2018-10-05, MAE is:4.27 & sMAPE is:6.54% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 16.23% & 0.88\n",
      "for 2018-10-06, MAE is:16.72 & sMAPE is:32.11% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 16.29% & 0.88\n",
      "for 2018-10-07, MAE is:4.24 & sMAPE is:7.30% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 16.26% & 0.88\n",
      "for 2018-10-08, MAE is:3.27 & sMAPE is:4.28% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 16.21% & 0.87\n",
      "for 2018-10-09, MAE is:9.72 & sMAPE is:12.15% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 16.20% & 0.87\n",
      "for 2018-10-10, MAE is:9.22 & sMAPE is:12.89% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 16.19% & 0.87\n",
      "for 2018-10-11, MAE is:6.06 & sMAPE is:8.63% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 16.16% & 0.87\n",
      "for 2018-10-12, MAE is:3.83 & sMAPE is:6.45% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 16.13% & 0.87\n",
      "for 2018-10-13, MAE is:19.67 & sMAPE is:30.63% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 16.18% & 0.87\n",
      "for 2018-10-14, MAE is:14.85 & sMAPE is:29.30% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 16.22% & 0.87\n",
      "for 2018-10-15, MAE is:9.80 & sMAPE is:14.64% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 16.22% & 0.88\n",
      "for 2018-10-16, MAE is:8.11 & sMAPE is:10.07% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 16.20% & 0.88\n",
      "for 2018-10-17, MAE is:8.44 & sMAPE is:9.69% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 16.17% & 0.88\n",
      "for 2018-10-18, MAE is:7.84 & sMAPE is:10.34% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 16.15% & 0.88\n",
      "for 2018-10-19, MAE is:5.39 & sMAPE is:7.78% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 16.12% & 0.88\n",
      "for 2018-10-20, MAE is:13.19 & sMAPE is:24.40% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 16.15% & 0.88\n",
      "for 2018-10-21, MAE is:13.14 & sMAPE is:26.06% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 16.19% & 0.88\n",
      "for 2018-10-22, MAE is:7.20 & sMAPE is:10.22% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 16.17% & 0.88\n",
      "for 2018-10-23, MAE is:11.03 & sMAPE is:13.11% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 16.16% & 0.88\n",
      "for 2018-10-24, MAE is:7.91 & sMAPE is:10.28% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 16.14% & 0.88\n",
      "for 2018-10-25, MAE is:10.27 & sMAPE is:10.87% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 16.12% & 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-26, MAE is:7.48 & sMAPE is:8.84% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 16.09% & 0.88\n",
      "for 2018-10-27, MAE is:17.25 & sMAPE is:22.77% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 16.12% & 0.88\n",
      "for 2018-10-28, MAE is:9.58 & sMAPE is:14.00% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 16.11% & 0.88\n",
      "for 2018-10-29, MAE is:26.50 & sMAPE is:22.41% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 16.13% & 0.88\n",
      "for 2018-10-30, MAE is:18.24 & sMAPE is:16.14% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 16.13% & 0.87\n",
      "for 2018-10-31, MAE is:17.70 & sMAPE is:18.19% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 16.14% & 0.87\n",
      "for 2018-11-01, MAE is:13.10 & sMAPE is:20.57% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 16.15% & 0.87\n",
      "for 2018-11-02, MAE is:9.50 & sMAPE is:11.76% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 16.14% & 0.87\n",
      "for 2018-11-03, MAE is:9.18 & sMAPE is:12.06% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 16.12% & 0.87\n",
      "for 2018-11-04, MAE is:4.51 & sMAPE is:7.05% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 16.09% & 0.87\n",
      "for 2018-11-05, MAE is:31.90 & sMAPE is:30.48% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 16.14% & 0.87\n",
      "for 2018-11-06, MAE is:30.73 & sMAPE is:37.14% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 16.21% & 0.87\n",
      "for 2018-11-07, MAE is:3.54 & sMAPE is:6.19% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 16.18% & 0.87\n",
      "for 2018-11-08, MAE is:7.19 & sMAPE is:10.01% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 16.16% & 0.87\n",
      "for 2018-11-09, MAE is:10.89 & sMAPE is:15.12% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 16.15% & 0.87\n",
      "for 2018-11-10, MAE is:9.75 & sMAPE is:15.77% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 16.15% & 0.86\n",
      "for 2018-11-11, MAE is:9.76 & sMAPE is:16.30% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 16.15% & 0.87\n",
      "for 2018-11-12, MAE is:11.37 & sMAPE is:15.89% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 16.15% & 0.86\n",
      "for 2018-11-13, MAE is:8.65 & sMAPE is:10.72% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 16.14% & 0.86\n",
      "for 2018-11-14, MAE is:21.49 & sMAPE is:26.11% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 16.17% & 0.87\n",
      "for 2018-11-15, MAE is:9.49 & sMAPE is:12.15% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 16.15% & 0.87\n",
      "for 2018-11-16, MAE is:5.17 & sMAPE is:7.01% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 16.13% & 0.87\n",
      "for 2018-11-17, MAE is:8.91 & sMAPE is:13.52% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 16.12% & 0.87\n",
      "for 2018-11-18, MAE is:7.08 & sMAPE is:11.49% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 16.10% & 0.87\n",
      "for 2018-11-19, MAE is:8.83 & sMAPE is:10.57% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 16.09% & 0.87\n",
      "for 2018-11-20, MAE is:45.18 & sMAPE is:36.16% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 16.15% & 0.87\n",
      "for 2018-11-21, MAE is:80.67 & sMAPE is:45.03% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.31 & 16.24% & 0.87\n",
      "for 2018-11-22, MAE is:26.10 & sMAPE is:15.88% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 16.24% & 0.87\n",
      "for 2018-11-23, MAE is:17.08 & sMAPE is:15.81% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 16.23% & 0.87\n",
      "for 2018-11-24, MAE is:5.96 & sMAPE is:8.40% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 16.21% & 0.87\n",
      "for 2018-11-25, MAE is:3.83 & sMAPE is:6.19% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 16.18% & 0.87\n",
      "for 2018-11-26, MAE is:30.65 & sMAPE is:23.20% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 16.20% & 0.87\n",
      "for 2018-11-27, MAE is:24.03 & sMAPE is:23.28% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 16.22% & 0.86\n",
      "for 2018-11-28, MAE is:7.90 & sMAPE is:12.16% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 16.21% & 0.86\n",
      "for 2018-11-29, MAE is:4.48 & sMAPE is:6.82% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 16.18% & 0.86\n",
      "for 2018-11-30, MAE is:2.61 & sMAPE is:3.97% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 16.15% & 0.86\n",
      "for 2018-12-01, MAE is:10.72 & sMAPE is:19.77% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 16.16% & 0.86\n",
      "for 2018-12-02, MAE is:6.88 & sMAPE is:13.05% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 16.15% & 0.86\n",
      "for 2018-12-03, MAE is:12.99 & sMAPE is:21.78% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 16.16% & 0.86\n",
      "for 2018-12-04, MAE is:6.79 & sMAPE is:9.48% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 16.14% & 0.86\n",
      "for 2018-12-05, MAE is:11.65 & sMAPE is:16.68% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 16.15% & 0.86\n",
      "for 2018-12-06, MAE is:3.64 & sMAPE is:5.93% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 16.12% & 0.86\n",
      "for 2018-12-07, MAE is:8.49 & sMAPE is:15.59% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 16.11% & 0.86\n",
      "for 2018-12-08, MAE is:10.44 & sMAPE is:24.98% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 16.14% & 0.86\n",
      "for 2018-12-09, MAE is:11.38 & sMAPE is:34.31% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 16.19% & 0.86\n",
      "for 2018-12-10, MAE is:8.01 & sMAPE is:16.37% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 16.19% & 0.86\n",
      "for 2018-12-11, MAE is:8.99 & sMAPE is:14.29% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 16.19% & 0.86\n",
      "for 2018-12-12, MAE is:7.56 & sMAPE is:10.90% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 16.17% & 0.86\n",
      "for 2018-12-13, MAE is:5.37 & sMAPE is:6.99% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 16.15% & 0.86\n",
      "for 2018-12-14, MAE is:4.24 & sMAPE is:5.33% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 16.11% & 0.85\n",
      "for 2018-12-15, MAE is:6.06 & sMAPE is:9.81% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 16.10% & 0.85\n",
      "for 2018-12-16, MAE is:7.23 & sMAPE is:13.48% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 16.09% & 0.85\n",
      "for 2018-12-17, MAE is:4.89 & sMAPE is:6.72% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 16.06% & 0.85\n",
      "for 2018-12-18, MAE is:7.32 & sMAPE is:10.42% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 16.05% & 0.85\n",
      "for 2018-12-19, MAE is:5.58 & sMAPE is:8.77% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 16.03% & 0.85\n",
      "for 2018-12-20, MAE is:4.63 & sMAPE is:7.96% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 16.00% & 0.85\n",
      "for 2018-12-21, MAE is:7.71 & sMAPE is:12.68% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 15.99% & 0.85\n",
      "for 2018-12-22, MAE is:15.59 & sMAPE is:37.88% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 16.06% & 0.85\n",
      "for 2018-12-23, MAE is:6.54 & sMAPE is:13.27% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 16.05% & 0.85\n",
      "for 2018-12-24, MAE is:9.11 & sMAPE is:16.27% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 16.05% & 0.85\n",
      "for 2018-12-25, MAE is:12.34 & sMAPE is:23.39% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 16.07% & 0.85\n",
      "for 2018-12-26, MAE is:5.83 & sMAPE is:10.75% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 16.05% & 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-12-27, MAE is:6.28 & sMAPE is:11.36% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 16.04% & 0.85\n",
      "for 2018-12-28, MAE is:4.91 & sMAPE is:8.92% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 16.02% & 0.85\n",
      "for 2018-12-29, MAE is:4.81 & sMAPE is:8.99% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 16.00% & 0.85\n",
      "for 2018-12-30, MAE is:7.51 & sMAPE is:13.87% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 16.00% & 0.85\n",
      "for 2018-12-31, MAE is:5.61 & sMAPE is:10.49% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 15.98% & 0.84\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.2 - (Calib Year = 3)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:35:04,358]\u001b[0m A new study created in RDB with name: BE_2019\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:35:23,716]\u001b[0m Trial 3 finished with value: 10.997997764795187 and parameters: {'n_hidden': 4, 'learning_rate': 0.006807457055297688, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1618136095549038, 'dropout_rate_Layer_2': 0.12431518269116122, 'dropout_rate_Layer_3': 0.2006665141940348, 'dropout_rate_Layer_4': 0.050358028431241354, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.994329300493106e-05, 'l1_Layer_2': 0.0008937109625642202, 'l1_Layer_3': 1.758394915374809e-05, 'l1_Layer_4': 3.646978228637383e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 150, 'n_units_Layer_3': 55, 'n_units_Layer_4': 265}. Best is trial 3 with value: 10.997997764795187.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.00 | sMAPE for Validation Set is: 19.82% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 10.38 | sMAPE for Test Set is: 26.32% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:35:24,009]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:35:30,490]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:35:31,663]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:35:38,012]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:35:41,306]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:35:46,319]\u001b[0m Trial 6 finished with value: 8.557252165227853 and parameters: {'n_hidden': 3, 'learning_rate': 0.004738456082860428, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.189729498826686, 'dropout_rate_Layer_2': 0.01568803340759022, 'dropout_rate_Layer_3': 0.05398470386473369, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5608351157144263e-05, 'l1_Layer_2': 0.04225445445108652, 'l1_Layer_3': 5.8622334902463775e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 205}. Best is trial 6 with value: 8.557252165227853.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 15.57% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.26 | sMAPE for Test Set is: 17.76% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:35:46,692]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:35:50,344]\u001b[0m Trial 1 finished with value: 9.524943812102135 and parameters: {'n_hidden': 3, 'learning_rate': 0.002454793362198906, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30527682174913706, 'dropout_rate_Layer_2': 0.39886197608910684, 'dropout_rate_Layer_3': 0.28869508108431446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004274261688557654, 'l1_Layer_2': 3.2539998260446366e-05, 'l1_Layer_3': 0.06883259324071947, 'n_units_Layer_1': 110, 'n_units_Layer_2': 275, 'n_units_Layer_3': 50}. Best is trial 6 with value: 8.557252165227853.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.52 | sMAPE for Validation Set is: 17.79% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 18.46% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:35:52,972]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:35:55,518]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:35:57,887]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:01,705]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:03,949]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:06,598]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:09,416]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:11,014]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:14,622]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:16,270]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:20,229]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:24,173]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:28,313]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:30,157]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:34,635]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:35,944]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:42,081]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:43,879]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:47,556]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:36:47,800]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:05,137]\u001b[0m Trial 22 finished with value: 12.689669404518229 and parameters: {'n_hidden': 4, 'learning_rate': 0.06659535564056607, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.276747538213056, 'dropout_rate_Layer_2': 0.33468898249895845, 'dropout_rate_Layer_3': 0.2848105356668017, 'dropout_rate_Layer_4': 0.20461023548194426, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00021295843347780458, 'l1_Layer_2': 0.0397355006816704, 'l1_Layer_3': 0.0001368187013801761, 'l1_Layer_4': 0.00020139582420948895, 'n_units_Layer_1': 240, 'n_units_Layer_2': 140, 'n_units_Layer_3': 250, 'n_units_Layer_4': 115}. Best is trial 6 with value: 8.557252165227853.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.69 | sMAPE for Validation Set is: 23.36% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 22.96% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:37:07,557]\u001b[0m Trial 5 finished with value: 9.237270659015167 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017350788719638682, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21412428764325886, 'dropout_rate_Layer_2': 0.0009056738733362658, 'dropout_rate_Layer_3': 0.03863192153338431, 'dropout_rate_Layer_4': 0.33418589279870053, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0015988072683734305, 'l1_Layer_2': 0.029086454675428225, 'l1_Layer_3': 0.035389275965800285, 'l1_Layer_4': 0.00040399982216207203, 'n_units_Layer_1': 95, 'n_units_Layer_2': 125, 'n_units_Layer_3': 140, 'n_units_Layer_4': 55}. Best is trial 6 with value: 8.557252165227853.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.24 | sMAPE for Validation Set is: 16.86% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 18.03% | rMAE for Test Set is: 0.74\n",
      "MAE for Validation Set is: 10.43 | sMAPE for Validation Set is: 19.22% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 7.23 | sMAPE for Test Set is: 20.02% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:37:09,327]\u001b[0m Trial 32 finished with value: 10.432075058823413 and parameters: {'n_hidden': 3, 'learning_rate': 0.030071073161378352, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03562950261852573, 'dropout_rate_Layer_2': 0.10595894330878407, 'dropout_rate_Layer_3': 0.08567770183177786, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00018076939656467027, 'l1_Layer_2': 0.0001303299511006775, 'l1_Layer_3': 0.0004179824767421713, 'n_units_Layer_1': 75, 'n_units_Layer_2': 75, 'n_units_Layer_3': 115}. Best is trial 6 with value: 8.557252165227853.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:10,876]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:16,171]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:18,324]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:20,655]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:24,636]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:24,761]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:27,165]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:34,513]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:34,596]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:34,686]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:43,869]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:44,437]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:51,875]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:52,792]\u001b[0m Trial 44 finished with value: 9.314304050484628 and parameters: {'n_hidden': 3, 'learning_rate': 0.055094894426266375, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.079681343084195, 'dropout_rate_Layer_2': 0.09556573315075761, 'dropout_rate_Layer_3': 0.04184131374174776, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2311832153344834e-05, 'l1_Layer_2': 1.9266232156240238e-05, 'l1_Layer_3': 1.3665080581408064e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 235, 'n_units_Layer_3': 170}. Best is trial 6 with value: 8.557252165227853.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.31 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.38 | sMAPE for Test Set is: 17.67% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:37:52,984]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:53,005]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:37:59,219]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:08,176]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:12,607]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:15,318]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:19,056]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:22,064]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:24,567]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:27,829]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:29,927]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:33,100]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:33,269]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:33,583]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:34,354]\u001b[0m Trial 49 finished with value: 9.997400510399924 and parameters: {'n_hidden': 4, 'learning_rate': 0.013318873094211547, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18521044078333293, 'dropout_rate_Layer_2': 0.12896718337075944, 'dropout_rate_Layer_3': 0.23993583960678666, 'dropout_rate_Layer_4': 0.06048082206491774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0267765183723933e-05, 'l1_Layer_2': 0.04296724630030575, 'l1_Layer_3': 4.3906951785874516e-05, 'l1_Layer_4': 0.00047986392424019287, 'n_units_Layer_1': 200, 'n_units_Layer_2': 150, 'n_units_Layer_3': 235, 'n_units_Layer_4': 260}. Best is trial 6 with value: 8.557252165227853.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.00 | sMAPE for Validation Set is: 18.70% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.11 | sMAPE for Test Set is: 19.98% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:38:42,843]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:44,633]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:45,760]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:48,283]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:49,808]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:55,003]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:38:59,874]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:00,206]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:06,784]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:09,947]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:10,606]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:11,096]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:16,297]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:19,462]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:20,047]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:21,824]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:24,718]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:27,322]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:33,592]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:36,646]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:39,284]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:42,115]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:47,151]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:49,689]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:39:56,742]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:01,113]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:01,395]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:01,786]\u001b[0m Trial 79 finished with value: 18.59530244302483 and parameters: {'n_hidden': 3, 'learning_rate': 0.018139927399104264, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12200238780098621, 'dropout_rate_Layer_2': 0.07235021751178294, 'dropout_rate_Layer_3': 0.296502133966868, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002546855262063628, 'l1_Layer_2': 0.08392534028412464, 'l1_Layer_3': 0.00036266402328666774, 'n_units_Layer_1': 130, 'n_units_Layer_2': 140, 'n_units_Layer_3': 75}. Best is trial 6 with value: 8.557252165227853.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.60 | sMAPE for Validation Set is: 35.41% | rMAE for Validation Set is: 1.44\n",
      "MAE for Test Set is: 8.32 | sMAPE for Test Set is: 22.05% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:40:13,159]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:13,339]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:13,575]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:14,015]\u001b[0m Trial 80 finished with value: 9.732679328581032 and parameters: {'n_hidden': 4, 'learning_rate': 0.018246816727806172, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1755631171765237, 'dropout_rate_Layer_2': 0.17292253420380688, 'dropout_rate_Layer_3': 0.052478293181322494, 'dropout_rate_Layer_4': 0.17867073549919496, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004507702602100724, 'l1_Layer_2': 0.0019369249937057234, 'l1_Layer_3': 0.00014181337033419535, 'l1_Layer_4': 0.00021006319830145997, 'n_units_Layer_1': 125, 'n_units_Layer_2': 175, 'n_units_Layer_3': 200, 'n_units_Layer_4': 220}. Best is trial 6 with value: 8.557252165227853.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.73 | sMAPE for Validation Set is: 17.53% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 18.50% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:40:23,031]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:23,622]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:25,938]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:33,736]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:38,610]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:39,490]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:44,111]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:44,140]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:44,606]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:44,851]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:53,461]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:40:56,867]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:00,090]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:00,511]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:00,634]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:00,784]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:09,812]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:12,007]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:13,411]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:20,468]\u001b[0m Trial 110 finished with value: 9.523744951342294 and parameters: {'n_hidden': 3, 'learning_rate': 0.019422512089136958, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09709649915700716, 'dropout_rate_Layer_2': 0.18400440050762373, 'dropout_rate_Layer_3': 0.3823163848945377, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.5937266323733694e-05, 'l1_Layer_2': 0.0005371737454560407, 'l1_Layer_3': 1.0007702577465826e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 155}. Best is trial 6 with value: 8.557252165227853.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.52 | sMAPE for Validation Set is: 17.39% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 18.39% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:41:23,191]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:24,352]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:26,580]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:27,934]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:34,009]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:36,576]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:38,032]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:41,087]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:52,190]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:52,743]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:58,118]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:41:58,767]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:01,270]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:07,460]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:11,036]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:14,636]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:18,123]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:20,721]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:26,554]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:29,159]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:32,935]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:39,275]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:43,854]\u001b[0m Trial 132 finished with value: 9.095041091357752 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007560316412909526, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11188046970911136, 'dropout_rate_Layer_2': 0.05760142433971824, 'dropout_rate_Layer_3': 0.13092336164374, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7561947511922207e-05, 'l1_Layer_2': 0.0055355875603142765, 'l1_Layer_3': 0.0006500424501134936, 'n_units_Layer_1': 160, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270}. Best is trial 6 with value: 8.557252165227853.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.10 | sMAPE for Validation Set is: 16.44% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 17.22% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:42:49,460]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:53,459]\u001b[0m Trial 136 finished with value: 8.106721822394118 and parameters: {'n_hidden': 3, 'learning_rate': 0.004911884484741235, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34099210866921636, 'dropout_rate_Layer_2': 0.024235817031332128, 'dropout_rate_Layer_3': 0.08471479228715159, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011072246391283676, 'l1_Layer_2': 0.0037112205806737624, 'l1_Layer_3': 7.474745795644575e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 60, 'n_units_Layer_3': 280}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.11 | sMAPE for Validation Set is: 14.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 17.47% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:42:54,705]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:42:56,707]\u001b[0m Trial 137 finished with value: 8.773469895459643 and parameters: {'n_hidden': 3, 'learning_rate': 0.007678758326771251, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19036215293874648, 'dropout_rate_Layer_2': 0.1774136498934082, 'dropout_rate_Layer_3': 0.017170974106051017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008413842765564534, 'l1_Layer_2': 0.03531293902035891, 'l1_Layer_3': 6.56950152687054e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 130, 'n_units_Layer_3': 255}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.77 | sMAPE for Validation Set is: 16.07% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 17.50% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:43:02,159]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:02,624]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:04,769]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.52 | sMAPE for Validation Set is: 15.26% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 17.56% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:43:08,941]\u001b[0m Trial 139 finished with value: 8.515890981853564 and parameters: {'n_hidden': 3, 'learning_rate': 0.011648888572819338, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017363694030617327, 'dropout_rate_Layer_2': 0.3486036070802291, 'dropout_rate_Layer_3': 0.022393671046629066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00031737056091723847, 'l1_Layer_2': 0.0038758498118016934, 'l1_Layer_3': 0.0002058747855839166, 'n_units_Layer_1': 270, 'n_units_Layer_2': 235, 'n_units_Layer_3': 230}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:13,995]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:17,779]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:24,316]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:27,520]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.24 | sMAPE for Validation Set is: 16.90% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 17.26% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:43:29,421]\u001b[0m Trial 145 finished with value: 9.2438963846743 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015510017197119628, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.057681951445277546, 'dropout_rate_Layer_2': 0.0592551967935456, 'dropout_rate_Layer_3': 0.13707037014692086, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010888145035460745, 'l1_Layer_2': 0.009708900903814087, 'l1_Layer_3': 0.00048560881311371097, 'n_units_Layer_1': 205, 'n_units_Layer_2': 260, 'n_units_Layer_3': 300}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:31,400]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.29 | sMAPE for Validation Set is: 16.73% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.30 | sMAPE for Test Set is: 17.20% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:43:32,755]\u001b[0m Trial 146 finished with value: 9.288773891939131 and parameters: {'n_hidden': 3, 'learning_rate': 0.001499425138546786, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06083382271159244, 'dropout_rate_Layer_2': 0.06946065696372965, 'dropout_rate_Layer_3': 0.12826699325364282, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.87124222231553e-05, 'l1_Layer_2': 0.007593924220365898, 'l1_Layer_3': 0.0005534318155497152, 'n_units_Layer_1': 195, 'n_units_Layer_2': 255, 'n_units_Layer_3': 220}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:35,520]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:38,876]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:43,087]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:45,825]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:49,557]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:53,062]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:43:56,333]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:00,867]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:04,302]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:05,075]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:11,758]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:12,457]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:12,571]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:19,987]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:24,852]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:29,194]\u001b[0m Trial 156 finished with value: 9.538861597503365 and parameters: {'n_hidden': 3, 'learning_rate': 0.001445940298230702, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0447416131485525, 'dropout_rate_Layer_2': 0.049323272005106736, 'dropout_rate_Layer_3': 0.12946161312551974, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.347291241965988e-05, 'l1_Layer_2': 0.009388911755393099, 'l1_Layer_3': 0.0005772091782933466, 'n_units_Layer_1': 260, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.54 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.30 | sMAPE for Test Set is: 17.22% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:44:31,603]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:37,837]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:41,960]\u001b[0m Trial 167 finished with value: 8.749719063822786 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013521469383410815, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.039080663445321503, 'dropout_rate_Layer_2': 0.04227650298130204, 'dropout_rate_Layer_3': 0.21166221314615252, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006736349746948802, 'l1_Layer_2': 0.004001124308972922, 'l1_Layer_3': 0.0008323946239011026, 'n_units_Layer_1': 255, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.75 | sMAPE for Validation Set is: 15.90% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 17.04% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:44:42,899]\u001b[0m Trial 165 finished with value: 8.423665915836391 and parameters: {'n_hidden': 3, 'learning_rate': 0.007033078867730634, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08487908619285633, 'dropout_rate_Layer_2': 0.2490028052180906, 'dropout_rate_Layer_3': 0.07154120010001319, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005338961048539411, 'l1_Layer_2': 0.03150083398231542, 'l1_Layer_3': 7.751148772615583e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 250}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.42 | sMAPE for Validation Set is: 14.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 16.51% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:44:48,324]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:51,403]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:44:57,173]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:45:02,163]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.32 | sMAPE for Validation Set is: 15.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 17.37% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:45:04,069]\u001b[0m Trial 172 finished with value: 8.316039753928088 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010172047764749935, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09407831063355146, 'dropout_rate_Layer_2': 0.2561067946958093, 'dropout_rate_Layer_3': 0.13483433006712753, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5301232796683498e-05, 'l1_Layer_2': 0.032875234945810884, 'l1_Layer_3': 7.222967950757348e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 260}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:45:10,281]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:45:11,202]\u001b[0m Trial 170 finished with value: 8.763249097669593 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006166660755893011, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12713461896658548, 'dropout_rate_Layer_2': 0.0364958650030411, 'dropout_rate_Layer_3': 0.2160506301861962, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046540136003880546, 'l1_Layer_2': 0.004676667469937015, 'l1_Layer_3': 0.0013099623440696302, 'n_units_Layer_1': 250, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.76 | sMAPE for Validation Set is: 15.86% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:45:12,161]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:45:17,977]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:45:23,688]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:45:28,972]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:45:44,398]\u001b[0m Trial 175 finished with value: 8.988914304090391 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005131950088135289, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01822017886732112, 'dropout_rate_Layer_2': 0.003072505163400227, 'dropout_rate_Layer_3': 0.21486722847476464, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004993223583936488, 'l1_Layer_2': 0.0043017590353567805, 'l1_Layer_3': 0.0013227684786313062, 'n_units_Layer_1': 255, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.99 | sMAPE for Validation Set is: 16.23% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 17.40% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:45:52,821]\u001b[0m Trial 183 finished with value: 8.574584871945659 and parameters: {'n_hidden': 3, 'learning_rate': 0.00092669896559549, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12765252462550924, 'dropout_rate_Layer_2': 0.0011602200444232325, 'dropout_rate_Layer_3': 0.2641841064890697, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004842897966821989, 'l1_Layer_2': 0.023161893123205372, 'l1_Layer_3': 0.0012037414057285386, 'n_units_Layer_1': 295, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 15.47% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 16.83% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:45:55,911]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:00,479]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.65 | sMAPE for Validation Set is: 15.80% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:46:03,237]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:03,285]\u001b[0m Trial 185 finished with value: 8.651130531877557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008833834250342691, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14851787166966532, 'dropout_rate_Layer_2': 0.00882568265214917, 'dropout_rate_Layer_3': 0.26034195145522754, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004932342600067796, 'l1_Layer_2': 0.02564877745219563, 'l1_Layer_3': 0.0012833167828487958, 'n_units_Layer_1': 300, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:06,904]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:11,710]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:12,484]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:17,646]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:20,733]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:21,240]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:24,613]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:28,115]\u001b[0m Trial 182 finished with value: 8.518469897719514 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008985183607540155, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14693161105321612, 'dropout_rate_Layer_2': 0.10660477123516648, 'dropout_rate_Layer_3': 0.2640007985658607, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004628696655320996, 'l1_Layer_2': 0.02724295906801371, 'l1_Layer_3': 0.001766653934359849, 'n_units_Layer_1': 295, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:28,226]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.52 | sMAPE for Validation Set is: 15.53% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.07 | sMAPE for Test Set is: 16.97% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:46:30,774]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:33,879]\u001b[0m Trial 197 finished with value: 11.963424420525465 and parameters: {'n_hidden': 3, 'learning_rate': 0.03216912431175496, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22655525169134302, 'dropout_rate_Layer_2': 0.09236901861289182, 'dropout_rate_Layer_3': 0.2794933350783757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017518603973811914, 'l1_Layer_2': 0.00017342744746424313, 'l1_Layer_3': 8.452188619136715e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 55}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.96 | sMAPE for Validation Set is: 21.81% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 10.19 | sMAPE for Test Set is: 25.76% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:46:37,510]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:40,002]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:44,074]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:45,052]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:48,438]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:53,728]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:56,632]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:46:59,738]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:04,903]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:08,862]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:14,204]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:17,738]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:18,147]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:19,003]\u001b[0m Trial 209 finished with value: 8.685472492656672 and parameters: {'n_hidden': 3, 'learning_rate': 0.009720079439740273, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22727751795102288, 'dropout_rate_Layer_2': 0.04475091683250573, 'dropout_rate_Layer_3': 0.02975515529227045, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015898589304395237, 'l1_Layer_2': 0.0740344765555455, 'l1_Layer_3': 4.2861030881584875e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 210}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.69 | sMAPE for Validation Set is: 15.80% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 17.24% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:47:26,575]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:26,978]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:30,020]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:36,016]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:43,602]\u001b[0m Trial 218 finished with value: 9.985595271360943 and parameters: {'n_hidden': 3, 'learning_rate': 0.011441762941195628, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39307061699212575, 'dropout_rate_Layer_2': 0.10745167698312924, 'dropout_rate_Layer_3': 0.30687020316617286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024943775205974934, 'l1_Layer_2': 0.00011065052467887763, 'l1_Layer_3': 4.389803938532789e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 90}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.99 | sMAPE for Validation Set is: 18.27% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:47:46,278]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:47,194]\u001b[0m Trial 208 finished with value: 8.570552006273962 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010107707225246558, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21344697970965087, 'dropout_rate_Layer_2': 0.08490198166850799, 'dropout_rate_Layer_3': 0.2705555145213374, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014818403300799687, 'l1_Layer_2': 0.025611983375012366, 'l1_Layer_3': 0.005063949554960604, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 245}. Best is trial 136 with value: 8.106721822394118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 15.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 16.90% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:47:52,430]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:56,152]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:47:58,899]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:02,024]\u001b[0m Trial 217 finished with value: 8.029105323000328 and parameters: {'n_hidden': 3, 'learning_rate': 0.00309218469360493, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22707535752661215, 'dropout_rate_Layer_2': 0.04328187445827129, 'dropout_rate_Layer_3': 0.0305343328543307, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015098536516441224, 'l1_Layer_2': 0.029625339216746212, 'l1_Layer_3': 1.0936939469006732e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 210}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.03 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:48:03,846]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:09,051]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:12,024]\u001b[0m Trial 225 finished with value: 10.739961601733276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0222334958300561, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36831395722247595, 'dropout_rate_Layer_2': 0.09672263514265006, 'dropout_rate_Layer_3': 0.3078287276865095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001829301492788623, 'l1_Layer_2': 0.00014797932218985998, 'l1_Layer_3': 6.553614193723485e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 60}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.74 | sMAPE for Validation Set is: 19.73% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 7.98 | sMAPE for Test Set is: 21.58% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:48:14,013]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:14,778]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:17,394]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:21,236]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:23,311]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:26,293]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:28,660]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:32,361]\u001b[0m Trial 232 finished with value: 10.376638270347923 and parameters: {'n_hidden': 3, 'learning_rate': 0.022252046610712308, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3442664370289291, 'dropout_rate_Layer_2': 0.08651004094345245, 'dropout_rate_Layer_3': 0.2880142770802797, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022577523823962884, 'l1_Layer_2': 5.026545317292137e-05, 'l1_Layer_3': 0.0002979118504376271, 'n_units_Layer_1': 285, 'n_units_Layer_2': 255, 'n_units_Layer_3': 50}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.38 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 20.40% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:48:35,381]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:35,816]\u001b[0m Trial 234 finished with value: 10.657531829479687 and parameters: {'n_hidden': 3, 'learning_rate': 0.013668498956378868, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3426810493522232, 'dropout_rate_Layer_2': 0.08482266731909828, 'dropout_rate_Layer_3': 0.35257051817275514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001884848268069707, 'l1_Layer_2': 4.798946601268615e-05, 'l1_Layer_3': 0.00041127976774867786, 'n_units_Layer_1': 290, 'n_units_Layer_2': 250, 'n_units_Layer_3': 60}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.66 | sMAPE for Validation Set is: 19.90% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 7.73 | sMAPE for Test Set is: 21.96% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:48:36,179]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:43,993]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:50,169]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:50,257]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:51,967]\u001b[0m Trial 238 finished with value: 9.508316510473994 and parameters: {'n_hidden': 3, 'learning_rate': 0.014013921428918658, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3466535536433049, 'dropout_rate_Layer_2': 0.03843351027342579, 'dropout_rate_Layer_3': 0.24708385994908794, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7624141860309187e-05, 'l1_Layer_2': 0.0003089481706625077, 'l1_Layer_3': 9.284823842245907e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 225, 'n_units_Layer_3': 55}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.51 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.32 | sMAPE for Test Set is: 17.36% | rMAE for Test Set is: 0.72\n",
      "MAE for Validation Set is: 10.21 | sMAPE for Validation Set is: 18.62% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.34 | sMAPE for Test Set is: 20.40% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:48:54,175]\u001b[0m Trial 242 finished with value: 10.208221854950464 and parameters: {'n_hidden': 3, 'learning_rate': 0.013869165972110145, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3607044925315403, 'dropout_rate_Layer_2': 0.10495354015073062, 'dropout_rate_Layer_3': 0.35565891638943936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.138695813562188e-05, 'l1_Layer_2': 0.00030716436751462384, 'l1_Layer_3': 0.00021575089376370778, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 55}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:48:57,103]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:02,924]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:04,546]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:05,671]\u001b[0m Trial 243 finished with value: 10.493018795080912 and parameters: {'n_hidden': 3, 'learning_rate': 0.014048077877712693, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3551595538937343, 'dropout_rate_Layer_2': 0.05914461069535008, 'dropout_rate_Layer_3': 0.3509965473449846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.493227313025696e-05, 'l1_Layer_2': 0.0001285842352737231, 'l1_Layer_3': 0.00020367785014491823, 'n_units_Layer_1': 185, 'n_units_Layer_2': 225, 'n_units_Layer_3': 55}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.49 | sMAPE for Validation Set is: 19.20% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 20.37% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:49:10,547]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:10,717]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:11,262]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:12,325]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:19,333]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:26,881]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:29,428]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:30,999]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:36,506]\u001b[0m Trial 255 finished with value: 9.600280159358872 and parameters: {'n_hidden': 3, 'learning_rate': 0.010522775755799197, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3469404750881433, 'dropout_rate_Layer_2': 0.05804688246591991, 'dropout_rate_Layer_3': 0.3490420550644062, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8467985234199388e-05, 'l1_Layer_2': 0.00020575795978700995, 'l1_Layer_3': 0.0001218562921713606, 'n_units_Layer_1': 215, 'n_units_Layer_2': 235, 'n_units_Layer_3': 55}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.60 | sMAPE for Validation Set is: 17.56% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 18.14% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:49:41,775]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:42,478]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:48,835]\u001b[0m Trial 257 finished with value: 9.545682150585026 and parameters: {'n_hidden': 3, 'learning_rate': 0.011640977808412317, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36411203316446333, 'dropout_rate_Layer_2': 0.032205251844045685, 'dropout_rate_Layer_3': 0.3649413306380249, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.099717011532578e-05, 'l1_Layer_2': 0.00012087404279339807, 'l1_Layer_3': 0.0002749526255106701, 'n_units_Layer_1': 210, 'n_units_Layer_2': 235, 'n_units_Layer_3': 60}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.55 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 18.04% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:49:54,032]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:49:57,709]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:02,349]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:09,211]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:15,086]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:20,518]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:25,916]\u001b[0m Trial 261 finished with value: 8.354883609199879 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018588907681660314, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14536419206658263, 'dropout_rate_Layer_2': 0.08839114362754855, 'dropout_rate_Layer_3': 0.2023948022153159, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000723057632747994, 'l1_Layer_2': 0.017207401448058685, 'l1_Layer_3': 0.0008182783270596768, 'n_units_Layer_1': 270, 'n_units_Layer_2': 245, 'n_units_Layer_3': 255}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 15.33% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 17.22% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:50:33,988]\u001b[0m Trial 253 finished with value: 8.518020073768147 and parameters: {'n_hidden': 3, 'learning_rate': 0.000781669439293128, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15049008594062652, 'dropout_rate_Layer_2': 0.08418635475934215, 'dropout_rate_Layer_3': 0.1922595292965692, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008488958739755573, 'l1_Layer_2': 0.06683305242296719, 'l1_Layer_3': 0.0008852476718854336, 'n_units_Layer_1': 270, 'n_units_Layer_2': 240, 'n_units_Layer_3': 260}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.52 | sMAPE for Validation Set is: 15.43% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:50:35,431]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:40,404]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:41,563]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:44,742]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:49,241]\u001b[0m Trial 260 finished with value: 8.434162169053346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008143745353795545, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14322748004092617, 'dropout_rate_Layer_2': 0.0812349557511777, 'dropout_rate_Layer_3': 0.19427545548173264, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007435971304451844, 'l1_Layer_2': 0.015851385068256413, 'l1_Layer_3': 0.0009899951585041686, 'n_units_Layer_1': 270, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.43 | sMAPE for Validation Set is: 15.34% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:50:50,043]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:55,122]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:57,168]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:58,985]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:50:59,811]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:05,370]\u001b[0m Trial 273 finished with value: 9.52583497639697 and parameters: {'n_hidden': 3, 'learning_rate': 0.013455912783160343, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37534606486640293, 'dropout_rate_Layer_2': 0.010446485663839655, 'dropout_rate_Layer_3': 0.38997779482496525, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2570870864178442e-05, 'l1_Layer_2': 0.00026215830826052406, 'l1_Layer_3': 0.00019561559872257247, 'n_units_Layer_1': 190, 'n_units_Layer_2': 260, 'n_units_Layer_3': 65}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.53 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 17.92% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:51:08,336]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:08,574]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:09,214]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:11,041]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:17,780]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:20,807]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:21,192]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:22,108]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:30,720]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:30,960]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:32,059]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:32,217]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:40,676]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:43,933]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:45,408]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:50,084]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:53,616]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:56,237]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:51:57,833]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:52:00,646]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:52:01,609]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:52:08,433]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:52:12,514]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:52:13,985]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:52:18,263]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:52:21,691]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:52:28,837]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:52:34,350]\u001b[0m Trial 296 finished with value: 8.302666156456235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007495626453043396, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14203814865939693, 'dropout_rate_Layer_2': 0.1254293953500482, 'dropout_rate_Layer_3': 0.18941727559723073, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000278644524104178, 'l1_Layer_2': 0.037337596086827796, 'l1_Layer_3': 8.603791274511526e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 16.63% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:52:35,070]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.39 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 18.38% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:52:38,796]\u001b[0m Trial 307 finished with value: 9.39156966891369 and parameters: {'n_hidden': 3, 'learning_rate': 0.01107111608470754, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3812029921055434, 'dropout_rate_Layer_2': 0.08866132955351663, 'dropout_rate_Layer_3': 0.39970468235752943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.011313351610945e-05, 'l1_Layer_2': 5.7096423448212946e-05, 'l1_Layer_3': 0.00015647429190554325, 'n_units_Layer_1': 170, 'n_units_Layer_2': 245, 'n_units_Layer_3': 70}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:52:47,275]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:52:55,412]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:01,061]\u001b[0m Trial 309 finished with value: 8.262876734316238 and parameters: {'n_hidden': 3, 'learning_rate': 0.00705116401610306, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21895471207829428, 'dropout_rate_Layer_2': 0.09831521441909281, 'dropout_rate_Layer_3': 0.03424213654732465, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.812079870490078e-05, 'l1_Layer_2': 0.030705464531124035, 'l1_Layer_3': 4.0842761388868816e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 200, 'n_units_Layer_3': 210}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.26 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 17.47% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:53:05,226]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:11,379]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:15,993]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:18,985]\u001b[0m Trial 314 finished with value: 8.55864920033645 and parameters: {'n_hidden': 3, 'learning_rate': 0.011184761698871575, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3784733293820323, 'dropout_rate_Layer_2': 0.07256189833631047, 'dropout_rate_Layer_3': 0.3877905085221095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.1315466390511836e-05, 'l1_Layer_2': 6.125676866177567e-05, 'l1_Layer_3': 0.00016031461149989445, 'n_units_Layer_1': 175, 'n_units_Layer_2': 245, 'n_units_Layer_3': 70}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 15.61% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.45 | sMAPE for Test Set is: 18.16% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:53:19,444]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:24,346]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:25,022]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:25,490]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:30,743]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:34,825]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:38,247]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:39,490]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:44,080]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:46,497]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:53:51,682]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:00,865]\u001b[0m Trial 327 finished with value: 8.50254967869771 and parameters: {'n_hidden': 3, 'learning_rate': 0.008345059245338394, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24149410614840994, 'dropout_rate_Layer_2': 0.06547729665827644, 'dropout_rate_Layer_3': 0.007812757816282129, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011237307050272705, 'l1_Layer_2': 0.02601547135810949, 'l1_Layer_3': 5.6048279363162495e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 170}. Best is trial 217 with value: 8.029105323000328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.50 | sMAPE for Validation Set is: 15.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 16.83% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:54:02,121]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:05,512]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:09,567]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:14,552]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:15,002]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:21,037]\u001b[0m Trial 316 finished with value: 7.988026153770462 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005817947411949246, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21737216590208863, 'dropout_rate_Layer_2': 0.11496823173955661, 'dropout_rate_Layer_3': 0.15906792920187707, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014996982086206815, 'l1_Layer_2': 0.013365252280120194, 'l1_Layer_3': 6.690664178645301e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 190, 'n_units_Layer_3': 260}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.99 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 17.06% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:54:21,718]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:26,306]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:27,483]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:31,284]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:33,687]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:34,922]\u001b[0m Trial 321 finished with value: 8.178871033036287 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005938247815878673, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21648891128143655, 'dropout_rate_Layer_2': 0.13946316375822268, 'dropout_rate_Layer_3': 0.35143020911110223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016986574867472997, 'l1_Layer_2': 0.013742706802318998, 'l1_Layer_3': 8.237414194191655e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 190, 'n_units_Layer_3': 260}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 14.80% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:54:37,015]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:39,721]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:42,295]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.23 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.16 | sMAPE for Test Set is: 19.06% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:54:46,603]\u001b[0m Trial 335 finished with value: 8.231544663972693 and parameters: {'n_hidden': 3, 'learning_rate': 0.010278500097711236, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3105354950136513, 'dropout_rate_Layer_2': 0.061062364054110266, 'dropout_rate_Layer_3': 0.31021761064325387, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.122616670733466e-05, 'l1_Layer_2': 0.00010919829407642439, 'l1_Layer_3': 0.00013285772947343135, 'n_units_Layer_1': 155, 'n_units_Layer_2': 285, 'n_units_Layer_3': 50}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:48,865]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:51,042]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:51,586]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:52,958]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:54:57,146]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:01,719]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:06,054]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:09,841]\u001b[0m Trial 343 finished with value: 8.628048841167429 and parameters: {'n_hidden': 3, 'learning_rate': 0.012137150861035456, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3096861277792244, 'dropout_rate_Layer_2': 0.09751847109406267, 'dropout_rate_Layer_3': 0.36436254129431794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.311958223874341e-05, 'l1_Layer_2': 6.168795176336622e-05, 'l1_Layer_3': 0.0002795347599475865, 'n_units_Layer_1': 195, 'n_units_Layer_2': 255, 'n_units_Layer_3': 65}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 15.86% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.91 | sMAPE for Test Set is: 17.88% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:55:10,074]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:14,009]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:18,216]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:18,975]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:20,292]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:24,495]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:27,964]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:30,772]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:34,469]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:37,624]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:41,225]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:45,345]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:48,946]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:54,238]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:55:59,354]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:56:03,131]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:56:07,065]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:56:07,283]\u001b[0m Trial 350 finished with value: 8.063044024073212 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005155500419802263, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23546434018968113, 'dropout_rate_Layer_2': 0.13821678563176798, 'dropout_rate_Layer_3': 0.09525794834298612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012276445580815696, 'l1_Layer_2': 0.0071664010678425495, 'l1_Layer_3': 8.154737599805387e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 195, 'n_units_Layer_3': 275}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.06 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 16.86% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:56:13,677]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:56:15,123]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:56:20,445]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:56:21,066]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:56:30,301]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:56:33,681]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:56:37,448]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:56:42,922]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:05,618]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:08,272]\u001b[0m Trial 359 finished with value: 8.112009786982332 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007081528217845572, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1647784591484028, 'dropout_rate_Layer_2': 0.11454148554456232, 'dropout_rate_Layer_3': 0.15392127709567524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010966474445598864, 'l1_Layer_2': 0.014589055009182554, 'l1_Layer_3': 9.145177317408642e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 195, 'n_units_Layer_3': 265}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.11 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 16.37% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:57:10,125]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:15,967]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:18,482]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:21,731]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:24,770]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:25,504]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:31,646]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:35,303]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:39,452]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:42,103]\u001b[0m Trial 378 finished with value: 8.214838778559724 and parameters: {'n_hidden': 3, 'learning_rate': 0.000700517478041211, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19702961552549672, 'dropout_rate_Layer_2': 0.2010950265892528, 'dropout_rate_Layer_3': 0.04754083918838966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.029043384940255483, 'l1_Layer_2': 0.0029202128851563247, 'l1_Layer_3': 0.00017674407966729072, 'n_units_Layer_1': 95, 'n_units_Layer_2': 210, 'n_units_Layer_3': 275}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.21 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:57:45,133]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:49,970]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:57:53,936]\u001b[0m Trial 387 finished with value: 8.121760292772475 and parameters: {'n_hidden': 3, 'learning_rate': 0.004797774037128433, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06197950033920873, 'dropout_rate_Layer_2': 0.04906479495275812, 'dropout_rate_Layer_3': 0.08764770525066473, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3678582522433617e-05, 'l1_Layer_2': 0.01654548518293343, 'l1_Layer_3': 4.2697364552460174e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 115, 'n_units_Layer_3': 205}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.12 | sMAPE for Validation Set is: 14.74% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 16.77% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:57:54,501]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:58:01,076]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:58:02,583]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:58:07,976]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:58:13,383]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:58:18,569]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:58:22,470]\u001b[0m Trial 395 finished with value: 8.335531243816213 and parameters: {'n_hidden': 3, 'learning_rate': 0.0069389284199630665, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19346303099168516, 'dropout_rate_Layer_2': 0.17368458390908173, 'dropout_rate_Layer_3': 0.2856477495851244, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.3373455452591406e-05, 'l1_Layer_2': 0.0022060565551908344, 'l1_Layer_3': 9.126096036979061e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 180, 'n_units_Layer_3': 65}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 14.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:58:28,863]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:58:33,356]\u001b[0m Trial 380 finished with value: 8.009073780510903 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005012246714288619, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11093466155064752, 'dropout_rate_Layer_2': 0.20169621975736995, 'dropout_rate_Layer_3': 0.02231168269154067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0036256263075972015, 'l1_Layer_2': 0.011460870750897299, 'l1_Layer_3': 0.00018169875101577831, 'n_units_Layer_1': 100, 'n_units_Layer_2': 215, 'n_units_Layer_3': 270}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.01 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 16.84% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:58:33,576]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:58:33,881]\u001b[0m Trial 397 finished with value: 8.215982112982198 and parameters: {'n_hidden': 3, 'learning_rate': 0.00650588432022031, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1886643388609334, 'dropout_rate_Layer_2': 0.04199359115473249, 'dropout_rate_Layer_3': 0.27907484123379245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.095545498365083e-05, 'l1_Layer_2': 0.0005307000700754684, 'l1_Layer_3': 5.197669495750153e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 65}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.22 | sMAPE for Validation Set is: 14.82% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 17.07% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:58:44,225]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:58:55,851]\u001b[0m Trial 406 finished with value: 8.168021003724922 and parameters: {'n_hidden': 3, 'learning_rate': 0.006724138483449964, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20850348162188378, 'dropout_rate_Layer_2': 0.12509290274035545, 'dropout_rate_Layer_3': 0.2715646808387089, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4915173424408786e-05, 'l1_Layer_2': 0.0006086768308788803, 'l1_Layer_3': 7.982227225502946e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 200, 'n_units_Layer_3': 70}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.17 | sMAPE for Validation Set is: 14.78% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:59:07,374]\u001b[0m Trial 407 finished with value: 8.349283861288145 and parameters: {'n_hidden': 3, 'learning_rate': 0.006680547294511353, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18777071100499051, 'dropout_rate_Layer_2': 0.09735726113106648, 'dropout_rate_Layer_3': 0.27703062539548634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.661880718856842e-05, 'l1_Layer_2': 0.0005487749748331836, 'l1_Layer_3': 6.670655285475519e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 235, 'n_units_Layer_3': 70}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 15.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 18.46% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:59:11,127]\u001b[0m Trial 408 finished with value: 8.34268604495672 and parameters: {'n_hidden': 3, 'learning_rate': 0.006665650165995367, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18562200912005936, 'dropout_rate_Layer_2': 0.10830213863925998, 'dropout_rate_Layer_3': 0.29016001167884836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.710797429833724e-05, 'l1_Layer_2': 0.000729681401371968, 'l1_Layer_3': 7.53542274240192e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 215, 'n_units_Layer_3': 70}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 15.16% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:59:11,450]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:59:16,453]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:59:20,596]\u001b[0m Trial 401 finished with value: 8.02351106414582 and parameters: {'n_hidden': 3, 'learning_rate': 0.000665582446735932, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19949295022950664, 'dropout_rate_Layer_2': 0.2535516000718948, 'dropout_rate_Layer_3': 0.0636411190516558, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016415055616385992, 'l1_Layer_2': 0.0010748222465140132, 'l1_Layer_3': 0.00016832320811956572, 'n_units_Layer_1': 60, 'n_units_Layer_2': 205, 'n_units_Layer_3': 270}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.02 | sMAPE for Validation Set is: 14.53% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 16.96% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:59:23,083]\u001b[0m Trial 405 finished with value: 8.278063165311265 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007023510622009856, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20581528899110338, 'dropout_rate_Layer_2': 0.21412684233870943, 'dropout_rate_Layer_3': 0.007383265623872317, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02853060567679914, 'l1_Layer_2': 0.0051890902877815125, 'l1_Layer_3': 8.894574680629348e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 190, 'n_units_Layer_3': 275}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.28 | sMAPE for Validation Set is: 15.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 17.10% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:59:26,683]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:59:26,958]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:59:39,744]\u001b[0m Trial 415 finished with value: 8.330243780191163 and parameters: {'n_hidden': 3, 'learning_rate': 0.006495326533346128, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19221806169524686, 'dropout_rate_Layer_2': 0.1187638177855817, 'dropout_rate_Layer_3': 0.27755811336096825, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5991413298451448e-05, 'l1_Layer_2': 0.0005196592821074097, 'l1_Layer_3': 4.145124202568958e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 215, 'n_units_Layer_3': 70}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 15.12% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 17.39% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:59:40,513]\u001b[0m Trial 412 finished with value: 8.105328263117615 and parameters: {'n_hidden': 3, 'learning_rate': 0.007013594303724998, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19883603126307084, 'dropout_rate_Layer_2': 0.12314123852742931, 'dropout_rate_Layer_3': 0.2825512571849814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.6986291662966863e-05, 'l1_Layer_2': 0.000594092670534577, 'l1_Layer_3': 7.89058928755426e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 205, 'n_units_Layer_3': 65}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.11 | sMAPE for Validation Set is: 14.67% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 16.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-12 23:59:40,784]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:59:48,356]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:59:51,926]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-12 23:59:59,966]\u001b[0m Trial 417 finished with value: 8.26694014914209 and parameters: {'n_hidden': 3, 'learning_rate': 0.005531564883444427, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03517083351558077, 'dropout_rate_Layer_2': 0.024738287967167136, 'dropout_rate_Layer_3': 0.0719233464233018, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00062661728046445, 'l1_Layer_2': 0.021644306531835127, 'l1_Layer_3': 0.00011031776405859316, 'n_units_Layer_1': 245, 'n_units_Layer_2': 125, 'n_units_Layer_3': 295}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 17.09% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:00:12,074]\u001b[0m Trial 418 finished with value: 8.018590134579823 and parameters: {'n_hidden': 3, 'learning_rate': 0.005741644808110462, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05908333331955234, 'dropout_rate_Layer_2': 0.025290682344465368, 'dropout_rate_Layer_3': 0.07049676317622869, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006147161091043577, 'l1_Layer_2': 0.020725538701748678, 'l1_Layer_3': 6.843488803833537e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 120, 'n_units_Layer_3': 210}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.02 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 16.96% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:00:15,522]\u001b[0m Trial 420 finished with value: 8.06245903139452 and parameters: {'n_hidden': 3, 'learning_rate': 0.005730817123579819, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.057057439810980076, 'dropout_rate_Layer_2': 0.08075256823358613, 'dropout_rate_Layer_3': 0.11317852351287772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.0666096932207934e-05, 'l1_Layer_2': 0.048205365648386185, 'l1_Layer_3': 0.00011149995848535364, 'n_units_Layer_1': 255, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.06 | sMAPE for Validation Set is: 14.72% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:00:22,364]\u001b[0m Trial 422 finished with value: 8.11396529805949 and parameters: {'n_hidden': 3, 'learning_rate': 0.005875868433646285, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19551350321141234, 'dropout_rate_Layer_2': 0.11083913596327474, 'dropout_rate_Layer_3': 0.2670491335817026, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.226680025477188e-05, 'l1_Layer_2': 0.0007606381177993563, 'l1_Layer_3': 6.669118610241263e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 215, 'n_units_Layer_3': 85}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.11 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 16.77% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:00:22,800]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:00:41,136]\u001b[0m Trial 421 finished with value: 8.077638642996606 and parameters: {'n_hidden': 3, 'learning_rate': 0.005604823764196875, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030183441571828305, 'dropout_rate_Layer_2': 0.024602851556874257, 'dropout_rate_Layer_3': 0.07241283274741073, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.4171217269198355e-05, 'l1_Layer_2': 0.0487683866902117, 'l1_Layer_3': 7.138421732044973e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 125, 'n_units_Layer_3': 200}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.08 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 16.39% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:00:48,343]\u001b[0m Trial 425 finished with value: 8.273635294504007 and parameters: {'n_hidden': 3, 'learning_rate': 0.0058401672662226406, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19465885155765164, 'dropout_rate_Layer_2': 0.11095560318571213, 'dropout_rate_Layer_3': 0.2651911713935957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1156439304534886e-05, 'l1_Layer_2': 0.0007284802911344755, 'l1_Layer_3': 4.032179591602297e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 215, 'n_units_Layer_3': 85}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 14.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 17.30% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:00:52,958]\u001b[0m Trial 426 finished with value: 8.083021861481269 and parameters: {'n_hidden': 3, 'learning_rate': 0.004572508522202526, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19857476655043993, 'dropout_rate_Layer_2': 0.11529857524645103, 'dropout_rate_Layer_3': 0.2729437253762255, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.446186463110192e-05, 'l1_Layer_2': 0.0007778065464912077, 'l1_Layer_3': 4.178025538219922e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 215, 'n_units_Layer_3': 90}. Best is trial 316 with value: 7.988026153770462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.08 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 17.19% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:00:57,757]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:00:59,451]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:03,549]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:08,474]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:08,839]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:10,129]\u001b[0m Trial 423 finished with value: 7.928591351917558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012142734033971161, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23612533548017345, 'dropout_rate_Layer_2': 0.2696234587121439, 'dropout_rate_Layer_3': 0.01874505461559535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01126266920773188, 'l1_Layer_2': 0.0008754731719624934, 'l1_Layer_3': 1.8773357859935303e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 265}. Best is trial 423 with value: 7.928591351917558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.93 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 16.93% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:01:14,787]\u001b[0m Trial 430 finished with value: 8.175184695876068 and parameters: {'n_hidden': 3, 'learning_rate': 0.005053950781293738, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19546614266365045, 'dropout_rate_Layer_2': 0.12340481384384039, 'dropout_rate_Layer_3': 0.2681258376363669, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.322488704836389e-05, 'l1_Layer_2': 0.0008515914077039586, 'l1_Layer_3': 4.556228825711556e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 215, 'n_units_Layer_3': 90}. Best is trial 423 with value: 7.928591351917558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 14.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 17.52% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:01:15,933]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:17,567]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:22,982]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:27,498]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:29,218]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:33,554]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:42,428]\u001b[0m Trial 440 finished with value: 8.369883000073708 and parameters: {'n_hidden': 3, 'learning_rate': 0.005162246013902212, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012406472423585713, 'dropout_rate_Layer_2': 0.028366231077061328, 'dropout_rate_Layer_3': 0.07511444277636517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006246390011414286, 'l1_Layer_2': 0.04779836322732945, 'l1_Layer_3': 0.00011949800310611557, 'n_units_Layer_1': 265, 'n_units_Layer_2': 115, 'n_units_Layer_3': 200}. Best is trial 423 with value: 7.928591351917558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 15.11% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 17.29% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:01:43,390]\u001b[0m Trial 434 finished with value: 8.061455977313791 and parameters: {'n_hidden': 3, 'learning_rate': 0.006216148084007757, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04798920623589861, 'dropout_rate_Layer_2': 0.04426422411075306, 'dropout_rate_Layer_3': 0.10274180103147972, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006335488774386542, 'l1_Layer_2': 0.04882012505217339, 'l1_Layer_3': 0.00016727851761871022, 'n_units_Layer_1': 235, 'n_units_Layer_2': 120, 'n_units_Layer_3': 200}. Best is trial 423 with value: 7.928591351917558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.06 | sMAPE for Validation Set is: 14.66% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:01:49,661]\u001b[0m Trial 436 finished with value: 8.105109671640664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0052970098610850575, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0302967516954004, 'dropout_rate_Layer_2': 0.017725328070944353, 'dropout_rate_Layer_3': 0.0728817472377245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006141872979558828, 'l1_Layer_2': 0.04631327809210028, 'l1_Layer_3': 0.00010701449229073258, 'n_units_Layer_1': 245, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200}. Best is trial 423 with value: 7.928591351917558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.11 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 16.84% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:01:54,675]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:54,939]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:55,455]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:01:56,693]\u001b[0m Trial 442 finished with value: 8.107251349321292 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011399943951703184, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23821077547699065, 'dropout_rate_Layer_2': 0.28675213971359126, 'dropout_rate_Layer_3': 0.017100938456603543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01167316573289489, 'l1_Layer_2': 0.001078578165852297, 'l1_Layer_3': 2.9983192477627702e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 423 with value: 7.928591351917558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.11 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 16.86% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:02:02,697]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:10,349]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:12,386]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:13,378]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:14,172]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:16,040]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:23,692]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:26,575]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:27,848]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:34,225]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:40,807]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:46,086]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:50,150]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:52,720]\u001b[0m Trial 457 finished with value: 8.11062601257303 and parameters: {'n_hidden': 3, 'learning_rate': 0.005782137950414638, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0588787047201277, 'dropout_rate_Layer_2': 0.025491502685703257, 'dropout_rate_Layer_3': 0.09437119915050052, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001109501954197915, 'l1_Layer_2': 0.036229814024638034, 'l1_Layer_3': 0.0003165184105505841, 'n_units_Layer_1': 225, 'n_units_Layer_2': 125, 'n_units_Layer_3': 175}. Best is trial 423 with value: 7.928591351917558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.11 | sMAPE for Validation Set is: 14.69% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 16.62% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:02:54,587]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:02:57,367]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:03:00,924]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:03:03,275]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:03:04,917]\u001b[0m Trial 452 finished with value: 7.899989485110207 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011560096347978637, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2659196736496035, 'dropout_rate_Layer_2': 0.2904164461837798, 'dropout_rate_Layer_3': 0.05462767166597732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005189914027965166, 'l1_Layer_2': 0.0004688850106415459, 'l1_Layer_3': 5.204044603046574e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 145, 'n_units_Layer_3': 285}. Best is trial 452 with value: 7.899989485110207.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.90 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 16.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:03:07,032]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:03:16,977]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:03:21,161]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:03:22,150]\u001b[0m Trial 467 finished with value: 8.306490774332257 and parameters: {'n_hidden': 3, 'learning_rate': 0.006891588976314923, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04461744673052023, 'dropout_rate_Layer_2': 0.040066267226634755, 'dropout_rate_Layer_3': 0.08286218148423181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011223018915310211, 'l1_Layer_2': 0.04281026491323764, 'l1_Layer_3': 0.00011802118813574376, 'n_units_Layer_1': 235, 'n_units_Layer_2': 140, 'n_units_Layer_3': 175}. Best is trial 452 with value: 7.899989485110207.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.31 | sMAPE for Validation Set is: 15.17% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 17.35% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:03:27,694]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:03:28,825]\u001b[0m Trial 465 finished with value: 8.348897198836012 and parameters: {'n_hidden': 3, 'learning_rate': 0.006806253427157429, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19674951368866214, 'dropout_rate_Layer_2': 0.10334273645352564, 'dropout_rate_Layer_3': 0.2895688582915735, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1254117268256645e-05, 'l1_Layer_2': 0.0005185247874618152, 'l1_Layer_3': 2.8508686671146273e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 230, 'n_units_Layer_3': 65}. Best is trial 452 with value: 7.899989485110207.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 15.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 17.39% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:03:38,466]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:03:41,219]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:03:44,936]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:03:46,998]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:03:50,891]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:03:53,958]\u001b[0m Trial 469 finished with value: 7.985136197328124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0066441868819611, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00914066011711679, 'dropout_rate_Layer_2': 0.027362637710323743, 'dropout_rate_Layer_3': 0.08437727874453396, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001250864148544348, 'l1_Layer_2': 0.021415568329646615, 'l1_Layer_3': 0.00011608503489334801, 'n_units_Layer_1': 220, 'n_units_Layer_2': 100, 'n_units_Layer_3': 175}. Best is trial 452 with value: 7.899989485110207.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.99 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 16.33% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:03:56,330]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:04:00,141]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:04:06,118]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:04:14,927]\u001b[0m Trial 478 finished with value: 8.077124966296404 and parameters: {'n_hidden': 3, 'learning_rate': 0.004177981055340187, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025453926011120186, 'dropout_rate_Layer_2': 0.00027037648121999713, 'dropout_rate_Layer_3': 0.07112015649868371, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001712685630758051, 'l1_Layer_2': 0.07461689686513526, 'l1_Layer_3': 7.478625918188227e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 120, 'n_units_Layer_3': 210}. Best is trial 452 with value: 7.899989485110207.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.08 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:04:20,538]\u001b[0m Trial 482 finished with value: 8.25421187074935 and parameters: {'n_hidden': 3, 'learning_rate': 0.007208446895362242, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20033068222573155, 'dropout_rate_Layer_2': 0.10069373269459045, 'dropout_rate_Layer_3': 0.2718500491058521, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5889393545955144e-05, 'l1_Layer_2': 0.0009827454854224422, 'l1_Layer_3': 6.15100216146953e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 215, 'n_units_Layer_3': 85}. Best is trial 452 with value: 7.899989485110207.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.25 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 17.50% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:04:23,587]\u001b[0m Trial 483 finished with value: 8.43142857519608 and parameters: {'n_hidden': 3, 'learning_rate': 0.006931960726405612, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17847931505632372, 'dropout_rate_Layer_2': 0.10482361340218757, 'dropout_rate_Layer_3': 0.29771565930983984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005528313074366785, 'l1_Layer_2': 0.0012229232285612002, 'l1_Layer_3': 3.742499052125674e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 205, 'n_units_Layer_3': 55}. Best is trial 452 with value: 7.899989485110207.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.43 | sMAPE for Validation Set is: 15.33% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:04:26,243]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:04:29,481]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:04:30,409]\u001b[0m Trial 476 finished with value: 7.928612444192116 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009773779447197928, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2864435195256246, 'dropout_rate_Layer_2': 0.3484695067077137, 'dropout_rate_Layer_3': 0.02428557490818562, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0050701469728264, 'l1_Layer_2': 0.0002108009929034175, 'l1_Layer_3': 3.474931141690204e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285}. Best is trial 452 with value: 7.899989485110207.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.93 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 16.50% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:04:35,028]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:04:36,878]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:04:40,000]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:04:43,112]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:04:46,067]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:04:49,166]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:04:53,301]\u001b[0m Trial 485 finished with value: 7.81150210487998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016340428938259842, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22081216713831628, 'dropout_rate_Layer_2': 0.2780336184316953, 'dropout_rate_Layer_3': 0.05853979783717003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021551941385276954, 'l1_Layer_2': 0.00012958055546173934, 'l1_Layer_3': 3.510274859493748e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285}. Best is trial 485 with value: 7.81150210487998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.81 | sMAPE for Validation Set is: 14.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.61% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:04:57,055]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:05:06,594]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:05:13,386]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:05:17,055]\u001b[0m Trial 495 finished with value: 8.184163080567089 and parameters: {'n_hidden': 3, 'learning_rate': 0.0048490799944950124, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01608590408898817, 'dropout_rate_Layer_2': 0.04748557197274322, 'dropout_rate_Layer_3': 0.07590631510917548, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010635455182762751, 'l1_Layer_2': 0.09870158155148422, 'l1_Layer_3': 0.00014189718844010931, 'n_units_Layer_1': 230, 'n_units_Layer_2': 120, 'n_units_Layer_3': 190}. Best is trial 485 with value: 7.81150210487998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 16.93% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:05:22,173]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:05:22,677]\u001b[0m Trial 496 finished with value: 8.285081825060995 and parameters: {'n_hidden': 3, 'learning_rate': 0.005406009165967748, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013892499220905189, 'dropout_rate_Layer_2': 0.026594091167690702, 'dropout_rate_Layer_3': 0.07622378738200486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028023295884914744, 'l1_Layer_2': 0.07349076672588427, 'l1_Layer_3': 0.00014131446834984274, 'n_units_Layer_1': 230, 'n_units_Layer_2': 120, 'n_units_Layer_3': 190}. Best is trial 485 with value: 7.81150210487998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.29 | sMAPE for Validation Set is: 14.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 16.60% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:05:26,630]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:05:29,877]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:05:33,485]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:05:34,110]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:05:34,199]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:05:45,480]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:05:49,140]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:05:53,208]\u001b[0m Trial 499 finished with value: 8.136586739115655 and parameters: {'n_hidden': 3, 'learning_rate': 0.005178176971351491, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1984484001073084, 'dropout_rate_Layer_2': 0.11061009480538335, 'dropout_rate_Layer_3': 0.2965925798716906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004078904692958998, 'l1_Layer_2': 0.0008551920767760455, 'l1_Layer_3': 5.7278039112153094e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75}. Best is trial 485 with value: 7.81150210487998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.14 | sMAPE for Validation Set is: 14.76% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 17.10% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:05:55,731]\u001b[0m Trial 506 finished with value: 8.27633331529699 and parameters: {'n_hidden': 3, 'learning_rate': 0.007824289492245683, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21161005406135158, 'dropout_rate_Layer_2': 0.0988827802483786, 'dropout_rate_Layer_3': 0.29417746892836927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2469200047193205e-05, 'l1_Layer_2': 0.0006849737687571039, 'l1_Layer_3': 5.348911457773827e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 215, 'n_units_Layer_3': 100}. Best is trial 485 with value: 7.81150210487998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.28 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 17.60% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:05:59,571]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:02,671]\u001b[0m Trial 507 finished with value: 8.335530889864518 and parameters: {'n_hidden': 3, 'learning_rate': 0.007430035889747136, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22008698540736002, 'dropout_rate_Layer_2': 0.1323323744252652, 'dropout_rate_Layer_3': 0.2604358762292682, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.38319096862701e-05, 'l1_Layer_2': 0.0009804182121879396, 'l1_Layer_3': 5.8496425754241314e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 215, 'n_units_Layer_3': 75}. Best is trial 485 with value: 7.81150210487998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 15.06% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 17.71% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:06:08,928]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:12,602]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:15,452]\u001b[0m Trial 509 finished with value: 8.234108436001081 and parameters: {'n_hidden': 3, 'learning_rate': 0.0073588642299527735, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20712231668622924, 'dropout_rate_Layer_2': 0.10199295478194234, 'dropout_rate_Layer_3': 0.2606680913551017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4037606689939687e-05, 'l1_Layer_2': 0.0006646171283540793, 'l1_Layer_3': 7.508255187827142e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 215, 'n_units_Layer_3': 70}. Best is trial 485 with value: 7.81150210487998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.23 | sMAPE for Validation Set is: 14.98% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 17.60% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:06:19,469]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:19,997]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:25,141]\u001b[0m Trial 510 finished with value: 8.365460113777573 and parameters: {'n_hidden': 3, 'learning_rate': 0.0042308194811505094, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20453610513988138, 'dropout_rate_Layer_2': 0.09706780503374474, 'dropout_rate_Layer_3': 0.3107050226968089, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003912860559225963, 'l1_Layer_2': 0.0007509203793719978, 'l1_Layer_3': 7.539248158171431e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 50, 'n_units_Layer_3': 80}. Best is trial 485 with value: 7.81150210487998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 15.25% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 17.35% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:06:27,976]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:28,656]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:32,859]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:36,354]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:36,753]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:37,389]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:46,162]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:47,097]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:48,765]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:49,986]\u001b[0m Trial 513 finished with value: 7.793737815354347 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021386960397723025, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2397195003096661, 'dropout_rate_Layer_2': 0.3802781556472931, 'dropout_rate_Layer_3': 0.01824550161960406, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022098910820989083, 'l1_Layer_2': 0.00016069092168180833, 'l1_Layer_3': 4.106605385726978e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 145, 'n_units_Layer_3': 295}. Best is trial 513 with value: 7.793737815354347.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.79 | sMAPE for Validation Set is: 14.09% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:06:51,944]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:58,971]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:59,483]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:06:59,720]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:07:06,262]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:07:09,971]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:07:14,436]\u001b[0m Trial 527 finished with value: 8.40515478854295 and parameters: {'n_hidden': 3, 'learning_rate': 0.004616793730145558, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029204374269643455, 'dropout_rate_Layer_2': 0.0038535494574483964, 'dropout_rate_Layer_3': 0.10224911423474844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009115763498682984, 'l1_Layer_2': 0.03666869490768818, 'l1_Layer_3': 6.958363513552542e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 130, 'n_units_Layer_3': 205}. Best is trial 513 with value: 7.793737815354347.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.41 | sMAPE for Validation Set is: 15.19% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 17.38% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:07:15,016]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:07:18,029]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:07:22,688]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:07:28,918]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:07:32,314]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:07:38,073]\u001b[0m Trial 533 finished with value: 8.08015492872597 and parameters: {'n_hidden': 3, 'learning_rate': 0.0046803250524586545, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029541935405330788, 'dropout_rate_Layer_2': 0.0018748147249553048, 'dropout_rate_Layer_3': 0.1073633663145933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000869706178556731, 'l1_Layer_2': 0.03600015721804446, 'l1_Layer_3': 6.985260999831498e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 120, 'n_units_Layer_3': 205}. Best is trial 513 with value: 7.793737815354347.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.08 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 16.97% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:07:41,336]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:07:48,653]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:07:55,791]\u001b[0m Trial 541 finished with value: 8.054982618797203 and parameters: {'n_hidden': 3, 'learning_rate': 0.005115814322417831, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20387367596331124, 'dropout_rate_Layer_2': 0.08489015333587596, 'dropout_rate_Layer_3': 0.24503436080982371, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.675005528441177e-05, 'l1_Layer_2': 0.0006680469259623891, 'l1_Layer_3': 7.377690587182286e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 80}. Best is trial 513 with value: 7.793737815354347.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.05 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 17.21% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:07:59,996]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.91 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 16.68% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:08:02,635]\u001b[0m Trial 543 finished with value: 7.914235948663851 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010026816306504993, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18386836990237837, 'dropout_rate_Layer_2': 0.270428178158522, 'dropout_rate_Layer_3': 0.09321837731231748, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010771966288268147, 'l1_Layer_2': 0.00016807444026002547, 'l1_Layer_3': 6.501922735031999e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 120, 'n_units_Layer_3': 270}. Best is trial 513 with value: 7.793737815354347.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:08:07,856]\u001b[0m Trial 539 finished with value: 7.886795746290041 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009866392534127726, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2359461744785792, 'dropout_rate_Layer_2': 0.27670840465366037, 'dropout_rate_Layer_3': 0.03623287771157663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029199116548384854, 'l1_Layer_2': 0.00024930463260320744, 'l1_Layer_3': 6.622525485639977e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 120, 'n_units_Layer_3': 270}. Best is trial 513 with value: 7.793737815354347.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.89 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:08:16,973]\u001b[0m Trial 544 finished with value: 8.148759368757963 and parameters: {'n_hidden': 3, 'learning_rate': 0.003515054151534887, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1906919323407103, 'dropout_rate_Layer_2': 0.10715148789883226, 'dropout_rate_Layer_3': 0.26276627724761065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.0804516148837874e-05, 'l1_Layer_2': 0.0008192550363672552, 'l1_Layer_3': 5.9207914978061976e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 220, 'n_units_Layer_3': 75}. Best is trial 513 with value: 7.793737815354347.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.15 | sMAPE for Validation Set is: 14.69% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 16.92% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:08:23,067]\u001b[0m Trial 547 finished with value: 8.224245998002521 and parameters: {'n_hidden': 3, 'learning_rate': 0.00540825191491553, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005808798481430694, 'dropout_rate_Layer_2': 0.02702092126833784, 'dropout_rate_Layer_3': 0.10834654074715794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00048577715962922526, 'l1_Layer_2': 0.027830939693314596, 'l1_Layer_3': 8.692583863608222e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 125, 'n_units_Layer_3': 195}. Best is trial 513 with value: 7.793737815354347.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.22 | sMAPE for Validation Set is: 14.98% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 17.47% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:08:23,903]\u001b[0m Trial 546 finished with value: 8.465113757167227 and parameters: {'n_hidden': 3, 'learning_rate': 0.005692657006729872, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002859998110142632, 'dropout_rate_Layer_2': 0.0265753429521339, 'dropout_rate_Layer_3': 0.07216997302820884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025471160581761903, 'l1_Layer_2': 0.029419487216639367, 'l1_Layer_3': 8.490170526827631e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210}. Best is trial 513 with value: 7.793737815354347.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.47 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 17.06% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:08:30,868]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:08:31,560]\u001b[0m Trial 548 finished with value: 8.462238190311739 and parameters: {'n_hidden': 3, 'learning_rate': 0.005435003459340028, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018937836859177517, 'dropout_rate_Layer_2': 0.0016547438607431714, 'dropout_rate_Layer_3': 0.06835516753812365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028098585471121817, 'l1_Layer_2': 0.02871201305063957, 'l1_Layer_3': 9.218923936101154e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 125, 'n_units_Layer_3': 195}. Best is trial 513 with value: 7.793737815354347.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 15.35% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 17.27% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:08:31,928]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:08:41,746]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:08:42,485]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:08:47,166]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:08:50,980]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:08:52,713]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:08:55,657]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:08:58,273]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:09:03,571]\u001b[0m Trial 552 finished with value: 7.747314363369507 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010149666000634134, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07218148395153692, 'dropout_rate_Layer_2': 0.26404127648187425, 'dropout_rate_Layer_3': 0.05546383071322162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002830160621697893, 'l1_Layer_2': 0.0001434947859886938, 'l1_Layer_3': 7.057647540336722e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 90, 'n_units_Layer_3': 290}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.75 | sMAPE for Validation Set is: 14.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 16.62% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:09:17,493]\u001b[0m Trial 561 finished with value: 8.134838146639494 and parameters: {'n_hidden': 3, 'learning_rate': 0.003647651217169347, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23817976091361925, 'dropout_rate_Layer_2': 0.13988974118247458, 'dropout_rate_Layer_3': 0.27580459460906614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3565049908274567e-05, 'l1_Layer_2': 0.000968375563750987, 'l1_Layer_3': 7.581147815692807e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 85}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.13 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 17.02% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:09:21,859]\u001b[0m Trial 562 finished with value: 8.052668649071423 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036996121188824366, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2095194764339506, 'dropout_rate_Layer_2': 0.09301490457862527, 'dropout_rate_Layer_3': 0.2765575245068863, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4086365622078247e-05, 'l1_Layer_2': 0.0009507773788889909, 'l1_Layer_3': 8.024542710789971e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 85}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.05 | sMAPE for Validation Set is: 14.52% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:09:26,631]\u001b[0m Trial 556 finished with value: 7.838462616016524 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009471683805757163, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2245758479604976, 'dropout_rate_Layer_2': 0.27208178294682983, 'dropout_rate_Layer_3': 0.053459915673740865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002738401333132849, 'l1_Layer_2': 0.00016837101510731016, 'l1_Layer_3': 6.318959297915382e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 120, 'n_units_Layer_3': 290}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.84 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:09:27,195]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:09:31,352]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:09:33,194]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:09:38,325]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:09:38,795]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:09:44,783]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:09:49,555]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:09:53,450]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:09:54,360]\u001b[0m Trial 560 finished with value: 7.8238686083814954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009955818644205314, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22301739504951362, 'dropout_rate_Layer_2': 0.26107525803144643, 'dropout_rate_Layer_3': 0.053823838963816824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013743960601671917, 'l1_Layer_2': 0.00014643354707780112, 'l1_Layer_3': 0.00011622994987996265, 'n_units_Layer_1': 65, 'n_units_Layer_2': 125, 'n_units_Layer_3': 290}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.82 | sMAPE for Validation Set is: 14.17% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 16.90% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:10:00,551]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:10:07,618]\u001b[0m Trial 570 finished with value: 8.17730594201683 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038322024251223655, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2281601976091958, 'dropout_rate_Layer_2': 0.1169937332491221, 'dropout_rate_Layer_3': 0.26780325800210425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.951291679759199e-05, 'l1_Layer_2': 0.0014403763159860981, 'l1_Layer_3': 5.8647912576543104e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 80}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 14.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 17.42% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:10:08,175]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.16 | sMAPE for Validation Set is: 14.87% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 17.42% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:10:08,186]\u001b[0m Trial 574 finished with value: 8.156830789336945 and parameters: {'n_hidden': 3, 'learning_rate': 0.003851652177633968, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20168998873688307, 'dropout_rate_Layer_2': 0.1073224846689324, 'dropout_rate_Layer_3': 0.2940033823542847, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0197149609660583e-05, 'l1_Layer_2': 0.000694573410863959, 'l1_Layer_3': 6.500188826972695e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 205, 'n_units_Layer_3': 80}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:10:17,407]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:10:18,136]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:10:25,841]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:10:26,399]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:10:31,387]\u001b[0m Trial 568 finished with value: 7.933995926029412 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013855146111537483, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3307855699311868, 'dropout_rate_Layer_2': 0.2615993356999868, 'dropout_rate_Layer_3': 0.03818155419276177, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002113348461871478, 'l1_Layer_2': 0.0002370916482722363, 'l1_Layer_3': 0.0001178012470279991, 'n_units_Layer_1': 70, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.93 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 16.62% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:10:38,652]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:10:41,046]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:10:41,521]\u001b[0m Trial 576 finished with value: 8.192420794337822 and parameters: {'n_hidden': 3, 'learning_rate': 0.007319443912068346, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008797669861806997, 'dropout_rate_Layer_2': 0.04030642462122235, 'dropout_rate_Layer_3': 0.0648317383406137, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013843720347188585, 'l1_Layer_2': 0.0975689266299209, 'l1_Layer_3': 0.0001001045957727605, 'n_units_Layer_1': 245, 'n_units_Layer_2': 105, 'n_units_Layer_3': 220}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.19 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 16.52% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:10:41,723]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:10:49,731]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:10:50,241]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:10:53,886]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:10:59,761]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:11:00,973]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.19 | sMAPE for Validation Set is: 14.84% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 17.37% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:11:03,202]\u001b[0m Trial 584 finished with value: 8.188094639769258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027299209296496544, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2155543263288405, 'dropout_rate_Layer_2': 0.11968922994063075, 'dropout_rate_Layer_3': 0.2768104797563147, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.4808746228698e-05, 'l1_Layer_2': 0.0018107461288735087, 'l1_Layer_3': 6.69313173416265e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 200, 'n_units_Layer_3': 100}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:11:09,654]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:11:13,228]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:11:14,106]\u001b[0m Trial 590 finished with value: 8.170099918891154 and parameters: {'n_hidden': 3, 'learning_rate': 0.004357238894929181, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20597049547766266, 'dropout_rate_Layer_2': 0.11134242908355825, 'dropout_rate_Layer_3': 0.26333717845166515, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4739661528991865e-05, 'l1_Layer_2': 0.0004938889679793109, 'l1_Layer_3': 4.438400121147584e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 210, 'n_units_Layer_3': 85}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.17 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 17.42% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:11:22,085]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:11:25,863]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:11:28,576]\u001b[0m Trial 591 finished with value: 8.108582630841205 and parameters: {'n_hidden': 3, 'learning_rate': 0.005620492155528571, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006016939931619281, 'dropout_rate_Layer_2': 0.012313260356621279, 'dropout_rate_Layer_3': 0.057123324316528196, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005371321605341956, 'l1_Layer_2': 0.09663848867086314, 'l1_Layer_3': 0.00035388762662402035, 'n_units_Layer_1': 255, 'n_units_Layer_2': 115, 'n_units_Layer_3': 225}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.11 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:11:31,341]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:11:31,791]\u001b[0m Trial 592 finished with value: 7.9771781812788625 and parameters: {'n_hidden': 3, 'learning_rate': 0.005614528395779616, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009604374388763626, 'dropout_rate_Layer_2': 0.011295958416181813, 'dropout_rate_Layer_3': 0.058368331604432985, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005589368831593782, 'l1_Layer_2': 0.0643837154713547, 'l1_Layer_3': 7.280227591180146e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 100, 'n_units_Layer_3': 225}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.98 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 17.11% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:11:34,759]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:11:39,054]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:11:42,373]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:11:47,275]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.89 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:11:50,099]\u001b[0m Trial 595 finished with value: 7.887764179453504 and parameters: {'n_hidden': 3, 'learning_rate': 0.001430702070369675, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3510127275411826, 'dropout_rate_Layer_2': 0.275189996841229, 'dropout_rate_Layer_3': 0.055543441345405106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001369476548179841, 'l1_Layer_2': 0.00014983109988558565, 'l1_Layer_3': 5.6744652950241385e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 120, 'n_units_Layer_3': 300}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:11:52,894]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:12:06,781]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:12:10,510]\u001b[0m Trial 604 finished with value: 8.18384157667391 and parameters: {'n_hidden': 3, 'learning_rate': 0.004429126929333122, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021356675981106552, 'dropout_rate_Layer_2': 0.009041029756487365, 'dropout_rate_Layer_3': 0.05142269454262792, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006092231571202351, 'l1_Layer_2': 0.09600267825655784, 'l1_Layer_3': 0.0003768481165833596, 'n_units_Layer_1': 255, 'n_units_Layer_2': 100, 'n_units_Layer_3': 225}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 14.82% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 16.84% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:12:14,682]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:12:15,712]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:12:23,610]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:12:26,704]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:12:28,492]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.19 | sMAPE for Validation Set is: 14.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 16.95% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:12:30,733]\u001b[0m Trial 607 finished with value: 8.193120600218213 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030101405800551416, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20709095146452405, 'dropout_rate_Layer_2': 0.14748843019575303, 'dropout_rate_Layer_3': 0.2423635235510553, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9806089557083973e-05, 'l1_Layer_2': 0.0007871920675244114, 'l1_Layer_3': 5.628675108573341e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 85}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:12:35,288]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:12:38,223]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:12:42,020]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:12:42,115]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:12:51,494]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:03,785]\u001b[0m Trial 615 finished with value: 7.965289783362348 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017508121043358811, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36390464743673623, 'dropout_rate_Layer_2': 0.29708454852059507, 'dropout_rate_Layer_3': 0.044893431603259724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00195624243392937, 'l1_Layer_2': 0.00024082653855751418, 'l1_Layer_3': 5.81335154672881e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.97 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:13:08,653]\u001b[0m Trial 619 finished with value: 8.217803039128997 and parameters: {'n_hidden': 3, 'learning_rate': 0.00418411853549825, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21125208071623183, 'dropout_rate_Layer_2': 0.17205853472732585, 'dropout_rate_Layer_3': 0.2487358076530568, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.570931597320567e-05, 'l1_Layer_2': 0.0008368137224309426, 'l1_Layer_3': 8.751888791428371e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 85}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.22 | sMAPE for Validation Set is: 14.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 17.40% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:13:08,909]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:09,571]\u001b[0m Trial 618 finished with value: 7.931208500462539 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010362815062279957, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34838635043661037, 'dropout_rate_Layer_2': 0.29846808615398496, 'dropout_rate_Layer_3': 0.07575126757933018, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00060333740634852, 'l1_Layer_2': 0.00016819522104815086, 'l1_Layer_3': 3.550524630224619e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 120, 'n_units_Layer_3': 290}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.93 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 16.70% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:13:16,266]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:18,646]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:21,011]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:22,365]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:23,711]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:29,863]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:33,102]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:34,317]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:39,476]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:40,456]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:45,846]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:46,653]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:51,428]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:54,607]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:58,146]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:13:58,589]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:01,173]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:03,429]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:06,407]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:08,545]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:09,358]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:10,911]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:15,741]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:20,178]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:21,695]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:22,727]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:25,263]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:25,378]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:27,192]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:27,976]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:35,294]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:37,237]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:39,829]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:42,824]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:46,682]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:49,600]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:51,781]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:54,597]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:14:55,908]\u001b[0m Trial 652 finished with value: 8.169277700925008 and parameters: {'n_hidden': 3, 'learning_rate': 0.005221175386170698, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009884632775642981, 'dropout_rate_Layer_2': 0.024326102905893182, 'dropout_rate_Layer_3': 0.073542427162182, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007039384757238138, 'l1_Layer_2': 0.07830020054496697, 'l1_Layer_3': 0.00015155901624706674, 'n_units_Layer_1': 225, 'n_units_Layer_2': 125, 'n_units_Layer_3': 185}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.17 | sMAPE for Validation Set is: 14.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:15:00,091]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:01,980]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:06,254]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:10,248]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:11,022]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:17,336]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:21,058]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:21,503]\u001b[0m Trial 661 finished with value: 8.182408811477755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032147418814771314, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1998181756045675, 'dropout_rate_Layer_2': 0.11498085853902223, 'dropout_rate_Layer_3': 0.2687194799865857, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.132184795269256e-05, 'l1_Layer_2': 0.0005438063907398248, 'l1_Layer_3': 6.459303212996864e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 215, 'n_units_Layer_3': 75}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 14.80% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 17.10% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:15:25,501]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:29,050]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:30,708]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:33,242]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:37,563]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:40,607]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:43,601]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:49,949]\u001b[0m Trial 667 finished with value: 8.179651592181827 and parameters: {'n_hidden': 3, 'learning_rate': 0.004002319398851735, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04299155885877334, 'dropout_rate_Layer_2': 0.018470265803427213, 'dropout_rate_Layer_3': 0.0685543060341053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006590115656149814, 'l1_Layer_2': 0.04420904037275281, 'l1_Layer_3': 9.115016321215106e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 125, 'n_units_Layer_3': 195}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 14.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 16.81% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:15:54,314]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:15:58,738]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:16:02,747]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:16:08,641]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.94 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 16.79% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:16:11,193]\u001b[0m Trial 677 finished with value: 7.936170439169618 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026981181381149455, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1982728153745002, 'dropout_rate_Layer_2': 0.12048457475044097, 'dropout_rate_Layer_3': 0.2370256873569457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.740065610645239e-05, 'l1_Layer_2': 0.0007155152604053745, 'l1_Layer_3': 3.1932354543188406e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 210, 'n_units_Layer_3': 75}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:16:13,125]\u001b[0m Trial 679 finished with value: 8.059946441863502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035220781669786324, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17860623447577448, 'dropout_rate_Layer_2': 0.12070142367636116, 'dropout_rate_Layer_3': 0.2703442921284726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.478059709516807e-05, 'l1_Layer_2': 0.0006990723730782613, 'l1_Layer_3': 5.578200065315085e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 210, 'n_units_Layer_3': 75}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.06 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 17.49% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:16:15,111]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:16:15,308]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:16:23,245]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:16:24,509]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:16:27,682]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:16:31,936]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:16:32,734]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:16:39,772]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:16:40,526]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:16:54,893]\u001b[0m Trial 693 finished with value: 8.194203110234033 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033420201214624354, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21133189465117058, 'dropout_rate_Layer_2': 0.1090194565377728, 'dropout_rate_Layer_3': 0.2517985129568819, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.182260423042606e-05, 'l1_Layer_2': 0.001053638551081334, 'l1_Layer_3': 2.426956004366446e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 55, 'n_units_Layer_3': 80}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.19 | sMAPE for Validation Set is: 14.92% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 17.45% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:16:58,487]\u001b[0m Trial 684 finished with value: 7.859852636983718 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014900956467388865, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33679516124874187, 'dropout_rate_Layer_2': 0.24698273957256076, 'dropout_rate_Layer_3': 0.0007800155259462538, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009320418981568846, 'l1_Layer_2': 0.00017224211714588703, 'l1_Layer_3': 0.00010160331688413526, 'n_units_Layer_1': 55, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.86 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 16.65% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:16:59,638]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:17:04,643]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:17:06,046]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:17:08,624]\u001b[0m Trial 694 finished with value: 8.067483387086645 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033641785340205775, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21085136386714573, 'dropout_rate_Layer_2': 0.09139589290956052, 'dropout_rate_Layer_3': 0.2517638667275037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1642024944726094e-05, 'l1_Layer_2': 0.001043882599179029, 'l1_Layer_3': 2.4572776841804264e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 210, 'n_units_Layer_3': 80}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.07 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 17.39% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:17:09,854]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:17:18,145]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:17:22,224]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.86 | sMAPE for Validation Set is: 14.14% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 16.65% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:17:25,211]\u001b[0m Trial 690 finished with value: 7.8578937755083915 and parameters: {'n_hidden': 3, 'learning_rate': 0.00144894361200218, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3372225891924677, 'dropout_rate_Layer_2': 0.28791775354299587, 'dropout_rate_Layer_3': 0.031024589373089433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022077650265567694, 'l1_Layer_2': 0.00016914813031338068, 'l1_Layer_3': 0.00010661860342368033, 'n_units_Layer_1': 55, 'n_units_Layer_2': 120, 'n_units_Layer_3': 290}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:17:34,341]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:17:34,859]\u001b[0m Trial 699 finished with value: 7.943262448985706 and parameters: {'n_hidden': 3, 'learning_rate': 0.004158697401618144, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21192499756463692, 'dropout_rate_Layer_2': 0.08324036047448459, 'dropout_rate_Layer_3': 0.2516950283672353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.543083401900449e-05, 'l1_Layer_2': 0.0011343786020753864, 'l1_Layer_3': 1.3697095809366631e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 70, 'n_units_Layer_3': 75}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.94 | sMAPE for Validation Set is: 14.33% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 16.69% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:17:40,291]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:17:47,822]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:17:51,836]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:17:52,520]\u001b[0m Trial 704 finished with value: 8.015565824686261 and parameters: {'n_hidden': 3, 'learning_rate': 0.00400569613606321, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21093267949468694, 'dropout_rate_Layer_2': 0.0883322705616067, 'dropout_rate_Layer_3': 0.25068826391666643, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.2112277717707873e-05, 'l1_Layer_2': 0.0012146963879868424, 'l1_Layer_3': 8.740606916600934e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 70, 'n_units_Layer_3': 85}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.02 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 17.02% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:17:58,943]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:01,938]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:04,384]\u001b[0m Trial 702 finished with value: 8.058537010649287 and parameters: {'n_hidden': 3, 'learning_rate': 0.005661952450644476, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029829688733962405, 'dropout_rate_Layer_2': 0.010234386308747031, 'dropout_rate_Layer_3': 0.11906479283188044, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007691554122666288, 'l1_Layer_2': 0.04048419105864037, 'l1_Layer_3': 7.076912453683894e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 60, 'n_units_Layer_3': 230}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.06 | sMAPE for Validation Set is: 14.53% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:18:07,160]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:07,904]\u001b[0m Trial 706 finished with value: 8.015704921947957 and parameters: {'n_hidden': 3, 'learning_rate': 0.005563390830186973, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04672709353079252, 'dropout_rate_Layer_2': 0.010941218618394453, 'dropout_rate_Layer_3': 0.10546920902183021, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007795237678047288, 'l1_Layer_2': 0.06871321233986438, 'l1_Layer_3': 9.330627037147722e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.02 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 16.42% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:18:11,327]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:19,138]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:20,562]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:22,635]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:27,592]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:32,787]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:33,532]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:36,213]\u001b[0m Trial 712 finished with value: 8.009396042788273 and parameters: {'n_hidden': 3, 'learning_rate': 0.005623082247590996, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017937826367785056, 'dropout_rate_Layer_2': 0.008585801089602156, 'dropout_rate_Layer_3': 0.10402548966416567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008097151143315932, 'l1_Layer_2': 0.03708009012821811, 'l1_Layer_3': 8.239675170974439e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 65, 'n_units_Layer_3': 225}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.01 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:18:38,870]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:41,508]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:46,546]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:46,867]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:48,106]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:56,055]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:56,698]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:18:57,544]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:19:02,024]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:19:05,247]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:19:07,372]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:19:08,824]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:19:13,630]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:19:15,757]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:19:21,744]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:19:25,764]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:19:37,541]\u001b[0m Trial 736 finished with value: 8.047907587784852 and parameters: {'n_hidden': 3, 'learning_rate': 0.004378497370915143, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01962586627636354, 'dropout_rate_Layer_2': 0.005562398361483716, 'dropout_rate_Layer_3': 0.1153554908282191, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000846891178631263, 'l1_Layer_2': 0.05179902914298658, 'l1_Layer_3': 9.455430813904813e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 75, 'n_units_Layer_3': 235}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.05 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 16.85% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:19:41,278]\u001b[0m Trial 726 finished with value: 8.303959538497073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029582751806818686, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2809277989178676, 'dropout_rate_Layer_2': 0.08138958274836075, 'dropout_rate_Layer_3': 0.24521199351719972, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010832463807692892, 'l1_Layer_2': 0.0003742405308131502, 'l1_Layer_3': 6.699789209643653e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 95}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 17.08% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:19:42,571]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:19:44,657]\u001b[0m Trial 735 finished with value: 8.082841879056152 and parameters: {'n_hidden': 3, 'learning_rate': 0.0043567480894443405, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0214896252597548, 'dropout_rate_Layer_2': 0.009603678266064621, 'dropout_rate_Layer_3': 0.12178978871199846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000823348734932973, 'l1_Layer_2': 0.05365453040149529, 'l1_Layer_3': 9.92466145975921e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 235}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.08 | sMAPE for Validation Set is: 14.67% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 16.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:19:52,509]\u001b[0m Trial 739 finished with value: 7.958989232727492 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026849180244332984, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26681609302852316, 'dropout_rate_Layer_2': 0.2699634630257522, 'dropout_rate_Layer_3': 0.011217018063231233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024505332691228715, 'l1_Layer_2': 5.380029038479019e-05, 'l1_Layer_3': 7.752232725714464e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 105, 'n_units_Layer_3': 275}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.96 | sMAPE for Validation Set is: 14.30% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:19:56,592]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:04,819]\u001b[0m Trial 741 finished with value: 8.052591700021116 and parameters: {'n_hidden': 3, 'learning_rate': 0.004352570428485502, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019793405123434714, 'dropout_rate_Layer_2': 3.543047615390746e-05, 'dropout_rate_Layer_3': 0.14496949818792643, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008642762156000772, 'l1_Layer_2': 0.05370960876639838, 'l1_Layer_3': 9.543755470343973e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 60, 'n_units_Layer_3': 235}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.05 | sMAPE for Validation Set is: 14.62% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 16.71% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:20:06,856]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:09,674]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:12,767]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:14,448]\u001b[0m Trial 743 finished with value: 8.069653833600618 and parameters: {'n_hidden': 3, 'learning_rate': 0.004253513953736303, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019646975323288764, 'dropout_rate_Layer_2': 0.005243418100687023, 'dropout_rate_Layer_3': 0.12383966476778305, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008065823794435318, 'l1_Layer_2': 0.052222223050799474, 'l1_Layer_3': 0.0001247887812892602, 'n_units_Layer_1': 215, 'n_units_Layer_2': 55, 'n_units_Layer_3': 235}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.07 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 16.83% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:20:14,998]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:20,412]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.77 | sMAPE for Validation Set is: 14.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 16.63% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:20:21,639]\u001b[0m Trial 742 finished with value: 7.769596931996515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027499924363057534, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026979199566658126, 'dropout_rate_Layer_2': 0.2386894444922899, 'dropout_rate_Layer_3': 0.010322470743703707, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008187736312399556, 'l1_Layer_2': 0.00020385845081209275, 'l1_Layer_3': 0.00021609954621099438, 'n_units_Layer_1': 60, 'n_units_Layer_2': 105, 'n_units_Layer_3': 275}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:22,972]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:28,886]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:30,316]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:32,374]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:35,174]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:38,785]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:41,596]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:45,787]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:53,266]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:55,527]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:20:59,353]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:03,261]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:07,889]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:11,969]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:13,002]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:16,326]\u001b[0m Trial 759 finished with value: 8.19543718231457 and parameters: {'n_hidden': 3, 'learning_rate': 0.004455438101644488, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023692567930732322, 'dropout_rate_Layer_2': 0.009996124940519635, 'dropout_rate_Layer_3': 0.1472947989547504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005890354117599485, 'l1_Layer_2': 0.06625398623965659, 'l1_Layer_3': 7.812073481408002e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 55, 'n_units_Layer_3': 240}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.20 | sMAPE for Validation Set is: 14.89% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 17.39% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:21:17,251]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:25,882]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:28,950]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:33,986]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:34,289]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:41,053]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:41,328]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:47,802]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:21:50,796]\u001b[0m Trial 769 finished with value: 8.114410834649867 and parameters: {'n_hidden': 3, 'learning_rate': 0.005076504460162999, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018702190402050078, 'dropout_rate_Layer_2': 0.016320153125493182, 'dropout_rate_Layer_3': 0.11479090290696257, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009449370291205545, 'l1_Layer_2': 0.039134324124387915, 'l1_Layer_3': 0.0004472170016528228, 'n_units_Layer_1': 220, 'n_units_Layer_2': 60, 'n_units_Layer_3': 230}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.11 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 16.61% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:21:55,231]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:00,581]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:00,741]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.02 | sMAPE for Validation Set is: 14.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 17.20% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:22:02,421]\u001b[0m Trial 764 finished with value: 8.017164375937407 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031546971029992716, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19576870583763956, 'dropout_rate_Layer_2': 0.10113404338983241, 'dropout_rate_Layer_3': 0.2709293020115465, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.205176891676752e-05, 'l1_Layer_2': 0.0009392750781855219, 'l1_Layer_3': 0.003636500634026701, 'n_units_Layer_1': 255, 'n_units_Layer_2': 95, 'n_units_Layer_3': 75}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:08,314]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:08,860]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:11,638]\u001b[0m Trial 775 finished with value: 8.181623356675303 and parameters: {'n_hidden': 3, 'learning_rate': 0.004963757577588211, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05904561264113492, 'dropout_rate_Layer_2': 0.0075922479071220145, 'dropout_rate_Layer_3': 0.13065101672727883, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005920204592540672, 'l1_Layer_2': 0.05142714095129622, 'l1_Layer_3': 0.00016694327748005599, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 14.78% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 16.57% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:22:16,122]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:20,672]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:20,881]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:28,711]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:33,636]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:42,698]\u001b[0m Trial 785 finished with value: 8.278767733023377 and parameters: {'n_hidden': 3, 'learning_rate': 0.00588708338136422, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07818558708084576, 'dropout_rate_Layer_2': 0.020836860594660063, 'dropout_rate_Layer_3': 0.1300319559842486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010931249878107063, 'l1_Layer_2': 0.043154954934099966, 'l1_Layer_3': 0.00017530121892386056, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 245}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.28 | sMAPE for Validation Set is: 14.90% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 16.43% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:22:43,336]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:46,869]\u001b[0m Trial 783 finished with value: 7.810138772719401 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019679472534010274, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05933621509700237, 'dropout_rate_Layer_2': 0.24608848917519677, 'dropout_rate_Layer_3': 0.022599763859298853, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008168621190849774, 'l1_Layer_2': 0.0002030215926576207, 'l1_Layer_3': 0.00023257605312469864, 'n_units_Layer_1': 50, 'n_units_Layer_2': 110, 'n_units_Layer_3': 290}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.81 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 16.62% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:22:49,874]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:50,426]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:22:52,943]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:01,115]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:01,204]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:01,548]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:10,666]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:11,131]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:18,496]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:18,577]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:18,800]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:27,897]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:32,842]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:37,180]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:40,231]\u001b[0m Trial 798 finished with value: 7.795995261220738 and parameters: {'n_hidden': 3, 'learning_rate': 0.001998306499642281, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05599104812523607, 'dropout_rate_Layer_2': 0.24376358777590088, 'dropout_rate_Layer_3': 0.009837623441856548, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010015995315588385, 'l1_Layer_2': 0.000499639579387339, 'l1_Layer_3': 9.776317326099322e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 115, 'n_units_Layer_3': 280}. Best is trial 552 with value: 7.747314363369507.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.80 | sMAPE for Validation Set is: 14.06% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 16.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:23:42,306]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:45,990]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:49,164]\u001b[0m Trial 802 finished with value: 7.744800147468596 and parameters: {'n_hidden': 3, 'learning_rate': 0.002744903529161969, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03315811802775002, 'dropout_rate_Layer_2': 0.244814239615696, 'dropout_rate_Layer_3': 0.049964506394367815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001601951921956426, 'l1_Layer_2': 0.00013876257777726875, 'l1_Layer_3': 0.00013742549701895585, 'n_units_Layer_1': 50, 'n_units_Layer_2': 140, 'n_units_Layer_3': 290}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.74 | sMAPE for Validation Set is: 14.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 16.69% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:23:50,618]\u001b[0m Trial 803 finished with value: 8.134882503994351 and parameters: {'n_hidden': 3, 'learning_rate': 0.003520334364227509, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21839134294408535, 'dropout_rate_Layer_2': 0.09299994115615974, 'dropout_rate_Layer_3': 0.2367126344023877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018456158609303762, 'l1_Layer_2': 0.00110318433977065, 'l1_Layer_3': 6.842784660311029e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 215, 'n_units_Layer_3': 65}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.13 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 17.13% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:23:52,567]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:23:58,053]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:01,176]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:03,429]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:08,199]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:08,435]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:09,420]\u001b[0m Trial 809 finished with value: 7.843655115701189 and parameters: {'n_hidden': 3, 'learning_rate': 0.002910638378435515, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07050374687110891, 'dropout_rate_Layer_2': 0.24149671461615307, 'dropout_rate_Layer_3': 0.008258606397335125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014297867454208745, 'l1_Layer_2': 0.00013934629319628354, 'l1_Layer_3': 7.629456372858078e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 105, 'n_units_Layer_3': 290}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.84 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:24:17,283]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:17,592]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:18,215]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:25,690]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:27,400]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:28,373]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:31,254]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:36,698]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:37,976]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:41,263]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:42,100]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:42,695]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:43,700]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:52,701]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:54,575]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:24:58,137]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:01,162]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:03,785]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:05,911]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:08,844]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:12,314]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:15,537]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:16,838]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:17,817]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.79 | sMAPE for Validation Set is: 14.06% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:25:21,876]\u001b[0m Trial 831 finished with value: 7.791135360666272 and parameters: {'n_hidden': 3, 'learning_rate': 0.002174434288075014, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04102611877157791, 'dropout_rate_Layer_2': 0.23896798580385709, 'dropout_rate_Layer_3': 0.006645258929549109, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016867922771431668, 'l1_Layer_2': 0.00011962488582283387, 'l1_Layer_3': 7.953259497074071e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 125, 'n_units_Layer_3': 290}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:22,057]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:27,002]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:27,520]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:31,584]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:33,106]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:34,224]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:34,625]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:40,101]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:44,440]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:51,866]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:54,181]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:54,793]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:25:55,961]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:01,493]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:05,835]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:05,892]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:09,355]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:14,967]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:18,575]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:22,777]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:29,893]\u001b[0m Trial 861 finished with value: 7.82993482689174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022009754415148776, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.032040159622387536, 'dropout_rate_Layer_2': 0.23685641038361888, 'dropout_rate_Layer_3': 0.006617169546910675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009275713344402114, 'l1_Layer_2': 0.00010735257186375897, 'l1_Layer_3': 9.718154982288429e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 115, 'n_units_Layer_3': 280}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.83 | sMAPE for Validation Set is: 14.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:26:33,009]\u001b[0m Trial 858 finished with value: 8.15033210692237 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034632360364300276, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18067761439139957, 'dropout_rate_Layer_2': 0.09459969104009688, 'dropout_rate_Layer_3': 0.269882959828351, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7095588268363855e-05, 'l1_Layer_2': 0.0010228815789884093, 'l1_Layer_3': 6.45525916037245e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 225, 'n_units_Layer_3': 75}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.15 | sMAPE for Validation Set is: 14.82% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 17.05% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:26:33,483]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:36,089]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:36,973]\u001b[0m Trial 862 finished with value: 7.835413477744915 and parameters: {'n_hidden': 3, 'learning_rate': 0.002582143542720397, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03516353012985177, 'dropout_rate_Layer_2': 0.23488628453347754, 'dropout_rate_Layer_3': 0.0048178824846121715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009659532748428273, 'l1_Layer_2': 0.00010635284773766685, 'l1_Layer_3': 9.519635143951268e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 115, 'n_units_Layer_3': 280}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.84 | sMAPE for Validation Set is: 14.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 16.71% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:26:38,951]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:40,320]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:45,713]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:47,900]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:49,165]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:53,411]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:56,359]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:26:59,987]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:01,183]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:04,321]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:05,978]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:07,597]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:12,173]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:12,325]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:14,887]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:16,285]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:20,470]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:22,380]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:24,601]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:30,091]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:36,929]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:41,842]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:45,100]\u001b[0m Trial 885 finished with value: 7.749043416697219 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024201646674919404, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011863469803132728, 'dropout_rate_Layer_2': 0.19317986965214806, 'dropout_rate_Layer_3': 0.015683290305619324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006836440692386101, 'l1_Layer_2': 8.014054297051083e-05, 'l1_Layer_3': 0.00015710537519887153, 'n_units_Layer_1': 70, 'n_units_Layer_2': 100, 'n_units_Layer_3': 75}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.75 | sMAPE for Validation Set is: 13.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 16.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:27:47,667]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:52,952]\u001b[0m Trial 887 finished with value: 8.134810655769689 and parameters: {'n_hidden': 3, 'learning_rate': 0.006354987572429214, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01200613438107788, 'dropout_rate_Layer_2': 0.0002554783632847571, 'dropout_rate_Layer_3': 0.08391221258085874, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006800124505436288, 'l1_Layer_2': 0.06562167945821544, 'l1_Layer_3': 0.0004959296144233289, 'n_units_Layer_1': 220, 'n_units_Layer_2': 130, 'n_units_Layer_3': 220}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.13 | sMAPE for Validation Set is: 14.74% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.11 | sMAPE for Test Set is: 17.36% | rMAE for Test Set is: 0.69\n",
      "MAE for Validation Set is: 8.02 | sMAPE for Validation Set is: 14.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 17.30% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:27:56,120]\u001b[0m Trial 888 finished with value: 8.023916058305035 and parameters: {'n_hidden': 3, 'learning_rate': 0.003954014862825393, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16534585444940766, 'dropout_rate_Layer_2': 0.08346821072636841, 'dropout_rate_Layer_3': 0.23841171045432313, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.453588467362319e-05, 'l1_Layer_2': 0.0010155206803927916, 'l1_Layer_3': 5.901831972245127e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 220, 'n_units_Layer_3': 85}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:27:59,623]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:00,607]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:03,425]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:09,818]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:10,482]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:16,517]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:17,692]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:21,349]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:24,516]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:27,286]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:30,841]\u001b[0m Trial 892 finished with value: 8.003927580151478 and parameters: {'n_hidden': 3, 'learning_rate': 0.004810483582805039, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04811322226855793, 'dropout_rate_Layer_2': 0.02003073693093227, 'dropout_rate_Layer_3': 0.11001364561731145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005782141385144472, 'l1_Layer_2': 0.04527243489083131, 'l1_Layer_3': 5.066195233749721e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 70, 'n_units_Layer_3': 195}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.00 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 16.68% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:28:31,917]\u001b[0m Trial 896 finished with value: 7.810047133887946 and parameters: {'n_hidden': 3, 'learning_rate': 0.002267188244943683, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016698617269367083, 'dropout_rate_Layer_2': 0.19027257492619856, 'dropout_rate_Layer_3': 0.014755257206608995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006889230070448709, 'l1_Layer_2': 8.815333939025331e-05, 'l1_Layer_3': 0.0004724890570801477, 'n_units_Layer_1': 70, 'n_units_Layer_2': 100, 'n_units_Layer_3': 125}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.81 | sMAPE for Validation Set is: 14.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 17.00% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:28:33,954]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:34,396]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:39,529]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:45,112]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:48,673]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:50,388]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:53,989]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:28:56,844]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.10 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 17.09% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:28:58,810]\u001b[0m Trial 906 finished with value: 8.101725590277873 and parameters: {'n_hidden': 3, 'learning_rate': 0.004718480808771187, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16560451305427418, 'dropout_rate_Layer_2': 0.09580940558835185, 'dropout_rate_Layer_3': 0.29631820607233816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0590941762084747e-05, 'l1_Layer_2': 0.0012173290572057094, 'l1_Layer_3': 4.416879065683377e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 205, 'n_units_Layer_3': 75}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:04,605]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:07,857]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:08,461]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:09,597]\u001b[0m Trial 910 finished with value: 8.173804123015378 and parameters: {'n_hidden': 3, 'learning_rate': 0.003607304688351898, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1701280326822399, 'dropout_rate_Layer_2': 0.1275642421808289, 'dropout_rate_Layer_3': 0.2431767544159217, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.966463229313126e-05, 'l1_Layer_2': 0.0027161877176809144, 'l1_Layer_3': 5.8629558213896355e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 195, 'n_units_Layer_3': 155}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.17 | sMAPE for Validation Set is: 14.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 17.13% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:29:17,305]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:17,853]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:20,942]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:23,707]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:25,207]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:29,496]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:33,894]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:35,284]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:37,174]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:40,683]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:42,984]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:47,290]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:51,521]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:52,173]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:29:59,387]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:30:00,596]\u001b[0m Trial 923 finished with value: 8.136105791523471 and parameters: {'n_hidden': 3, 'learning_rate': 0.0065785230870516395, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021685626036075656, 'dropout_rate_Layer_2': 0.009151420647681872, 'dropout_rate_Layer_3': 0.08212645966022974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00037124676632997207, 'l1_Layer_2': 0.04613992941351712, 'l1_Layer_3': 0.00037970657114705245, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 215}. Best is trial 802 with value: 7.744800147468596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.14 | sMAPE for Validation Set is: 14.89% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:30:05,820]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:30:14,169]\u001b[0m Trial 933 finished with value: 7.7413508840068985 and parameters: {'n_hidden': 3, 'learning_rate': 0.002217411905226285, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011751692676453738, 'dropout_rate_Layer_2': 0.19101675857163194, 'dropout_rate_Layer_3': 0.011276521553547247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005047931946985923, 'l1_Layer_2': 7.638547739530967e-05, 'l1_Layer_3': 0.00020467961179129114, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 140}. Best is trial 933 with value: 7.7413508840068985.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.74 | sMAPE for Validation Set is: 13.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.56% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:30:18,796]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.67 | sMAPE for Validation Set is: 13.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.65 | sMAPE for Test Set is: 16.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:30:22,574]\u001b[0m Trial 936 finished with value: 7.669999932212758 and parameters: {'n_hidden': 3, 'learning_rate': 0.002241804973987125, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010795162458886412, 'dropout_rate_Layer_2': 0.19521321712989004, 'dropout_rate_Layer_3': 0.010442328947918165, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006995658665372785, 'l1_Layer_2': 7.730786694049668e-05, 'l1_Layer_3': 0.0002696613512384638, 'n_units_Layer_1': 190, 'n_units_Layer_2': 110, 'n_units_Layer_3': 70}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:30:31,285]\u001b[0m Trial 934 finished with value: 7.8025350990464135 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022388328606502885, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008608125395372231, 'dropout_rate_Layer_2': 0.1937270838260157, 'dropout_rate_Layer_3': 0.009063634005127958, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006694624514885764, 'l1_Layer_2': 8.519349005744492e-05, 'l1_Layer_3': 0.0002919765628958801, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 85}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.80 | sMAPE for Validation Set is: 14.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 16.57% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:30:31,740]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:30:32,647]\u001b[0m Trial 937 finished with value: 7.786109968501539 and parameters: {'n_hidden': 3, 'learning_rate': 0.002271696994837499, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01258916385158245, 'dropout_rate_Layer_2': 0.21821564252956788, 'dropout_rate_Layer_3': 0.022404725738140938, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006373745114644325, 'l1_Layer_2': 7.423518239629383e-05, 'l1_Layer_3': 0.00042547448547837176, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 70}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.79 | sMAPE for Validation Set is: 14.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 16.41% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:30:39,324]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:30:42,925]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:30:43,509]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:30:43,651]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:30:52,383]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:30:53,289]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:30:53,629]\u001b[0m Trial 939 finished with value: 7.813315570958278 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021079307841013937, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011483644251018898, 'dropout_rate_Layer_2': 0.18974183549133222, 'dropout_rate_Layer_3': 0.011654250113301564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005424713168856234, 'l1_Layer_2': 7.676983255143605e-05, 'l1_Layer_3': 0.00021679423780619363, 'n_units_Layer_1': 190, 'n_units_Layer_2': 110, 'n_units_Layer_3': 90}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.81 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:30:53,821]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:03,416]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:03,504]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:05,225]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:07,528]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:09,910]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:11,031]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:20,323]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:21,740]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:26,955]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:30,995]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:34,465]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:34,711]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:40,715]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:41,852]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:46,360]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:49,972]\u001b[0m Trial 954 finished with value: 7.917798728854076 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013335654573331274, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16443450736136553, 'dropout_rate_Layer_2': 0.12300052718259133, 'dropout_rate_Layer_3': 0.27698114689671144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.4080386617577164e-05, 'l1_Layer_2': 0.0011225980453963653, 'l1_Layer_3': 3.828182675033228e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 175, 'n_units_Layer_3': 80}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.92 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 16.50% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:31:51,309]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:31:53,613]\u001b[0m Trial 959 finished with value: 7.78141491297681 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024586176605173628, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03391209413164295, 'dropout_rate_Layer_2': 0.1787003236256726, 'dropout_rate_Layer_3': 0.00983328388213732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006298057899064079, 'l1_Layer_2': 4.351703198165903e-05, 'l1_Layer_3': 0.00028101338435148704, 'n_units_Layer_1': 185, 'n_units_Layer_2': 110, 'n_units_Layer_3': 60}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.78 | sMAPE for Validation Set is: 14.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:31:59,400]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:32:00,200]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:32:07,297]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:32:20,042]\u001b[0m Trial 971 finished with value: 7.840496799621725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024790318396891112, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04533537802673683, 'dropout_rate_Layer_2': 0.17905975334322513, 'dropout_rate_Layer_3': 0.022768779120275993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006586603722432197, 'l1_Layer_2': 4.316226950148964e-05, 'l1_Layer_3': 0.0002795241422815979, 'n_units_Layer_1': 170, 'n_units_Layer_2': 110, 'n_units_Layer_3': 55}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.84 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 16.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:32:20,862]\u001b[0m Trial 966 finished with value: 7.75450669121254 and parameters: {'n_hidden': 3, 'learning_rate': 0.00239971594996712, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029421304387279145, 'dropout_rate_Layer_2': 0.17564027553168673, 'dropout_rate_Layer_3': 0.010201253962865286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000646486469255225, 'l1_Layer_2': 4.21934928977254e-05, 'l1_Layer_3': 0.0003905962589076958, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 60}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.75 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 16.87% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:32:27,039]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:32:30,395]\u001b[0m Trial 967 finished with value: 7.951104918378692 and parameters: {'n_hidden': 3, 'learning_rate': 0.004620602707973382, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020668802592899133, 'dropout_rate_Layer_2': 0.00014869956721802122, 'dropout_rate_Layer_3': 0.11563253780783508, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013712936672366353, 'l1_Layer_2': 0.022768594246967973, 'l1_Layer_3': 9.005492095013176e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.95 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 16.43% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:32:32,783]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:32:37,958]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:32:42,354]\u001b[0m Trial 973 finished with value: 8.195419969114734 and parameters: {'n_hidden': 3, 'learning_rate': 0.004641243940861601, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08518154120331445, 'dropout_rate_Layer_2': 0.00032398820742797485, 'dropout_rate_Layer_3': 0.06903964582366125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010097000054714825, 'l1_Layer_2': 0.022337793873870332, 'l1_Layer_3': 0.0002624018013072468, 'n_units_Layer_1': 265, 'n_units_Layer_2': 75, 'n_units_Layer_3': 155}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.20 | sMAPE for Validation Set is: 14.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 17.10% | rMAE for Test Set is: 0.68\n",
      "MAE for Validation Set is: 7.95 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 16.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:32:45,101]\u001b[0m Trial 972 finished with value: 7.954572387247779 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012667499458466572, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.174050031841952, 'dropout_rate_Layer_2': 0.11980279467827387, 'dropout_rate_Layer_3': 0.28801131937690894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009919278446178326, 'l1_Layer_2': 0.0012109493272112065, 'l1_Layer_3': 3.144193114943408e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 80}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:32:45,548]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:32:47,471]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:32:53,067]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:32:56,089]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:32:58,908]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:33:02,161]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:33:11,097]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:33:15,132]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:33:18,087]\u001b[0m Trial 981 finished with value: 7.800702496294204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018533693820253778, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023201101060726998, 'dropout_rate_Layer_2': 0.16710895924258878, 'dropout_rate_Layer_3': 0.011366395256287562, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041994614434937884, 'l1_Layer_2': 7.01164577949842e-05, 'l1_Layer_3': 0.0006918351147532436, 'n_units_Layer_1': 175, 'n_units_Layer_2': 85, 'n_units_Layer_3': 65}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.80 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.72 | sMAPE for Test Set is: 16.55% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:33:22,838]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:33:35,284]\u001b[0m Trial 986 finished with value: 7.8240772596639845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017717739949878798, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022740818031978423, 'dropout_rate_Layer_2': 0.17138706318266256, 'dropout_rate_Layer_3': 0.011930179740398691, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006484328889406581, 'l1_Layer_2': 3.2951866592583246e-05, 'l1_Layer_3': 0.0003893615204830477, 'n_units_Layer_1': 205, 'n_units_Layer_2': 100, 'n_units_Layer_3': 65}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.82 | sMAPE for Validation Set is: 14.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 16.90% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:33:35,709]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.77 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.67 | sMAPE for Test Set is: 16.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:33:38,445]\u001b[0m Trial 989 finished with value: 7.767366926718913 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018432933312265162, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02665413990420338, 'dropout_rate_Layer_2': 0.16678540288383284, 'dropout_rate_Layer_3': 0.02861045342787109, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00043940948437153066, 'l1_Layer_2': 6.580548514399923e-05, 'l1_Layer_3': 0.0003875521077583588, 'n_units_Layer_1': 155, 'n_units_Layer_2': 70, 'n_units_Layer_3': 65}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:33:44,466]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:33:46,100]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:33:51,458]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:33:55,768]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:33:57,921]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:01,101]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:01,754]\u001b[0m Trial 985 finished with value: 7.908380791097604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008607045128217392, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1799489843909507, 'dropout_rate_Layer_2': 0.08692449837141394, 'dropout_rate_Layer_3': 0.2851351606294257, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012622487052790836, 'l1_Layer_2': 0.000864055770234524, 'l1_Layer_3': 3.6244755872845e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 185, 'n_units_Layer_3': 85}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.91 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.63% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:34:07,630]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:10,269]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:10,835]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:12,446]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:12,810]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:24,363]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:31,049]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:32,964]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:38,450]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:38,688]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:46,153]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:47,384]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:54,041]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:58,517]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:58,903]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:34:59,745]\u001b[0m Trial 1007 finished with value: 7.803992571999465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023982638474657203, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00015416239124407642, 'dropout_rate_Layer_2': 0.1684651609404518, 'dropout_rate_Layer_3': 1.5164990125887332e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044061887636160366, 'l1_Layer_2': 8.62361075142859e-05, 'l1_Layer_3': 0.0007284106003890439, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 140}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.80 | sMAPE for Validation Set is: 14.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 16.57% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:35:03,119]\u001b[0m Trial 1003 finished with value: 7.994814671058229 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009808809621069494, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17775917201714145, 'dropout_rate_Layer_2': 0.0725443547923486, 'dropout_rate_Layer_3': 0.30601831073512953, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018087536002007432, 'l1_Layer_2': 0.001020118871977582, 'l1_Layer_3': 2.2841302449885046e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 60}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.99 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 17.02% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:35:08,594]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:35:12,720]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:35:15,746]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:35:22,870]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:35:31,483]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:35:38,247]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:35:44,351]\u001b[0m Trial 1019 finished with value: 7.6997409971244295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024520877258578204, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00018029834465025513, 'dropout_rate_Layer_2': 0.1676488490986506, 'dropout_rate_Layer_3': 0.0018119066860577508, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004564840926469834, 'l1_Layer_2': 7.606673329584157e-05, 'l1_Layer_3': 0.0008276244115727454, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 145}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:35:44,381]\u001b[0m Trial 1018 finished with value: 7.770650860766016 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024576470339834383, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005147082840170979, 'dropout_rate_Layer_2': 0.1645294190633216, 'dropout_rate_Layer_3': 0.0005210469805412843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004789370055579127, 'l1_Layer_2': 9.137491661482145e-05, 'l1_Layer_3': 0.0003579620805199404, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.70 | sMAPE for Validation Set is: 13.89% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 16.45% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 7.77 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 16.63% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:35:45,784]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:35:46,255]\u001b[0m Trial 1021 finished with value: 7.703437295972303 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026405632133777567, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001686198036127082, 'dropout_rate_Layer_2': 0.16389201467661582, 'dropout_rate_Layer_3': 0.005564843815477524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004633696064080272, 'l1_Layer_2': 9.01099642026159e-05, 'l1_Layer_3': 0.0002710040779977483, 'n_units_Layer_1': 155, 'n_units_Layer_2': 75, 'n_units_Layer_3': 140}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.70 | sMAPE for Validation Set is: 13.90% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 16.39% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:35:52,280]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:35:57,187]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:00,259]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:01,050]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:13,082]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:16,945]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:23,500]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:26,001]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:27,157]\u001b[0m Trial 1029 finished with value: 7.804602017677919 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027072455367498534, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008777240162925524, 'dropout_rate_Layer_2': 0.1736375977879747, 'dropout_rate_Layer_3': 0.0065075291365129075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000365533548326471, 'l1_Layer_2': 5.526085517962177e-05, 'l1_Layer_3': 0.0011421219256599023, 'n_units_Layer_1': 160, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.80 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 16.61% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:36:34,280]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:35,069]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:35,794]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:41,781]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:48,156]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:51,670]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:56,121]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:36:59,385]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:00,554]\u001b[0m Trial 1034 finished with value: 7.747389079836272 and parameters: {'n_hidden': 3, 'learning_rate': 0.002693532322708351, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007646967552194264, 'dropout_rate_Layer_2': 0.1746815245390865, 'dropout_rate_Layer_3': 0.005365950197141542, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00030558013184609634, 'l1_Layer_2': 4.0296899972717045e-05, 'l1_Layer_3': 0.0003532140310754423, 'n_units_Layer_1': 160, 'n_units_Layer_2': 75, 'n_units_Layer_3': 70}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.75 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 16.51% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:37:07,119]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:09,510]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:11,409]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:17,648]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:18,680]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:19,849]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:25,364]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:28,433]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:35,095]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:38,631]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:39,230]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:47,424]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:47,864]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:57,247]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:37:58,495]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:38:05,393]\u001b[0m Trial 1038 finished with value: 7.957085006090516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009311905639895055, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20183203080612264, 'dropout_rate_Layer_2': 0.08331717528815809, 'dropout_rate_Layer_3': 0.28191540097691054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.994902265103277e-05, 'l1_Layer_2': 0.0012439660307943822, 'l1_Layer_3': 2.5625750747093892e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 70}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.96 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:38:11,420]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:38:14,257]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:38:18,653]\u001b[0m Trial 1060 finished with value: 7.940096353054936 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021158920912979907, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017017109854196896, 'dropout_rate_Layer_2': 0.2020180116353108, 'dropout_rate_Layer_3': 0.01812005447163772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029749156046364044, 'l1_Layer_2': 2.520488344980688e-05, 'l1_Layer_3': 0.0002771526951875409, 'n_units_Layer_1': 155, 'n_units_Layer_2': 70, 'n_units_Layer_3': 100}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.94 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 16.67% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:38:23,586]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:38:29,632]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:38:33,267]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:38:39,839]\u001b[0m Trial 1062 finished with value: 7.771059537573234 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020892710531300184, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018933572620610413, 'dropout_rate_Layer_2': 0.2076094106487698, 'dropout_rate_Layer_3': 0.019185133834834923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004067399398306, 'l1_Layer_2': 9.1431907674128e-05, 'l1_Layer_3': 0.0002616464891568094, 'n_units_Layer_1': 165, 'n_units_Layer_2': 60, 'n_units_Layer_3': 60}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.77 | sMAPE for Validation Set is: 14.03% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 16.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:38:43,413]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:38:47,561]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:38:50,931]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:38:57,531]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:39:02,547]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:39:03,161]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:39:11,161]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:39:14,047]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:39:35,777]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:39:41,118]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:39:47,757]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:39:49,956]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:39:57,236]\u001b[0m Trial 1056 finished with value: 7.94743677653414 and parameters: {'n_hidden': 3, 'learning_rate': 0.002106185397159531, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018804735358099386, 'dropout_rate_Layer_2': 0.20007648013267199, 'dropout_rate_Layer_3': 0.018322930335987503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003167586055352879, 'l1_Layer_2': 9.584891429024197e-05, 'l1_Layer_3': 0.00018241505546131084, 'n_units_Layer_1': 165, 'n_units_Layer_2': 55, 'n_units_Layer_3': 105}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.95 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 16.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:39:59,881]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:03,945]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:06,499]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:11,769]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:11,962]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:17,088]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:19,406]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:23,511]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:27,496]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:28,786]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:33,775]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:33,977]\u001b[0m Trial 1079 finished with value: 7.8473688212630925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026574968662295283, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02211004639773282, 'dropout_rate_Layer_2': 0.21718535467807726, 'dropout_rate_Layer_3': 0.03099127425505068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004166299519830613, 'l1_Layer_2': 9.482119599896672e-05, 'l1_Layer_3': 0.00024570944856535504, 'n_units_Layer_1': 170, 'n_units_Layer_2': 60, 'n_units_Layer_3': 145}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.85 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 16.40% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:40:35,126]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:42,617]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:50,699]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:40:51,305]\u001b[0m Trial 1090 finished with value: 7.791959031707083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018416211627179766, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023059596848235824, 'dropout_rate_Layer_2': 0.14574965594396613, 'dropout_rate_Layer_3': 0.008260435398587179, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013524626063205806, 'l1_Layer_2': 5.5124119530588555e-05, 'l1_Layer_3': 0.00034216913948498175, 'n_units_Layer_1': 175, 'n_units_Layer_2': 75, 'n_units_Layer_3': 70}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.79 | sMAPE for Validation Set is: 14.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 16.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:40:59,607]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:01,293]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:04,255]\u001b[0m Trial 1094 finished with value: 7.724654880502371 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022240100200684593, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014672087966736603, 'dropout_rate_Layer_2': 0.18703745438179298, 'dropout_rate_Layer_3': 0.008670275994780343, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005837231453236711, 'l1_Layer_2': 7.911204637259901e-05, 'l1_Layer_3': 0.0002894821621033875, 'n_units_Layer_1': 155, 'n_units_Layer_2': 80, 'n_units_Layer_3': 80}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.72 | sMAPE for Validation Set is: 13.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.67 | sMAPE for Test Set is: 16.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:41:06,957]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:10,928]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:13,711]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:15,094]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:18,392]\u001b[0m Trial 1093 finished with value: 7.770679879961068 and parameters: {'n_hidden': 3, 'learning_rate': 0.002229174622211911, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010117257642368592, 'dropout_rate_Layer_2': 0.1865481810752462, 'dropout_rate_Layer_3': 0.0072949940971423375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014792002063438584, 'l1_Layer_2': 7.92096690874367e-05, 'l1_Layer_3': 0.0002998243181264648, 'n_units_Layer_1': 150, 'n_units_Layer_2': 95, 'n_units_Layer_3': 80}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.77 | sMAPE for Validation Set is: 14.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:41:20,013]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:21,720]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:26,585]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:30,090]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:31,590]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:35,710]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:41,108]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:42,009]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:44,827]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:51,003]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:54,722]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:41:58,074]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:01,788]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:05,637]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:10,350]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:12,028]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:17,375]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:17,437]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:19,792]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:27,150]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:29,210]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:29,617]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:32,725]\u001b[0m Trial 1109 finished with value: 8.063484854831376 and parameters: {'n_hidden': 3, 'learning_rate': 0.0056023716839143, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.050283769865548986, 'dropout_rate_Layer_2': 0.00834430410661809, 'dropout_rate_Layer_3': 0.11256068046876623, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011927870592497436, 'l1_Layer_2': 0.05783379122811137, 'l1_Layer_3': 0.000201176772448639, 'n_units_Layer_1': 255, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.06 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 16.62% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:42:33,276]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:45,485]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:48,022]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:48,166]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:42:53,117]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:01,401]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:03,174]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:04,559]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:05,689]\u001b[0m Trial 1127 finished with value: 7.898842147857341 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039515762159426536, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01390855315327632, 'dropout_rate_Layer_2': 0.16177726382754595, 'dropout_rate_Layer_3': 0.015347372647269873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.6521383117761755e-05, 'l1_Layer_2': 3.8088707564320955e-05, 'l1_Layer_3': 0.00016315259757934594, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 200}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.90 | sMAPE for Validation Set is: 14.27% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 16.97% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:43:14,274]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:17,873]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:21,977]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:30,692]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:33,204]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:37,827]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:40,444]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:42,527]\u001b[0m Trial 1136 finished with value: 7.725073753273466 and parameters: {'n_hidden': 3, 'learning_rate': 0.00208344834770525, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 1.1257413603416467e-05, 'dropout_rate_Layer_2': 0.2072298024506973, 'dropout_rate_Layer_3': 0.009899585914037466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012388981703564305, 'l1_Layer_2': 9.680510746837866e-05, 'l1_Layer_3': 0.0001967043680057705, 'n_units_Layer_1': 150, 'n_units_Layer_2': 70, 'n_units_Layer_3': 130}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.73 | sMAPE for Validation Set is: 13.94% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 16.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:43:52,346]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:54,814]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:56,832]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:43:57,832]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:44:03,998]\u001b[0m Trial 1141 finished with value: 7.732918711716459 and parameters: {'n_hidden': 3, 'learning_rate': 0.002075090899237697, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.038084604536419375, 'dropout_rate_Layer_2': 0.18514891634969005, 'dropout_rate_Layer_3': 0.008672996728200025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012698362013834926, 'l1_Layer_2': 9.453200395827336e-05, 'l1_Layer_3': 0.00030103543469656824, 'n_units_Layer_1': 160, 'n_units_Layer_2': 105, 'n_units_Layer_3': 75}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.73 | sMAPE for Validation Set is: 13.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 16.58% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:44:09,216]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:44:09,501]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:44:18,332]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:44:19,003]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:44:25,729]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.83 | sMAPE for Validation Set is: 14.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 16.44% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:44:29,911]\u001b[0m Trial 1148 finished with value: 7.83309022510074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020284653498819204, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007140850680973367, 'dropout_rate_Layer_2': 0.20611350489119518, 'dropout_rate_Layer_3': 0.008231442034649485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017575893190040134, 'l1_Layer_2': 9.825137175443102e-05, 'l1_Layer_3': 0.0003093117153820663, 'n_units_Layer_1': 150, 'n_units_Layer_2': 75, 'n_units_Layer_3': 125}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:44:31,125]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.76 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 16.47% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:44:34,527]\u001b[0m Trial 1150 finished with value: 7.762761942536694 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019590250042022667, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005681359597834869, 'dropout_rate_Layer_2': 0.20936683244116383, 'dropout_rate_Layer_3': 0.007267402388321325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000108633462952367, 'l1_Layer_2': 0.00010082114861383398, 'l1_Layer_3': 0.0003257968245170126, 'n_units_Layer_1': 150, 'n_units_Layer_2': 70, 'n_units_Layer_3': 130}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:44:35,782]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:44:44,317]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:44:45,042]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:44:45,251]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:44:45,998]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:44:58,384]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:03,994]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:08,455]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:09,363]\u001b[0m Trial 1161 finished with value: 8.289246095616503 and parameters: {'n_hidden': 3, 'learning_rate': 0.005604825416810695, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06798793983747455, 'dropout_rate_Layer_2': 0.007778469136496341, 'dropout_rate_Layer_3': 0.10986969470879945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1750416870953003e-05, 'l1_Layer_2': 0.07653745960596554, 'l1_Layer_3': 1.0163521163659914e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 55, 'n_units_Layer_3': 200}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.29 | sMAPE for Validation Set is: 15.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 17.34% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:45:14,654]\u001b[0m Trial 1163 finished with value: 7.811046830742054 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034338273160668693, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0010857584676646995, 'dropout_rate_Layer_2': 0.20999656095491948, 'dropout_rate_Layer_3': 0.024349412390913823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.041789897834988e-05, 'l1_Layer_2': 0.00011739632027778541, 'l1_Layer_3': 0.0002636206554931899, 'n_units_Layer_1': 150, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.81 | sMAPE for Validation Set is: 14.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:45:14,932]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:16,827]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:23,116]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:25,391]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:29,927]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:31,749]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:36,564]\u001b[0m Trial 1165 finished with value: 7.778822575023942 and parameters: {'n_hidden': 3, 'learning_rate': 0.003264206034075004, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0001868552112404276, 'dropout_rate_Layer_2': 0.20898924963719975, 'dropout_rate_Layer_3': 0.02494356561393626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.893126246852405e-05, 'l1_Layer_2': 0.00011766972906563585, 'l1_Layer_3': 0.0002656592545301361, 'n_units_Layer_1': 150, 'n_units_Layer_2': 60, 'n_units_Layer_3': 120}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.78 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 16.71% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:45:40,470]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:42,259]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.68 | sMAPE for Validation Set is: 13.90% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 16.21% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:45:44,557]\u001b[0m Trial 1168 finished with value: 7.684564679428187 and parameters: {'n_hidden': 3, 'learning_rate': 0.002754909090445273, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012828050320179852, 'dropout_rate_Layer_2': 0.20103030782010306, 'dropout_rate_Layer_3': 8.512957219553225e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010831165411069778, 'l1_Layer_2': 9.603563909858036e-05, 'l1_Layer_3': 0.0004271051094505221, 'n_units_Layer_1': 145, 'n_units_Layer_2': 95, 'n_units_Layer_3': 85}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:45,362]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:52,343]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:55,725]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:45:56,454]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:03,991]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:05,098]\u001b[0m Trial 1173 finished with value: 7.816613342180378 and parameters: {'n_hidden': 3, 'learning_rate': 0.002778758574917735, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029194727400501625, 'dropout_rate_Layer_2': 0.1947235360970096, 'dropout_rate_Layer_3': 0.00047940455129311804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011207861670877401, 'l1_Layer_2': 9.955453404643555e-05, 'l1_Layer_3': 0.0001886281503497197, 'n_units_Layer_1': 135, 'n_units_Layer_2': 50, 'n_units_Layer_3': 120}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.82 | sMAPE for Validation Set is: 14.05% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.67 | sMAPE for Test Set is: 16.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:46:12,593]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:12,759]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:19,992]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:20,977]\u001b[0m Trial 1180 finished with value: 7.830805991721554 and parameters: {'n_hidden': 3, 'learning_rate': 0.002782200419373775, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0007415593528013448, 'dropout_rate_Layer_2': 0.19666138869035743, 'dropout_rate_Layer_3': 0.00012378380840319132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010983917769330082, 'l1_Layer_2': 9.757453199950349e-05, 'l1_Layer_3': 0.00019568051690723614, 'n_units_Layer_1': 145, 'n_units_Layer_2': 65, 'n_units_Layer_3': 110}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.83 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 16.45% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:46:21,541]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:28,028]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:30,058]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:31,734]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:35,658]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:37,510]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:39,868]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:42,399]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:52,018]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:52,535]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:46:56,653]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.84 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 16.54% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:47:00,073]\u001b[0m Trial 1193 finished with value: 7.842571085849066 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025393514526938178, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013558559060601544, 'dropout_rate_Layer_2': 0.18424527220432274, 'dropout_rate_Layer_3': 0.03029797160950488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.50319460359473e-05, 'l1_Layer_2': 6.388509127077642e-05, 'l1_Layer_3': 0.00038278155402820407, 'n_units_Layer_1': 160, 'n_units_Layer_2': 85, 'n_units_Layer_3': 135}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:00,910]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:01,527]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:10,398]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:11,181]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:11,251]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:11,945]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:21,318]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:23,749]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:29,383]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:34,132]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:35,772]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:39,786]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:42,935]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:47,917]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:48,055]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:54,373]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:47:57,436]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:02,230]\u001b[0m Trial 1203 finished with value: 7.759845072748053 and parameters: {'n_hidden': 3, 'learning_rate': 0.002097776254220029, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013175452730458774, 'dropout_rate_Layer_2': 0.1864424184050262, 'dropout_rate_Layer_3': 0.015426281819513178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001811611304338588, 'l1_Layer_2': 0.00012045033498710858, 'l1_Layer_3': 0.0004949644731000853, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 80}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.76 | sMAPE for Validation Set is: 14.03% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:48:04,903]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:06,324]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:11,061]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:15,834]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:19,998]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:22,111]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:27,616]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:27,844]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:28,556]\u001b[0m Trial 1216 finished with value: 7.730953361148941 and parameters: {'n_hidden': 3, 'learning_rate': 0.002060847986495392, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01426154765986767, 'dropout_rate_Layer_2': 0.1872142060383648, 'dropout_rate_Layer_3': 0.01799472046086404, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018824951627360138, 'l1_Layer_2': 0.00012883918102953975, 'l1_Layer_3': 0.00031787109437710694, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 80}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.73 | sMAPE for Validation Set is: 13.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 16.43% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:48:35,870]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:37,905]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:38,369]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:42,189]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:42,459]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:48,598]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:49,270]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:54,340]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:55,766]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:48:59,083]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:03,508]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:03,908]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:07,414]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:09,029]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:16,838]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:20,626]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:23,911]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:25,314]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:25,437]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:30,927]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:33,877]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:35,018]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:37,482]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:41,125]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:48,845]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:49,682]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:49:55,470]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:00,888]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:05,656]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:06,282]\u001b[0m Trial 1249 finished with value: 8.045140624747818 and parameters: {'n_hidden': 3, 'learning_rate': 0.003958212641880642, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23356229017607164, 'dropout_rate_Layer_2': 0.10374913453785545, 'dropout_rate_Layer_3': 0.278501919489479, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9384214574017397e-05, 'l1_Layer_2': 0.001291004591543516, 'l1_Layer_3': 7.150854871754163e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 215, 'n_units_Layer_3': 75}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.05 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 17.02% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:50:10,854]\u001b[0m Trial 1252 finished with value: 7.730151322309754 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017936644369624993, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008361175642160585, 'dropout_rate_Layer_2': 0.16144072132186638, 'dropout_rate_Layer_3': 7.530595097015279e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001237582455974455, 'l1_Layer_2': 9.288290466036391e-05, 'l1_Layer_3': 0.00036438740675527994, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 175}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.73 | sMAPE for Validation Set is: 13.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.66 | sMAPE for Test Set is: 16.31% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:50:12,472]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:12,645]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:16,856]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:17,835]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:27,962]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:31,599]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:31,914]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:34,136]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:38,490]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:39,123]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:44,890]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:47,798]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:49,955]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:50,287]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:50:52,918]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:03,125]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:04,431]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:05,443]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:12,094]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:15,456]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:16,941]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:24,114]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:24,491]\u001b[0m Trial 1270 finished with value: 7.731860043607388 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018045055118817619, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011058534028138021, 'dropout_rate_Layer_2': 0.15644049263914284, 'dropout_rate_Layer_3': 0.0005009545021120894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.822085275292531e-05, 'l1_Layer_2': 8.395484132432706e-05, 'l1_Layer_3': 0.00037817835132653504, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 185}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.73 | sMAPE for Validation Set is: 13.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:51:31,491]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:33,691]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:40,371]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:44,832]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.69 | sMAPE for Validation Set is: 13.89% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 16.44% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:51:48,218]\u001b[0m Trial 1280 finished with value: 7.686093497160871 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019873317937237466, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007989144144455422, 'dropout_rate_Layer_2': 0.15757450692767347, 'dropout_rate_Layer_3': 0.0031847847517191626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001292397180042569, 'l1_Layer_2': 9.179382879483575e-05, 'l1_Layer_3': 0.00040318989161079814, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 165}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:50,334]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:51:51,754]\u001b[0m Trial 1277 finished with value: 7.818412283816596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018893242244467827, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008195672416115555, 'dropout_rate_Layer_2': 0.1621215234766471, 'dropout_rate_Layer_3': 0.005194170641637758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.508122722587953e-05, 'l1_Layer_2': 9.827150690735047e-05, 'l1_Layer_3': 0.00039162403226522085, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.82 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 16.20% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:51:54,924]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:00,003]\u001b[0m Trial 1282 finished with value: 7.782434541646329 and parameters: {'n_hidden': 3, 'learning_rate': 0.001930733698485876, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010075024420817815, 'dropout_rate_Layer_2': 0.15511029452645558, 'dropout_rate_Layer_3': 0.0015886824549150736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016668696174985191, 'l1_Layer_2': 8.996861977991957e-05, 'l1_Layer_3': 0.0004550351303263236, 'n_units_Layer_1': 165, 'n_units_Layer_2': 95, 'n_units_Layer_3': 175}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.78 | sMAPE for Validation Set is: 14.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.64% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:52:02,933]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:05,308]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:09,675]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:12,427]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:15,498]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:19,670]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:23,686]\u001b[0m Trial 1287 finished with value: 8.300820536276037 and parameters: {'n_hidden': 3, 'learning_rate': 0.005411669432648246, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13759250004050208, 'dropout_rate_Layer_2': 0.026235511101434218, 'dropout_rate_Layer_3': 0.05347093346775528, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.5729373710579426e-05, 'l1_Layer_2': 0.0836736865282433, 'l1_Layer_3': 0.00019802599664098228, 'n_units_Layer_1': 220, 'n_units_Layer_2': 80, 'n_units_Layer_3': 230}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 15.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 17.27% | rMAE for Test Set is: 0.69\n",
      "MAE for Validation Set is: 7.72 | sMAPE for Validation Set is: 13.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 16.36% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:52:25,923]\u001b[0m Trial 1288 finished with value: 7.717617782405415 and parameters: {'n_hidden': 3, 'learning_rate': 0.001634308142265157, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007904859068339033, 'dropout_rate_Layer_2': 0.15441080332714147, 'dropout_rate_Layer_3': 0.0018195201549709127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011806257314476407, 'l1_Layer_2': 7.570299252093076e-05, 'l1_Layer_3': 0.00038501102841869745, 'n_units_Layer_1': 160, 'n_units_Layer_2': 95, 'n_units_Layer_3': 180}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:30,219]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:32,630]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:37,243]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:38,343]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:44,143]\u001b[0m Trial 1295 finished with value: 8.152299463247232 and parameters: {'n_hidden': 3, 'learning_rate': 0.003874498825190371, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1831367850278618, 'dropout_rate_Layer_2': 0.09281462784855835, 'dropout_rate_Layer_3': 0.27097108059504177, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5499960936935822e-05, 'l1_Layer_2': 0.0007066617130995736, 'l1_Layer_3': 5.257579466683519e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 220, 'n_units_Layer_3': 80}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.15 | sMAPE for Validation Set is: 14.82% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 18.06% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:52:47,537]\u001b[0m Trial 1296 finished with value: 7.7842270423713344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016271565472662703, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019228807661392962, 'dropout_rate_Layer_2': 0.1634490399549667, 'dropout_rate_Layer_3': 0.0003212260273696884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011597445183819275, 'l1_Layer_2': 7.075945278579823e-05, 'l1_Layer_3': 0.00047365903891096275, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 180}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.78 | sMAPE for Validation Set is: 14.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 16.51% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:52:48,617]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:50,981]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:52:56,113]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:00,574]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:05,761]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:06,169]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:07,506]\u001b[0m Trial 1301 finished with value: 7.784197778026929 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015992052803263978, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018439287081542678, 'dropout_rate_Layer_2': 0.1490371124326137, 'dropout_rate_Layer_3': 0.0014152602623340605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000123535667263768, 'l1_Layer_2': 6.531441563186045e-05, 'l1_Layer_3': 0.00047419355638866055, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 175}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.78 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 16.39% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:53:08,359]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:15,739]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:18,571]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:25,677]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:26,516]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:27,875]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:33,025]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:35,567]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:39,896]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:44,299]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:48,297]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:49,212]\u001b[0m Trial 1313 finished with value: 7.716028291770645 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017750869006055994, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007010551890122622, 'dropout_rate_Layer_2': 0.15521063330183882, 'dropout_rate_Layer_3': 0.01109085658101873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014585404713524078, 'l1_Layer_2': 8.078756081580877e-05, 'l1_Layer_3': 0.0003669685574218305, 'n_units_Layer_1': 145, 'n_units_Layer_2': 95, 'n_units_Layer_3': 190}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.72 | sMAPE for Validation Set is: 13.89% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 16.51% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:53:53,558]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:53:57,204]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:00,813]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:03,506]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:06,728]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:10,607]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:13,986]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:17,706]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:20,969]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:24,616]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:27,453]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:29,204]\u001b[0m Trial 1326 finished with value: 7.718597323579274 and parameters: {'n_hidden': 3, 'learning_rate': 0.001835537207521286, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009106523625529397, 'dropout_rate_Layer_2': 0.16025443839056194, 'dropout_rate_Layer_3': 0.012659777134818709, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5019580772559127e-05, 'l1_Layer_2': 8.072157336693855e-05, 'l1_Layer_3': 0.0003388326890957594, 'n_units_Layer_1': 135, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.72 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.66 | sMAPE for Test Set is: 16.30% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 8.01 | sMAPE for Validation Set is: 14.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.24% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:54:31,417]\u001b[0m Trial 1324 finished with value: 8.005174464380275 and parameters: {'n_hidden': 3, 'learning_rate': 0.008195188293112355, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009706779496745827, 'dropout_rate_Layer_2': 0.03553698879941031, 'dropout_rate_Layer_3': 0.1129118411098409, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008904815825278964, 'l1_Layer_2': 0.04357258436832714, 'l1_Layer_3': 9.472810082688152e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 125, 'n_units_Layer_3': 215}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:32,949]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:39,274]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:41,876]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:42,936]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:43,117]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:47,497]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:50,824]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:54,053]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:54:55,860]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:55:02,428]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:55:02,972]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:55:03,513]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:55:12,342]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:55:17,165]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:55:20,974]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:55:24,155]\u001b[0m Trial 1341 finished with value: 8.25443401512487 and parameters: {'n_hidden': 3, 'learning_rate': 0.004549930931254466, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1743631854914332, 'dropout_rate_Layer_2': 0.09594890969081328, 'dropout_rate_Layer_3': 0.28371635800853695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4743573423335287e-05, 'l1_Layer_2': 0.0008976025719778909, 'l1_Layer_3': 6.851759071719094e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 220, 'n_units_Layer_3': 85}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.25 | sMAPE for Validation Set is: 14.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 17.53% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:55:27,253]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:55:27,493]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:55:36,372]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:55:41,008]\u001b[0m Trial 1348 finished with value: 8.003486610773113 and parameters: {'n_hidden': 3, 'learning_rate': 0.007144392862436693, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024070877670766905, 'dropout_rate_Layer_2': 7.692984217319999e-05, 'dropout_rate_Layer_3': 0.029143260633042865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013235243914313823, 'l1_Layer_2': 0.04805108459506718, 'l1_Layer_3': 0.0002672433204142063, 'n_units_Layer_1': 210, 'n_units_Layer_2': 145, 'n_units_Layer_3': 230}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.00 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 16.86% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:55:45,078]\u001b[0m Trial 1352 finished with value: 7.817122585209611 and parameters: {'n_hidden': 3, 'learning_rate': 0.001752323276776343, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027521213770222184, 'dropout_rate_Layer_2': 0.15913556301313816, 'dropout_rate_Layer_3': 0.01350554070806249, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013464000631961676, 'l1_Layer_2': 0.00010433143138136885, 'l1_Layer_3': 0.0003467341444731511, 'n_units_Layer_1': 150, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.82 | sMAPE for Validation Set is: 14.14% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.73% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:55:45,911]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:55:52,256]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.80 | sMAPE for Validation Set is: 14.06% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.52% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:55:55,174]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:55:55,209]\u001b[0m Trial 1354 finished with value: 7.800973004904097 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018042869523092345, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007807799166286003, 'dropout_rate_Layer_2': 0.15755873215349614, 'dropout_rate_Layer_3': 0.01666067517235004, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8453308837045497e-05, 'l1_Layer_2': 0.00011176614236285046, 'l1_Layer_3': 0.00037833918794688684, 'n_units_Layer_1': 130, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:03,613]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:03,740]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:15,123]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:16,213]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:23,083]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:24,640]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:24,825]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:27,724]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:35,630]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:36,655]\u001b[0m Trial 1357 finished with value: 7.816522848472917 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018299725771975292, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006823683413851934, 'dropout_rate_Layer_2': 0.1703530789161034, 'dropout_rate_Layer_3': 0.01441322744766007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9153529124797198e-05, 'l1_Layer_2': 0.00014375390462208605, 'l1_Layer_3': 0.0008658310142140306, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 170}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.82 | sMAPE for Validation Set is: 14.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:56:39,742]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:40,132]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:46,179]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:48,574]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:49,527]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:50,035]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:56:56,322]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:00,409]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:02,346]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:05,134]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:13,277]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:15,690]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:19,189]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:23,937]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:24,468]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:29,951]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:30,348]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:31,543]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:38,593]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:39,563]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:41,012]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:49,228]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:50,001]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:54,799]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:55,697]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:56,656]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:57:59,536]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:02,746]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:05,328]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:07,822]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:13,743]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:15,226]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:16,904]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:17,470]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:25,419]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:26,012]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:34,216]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:34,385]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:36,280]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:36,417]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:45,395]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:47,443]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:50,658]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:58:50,733]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:01,101]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:08,739]\u001b[0m Trial 1413 finished with value: 8.21598812724847 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030048643184964366, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20836277982302248, 'dropout_rate_Layer_2': 0.06614948473041271, 'dropout_rate_Layer_3': 0.2653058751794857, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.927627032789031e-05, 'l1_Layer_2': 0.0005588968275537188, 'l1_Layer_3': 3.9033245371590875e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 225, 'n_units_Layer_3': 260}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.22 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 16.81% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:59:13,129]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.81 | sMAPE for Validation Set is: 14.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.72 | sMAPE for Test Set is: 16.46% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:59:16,631]\u001b[0m Trial 1415 finished with value: 7.814474893291126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021389684996390127, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014779866643521782, 'dropout_rate_Layer_2': 0.16405896715470406, 'dropout_rate_Layer_3': 0.0001378292338860762, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.3175339129671495e-05, 'l1_Layer_2': 9.215584353442234e-05, 'l1_Layer_3': 0.0004494114327585152, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 180}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.86 | sMAPE for Validation Set is: 14.12% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 16.63% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:59:17,215]\u001b[0m Trial 1412 finished with value: 7.863818717065027 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021711720510255907, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014476966228564425, 'dropout_rate_Layer_2': 0.12901547963643545, 'dropout_rate_Layer_3': 0.00023949372270262552, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013174611788992433, 'l1_Layer_2': 9.576680284226323e-05, 'l1_Layer_3': 0.0004101373871283443, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 180}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:20,224]\u001b[0m Trial 1416 finished with value: 7.783247167402585 and parameters: {'n_hidden': 3, 'learning_rate': 0.002166824517790173, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013995250716034259, 'dropout_rate_Layer_2': 0.16637950062505225, 'dropout_rate_Layer_3': 0.0012828916405194894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.490123624819566e-05, 'l1_Layer_2': 8.990606815675149e-05, 'l1_Layer_3': 0.000401903638030721, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 185}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.78 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.72 | sMAPE for Test Set is: 16.50% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 00:59:24,235]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:25,873]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:32,822]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:36,016]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:36,656]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:37,925]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:38,436]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:46,493]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:47,514]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:49,174]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:57,114]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:57,336]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 00:59:59,559]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:06,266]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:07,006]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:08,440]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:16,279]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:20,866]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:20,975]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:27,906]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:29,034]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:33,863]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:38,368]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:43,242]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:44,443]\u001b[0m Trial 1436 finished with value: 8.10088733493727 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025960007597694125, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20108540695333857, 'dropout_rate_Layer_2': 0.10973950298539775, 'dropout_rate_Layer_3': 0.24137550834328356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017459466082038273, 'l1_Layer_2': 0.0006410423908957401, 'l1_Layer_3': 5.832098635465388e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 195, 'n_units_Layer_3': 70}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.10 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 16.95% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 01:00:47,908]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:55,158]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:00:58,463]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:00,078]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:06,635]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:10,776]\u001b[0m Trial 1445 finished with value: 7.720209908068068 and parameters: {'n_hidden': 3, 'learning_rate': 0.00197148941026681, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004448922442297528, 'dropout_rate_Layer_2': 0.1611685020017198, 'dropout_rate_Layer_3': 0.013866535165681638, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001627830537787031, 'l1_Layer_2': 5.549620310499674e-05, 'l1_Layer_3': 0.00022039050002395523, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 210}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.72 | sMAPE for Validation Set is: 13.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.73% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 01:01:11,990]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.79 | sMAPE for Validation Set is: 14.00% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 16.50% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 01:01:16,261]\u001b[0m Trial 1447 finished with value: 7.787961159675926 and parameters: {'n_hidden': 3, 'learning_rate': 0.002328418653610093, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00023158480012798466, 'dropout_rate_Layer_2': 0.1609798418719326, 'dropout_rate_Layer_3': 0.011914424549603215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015647804998152151, 'l1_Layer_2': 5.724498944527494e-05, 'l1_Layer_3': 0.0002091469789322973, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 75}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:18,772]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:24,233]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:24,713]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:26,453]\u001b[0m Trial 1449 finished with value: 7.858912665666371 and parameters: {'n_hidden': 3, 'learning_rate': 0.002271980776826684, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01902279465410828, 'dropout_rate_Layer_2': 0.1952196135760526, 'dropout_rate_Layer_3': 0.02082028502796934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015442962655371978, 'l1_Layer_2': 0.00010248801517310612, 'l1_Layer_3': 0.00023365066005214867, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 150}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.86 | sMAPE for Validation Set is: 14.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 16.78% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 01:01:34,349]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:36,217]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:38,846]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:39,618]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.75 | sMAPE for Validation Set is: 13.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 16.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 01:01:41,422]\u001b[0m Trial 1452 finished with value: 7.745701888912883 and parameters: {'n_hidden': 3, 'learning_rate': 0.001707924131826964, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017698710094421193, 'dropout_rate_Layer_2': 0.19251375239133806, 'dropout_rate_Layer_3': 0.02389348718700271, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014501405535960308, 'l1_Layer_2': 5.3952312433150357e-05, 'l1_Layer_3': 0.00022027617242801286, 'n_units_Layer_1': 165, 'n_units_Layer_2': 100, 'n_units_Layer_3': 205}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:51,307]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:51,715]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:56,043]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:58,958]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:01:59,586]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:05,246]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:07,867]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:08,678]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:08,695]\u001b[0m Trial 1460 finished with value: 7.77575939705918 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017106298345011279, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009935492812876728, 'dropout_rate_Layer_2': 0.19144829679648878, 'dropout_rate_Layer_3': 0.008287409999684166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001167451132294552, 'l1_Layer_2': 6.817542549352372e-05, 'l1_Layer_3': 0.00028350147089342595, 'n_units_Layer_1': 135, 'n_units_Layer_2': 100, 'n_units_Layer_3': 75}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.78 | sMAPE for Validation Set is: 13.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.67 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 01:02:15,646]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:20,971]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:21,573]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:26,403]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:31,866]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:32,636]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:38,955]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:39,742]\u001b[0m Trial 1471 finished with value: 7.743210228350797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018892689900078736, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013359646776803152, 'dropout_rate_Layer_2': 0.17233004948565417, 'dropout_rate_Layer_3': 0.0279256081725128, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018679508951723, 'l1_Layer_2': 4.0554205070931e-05, 'l1_Layer_3': 0.0005141254118132451, 'n_units_Layer_1': 170, 'n_units_Layer_2': 115, 'n_units_Layer_3': 185}. Best is trial 936 with value: 7.669999932212758.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.74 | sMAPE for Validation Set is: 13.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 16.52% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 01:02:40,523]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:48,499]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:49,590]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:54,573]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:56,222]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:02:56,600]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:02,362]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:06,089]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:09,040]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:10,113]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:11,335]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:14,458]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:22,316]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:23,741]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:25,578]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:29,295]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:35,226]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:36,160]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:41,470]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:44,573]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:45,578]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:46,307]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 01:03:49,233]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-01-01, MAE is:16.17 & sMAPE is:29.68% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :16.17 & 29.68% & 1.10\n",
      "for 2019-01-02, MAE is:9.07 & sMAPE is:16.35% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :12.62 & 23.01% & 1.08\n",
      "for 2019-01-03, MAE is:4.70 & sMAPE is:8.23% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :9.98 & 18.09% & 1.27\n",
      "for 2019-01-04, MAE is:12.11 & sMAPE is:19.24% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 18.37% & 1.28\n",
      "for 2019-01-05, MAE is:9.54 & sMAPE is:16.71% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 18.04% & 1.27\n",
      "for 2019-01-06, MAE is:3.80 & sMAPE is:7.46% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.23 & 16.28% & 1.17\n",
      "for 2019-01-07, MAE is:9.00 & sMAPE is:15.73% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :9.20 & 16.20% & 1.22\n",
      "for 2019-01-08, MAE is:8.68 & sMAPE is:16.77% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.13 & 16.27% & 1.15\n",
      "for 2019-01-09, MAE is:6.92 & sMAPE is:12.34% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 15.83% & 1.11\n",
      "for 2019-01-10, MAE is:15.89 & sMAPE is:26.14% & rMAE is:2.50 ||| daily mean of MAE & sMAPE & rMAE till now are :9.59 & 16.86% & 1.25\n",
      "for 2019-01-11, MAE is:6.76 & sMAPE is:12.08% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 16.43% & 1.20\n",
      "for 2019-01-12, MAE is:6.97 & sMAPE is:13.13% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :9.13 & 16.15% & 1.17\n",
      "for 2019-01-13, MAE is:5.00 & sMAPE is:12.17% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 15.85% & 1.12\n",
      "for 2019-01-14, MAE is:7.68 & sMAPE is:14.49% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.74 & 15.75% & 1.09\n",
      "for 2019-01-15, MAE is:6.14 & sMAPE is:11.60% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 15.47% & 1.09\n",
      "for 2019-01-16, MAE is:5.97 & sMAPE is:12.17% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 15.27% & 1.08\n",
      "for 2019-01-17, MAE is:6.58 & sMAPE is:12.82% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.29 & 15.12% & 1.05\n",
      "for 2019-01-18, MAE is:15.91 & sMAPE is:28.74% & rMAE is:2.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 15.88% & 1.12\n",
      "for 2019-01-19, MAE is:8.01 & sMAPE is:15.15% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 15.84% & 1.13\n",
      "for 2019-01-20, MAE is:5.86 & sMAPE is:11.17% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 15.61% & 1.09\n",
      "for 2019-01-21, MAE is:8.81 & sMAPE is:13.75% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.55 & 15.52% & 1.07\n",
      "for 2019-01-22, MAE is:11.75 & sMAPE is:17.19% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.70 & 15.60% & 1.05\n",
      "for 2019-01-23, MAE is:8.38 & sMAPE is:11.25% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 15.41% & 1.02\n",
      "for 2019-01-24, MAE is:20.25 & sMAPE is:25.26% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 15.82% & 1.00\n",
      "for 2019-01-25, MAE is:9.21 & sMAPE is:13.97% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 15.74% & 1.02\n",
      "for 2019-01-26, MAE is:5.18 & sMAPE is:10.12% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.01 & 15.53% & 1.00\n",
      "for 2019-01-27, MAE is:4.54 & sMAPE is:12.66% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.85 & 15.42% & 0.98\n",
      "for 2019-01-28, MAE is:8.12 & sMAPE is:16.38% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 15.46% & 0.96\n",
      "for 2019-01-29, MAE is:7.68 & sMAPE is:13.68% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.78 & 15.39% & 0.95\n",
      "for 2019-01-30, MAE is:3.95 & sMAPE is:6.34% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.62 & 15.09% & 0.93\n",
      "for 2019-01-31, MAE is:5.12 & sMAPE is:8.78% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 14.89% & 0.91\n",
      "for 2019-02-01, MAE is:7.73 & sMAPE is:13.30% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 14.84% & 0.90\n",
      "for 2019-02-02, MAE is:3.01 & sMAPE is:6.15% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 14.58% & 0.90\n",
      "for 2019-02-03, MAE is:7.63 & sMAPE is:17.09% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :8.30 & 14.65% & 0.91\n",
      "for 2019-02-04, MAE is:4.45 & sMAPE is:8.42% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 14.47% & 0.91\n",
      "for 2019-02-05, MAE is:4.66 & sMAPE is:8.71% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 14.31% & 0.91\n",
      "for 2019-02-06, MAE is:4.02 & sMAPE is:8.03% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 14.14% & 0.90\n",
      "for 2019-02-07, MAE is:5.74 & sMAPE is:11.22% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 14.06% & 0.89\n",
      "for 2019-02-08, MAE is:3.89 & sMAPE is:8.19% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 13.91% & 0.87\n",
      "for 2019-02-09, MAE is:6.29 & sMAPE is:17.28% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 14.00% & 0.86\n",
      "for 2019-02-10, MAE is:3.89 & sMAPE is:12.32% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 13.96% & 0.85\n",
      "for 2019-02-11, MAE is:17.77 & sMAPE is:37.61% & rMAE is:3.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 14.52% & 0.91\n",
      "for 2019-02-12, MAE is:6.22 & sMAPE is:11.23% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 14.44% & 0.91\n",
      "for 2019-02-13, MAE is:4.96 & sMAPE is:10.86% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 14.36% & 0.92\n",
      "for 2019-02-14, MAE is:6.20 & sMAPE is:13.32% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 14.34% & 0.94\n",
      "for 2019-02-15, MAE is:6.14 & sMAPE is:13.80% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 14.33% & 0.95\n",
      "for 2019-02-16, MAE is:7.35 & sMAPE is:17.33% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 14.39% & 0.95\n",
      "for 2019-02-17, MAE is:4.69 & sMAPE is:12.89% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 14.36% & 0.94\n",
      "for 2019-02-18, MAE is:6.14 & sMAPE is:14.30% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 14.36% & 0.93\n",
      "for 2019-02-19, MAE is:4.34 & sMAPE is:10.00% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 14.27% & 0.93\n",
      "for 2019-02-20, MAE is:4.65 & sMAPE is:10.54% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 14.20% & 0.94\n",
      "for 2019-02-21, MAE is:4.24 & sMAPE is:9.20% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 14.10% & 0.95\n",
      "for 2019-02-22, MAE is:4.96 & sMAPE is:11.07% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 14.05% & 0.96\n",
      "for 2019-02-23, MAE is:4.91 & sMAPE is:12.31% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 14.01% & 0.96\n",
      "for 2019-02-24, MAE is:5.02 & sMAPE is:13.26% & rMAE is:2.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 14.00% & 1.00\n",
      "for 2019-02-25, MAE is:8.25 & sMAPE is:17.14% & rMAE is:3.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 14.06% & 1.04\n",
      "for 2019-02-26, MAE is:5.78 & sMAPE is:13.06% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 14.04% & 1.06\n",
      "for 2019-02-27, MAE is:7.01 & sMAPE is:15.75% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 14.07% & 1.07\n",
      "for 2019-02-28, MAE is:5.74 & sMAPE is:13.21% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 14.05% & 1.07\n",
      "for 2019-03-01, MAE is:6.08 & sMAPE is:14.68% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 14.06% & 1.09\n",
      "for 2019-03-02, MAE is:6.43 & sMAPE is:16.45% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 14.10% & 1.09\n",
      "for 2019-03-03, MAE is:9.90 & sMAPE is:43.05% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 14.57% & 1.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-04, MAE is:8.64 & sMAPE is:27.93% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 14.78% & 1.08\n",
      "for 2019-03-05, MAE is:5.56 & sMAPE is:13.09% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 14.76% & 1.08\n",
      "for 2019-03-06, MAE is:5.99 & sMAPE is:15.18% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 14.76% & 1.08\n",
      "for 2019-03-07, MAE is:4.65 & sMAPE is:11.73% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 14.72% & 1.07\n",
      "for 2019-03-08, MAE is:6.87 & sMAPE is:15.51% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 14.73% & 1.07\n",
      "for 2019-03-09, MAE is:4.64 & sMAPE is:14.50% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 14.72% & 1.06\n",
      "for 2019-03-10, MAE is:10.55 & sMAPE is:29.20% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 14.93% & 1.05\n",
      "for 2019-03-11, MAE is:5.50 & sMAPE is:14.18% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 14.92% & 1.05\n",
      "for 2019-03-12, MAE is:5.55 & sMAPE is:13.83% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 14.91% & 1.04\n",
      "for 2019-03-13, MAE is:7.64 & sMAPE is:22.19% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 15.01% & 1.04\n",
      "for 2019-03-14, MAE is:7.42 & sMAPE is:22.03% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 15.11% & 1.06\n",
      "for 2019-03-15, MAE is:4.50 & sMAPE is:13.15% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 15.08% & 1.05\n",
      "for 2019-03-16, MAE is:6.28 & sMAPE is:21.95% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 15.17% & 1.05\n",
      "for 2019-03-17, MAE is:13.76 & sMAPE is:95.35% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 16.23% & 1.04\n",
      "for 2019-03-18, MAE is:13.80 & sMAPE is:35.61% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 16.48% & 1.06\n",
      "for 2019-03-19, MAE is:5.78 & sMAPE is:13.89% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 16.44% & 1.06\n",
      "for 2019-03-20, MAE is:6.05 & sMAPE is:15.26% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 16.43% & 1.06\n",
      "for 2019-03-21, MAE is:5.07 & sMAPE is:12.68% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 16.38% & 1.06\n",
      "for 2019-03-22, MAE is:6.27 & sMAPE is:17.07% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 16.39% & 1.06\n",
      "for 2019-03-23, MAE is:5.33 & sMAPE is:16.09% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 16.39% & 1.05\n",
      "for 2019-03-24, MAE is:5.30 & sMAPE is:17.07% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 16.39% & 1.04\n",
      "for 2019-03-25, MAE is:4.30 & sMAPE is:12.84% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 16.35% & 1.03\n",
      "for 2019-03-26, MAE is:4.37 & sMAPE is:11.96% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 16.30% & 1.03\n",
      "for 2019-03-27, MAE is:4.34 & sMAPE is:10.96% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 16.24% & 1.03\n",
      "for 2019-03-28, MAE is:5.47 & sMAPE is:14.06% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 16.21% & 1.04\n",
      "for 2019-03-29, MAE is:5.77 & sMAPE is:14.66% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 16.20% & 1.06\n",
      "for 2019-03-30, MAE is:4.86 & sMAPE is:14.12% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 16.17% & 1.08\n",
      "for 2019-03-31, MAE is:5.76 & sMAPE is:21.36% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 16.23% & 1.08\n",
      "for 2019-04-01, MAE is:4.95 & sMAPE is:14.67% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 16.21% & 1.08\n",
      "for 2019-04-02, MAE is:5.53 & sMAPE is:16.33% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 16.21% & 1.08\n",
      "for 2019-04-03, MAE is:7.16 & sMAPE is:18.02% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 16.23% & 1.09\n",
      "for 2019-04-04, MAE is:5.31 & sMAPE is:12.70% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 16.20% & 1.10\n",
      "for 2019-04-05, MAE is:7.62 & sMAPE is:19.79% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 16.23% & 1.10\n",
      "for 2019-04-06, MAE is:6.77 & sMAPE is:19.06% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 16.26% & 1.10\n",
      "for 2019-04-07, MAE is:9.56 & sMAPE is:29.07% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 16.40% & 1.10\n",
      "for 2019-04-08, MAE is:5.38 & sMAPE is:12.92% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 16.36% & 1.10\n",
      "for 2019-04-09, MAE is:3.93 & sMAPE is:8.97% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 16.29% & 1.10\n",
      "for 2019-04-10, MAE is:5.05 & sMAPE is:12.28% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 16.25% & 1.10\n",
      "for 2019-04-11, MAE is:5.97 & sMAPE is:14.54% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 16.23% & 1.10\n",
      "for 2019-04-12, MAE is:6.09 & sMAPE is:14.81% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 16.21% & 1.12\n",
      "for 2019-04-13, MAE is:5.23 & sMAPE is:13.85% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 16.19% & 1.12\n",
      "for 2019-04-14, MAE is:6.63 & sMAPE is:18.16% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 16.21% & 1.14\n",
      "for 2019-04-15, MAE is:6.53 & sMAPE is:15.04% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 16.20% & 1.14\n",
      "for 2019-04-16, MAE is:5.77 & sMAPE is:14.32% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 16.18% & 1.15\n",
      "for 2019-04-17, MAE is:3.72 & sMAPE is:9.24% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 16.12% & 1.15\n",
      "for 2019-04-18, MAE is:6.37 & sMAPE is:16.35% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 16.12% & 1.16\n",
      "for 2019-04-19, MAE is:3.94 & sMAPE is:11.30% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 16.07% & 1.15\n",
      "for 2019-04-20, MAE is:4.64 & sMAPE is:15.68% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 16.07% & 1.15\n",
      "for 2019-04-21, MAE is:5.70 & sMAPE is:23.64% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 16.14% & 1.14\n",
      "for 2019-04-22, MAE is:24.24 & sMAPE is:100.26% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 16.89% & 1.14\n",
      "for 2019-04-23, MAE is:10.53 & sMAPE is:40.65% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 17.10% & 1.14\n",
      "for 2019-04-24, MAE is:4.07 & sMAPE is:12.54% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 17.06% & 1.13\n",
      "for 2019-04-25, MAE is:6.59 & sMAPE is:22.02% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 17.10% & 1.13\n",
      "for 2019-04-26, MAE is:9.47 & sMAPE is:26.21% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 17.18% & 1.13\n",
      "for 2019-04-27, MAE is:12.45 & sMAPE is:71.62% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 17.65% & 1.13\n",
      "for 2019-04-28, MAE is:12.54 & sMAPE is:44.50% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 17.88% & 1.14\n",
      "for 2019-04-29, MAE is:5.36 & sMAPE is:13.75% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 17.84% & 1.13\n",
      "for 2019-04-30, MAE is:6.31 & sMAPE is:16.18% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 17.83% & 1.12\n",
      "for 2019-05-01, MAE is:3.45 & sMAPE is:13.10% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 17.79% & 1.12\n",
      "for 2019-05-02, MAE is:4.12 & sMAPE is:11.04% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 17.73% & 1.11\n",
      "for 2019-05-03, MAE is:3.85 & sMAPE is:10.37% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 17.67% & 1.12\n",
      "for 2019-05-04, MAE is:9.11 & sMAPE is:27.41% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 17.75% & 1.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-05, MAE is:3.69 & sMAPE is:11.74% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 17.70% & 1.11\n",
      "for 2019-05-06, MAE is:6.66 & sMAPE is:16.23% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 17.69% & 1.12\n",
      "for 2019-05-07, MAE is:7.30 & sMAPE is:15.20% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 17.67% & 1.11\n",
      "for 2019-05-08, MAE is:5.41 & sMAPE is:12.48% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 17.63% & 1.11\n",
      "for 2019-05-09, MAE is:9.94 & sMAPE is:24.11% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 17.68% & 1.11\n",
      "for 2019-05-10, MAE is:5.68 & sMAPE is:13.86% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 17.65% & 1.12\n",
      "for 2019-05-11, MAE is:3.77 & sMAPE is:10.11% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.59% & 1.12\n",
      "for 2019-05-12, MAE is:7.92 & sMAPE is:39.96% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 17.76% & 1.12\n",
      "for 2019-05-13, MAE is:6.66 & sMAPE is:17.74% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 17.76% & 1.12\n",
      "for 2019-05-14, MAE is:4.96 & sMAPE is:12.30% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 17.72% & 1.11\n",
      "for 2019-05-15, MAE is:3.93 & sMAPE is:9.67% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 17.66% & 1.11\n",
      "for 2019-05-16, MAE is:5.32 & sMAPE is:14.87% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 17.64% & 1.11\n",
      "for 2019-05-17, MAE is:6.95 & sMAPE is:18.22% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 17.65% & 1.12\n",
      "for 2019-05-18, MAE is:5.29 & sMAPE is:15.85% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 17.63% & 1.12\n",
      "for 2019-05-19, MAE is:6.32 & sMAPE is:20.78% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 17.66% & 1.11\n",
      "for 2019-05-20, MAE is:6.89 & sMAPE is:16.72% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 17.65% & 1.11\n",
      "for 2019-05-21, MAE is:6.41 & sMAPE is:16.26% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 17.64% & 1.11\n",
      "for 2019-05-22, MAE is:4.64 & sMAPE is:12.31% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 17.60% & 1.12\n",
      "for 2019-05-23, MAE is:5.66 & sMAPE is:14.06% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 17.58% & 1.12\n",
      "for 2019-05-24, MAE is:3.46 & sMAPE is:8.89% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 17.52% & 1.12\n",
      "for 2019-05-25, MAE is:4.89 & sMAPE is:14.83% & rMAE is:4.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 17.50% & 1.14\n",
      "for 2019-05-26, MAE is:9.16 & sMAPE is:47.55% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 17.70% & 1.14\n",
      "for 2019-05-27, MAE is:4.30 & sMAPE is:14.83% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 17.69% & 1.13\n",
      "for 2019-05-28, MAE is:5.44 & sMAPE is:15.83% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 17.67% & 1.13\n",
      "for 2019-05-29, MAE is:6.39 & sMAPE is:18.36% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 17.68% & 1.14\n",
      "for 2019-05-30, MAE is:7.84 & sMAPE is:40.62% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 17.83% & 1.14\n",
      "for 2019-05-31, MAE is:4.30 & sMAPE is:13.35% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 17.80% & 1.13\n",
      "for 2019-06-01, MAE is:2.92 & sMAPE is:10.21% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 17.75% & 1.13\n",
      "for 2019-06-02, MAE is:8.90 & sMAPE is:54.71% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 17.99% & 1.14\n",
      "for 2019-06-03, MAE is:5.52 & sMAPE is:16.09% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 17.98% & 1.14\n",
      "for 2019-06-04, MAE is:3.61 & sMAPE is:10.16% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.93% & 1.14\n",
      "for 2019-06-05, MAE is:8.63 & sMAPE is:26.83% & rMAE is:2.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 17.99% & 1.15\n",
      "for 2019-06-06, MAE is:5.88 & sMAPE is:18.36% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.99% & 1.14\n",
      "for 2019-06-07, MAE is:5.21 & sMAPE is:17.06% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 17.98% & 1.14\n",
      "for 2019-06-08, MAE is:152.94 & sMAPE is:178.72% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 18.99% & 1.14\n",
      "for 2019-06-09, MAE is:81.32 & sMAPE is:200.00% & rMAE is:8.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.12 & 20.13% & 1.19\n",
      "for 2019-06-10, MAE is:5.81 & sMAPE is:20.87% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 20.13% & 1.18\n",
      "for 2019-06-11, MAE is:35.65 & sMAPE is:152.02% & rMAE is:5.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 20.94% & 1.21\n",
      "for 2019-06-12, MAE is:4.61 & sMAPE is:11.74% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 20.89% & 1.21\n",
      "for 2019-06-13, MAE is:5.60 & sMAPE is:15.67% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 20.86% & 1.21\n",
      "for 2019-06-14, MAE is:4.53 & sMAPE is:12.24% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 20.80% & 1.21\n",
      "for 2019-06-15, MAE is:33.76 & sMAPE is:180.16% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 21.76% & 1.20\n",
      "for 2019-06-16, MAE is:4.53 & sMAPE is:16.52% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 21.73% & 1.20\n",
      "for 2019-06-17, MAE is:4.83 & sMAPE is:12.50% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 21.68% & 1.19\n",
      "for 2019-06-18, MAE is:4.67 & sMAPE is:11.41% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.31 & 21.62% & 1.19\n",
      "for 2019-06-19, MAE is:3.31 & sMAPE is:8.72% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 21.54% & 1.19\n",
      "for 2019-06-20, MAE is:7.43 & sMAPE is:22.17% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 21.54% & 1.19\n",
      "for 2019-06-21, MAE is:2.90 & sMAPE is:8.33% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 21.47% & 1.19\n",
      "for 2019-06-22, MAE is:3.03 & sMAPE is:11.25% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.21 & 21.41% & 1.19\n",
      "for 2019-06-23, MAE is:10.87 & sMAPE is:79.96% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.23 & 21.74% & 1.18\n",
      "for 2019-06-24, MAE is:5.41 & sMAPE is:15.08% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.21 & 21.71% & 1.18\n",
      "for 2019-06-25, MAE is:10.08 & sMAPE is:22.95% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 21.71% & 1.19\n",
      "for 2019-06-26, MAE is:6.52 & sMAPE is:18.78% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.21 & 21.70% & 1.19\n",
      "for 2019-06-27, MAE is:5.48 & sMAPE is:17.16% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 21.67% & 1.19\n",
      "for 2019-06-28, MAE is:6.83 & sMAPE is:18.40% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 21.65% & 1.19\n",
      "for 2019-06-29, MAE is:3.57 & sMAPE is:12.05% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 21.60% & 1.19\n",
      "for 2019-06-30, MAE is:7.82 & sMAPE is:47.74% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 21.74% & 1.19\n",
      "for 2019-07-01, MAE is:3.71 & sMAPE is:11.71% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 21.69% & 1.19\n",
      "for 2019-07-02, MAE is:6.17 & sMAPE is:19.42% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 21.68% & 1.19\n",
      "for 2019-07-03, MAE is:4.62 & sMAPE is:14.85% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 21.64% & 1.18\n",
      "for 2019-07-04, MAE is:5.64 & sMAPE is:18.94% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 21.63% & 1.19\n",
      "for 2019-07-05, MAE is:4.71 & sMAPE is:14.64% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 21.59% & 1.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-06, MAE is:5.69 & sMAPE is:21.60% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 21.59% & 1.19\n",
      "for 2019-07-07, MAE is:5.75 & sMAPE is:24.64% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 21.60% & 1.19\n",
      "for 2019-07-08, MAE is:6.53 & sMAPE is:21.54% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 21.60% & 1.19\n",
      "for 2019-07-09, MAE is:6.88 & sMAPE is:21.31% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 21.60% & 1.20\n",
      "for 2019-07-10, MAE is:5.99 & sMAPE is:16.05% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 21.57% & 1.19\n",
      "for 2019-07-11, MAE is:8.51 & sMAPE is:20.64% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 21.57% & 1.19\n",
      "for 2019-07-12, MAE is:8.79 & sMAPE is:22.82% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 21.57% & 1.19\n",
      "for 2019-07-13, MAE is:9.21 & sMAPE is:29.30% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 21.61% & 1.19\n",
      "for 2019-07-14, MAE is:7.11 & sMAPE is:24.75% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 21.63% & 1.19\n",
      "for 2019-07-15, MAE is:6.94 & sMAPE is:19.71% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 21.62% & 1.19\n",
      "for 2019-07-16, MAE is:7.58 & sMAPE is:19.46% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 21.61% & 1.19\n",
      "for 2019-07-17, MAE is:5.84 & sMAPE is:14.35% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 21.57% & 1.19\n",
      "for 2019-07-18, MAE is:4.08 & sMAPE is:9.84% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 21.51% & 1.19\n",
      "for 2019-07-19, MAE is:5.42 & sMAPE is:13.21% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 21.47% & 1.19\n",
      "for 2019-07-20, MAE is:2.81 & sMAPE is:8.59% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 21.41% & 1.19\n",
      "for 2019-07-21, MAE is:9.12 & sMAPE is:33.29% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 21.47% & 1.20\n",
      "for 2019-07-22, MAE is:5.08 & sMAPE is:12.73% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 21.42% & 1.20\n",
      "for 2019-07-23, MAE is:6.80 & sMAPE is:15.63% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 21.40% & 1.20\n",
      "for 2019-07-24, MAE is:8.86 & sMAPE is:18.23% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 21.38% & 1.20\n",
      "for 2019-07-25, MAE is:7.11 & sMAPE is:15.29% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 21.35% & 1.20\n",
      "for 2019-07-26, MAE is:7.71 & sMAPE is:18.63% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 21.34% & 1.21\n",
      "for 2019-07-27, MAE is:3.49 & sMAPE is:10.00% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 21.28% & 1.21\n",
      "for 2019-07-28, MAE is:4.84 & sMAPE is:16.90% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 21.26% & 1.21\n",
      "for 2019-07-29, MAE is:5.38 & sMAPE is:14.46% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 21.23% & 1.21\n",
      "for 2019-07-30, MAE is:10.03 & sMAPE is:33.15% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 21.29% & 1.21\n",
      "for 2019-07-31, MAE is:3.74 & sMAPE is:11.46% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 21.24% & 1.20\n",
      "for 2019-08-01, MAE is:6.98 & sMAPE is:17.66% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 21.22% & 1.20\n",
      "for 2019-08-02, MAE is:3.70 & sMAPE is:9.45% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 21.17% & 1.20\n",
      "for 2019-08-03, MAE is:6.16 & sMAPE is:19.57% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 21.16% & 1.20\n",
      "for 2019-08-04, MAE is:7.19 & sMAPE is:23.39% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 21.17% & 1.21\n",
      "for 2019-08-05, MAE is:3.14 & sMAPE is:8.44% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 21.11% & 1.20\n",
      "for 2019-08-06, MAE is:4.72 & sMAPE is:12.71% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 21.07% & 1.20\n",
      "for 2019-08-07, MAE is:3.07 & sMAPE is:8.04% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 21.01% & 1.20\n",
      "for 2019-08-08, MAE is:4.35 & sMAPE is:12.59% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 20.98% & 1.19\n",
      "for 2019-08-09, MAE is:2.07 & sMAPE is:6.34% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 20.91% & 1.19\n",
      "for 2019-08-10, MAE is:16.08 & sMAPE is:93.68% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 21.24% & 1.19\n",
      "for 2019-08-11, MAE is:10.81 & sMAPE is:65.15% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 21.43% & 1.18\n",
      "for 2019-08-12, MAE is:10.93 & sMAPE is:37.46% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 21.51% & 1.19\n",
      "for 2019-08-13, MAE is:5.36 & sMAPE is:16.67% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 21.48% & 1.19\n",
      "for 2019-08-14, MAE is:5.04 & sMAPE is:16.34% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 21.46% & 1.19\n",
      "for 2019-08-15, MAE is:4.39 & sMAPE is:21.24% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 21.46% & 1.18\n",
      "for 2019-08-16, MAE is:7.20 & sMAPE is:25.68% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 21.48% & 1.19\n",
      "for 2019-08-17, MAE is:4.73 & sMAPE is:22.12% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 21.48% & 1.19\n",
      "for 2019-08-18, MAE is:5.73 & sMAPE is:40.19% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 21.56% & 1.18\n",
      "for 2019-08-19, MAE is:4.65 & sMAPE is:16.41% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 21.54% & 1.18\n",
      "for 2019-08-20, MAE is:7.52 & sMAPE is:23.17% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 21.55% & 1.19\n",
      "for 2019-08-21, MAE is:5.18 & sMAPE is:15.43% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 21.52% & 1.19\n",
      "for 2019-08-22, MAE is:3.45 & sMAPE is:10.17% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 21.47% & 1.19\n",
      "for 2019-08-23, MAE is:2.52 & sMAPE is:8.21% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 21.42% & 1.19\n",
      "for 2019-08-24, MAE is:4.59 & sMAPE is:16.00% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 21.39% & 1.18\n",
      "for 2019-08-25, MAE is:4.04 & sMAPE is:14.79% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 21.37% & 1.18\n",
      "for 2019-08-26, MAE is:9.65 & sMAPE is:26.10% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 21.39% & 1.18\n",
      "for 2019-08-27, MAE is:7.04 & sMAPE is:16.65% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 21.37% & 1.18\n",
      "for 2019-08-28, MAE is:8.79 & sMAPE is:20.04% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 21.36% & 1.18\n",
      "for 2019-08-29, MAE is:4.66 & sMAPE is:11.19% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 21.32% & 1.17\n",
      "for 2019-08-30, MAE is:5.45 & sMAPE is:13.43% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 21.29% & 1.17\n",
      "for 2019-08-31, MAE is:2.31 & sMAPE is:7.31% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 21.23% & 1.17\n",
      "for 2019-09-01, MAE is:4.87 & sMAPE is:18.06% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 21.22% & 1.18\n",
      "for 2019-09-02, MAE is:4.30 & sMAPE is:12.54% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 21.18% & 1.17\n",
      "for 2019-09-03, MAE is:5.47 & sMAPE is:15.33% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 21.16% & 1.17\n",
      "for 2019-09-04, MAE is:7.18 & sMAPE is:20.19% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 21.15% & 1.17\n",
      "for 2019-09-05, MAE is:5.42 & sMAPE is:18.62% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 21.14% & 1.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-06, MAE is:4.03 & sMAPE is:14.31% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 21.11% & 1.16\n",
      "for 2019-09-07, MAE is:8.51 & sMAPE is:32.57% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 21.16% & 1.16\n",
      "for 2019-09-08, MAE is:8.84 & sMAPE is:37.80% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 21.23% & 1.16\n",
      "for 2019-09-09, MAE is:10.82 & sMAPE is:29.74% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 21.26% & 1.17\n",
      "for 2019-09-10, MAE is:5.51 & sMAPE is:16.51% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 21.24% & 1.17\n",
      "for 2019-09-11, MAE is:3.91 & sMAPE is:12.24% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 21.21% & 1.18\n",
      "for 2019-09-12, MAE is:6.85 & sMAPE is:20.02% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.20% & 1.18\n",
      "for 2019-09-13, MAE is:9.99 & sMAPE is:30.53% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 21.24% & 1.18\n",
      "for 2019-09-14, MAE is:7.74 & sMAPE is:24.31% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 21.25% & 1.18\n",
      "for 2019-09-15, MAE is:7.13 & sMAPE is:25.80% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 21.27% & 1.18\n",
      "for 2019-09-16, MAE is:10.92 & sMAPE is:26.67% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 21.29% & 1.18\n",
      "for 2019-09-17, MAE is:7.12 & sMAPE is:19.39% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 21.28% & 1.18\n",
      "for 2019-09-18, MAE is:7.24 & sMAPE is:20.31% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 21.28% & 1.18\n",
      "for 2019-09-19, MAE is:10.55 & sMAPE is:27.17% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 21.30% & 1.18\n",
      "for 2019-09-20, MAE is:6.38 & sMAPE is:17.18% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 21.28% & 1.18\n",
      "for 2019-09-21, MAE is:4.97 & sMAPE is:19.98% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 21.28% & 1.18\n",
      "for 2019-09-22, MAE is:5.99 & sMAPE is:31.65% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 21.32% & 1.18\n",
      "for 2019-09-23, MAE is:6.81 & sMAPE is:20.13% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 21.31% & 1.18\n",
      "for 2019-09-24, MAE is:5.47 & sMAPE is:16.90% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.30% & 1.18\n",
      "for 2019-09-25, MAE is:5.44 & sMAPE is:19.10% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.29% & 1.18\n",
      "for 2019-09-26, MAE is:8.17 & sMAPE is:25.50% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.31% & 1.18\n",
      "for 2019-09-27, MAE is:8.03 & sMAPE is:24.48% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.32% & 1.18\n",
      "for 2019-09-28, MAE is:7.43 & sMAPE is:34.49% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.37% & 1.18\n",
      "for 2019-09-29, MAE is:6.69 & sMAPE is:42.25% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.44% & 1.18\n",
      "for 2019-09-30, MAE is:14.39 & sMAPE is:62.91% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 21.59% & 1.18\n",
      "for 2019-10-01, MAE is:13.05 & sMAPE is:47.57% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 21.69% & 1.18\n",
      "for 2019-10-02, MAE is:5.93 & sMAPE is:16.53% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 21.67% & 1.18\n",
      "for 2019-10-03, MAE is:12.83 & sMAPE is:38.54% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 21.73% & 1.18\n",
      "for 2019-10-04, MAE is:7.85 & sMAPE is:20.70% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 21.73% & 1.18\n",
      "for 2019-10-05, MAE is:7.57 & sMAPE is:22.36% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 21.73% & 1.18\n",
      "for 2019-10-06, MAE is:6.07 & sMAPE is:22.17% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 21.73% & 1.17\n",
      "for 2019-10-07, MAE is:12.06 & sMAPE is:31.39% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 21.77% & 1.17\n",
      "for 2019-10-08, MAE is:3.62 & sMAPE is:10.04% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 21.72% & 1.17\n",
      "for 2019-10-09, MAE is:5.24 & sMAPE is:15.76% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 21.70% & 1.17\n",
      "for 2019-10-10, MAE is:6.89 & sMAPE is:22.27% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 21.70% & 1.17\n",
      "for 2019-10-11, MAE is:4.42 & sMAPE is:16.44% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 21.69% & 1.17\n",
      "for 2019-10-12, MAE is:9.62 & sMAPE is:39.02% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 21.75% & 1.16\n",
      "for 2019-10-13, MAE is:5.25 & sMAPE is:21.88% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 21.75% & 1.16\n",
      "for 2019-10-14, MAE is:6.72 & sMAPE is:18.96% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 21.74% & 1.16\n",
      "for 2019-10-15, MAE is:12.61 & sMAPE is:33.46% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 21.78% & 1.16\n",
      "for 2019-10-16, MAE is:6.86 & sMAPE is:20.12% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 21.77% & 1.16\n",
      "for 2019-10-17, MAE is:10.07 & sMAPE is:25.59% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 21.79% & 1.16\n",
      "for 2019-10-18, MAE is:7.46 & sMAPE is:24.18% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 21.79% & 1.16\n",
      "for 2019-10-19, MAE is:9.25 & sMAPE is:32.26% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 21.83% & 1.16\n",
      "for 2019-10-20, MAE is:6.77 & sMAPE is:21.78% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 21.83% & 1.16\n",
      "for 2019-10-21, MAE is:8.75 & sMAPE is:22.67% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 21.83% & 1.16\n",
      "for 2019-10-22, MAE is:8.58 & sMAPE is:21.23% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 21.83% & 1.17\n",
      "for 2019-10-23, MAE is:5.02 & sMAPE is:12.09% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 21.80% & 1.17\n",
      "for 2019-10-24, MAE is:5.95 & sMAPE is:16.60% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 21.78% & 1.17\n",
      "for 2019-10-25, MAE is:6.29 & sMAPE is:17.95% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 21.77% & 1.17\n",
      "for 2019-10-26, MAE is:4.93 & sMAPE is:20.60% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 21.76% & 1.16\n",
      "for 2019-10-27, MAE is:8.42 & sMAPE is:28.75% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 21.79% & 1.17\n",
      "for 2019-10-28, MAE is:10.49 & sMAPE is:27.67% & rMAE is:2.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 21.81% & 1.17\n",
      "for 2019-10-29, MAE is:7.46 & sMAPE is:17.58% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 21.79% & 1.17\n",
      "for 2019-10-30, MAE is:7.30 & sMAPE is:16.94% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 21.78% & 1.18\n",
      "for 2019-10-31, MAE is:6.04 & sMAPE is:15.29% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 21.76% & 1.17\n",
      "for 2019-11-01, MAE is:3.32 & sMAPE is:9.69% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 21.72% & 1.17\n",
      "for 2019-11-02, MAE is:3.04 & sMAPE is:10.33% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.68% & 1.17\n",
      "for 2019-11-03, MAE is:4.48 & sMAPE is:21.22% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.68% & 1.17\n",
      "for 2019-11-04, MAE is:6.19 & sMAPE is:19.09% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.67% & 1.17\n",
      "for 2019-11-05, MAE is:6.61 & sMAPE is:17.34% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.65% & 1.17\n",
      "for 2019-11-06, MAE is:12.14 & sMAPE is:26.42% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.67% & 1.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-07, MAE is:4.57 & sMAPE is:11.71% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.64% & 1.17\n",
      "for 2019-11-08, MAE is:11.83 & sMAPE is:27.72% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 21.66% & 1.17\n",
      "for 2019-11-09, MAE is:4.76 & sMAPE is:12.57% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.63% & 1.17\n",
      "for 2019-11-10, MAE is:4.39 & sMAPE is:11.82% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.60% & 1.16\n",
      "for 2019-11-11, MAE is:7.38 & sMAPE is:19.35% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.59% & 1.16\n",
      "for 2019-11-12, MAE is:7.49 & sMAPE is:18.98% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.58% & 1.17\n",
      "for 2019-11-13, MAE is:11.93 & sMAPE is:23.63% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.59% & 1.17\n",
      "for 2019-11-14, MAE is:6.70 & sMAPE is:13.53% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.56% & 1.17\n",
      "for 2019-11-15, MAE is:5.12 & sMAPE is:10.53% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.53% & 1.17\n",
      "for 2019-11-16, MAE is:7.08 & sMAPE is:15.57% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.51% & 1.17\n",
      "for 2019-11-17, MAE is:8.92 & sMAPE is:22.58% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.51% & 1.17\n",
      "for 2019-11-18, MAE is:8.06 & sMAPE is:18.56% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.50% & 1.17\n",
      "for 2019-11-19, MAE is:10.42 & sMAPE is:20.47% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.50% & 1.17\n",
      "for 2019-11-20, MAE is:8.14 & sMAPE is:17.01% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.49% & 1.17\n",
      "for 2019-11-21, MAE is:4.72 & sMAPE is:10.19% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.45% & 1.17\n",
      "for 2019-11-22, MAE is:7.02 & sMAPE is:18.29% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.44% & 1.17\n",
      "for 2019-11-23, MAE is:6.15 & sMAPE is:14.10% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 21.42% & 1.16\n",
      "for 2019-11-24, MAE is:4.90 & sMAPE is:11.54% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 21.39% & 1.16\n",
      "for 2019-11-25, MAE is:8.25 & sMAPE is:18.25% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 21.38% & 1.16\n",
      "for 2019-11-26, MAE is:4.35 & sMAPE is:10.31% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 21.35% & 1.16\n",
      "for 2019-11-27, MAE is:5.78 & sMAPE is:14.05% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 21.32% & 1.16\n",
      "for 2019-11-28, MAE is:6.25 & sMAPE is:16.33% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 21.31% & 1.16\n",
      "for 2019-11-29, MAE is:6.25 & sMAPE is:14.44% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 21.29% & 1.16\n",
      "for 2019-11-30, MAE is:3.62 & sMAPE is:8.38% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 21.25% & 1.16\n",
      "for 2019-12-01, MAE is:4.85 & sMAPE is:12.57% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 21.22% & 1.16\n",
      "for 2019-12-02, MAE is:6.06 & sMAPE is:13.18% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 21.20% & 1.16\n",
      "for 2019-12-03, MAE is:8.86 & sMAPE is:17.22% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 21.19% & 1.16\n",
      "for 2019-12-04, MAE is:6.40 & sMAPE is:11.92% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 21.16% & 1.15\n",
      "for 2019-12-05, MAE is:9.87 & sMAPE is:18.29% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 21.15% & 1.15\n",
      "for 2019-12-06, MAE is:3.90 & sMAPE is:8.74% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 21.12% & 1.15\n",
      "for 2019-12-07, MAE is:6.58 & sMAPE is:16.89% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 21.10% & 1.15\n",
      "for 2019-12-08, MAE is:15.27 & sMAPE is:84.28% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 21.29% & 1.15\n",
      "for 2019-12-09, MAE is:7.80 & sMAPE is:42.02% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 21.35% & 1.15\n",
      "for 2019-12-10, MAE is:9.15 & sMAPE is:24.62% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 21.36% & 1.15\n",
      "for 2019-12-11, MAE is:14.59 & sMAPE is:37.98% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 21.41% & 1.15\n",
      "for 2019-12-12, MAE is:6.85 & sMAPE is:17.63% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 21.40% & 1.15\n",
      "for 2019-12-13, MAE is:4.24 & sMAPE is:11.97% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 21.37% & 1.14\n",
      "for 2019-12-14, MAE is:2.74 & sMAPE is:8.96% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 21.33% & 1.14\n",
      "for 2019-12-15, MAE is:4.93 & sMAPE is:26.06% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 21.35% & 1.14\n",
      "for 2019-12-16, MAE is:6.51 & sMAPE is:20.33% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 21.34% & 1.14\n",
      "for 2019-12-17, MAE is:5.76 & sMAPE is:15.75% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 21.33% & 1.14\n",
      "for 2019-12-18, MAE is:8.06 & sMAPE is:22.05% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 21.33% & 1.14\n",
      "for 2019-12-19, MAE is:7.40 & sMAPE is:27.77% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 21.35% & 1.14\n",
      "for 2019-12-20, MAE is:4.27 & sMAPE is:18.09% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 21.34% & 1.14\n",
      "for 2019-12-21, MAE is:4.64 & sMAPE is:21.56% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 21.34% & 1.13\n",
      "for 2019-12-22, MAE is:4.10 & sMAPE is:20.64% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 21.34% & 1.13\n",
      "for 2019-12-23, MAE is:9.63 & sMAPE is:43.64% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 21.40% & 1.13\n",
      "for 2019-12-24, MAE is:4.78 & sMAPE is:30.93% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 21.43% & 1.13\n",
      "for 2019-12-25, MAE is:11.80 & sMAPE is:49.60% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 21.50% & 1.13\n",
      "for 2019-12-26, MAE is:6.26 & sMAPE is:23.40% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 21.51% & 1.13\n",
      "for 2019-12-27, MAE is:7.66 & sMAPE is:25.26% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 21.52% & 1.13\n",
      "for 2019-12-28, MAE is:5.66 & sMAPE is:19.49% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 21.51% & 1.13\n",
      "for 2019-12-29, MAE is:2.92 & sMAPE is:9.25% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 21.48% & 1.12\n",
      "for 2019-12-30, MAE is:7.90 & sMAPE is:23.79% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 21.49% & 1.12\n",
      "for 2019-12-31, MAE is:6.49 & sMAPE is:18.36% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 21.48% & 1.12\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.2 - (Calib Year = 3)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:15:19,768]\u001b[0m A new study created in RDB with name: BE_2020\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:15:42,360]\u001b[0m Trial 2 finished with value: 7.687188353973617 and parameters: {'n_hidden': 3, 'learning_rate': 0.09984591407750185, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07367274871756857, 'dropout_rate_Layer_2': 0.19221292622725983, 'dropout_rate_Layer_3': 0.012814221489707834, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008354294861398092, 'l1_Layer_2': 1.6219341807093543e-05, 'l1_Layer_3': 0.0025924653850611617, 'n_units_Layer_1': 75, 'n_units_Layer_2': 80, 'n_units_Layer_3': 200}. Best is trial 2 with value: 7.687188353973617.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.69 | sMAPE for Validation Set is: 20.74% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 9.86 | sMAPE for Test Set is: 34.22% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:15:43,032]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 13.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:15:47,887]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:15:51,691]\u001b[0m Trial 3 finished with value: 6.4525588221789745 and parameters: {'n_hidden': 4, 'learning_rate': 0.0377016398719748, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15885973419850052, 'dropout_rate_Layer_2': 0.21797856281891864, 'dropout_rate_Layer_3': 0.2931724579670218, 'dropout_rate_Layer_4': 0.12439468603404934, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0050383950331621885, 'l1_Layer_2': 0.0012660457505734334, 'l1_Layer_3': 1.8228770754801046e-05, 'l1_Layer_4': 7.817114634710511e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 155, 'n_units_Layer_3': 55, 'n_units_Layer_4': 280}. Best is trial 3 with value: 6.4525588221789745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 9.15 | sMAPE for Test Set is: 32.44% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:15:55,689]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:15:56,161]\u001b[0m Trial 4 finished with value: 9.267442018910272 and parameters: {'n_hidden': 4, 'learning_rate': 0.030450569094243176, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10638022893295199, 'dropout_rate_Layer_2': 0.35647671592249963, 'dropout_rate_Layer_3': 0.3405471942654413, 'dropout_rate_Layer_4': 0.06457724898842741, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00011296019153045847, 'l1_Layer_2': 0.04786975298065689, 'l1_Layer_3': 0.008728195828362524, 'l1_Layer_4': 0.0004973204526816303, 'n_units_Layer_1': 250, 'n_units_Layer_2': 155, 'n_units_Layer_3': 270, 'n_units_Layer_4': 195}. Best is trial 3 with value: 6.4525588221789745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.27 | sMAPE for Validation Set is: 24.02% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 14.11 | sMAPE for Test Set is: 43.36% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:16:01,176]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:02,700]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:10,902]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:16,718]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:22,342]\u001b[0m Trial 11 finished with value: 7.463266784651985 and parameters: {'n_hidden': 3, 'learning_rate': 0.011518212850830514, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3251865253142436, 'dropout_rate_Layer_2': 0.39238863049018535, 'dropout_rate_Layer_3': 0.29454690679771967, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.07912924327881712, 'l1_Layer_2': 0.0020994738802662923, 'l1_Layer_3': 0.00012014633339606135, 'n_units_Layer_1': 145, 'n_units_Layer_2': 145, 'n_units_Layer_3': 100}. Best is trial 3 with value: 6.4525588221789745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.46 | sMAPE for Validation Set is: 19.88% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 10.75 | sMAPE for Test Set is: 36.07% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:16:24,905]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:26,091]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:30,560]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:33,133]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:33,477]\u001b[0m Trial 13 finished with value: 6.771556029186569 and parameters: {'n_hidden': 3, 'learning_rate': 0.012372152238162737, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03780442488652685, 'dropout_rate_Layer_2': 0.0743588419003598, 'dropout_rate_Layer_3': 0.2231863881012957, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004270789790699859, 'l1_Layer_2': 3.649424136282166e-05, 'l1_Layer_3': 2.8870701949144664e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 90, 'n_units_Layer_3': 85}. Best is trial 3 with value: 6.4525588221789745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.77 | sMAPE for Validation Set is: 18.68% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 9.86 | sMAPE for Test Set is: 34.19% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:16:35,592]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:39,549]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:42,271]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:45,482]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:48,038]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:50,352]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:53,860]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:58,029]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:16:58,240]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:04,673]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:04,859]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:08,783]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:14,971]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:15,048]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:16,823]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:22,614]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:25,932]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:30,583]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:34,345]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:34,584]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:36,270]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:43,383]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:45,384]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:51,637]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:17:56,938]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:03,098]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:03,687]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:11,153]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:13,106]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:17,000]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:22,940]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:25,200]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:27,858]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:32,439]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:32,821]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:33,216]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:40,898]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:48,459]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:53,136]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:18:58,069]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:19:06,011]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:19:12,866]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:19:16,386]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:19:18,919]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:19:21,119]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:19:22,810]\u001b[0m Trial 55 finished with value: 6.123041655213695 and parameters: {'n_hidden': 3, 'learning_rate': 0.019208249729715698, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32525807209922847, 'dropout_rate_Layer_2': 0.04716037778296354, 'dropout_rate_Layer_3': 0.20672369068049315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001172746544373806, 'l1_Layer_2': 1.871152633285655e-05, 'l1_Layer_3': 0.00019795896287308013, 'n_units_Layer_1': 170, 'n_units_Layer_2': 100, 'n_units_Layer_3': 130}. Best is trial 55 with value: 6.123041655213695.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.68 | sMAPE for Test Set is: 31.40% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:19:30,383]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:19:31,554]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:19:37,618]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:19:42,872]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:19:52,444]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:20:09,266]\u001b[0m Trial 1 finished with value: 5.755275501121578 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006024870695582097, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3472451943844562, 'dropout_rate_Layer_2': 0.19528019766447444, 'dropout_rate_Layer_3': 0.16622210918158534, 'dropout_rate_Layer_4': 0.39324994093321014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.5798416424064574e-05, 'l1_Layer_2': 0.0228277056316608, 'l1_Layer_3': 0.07523134680880687, 'l1_Layer_4': 3.7777226060191285e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 220, 'n_units_Layer_3': 190, 'n_units_Layer_4': 205}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 16.10% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.48 | sMAPE for Test Set is: 27.94% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:20:09,445]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:20:16,291]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:20:23,655]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:20:23,988]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:20:31,760]\u001b[0m Trial 69 finished with value: 6.2489923780057675 and parameters: {'n_hidden': 4, 'learning_rate': 0.004008882755838905, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1871574212097434, 'dropout_rate_Layer_2': 0.3542548673105848, 'dropout_rate_Layer_3': 0.25720511633396237, 'dropout_rate_Layer_4': 0.23448377430150014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006594561690070119, 'l1_Layer_2': 0.018733728673032912, 'l1_Layer_3': 0.005304154485674222, 'l1_Layer_4': 0.00137275982505529, 'n_units_Layer_1': 215, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260, 'n_units_Layer_4': 145}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.94 | sMAPE for Test Set is: 31.93% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:20:40,049]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:20:49,506]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:20:55,925]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:02,728]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:08,055]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:12,355]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:16,474]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:18,372]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:30,353]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:34,651]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:37,098]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:39,389]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:42,013]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:47,060]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:47,678]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:54,097]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:21:54,661]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:22:00,429]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:22:07,880]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:22:11,585]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:22:15,630]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:22:20,798]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:22:23,794]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:22:32,218]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:22:35,220]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:22:38,664]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:22:44,245]\u001b[0m Trial 83 finished with value: 6.359938813365815 and parameters: {'n_hidden': 3, 'learning_rate': 0.02532704164185043, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21359133211688933, 'dropout_rate_Layer_2': 0.0625189898550406, 'dropout_rate_Layer_3': 0.31572815882781685, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0012373592757441325, 'l1_Layer_2': 0.0017990833048552588, 'l1_Layer_3': 0.09505191133216118, 'n_units_Layer_1': 190, 'n_units_Layer_2': 210, 'n_units_Layer_3': 120}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 17.65% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 31.80% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:22:44,997]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:22:49,159]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:23:05,100]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:23:19,082]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:23:23,760]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:23:26,771]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:23:33,073]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:23:41,065]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:23:43,724]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:23:56,123]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:24:21,639]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:24:26,527]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:24:27,105]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:24:33,553]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:24:34,078]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:24:40,401]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:24:41,551]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:24:48,030]\u001b[0m Trial 111 finished with value: 6.267346707109632 and parameters: {'n_hidden': 4, 'learning_rate': 0.003177253601376873, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.052327194957369906, 'dropout_rate_Layer_2': 0.02585055919142315, 'dropout_rate_Layer_3': 0.3573025528938447, 'dropout_rate_Layer_4': 0.3435552793205455, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03173155657993002, 'l1_Layer_2': 0.0005666266342171448, 'l1_Layer_3': 1.0068676556987113e-05, 'l1_Layer_4': 0.004812117578795183, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 200, 'n_units_Layer_4': 290}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 17.42% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 31.89% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:24:50,864]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:24:55,306]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:25:02,753]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:25:04,696]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:25:06,299]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:25:10,537]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:25:20,980]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:25:28,789]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:25:38,516]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:25:48,508]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:25:51,377]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:25:54,511]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:25:54,899]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:02,364]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:06,798]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:07,145]\u001b[0m Trial 74 finished with value: 5.96382006790829 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035868652720161044, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39865742854372743, 'dropout_rate_Layer_2': 0.3647852155459969, 'dropout_rate_Layer_3': 0.25956929599711026, 'dropout_rate_Layer_4': 0.39434204259234945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.251317920708235e-05, 'l1_Layer_2': 0.09000655598349863, 'l1_Layer_3': 0.006427523900722383, 'l1_Layer_4': 8.928242058940143e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 240, 'n_units_Layer_3': 220, 'n_units_Layer_4': 155}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 16.68% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.19 | sMAPE for Test Set is: 30.00% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:26:13,832]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:18,485]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:18,837]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:26,310]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:26,419]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:32,402]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:37,266]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:39,747]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:42,376]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:47,540]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:52,230]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:57,348]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:26:58,237]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:05,600]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:05,754]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:13,410]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:13,668]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:17,918]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:21,532]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:22,007]\u001b[0m Trial 125 finished with value: 5.807559917164028 and parameters: {'n_hidden': 3, 'learning_rate': 0.008699235499094383, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15507585430916146, 'dropout_rate_Layer_2': 0.3166029781874617, 'dropout_rate_Layer_3': 0.20505066554039042, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0002940392213746992, 'l1_Layer_2': 0.00627300810585982, 'l1_Layer_3': 0.0001390076749121578, 'n_units_Layer_1': 165, 'n_units_Layer_2': 50, 'n_units_Layer_3': 145}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 16.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.68 | sMAPE for Test Set is: 28.55% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:27:26,914]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:28,067]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:39,518]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:43,063]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:46,935]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:47,355]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:50,307]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:52,094]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:27:58,665]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:28:03,625]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:28:08,649]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:28:11,908]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:28:18,048]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:28:22,524]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:28:43,303]\u001b[0m Trial 163 finished with value: 5.975534151051076 and parameters: {'n_hidden': 4, 'learning_rate': 0.004593951057932135, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2081906727171589, 'dropout_rate_Layer_2': 0.3999980387855384, 'dropout_rate_Layer_3': 0.12206033939721547, 'dropout_rate_Layer_4': 0.10364384897799483, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.100604497192484e-05, 'l1_Layer_2': 0.040531250593556084, 'l1_Layer_3': 0.0019612349475636773, 'l1_Layer_4': 7.538393472763966e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 165, 'n_units_Layer_3': 230, 'n_units_Layer_4': 150}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 26.58% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:28:48,107]\u001b[0m Trial 164 finished with value: 5.842685395956483 and parameters: {'n_hidden': 3, 'learning_rate': 0.012951952638157856, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1572452450270597, 'dropout_rate_Layer_2': 0.3283295943337982, 'dropout_rate_Layer_3': 0.18660952933943548, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.0155424635278165e-05, 'l1_Layer_2': 0.011180273868060519, 'l1_Layer_3': 0.0001330000010064828, 'n_units_Layer_1': 150, 'n_units_Layer_2': 70, 'n_units_Layer_3': 120}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 16.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.16 | sMAPE for Test Set is: 26.95% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:29:12,606]\u001b[0m Trial 170 finished with value: 6.181257246335348 and parameters: {'n_hidden': 4, 'learning_rate': 0.004627543954331688, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14103207430935638, 'dropout_rate_Layer_2': 0.23112384864305438, 'dropout_rate_Layer_3': 0.25549301452593215, 'dropout_rate_Layer_4': 0.045964065673044605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.556644240404656e-05, 'l1_Layer_2': 0.03930708600340751, 'l1_Layer_3': 0.002126678004505327, 'l1_Layer_4': 8.228092092828771e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 110, 'n_units_Layer_3': 185, 'n_units_Layer_4': 170}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.66 | sMAPE for Test Set is: 28.40% | rMAE for Test Set is: 0.91\n",
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 16.54% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.25 | sMAPE for Test Set is: 27.01% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:29:15,495]\u001b[0m Trial 171 finished with value: 5.917878552428836 and parameters: {'n_hidden': 3, 'learning_rate': 0.012389333263503768, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07671304191668955, 'dropout_rate_Layer_2': 0.3244169130552287, 'dropout_rate_Layer_3': 0.14617052840445208, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00021193596331348373, 'l1_Layer_2': 0.00012123577442962698, 'l1_Layer_3': 0.00028135908500394953, 'n_units_Layer_1': 105, 'n_units_Layer_2': 70, 'n_units_Layer_3': 150}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:29:16,620]\u001b[0m Trial 173 finished with value: 6.21625239459718 and parameters: {'n_hidden': 4, 'learning_rate': 0.00478458193207859, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03871027996499671, 'dropout_rate_Layer_2': 0.39805620794365415, 'dropout_rate_Layer_3': 0.10545246247897581, 'dropout_rate_Layer_4': 0.04886217766893365, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 5.558248856703776e-05, 'l1_Layer_2': 0.03990386846196878, 'l1_Layer_3': 0.002193227235073169, 'l1_Layer_4': 7.303695570394351e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 185, 'n_units_Layer_4': 175}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 17.40% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 7.45 | sMAPE for Test Set is: 27.71% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:29:23,974]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 17.10% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.05 | sMAPE for Test Set is: 29.56% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:29:24,822]\u001b[0m Trial 172 finished with value: 6.135561469848818 and parameters: {'n_hidden': 4, 'learning_rate': 0.003939237963752506, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0331388705546585, 'dropout_rate_Layer_2': 0.39233675958251163, 'dropout_rate_Layer_3': 0.2599255328123109, 'dropout_rate_Layer_4': 0.03702148782706528, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 5.060534408599831e-05, 'l1_Layer_2': 0.047427428271283864, 'l1_Layer_3': 0.000971306532849054, 'l1_Layer_4': 6.861493098448779e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190, 'n_units_Layer_4': 150}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:29:27,249]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:29:33,726]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:29:34,353]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:29:39,482]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:29:41,585]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:29:43,370]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:29:50,698]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:29:55,230]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:29:58,679]\u001b[0m Trial 178 finished with value: 6.075099072403082 and parameters: {'n_hidden': 3, 'learning_rate': 0.014742858471690946, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07795706523051851, 'dropout_rate_Layer_2': 0.32541360015070075, 'dropout_rate_Layer_3': 0.1463116817531575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.776701436705959e-05, 'l1_Layer_2': 1.6418122108241508e-05, 'l1_Layer_3': 0.00022174757389003966, 'n_units_Layer_1': 100, 'n_units_Layer_2': 70, 'n_units_Layer_3': 150}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 16.89% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.48 | sMAPE for Test Set is: 27.93% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:30:16,927]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:30:31,128]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:30:36,812]\u001b[0m Trial 185 finished with value: 6.23010834360922 and parameters: {'n_hidden': 4, 'learning_rate': 0.003835763640282593, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07405369747864221, 'dropout_rate_Layer_2': 0.2362002948168429, 'dropout_rate_Layer_3': 0.03843172901118887, 'dropout_rate_Layer_4': 0.0561059150769358, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 9.455655223862105e-05, 'l1_Layer_2': 0.06578728252911725, 'l1_Layer_3': 0.0011357185936071985, 'l1_Layer_4': 8.073324690920829e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 190, 'n_units_Layer_4': 100}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 7.74 | sMAPE for Test Set is: 28.68% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:30:39,723]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:30:47,474]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:30:49,456]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:30:55,014]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:30:55,446]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.95 | sMAPE for Test Set is: 29.32% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:30:58,918]\u001b[0m Trial 187 finished with value: 6.105107819097224 and parameters: {'n_hidden': 4, 'learning_rate': 0.004022785139066977, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06612452034947783, 'dropout_rate_Layer_2': 0.34283014081273283, 'dropout_rate_Layer_3': 0.043521466285950716, 'dropout_rate_Layer_4': 0.047141095764868725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 5.709656607305965e-05, 'l1_Layer_2': 0.06203410753821125, 'l1_Layer_3': 0.0010914825586212712, 'l1_Layer_4': 8.882588027076884e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 170, 'n_units_Layer_4': 105}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:02,571]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:07,403]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:08,768]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:10,369]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:18,913]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:19,337]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:19,950]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:26,042]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:29,398]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:32,853]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:37,493]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:42,582]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:31:48,564]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 16.37% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.26 | sMAPE for Test Set is: 27.37% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:31:51,403]\u001b[0m Trial 182 finished with value: 5.837835107675478 and parameters: {'n_hidden': 4, 'learning_rate': 0.021231262410058512, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05107461328543595, 'dropout_rate_Layer_2': 0.20853235764694392, 'dropout_rate_Layer_3': 0.025656302299844988, 'dropout_rate_Layer_4': 0.2874567694771185, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.2337167788844365e-05, 'l1_Layer_2': 0.000480646506366093, 'l1_Layer_3': 1.9020300356185647e-05, 'l1_Layer_4': 0.0004632055198211873, 'n_units_Layer_1': 185, 'n_units_Layer_2': 120, 'n_units_Layer_3': 65, 'n_units_Layer_4': 285}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:03,799]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:16,527]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:21,725]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:23,712]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:27,358]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:31,221]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:37,671]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:42,599]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:44,599]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:47,027]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:55,344]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:55,506]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:32:56,651]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:04,236]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:05,003]\u001b[0m Trial 213 finished with value: 5.87336636215615 and parameters: {'n_hidden': 3, 'learning_rate': 0.01581295271881584, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13291212749326195, 'dropout_rate_Layer_2': 0.21520896599585382, 'dropout_rate_Layer_3': 0.19594593532217547, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001862322807107032, 'l1_Layer_2': 1.019481530635717e-05, 'l1_Layer_3': 0.00022590595673837097, 'n_units_Layer_1': 140, 'n_units_Layer_2': 65, 'n_units_Layer_3': 135}. Best is trial 1 with value: 5.755275501121578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 16.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.59 | sMAPE for Test Set is: 28.02% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:33:05,327]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:12,293]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:14,888]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:15,134]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:19,023]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:25,154]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:25,406]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:25,623]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:35,583]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:36,373]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:40,670]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:42,438]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:46,408]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:47,403]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:52,471]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:54,438]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:33:58,475]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:00,146]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:00,659]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 16.03% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.27 | sMAPE for Test Set is: 26.97% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:34:02,566]\u001b[0m Trial 223 finished with value: 5.730404767475093 and parameters: {'n_hidden': 3, 'learning_rate': 0.009199728066266804, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13242167376753042, 'dropout_rate_Layer_2': 0.28729226562823523, 'dropout_rate_Layer_3': 0.23196283360017467, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0003642620527173177, 'l1_Layer_2': 1.4991225010536712e-05, 'l1_Layer_3': 0.0008150875820676956, 'n_units_Layer_1': 155, 'n_units_Layer_2': 100, 'n_units_Layer_3': 130}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:09,348]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:09,800]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:10,408]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:15,631]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:24,627]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:26,372]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:29,612]\u001b[0m Trial 245 finished with value: 6.133925600824409 and parameters: {'n_hidden': 3, 'learning_rate': 0.006924301776740522, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1370159675167966, 'dropout_rate_Layer_2': 0.25840947445067775, 'dropout_rate_Layer_3': 0.2236482380056802, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003167396313907746, 'l1_Layer_2': 1.1917850546124718e-05, 'l1_Layer_3': 0.0006141211317561131, 'n_units_Layer_1': 130, 'n_units_Layer_2': 55, 'n_units_Layer_3': 100}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 17.02% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.75 | sMAPE for Test Set is: 31.53% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:34:31,575]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:33,902]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:38,628]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:39,016]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:43,640]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:44,009]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:53,899]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:34:53,986]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:35:03,094]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:35:03,275]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:35:11,631]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:35:13,480]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:35:19,003]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:35:31,449]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:35:32,154]\u001b[0m Trial 255 finished with value: 6.202190240783621 and parameters: {'n_hidden': 4, 'learning_rate': 0.004851573764862325, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1332046278077352, 'dropout_rate_Layer_2': 0.21014747861696254, 'dropout_rate_Layer_3': 0.17914969085020332, 'dropout_rate_Layer_4': 0.042694693757551944, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.773970399149577e-05, 'l1_Layer_2': 0.054834903952822166, 'l1_Layer_3': 0.0017659135274891375, 'l1_Layer_4': 0.00017750962568296584, 'n_units_Layer_1': 270, 'n_units_Layer_2': 130, 'n_units_Layer_3': 205, 'n_units_Layer_4': 295}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.71 | sMAPE for Test Set is: 28.62% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:35:50,679]\u001b[0m Trial 263 finished with value: 6.101820039251884 and parameters: {'n_hidden': 3, 'learning_rate': 0.012849825963331426, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09839003383153752, 'dropout_rate_Layer_2': 0.30092667005516444, 'dropout_rate_Layer_3': 0.19626464034301666, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.8468661246366232e-05, 'l1_Layer_2': 2.4795431439119482e-05, 'l1_Layer_3': 0.00024739316124652925, 'n_units_Layer_1': 300, 'n_units_Layer_2': 75, 'n_units_Layer_3': 130}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 16.88% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.39 | sMAPE for Test Set is: 30.54% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:35:51,509]\u001b[0m Trial 261 finished with value: 6.010529454957617 and parameters: {'n_hidden': 3, 'learning_rate': 0.008698923475379457, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10936733615699307, 'dropout_rate_Layer_2': 0.296396510728944, 'dropout_rate_Layer_3': 0.1952051817324271, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.5850926782301783e-05, 'l1_Layer_2': 2.2466129030914054e-05, 'l1_Layer_3': 0.00023648672012199857, 'n_units_Layer_1': 110, 'n_units_Layer_2': 75, 'n_units_Layer_3': 130}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 16.64% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.57 | sMAPE for Test Set is: 28.17% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:35:59,128]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:00,816]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:05,445]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:12,625]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:13,268]\u001b[0m Trial 266 finished with value: 6.1827382024395625 and parameters: {'n_hidden': 4, 'learning_rate': 0.003298656211436028, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14393835296412524, 'dropout_rate_Layer_2': 0.21139589050421004, 'dropout_rate_Layer_3': 0.17388918977730147, 'dropout_rate_Layer_4': 0.045263172934155715, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.621754940949629e-05, 'l1_Layer_2': 0.04984847104025006, 'l1_Layer_3': 0.0036555833080256102, 'l1_Layer_4': 8.005385633557493e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 115, 'n_units_Layer_3': 190, 'n_units_Layer_4': 245}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 29.18% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:36:20,349]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:24,952]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:25,564]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:26,016]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.45 | sMAPE for Test Set is: 27.89% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:36:30,678]\u001b[0m Trial 267 finished with value: 6.165496311494093 and parameters: {'n_hidden': 4, 'learning_rate': 0.003526330200131356, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13938555430993652, 'dropout_rate_Layer_2': 0.21015729375657888, 'dropout_rate_Layer_3': 0.17794889640072095, 'dropout_rate_Layer_4': 0.044914364033536984, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.511320020559344e-05, 'l1_Layer_2': 0.054594319466217615, 'l1_Layer_3': 0.003382034340033842, 'l1_Layer_4': 0.00014826092335648905, 'n_units_Layer_1': 255, 'n_units_Layer_2': 115, 'n_units_Layer_3': 190, 'n_units_Layer_4': 280}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:32,597]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:36,320]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:36,423]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:37,596]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:40,369]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:47,160]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:47,394]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:47,864]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:51,449]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:36:57,248]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:37:00,958]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:37:06,279]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:37:14,194]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:37:22,872]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:37:50,279]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:38:05,007]\u001b[0m Trial 293 finished with value: 6.098208065698934 and parameters: {'n_hidden': 3, 'learning_rate': 0.008967174230912936, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20905704951367193, 'dropout_rate_Layer_2': 0.17638079861164507, 'dropout_rate_Layer_3': 0.1237761325226581, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00011315882166050663, 'l1_Layer_2': 8.408824418772748e-05, 'l1_Layer_3': 0.00014859276713696044, 'n_units_Layer_1': 285, 'n_units_Layer_2': 50, 'n_units_Layer_3': 160}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 30.31% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:38:08,506]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:38:11,925]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:38:17,199]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:38:19,675]\u001b[0m Trial 294 finished with value: 6.035355556699373 and parameters: {'n_hidden': 4, 'learning_rate': 0.00413610013707892, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26874202025313304, 'dropout_rate_Layer_2': 0.22334119563666321, 'dropout_rate_Layer_3': 0.13192492790061508, 'dropout_rate_Layer_4': 0.07291103013451446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.344872939230889e-05, 'l1_Layer_2': 0.023676538038929478, 'l1_Layer_3': 0.0019876452192531583, 'l1_Layer_4': 0.00016993887194338394, 'n_units_Layer_1': 280, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195, 'n_units_Layer_4': 240}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 16.84% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.02 | sMAPE for Test Set is: 29.57% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:39:11,151]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:17,801]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:24,401]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:24,767]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:29,591]\u001b[0m Trial 298 finished with value: 6.014197903007992 and parameters: {'n_hidden': 4, 'learning_rate': 0.004953940951275033, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2371911828664961, 'dropout_rate_Layer_2': 0.2821701291278305, 'dropout_rate_Layer_3': 0.16996718246566322, 'dropout_rate_Layer_4': 0.04808062436913567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004972595932989396, 'l1_Layer_2': 0.0001141294673986337, 'l1_Layer_3': 1.0199757529770186e-05, 'l1_Layer_4': 0.003557849824421467, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 265, 'n_units_Layer_4': 115}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 16.76% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 30.92% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:39:32,856]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:35,606]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 16.50% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 26.44% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:39:36,607]\u001b[0m Trial 286 finished with value: 5.909812452624409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030354003384963227, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1127119571923147, 'dropout_rate_Layer_2': 0.22687912555089074, 'dropout_rate_Layer_3': 0.24328859326202776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.8320254350370105e-05, 'l1_Layer_2': 0.08303485177329119, 'l1_Layer_3': 0.0026564924419330903, 'n_units_Layer_1': 130, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:42,009]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:44,584]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:44,856]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:49,147]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:49,900]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:50,294]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:57,632]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:39:59,003]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:40:03,273]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:40:05,352]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:40:10,053]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:40:10,859]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:40:15,719]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:40:17,962]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:40:21,951]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:40:23,926]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:40:27,861]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:40:34,378]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:40:43,314]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:40:55,138]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:41:22,035]\u001b[0m Trial 321 finished with value: 5.976948427546847 and parameters: {'n_hidden': 3, 'learning_rate': 0.026960912035057686, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.060559259970160075, 'dropout_rate_Layer_2': 0.31472536574985144, 'dropout_rate_Layer_3': 0.2502202418722252, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017635224658380056, 'l1_Layer_2': 1.5286675669656522e-05, 'l1_Layer_3': 7.184331007879384e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 95, 'n_units_Layer_3': 130}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 16.87% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.36 | sMAPE for Test Set is: 24.36% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:41:30,148]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:41:43,190]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:41:46,536]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:41:47,228]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:41:59,439]\u001b[0m Trial 326 finished with value: 6.1397197015680645 and parameters: {'n_hidden': 4, 'learning_rate': 0.004352024504407467, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15634310396508463, 'dropout_rate_Layer_2': 0.22936933717814711, 'dropout_rate_Layer_3': 0.18921380718883296, 'dropout_rate_Layer_4': 0.07673240425656702, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.249965742430846e-05, 'l1_Layer_2': 0.0445345329104308, 'l1_Layer_3': 0.001684349013413641, 'l1_Layer_4': 0.0004342347000215616, 'n_units_Layer_1': 105, 'n_units_Layer_2': 120, 'n_units_Layer_3': 195, 'n_units_Layer_4': 300}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 17.16% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.92 | sMAPE for Test Set is: 29.23% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:42:12,884]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:42:17,108]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:42:33,456]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:42:43,147]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:42:47,025]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:43:01,765]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:43:10,994]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:43:20,400]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:43:20,944]\u001b[0m Trial 331 finished with value: 6.172163697798603 and parameters: {'n_hidden': 4, 'learning_rate': 0.004226877336924893, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14117105334608493, 'dropout_rate_Layer_2': 0.2144079049974205, 'dropout_rate_Layer_3': 0.2227823562687828, 'dropout_rate_Layer_4': 0.07950742967244194, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.925119390397966e-05, 'l1_Layer_2': 0.04416965304615096, 'l1_Layer_3': 0.0019598815491517667, 'l1_Layer_4': 5.33113496387131e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 195, 'n_units_Layer_4': 245}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 17.22% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.32 | sMAPE for Test Set is: 30.43% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:43:33,341]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:43:44,268]\u001b[0m Trial 338 finished with value: 6.253738400221316 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022649446866828777, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2831404952755722, 'dropout_rate_Layer_2': 0.2654489556405542, 'dropout_rate_Layer_3': 0.09680031404933542, 'dropout_rate_Layer_4': 0.028621220264329637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002832032548472158, 'l1_Layer_2': 0.000818074394658685, 'l1_Layer_3': 1.4082236748764124e-05, 'l1_Layer_4': 0.013411883503876974, 'n_units_Layer_1': 75, 'n_units_Layer_2': 150, 'n_units_Layer_3': 250, 'n_units_Layer_4': 125}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 17.39% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.87 | sMAPE for Test Set is: 31.69% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:43:45,288]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:43:48,595]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:44:06,462]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:44:11,113]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:44:17,536]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:44:21,055]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:44:21,435]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:44:33,056]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:44:49,077]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:45:00,701]\u001b[0m Trial 349 finished with value: 5.817453839428154 and parameters: {'n_hidden': 3, 'learning_rate': 0.010301746594353652, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11548724217933552, 'dropout_rate_Layer_2': 0.3105702148019867, 'dropout_rate_Layer_3': 0.24973507839905226, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 9.739886807575691e-05, 'l1_Layer_2': 1.0084636311819967e-05, 'l1_Layer_3': 0.0001695224202270426, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 120}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 16.30% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.02 | sMAPE for Test Set is: 29.56% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:45:01,033]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:45:07,107]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:45:13,955]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:45:17,842]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:46:05,873]\u001b[0m Trial 357 finished with value: 6.10081019359816 and parameters: {'n_hidden': 4, 'learning_rate': 0.002990885334030422, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14508161992222277, 'dropout_rate_Layer_2': 0.19936205453070255, 'dropout_rate_Layer_3': 0.21846927378970357, 'dropout_rate_Layer_4': 0.07167487354415578, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.5311718391227096e-05, 'l1_Layer_2': 0.06380065308888472, 'l1_Layer_3': 0.0019367121580758408, 'l1_Layer_4': 9.205287972718927e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 210, 'n_units_Layer_4': 230}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 17.06% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.80 | sMAPE for Test Set is: 28.94% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:46:12,459]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:46:17,247]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:46:21,490]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:46:36,939]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:46:39,717]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:46:40,474]\u001b[0m Trial 350 finished with value: 6.175350108555132 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016221652371032668, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2973615787769086, 'dropout_rate_Layer_2': 0.2613125506313641, 'dropout_rate_Layer_3': 0.16292429838087377, 'dropout_rate_Layer_4': 0.0024948762492916637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002407029482396329, 'l1_Layer_2': 0.0007975735977229286, 'l1_Layer_3': 1.618722521623994e-05, 'l1_Layer_4': 0.012041871493227777, 'n_units_Layer_1': 70, 'n_units_Layer_2': 140, 'n_units_Layer_3': 230, 'n_units_Layer_4': 140}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.79 | sMAPE for Test Set is: 31.52% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:47:41,381]\u001b[0m Trial 360 finished with value: 6.092015052871776 and parameters: {'n_hidden': 4, 'learning_rate': 0.002717473910512293, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13902323209800857, 'dropout_rate_Layer_2': 0.19333381874812294, 'dropout_rate_Layer_3': 0.2076578949800849, 'dropout_rate_Layer_4': 0.07576628103578321, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.9088694770657564e-05, 'l1_Layer_2': 0.06435019894188033, 'l1_Layer_3': 0.001974563367582309, 'l1_Layer_4': 5.412908315248328e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 105, 'n_units_Layer_3': 210, 'n_units_Layer_4': 225}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.61 | sMAPE for Test Set is: 28.43% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:48:05,130]\u001b[0m Trial 363 finished with value: 6.125343177997867 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026968223718667446, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11888247082918037, 'dropout_rate_Layer_2': 0.19907048821460518, 'dropout_rate_Layer_3': 0.18748333540293824, 'dropout_rate_Layer_4': 0.07113254687695127, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.692013228468497e-05, 'l1_Layer_2': 0.061227082456892234, 'l1_Layer_3': 0.04364945770272628, 'l1_Layer_4': 9.787166473886443e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200, 'n_units_Layer_4': 220}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.03 | sMAPE for Test Set is: 29.59% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:48:13,186]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:48:13,592]\u001b[0m Trial 364 finished with value: 6.048929911454519 and parameters: {'n_hidden': 4, 'learning_rate': 0.002664512206930279, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11719080799937316, 'dropout_rate_Layer_2': 0.23117052771100938, 'dropout_rate_Layer_3': 0.21904529067564518, 'dropout_rate_Layer_4': 0.07104850040905755, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.616720416629112e-05, 'l1_Layer_2': 0.05965887148981297, 'l1_Layer_3': 0.002040928016997443, 'l1_Layer_4': 5.45213645013465e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 105, 'n_units_Layer_3': 210, 'n_units_Layer_4': 220}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.05 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.68 | sMAPE for Test Set is: 28.64% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:48:25,524]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:48:42,042]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:48:46,211]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:48:49,561]\u001b[0m Trial 365 finished with value: 5.744810981182191 and parameters: {'n_hidden': 3, 'learning_rate': 0.005792013329590899, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08970832810764041, 'dropout_rate_Layer_2': 0.33667656598495127, 'dropout_rate_Layer_3': 0.2859696130181312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 9.849905007725942e-05, 'l1_Layer_2': 0.005699822712490234, 'l1_Layer_3': 6.186730968393413e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 50, 'n_units_Layer_3': 105}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 16.15% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.82 | sMAPE for Test Set is: 28.94% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:48:58,469]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:49:57,309]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:50:01,486]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:50:06,032]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:50:15,033]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:50:26,362]\u001b[0m Trial 367 finished with value: 5.8477643170703075 and parameters: {'n_hidden': 3, 'learning_rate': 0.005530445764607331, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1433839162960362, 'dropout_rate_Layer_2': 0.33507879005659746, 'dropout_rate_Layer_3': 0.25938801981249, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00010337880897195535, 'l1_Layer_2': 0.0058225828053756635, 'l1_Layer_3': 6.568505318317852e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 16.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.18 | sMAPE for Test Set is: 27.02% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:50:36,857]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:50:41,420]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:50:47,262]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:50:54,453]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:50:57,627]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:51:01,856]\u001b[0m Trial 368 finished with value: 5.930790612870756 and parameters: {'n_hidden': 4, 'learning_rate': 0.00152509286005445, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26634037039548253, 'dropout_rate_Layer_2': 0.2661551756792713, 'dropout_rate_Layer_3': 0.13955833845048507, 'dropout_rate_Layer_4': 0.009375278892041209, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001336567657979094, 'l1_Layer_2': 0.0007718171525278655, 'l1_Layer_3': 1.675944772889874e-05, 'l1_Layer_4': 0.007165918291983195, 'n_units_Layer_1': 80, 'n_units_Layer_2': 135, 'n_units_Layer_3': 215, 'n_units_Layer_4': 160}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 16.64% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.10 | sMAPE for Test Set is: 29.75% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:51:23,483]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:51:29,097]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:52:00,155]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:52:10,172]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:52:14,786]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:52:21,912]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:52:27,171]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:52:32,181]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:52:35,163]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:52:42,476]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:53:04,969]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:53:08,692]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:53:13,355]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:53:18,834]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:53:26,414]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:53:38,527]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:53:44,550]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:53:47,488]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:53:56,084]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:53:59,143]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:54:08,658]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:54:26,636]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:55:09,914]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:55:24,762]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:55:27,428]\u001b[0m Trial 404 finished with value: 6.205936205071889 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024664980243147908, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3740904822147628, 'dropout_rate_Layer_2': 0.19399941103138305, 'dropout_rate_Layer_3': 0.16972115128535328, 'dropout_rate_Layer_4': 0.07598267743065125, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.4257516446480559e-05, 'l1_Layer_2': 0.03578410641459211, 'l1_Layer_3': 0.0013194965187908014, 'l1_Layer_4': 9.536279563610827e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 80, 'n_units_Layer_3': 230, 'n_units_Layer_4': 205}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.67 | sMAPE for Test Set is: 31.27% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:55:31,329]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:55:31,382]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:55:31,638]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:55:35,165]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:55:42,175]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:55:46,287]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:55:49,079]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:55:52,473]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:55:52,996]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:56:00,331]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:56:03,090]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:56:03,384]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:56:12,886]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:56:17,607]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:56:29,963]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:56:43,457]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:56:58,599]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:57:13,600]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:57:24,939]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:57:34,535]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:57:38,909]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:57:42,394]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:57:50,357]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:57:54,707]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:58:10,127]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:58:41,742]\u001b[0m Trial 424 finished with value: 5.902612452578058 and parameters: {'n_hidden': 4, 'learning_rate': 0.002492370335153788, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27768320776983707, 'dropout_rate_Layer_2': 0.2634908353975177, 'dropout_rate_Layer_3': 0.14986419296732173, 'dropout_rate_Layer_4': 0.009881684470301529, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0017258612015585962, 'l1_Layer_2': 0.0005252222313944002, 'l1_Layer_3': 1.1842461476519464e-05, 'l1_Layer_4': 0.0047866932674212785, 'n_units_Layer_1': 70, 'n_units_Layer_2': 120, 'n_units_Layer_3': 220, 'n_units_Layer_4': 150}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 16.57% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.09 | sMAPE for Test Set is: 29.74% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:58:45,444]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:58:46,020]\u001b[0m Trial 422 finished with value: 5.867975951501999 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016357892844363236, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32157744347175965, 'dropout_rate_Layer_2': 0.24225250953643557, 'dropout_rate_Layer_3': 0.16474805321840394, 'dropout_rate_Layer_4': 0.010003139165880427, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0011321948398878166, 'l1_Layer_2': 0.0012034821006357398, 'l1_Layer_3': 1.4498319965443061e-05, 'l1_Layer_4': 0.004898876584914633, 'n_units_Layer_1': 95, 'n_units_Layer_2': 105, 'n_units_Layer_3': 210, 'n_units_Layer_4': 170}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 16.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.08 | sMAPE for Test Set is: 29.64% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:58:51,880]\u001b[0m Trial 434 finished with value: 6.255866461146478 and parameters: {'n_hidden': 4, 'learning_rate': 0.003970927205493945, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1374792461421174, 'dropout_rate_Layer_2': 0.20975846009837165, 'dropout_rate_Layer_3': 0.24205909936055647, 'dropout_rate_Layer_4': 0.08115914222198613, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.048327248387248e-05, 'l1_Layer_2': 0.043387721711353903, 'l1_Layer_3': 0.0019580616543473507, 'l1_Layer_4': 5.201964165414326e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195, 'n_units_Layer_4': 240}. Best is trial 223 with value: 5.730404767475093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 17.42% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.17 | sMAPE for Test Set is: 30.03% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:58:56,227]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:58:58,600]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:59:02,932]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:59:11,988]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:59:20,222]\u001b[0m Trial 435 finished with value: 5.623345480799897 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013134135148927327, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29819442874278157, 'dropout_rate_Layer_2': 0.233460475854143, 'dropout_rate_Layer_3': 0.12820748497699133, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018821130224921034, 'l1_Layer_2': 0.0007754921205987321, 'l1_Layer_3': 2.9709524067935532e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 155, 'n_units_Layer_3': 205}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 15.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 25.72% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:59:27,810]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:59:46,291]\u001b[0m Trial 438 finished with value: 6.403606790990136 and parameters: {'n_hidden': 4, 'learning_rate': 0.004023549762911832, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32904562867115716, 'dropout_rate_Layer_2': 0.20706462014365945, 'dropout_rate_Layer_3': 0.23939318896947098, 'dropout_rate_Layer_4': 0.03220078100907363, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.0318737077758735e-05, 'l1_Layer_2': 0.04139332764099885, 'l1_Layer_3': 0.0020327861350664853, 'l1_Layer_4': 5.777852437101178e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 105, 'n_units_Layer_3': 195, 'n_units_Layer_4': 260}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 17.74% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 8.44 | sMAPE for Test Set is: 30.74% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 02:59:48,518]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:59:54,231]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 02:59:56,128]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:00:08,822]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:00:27,623]\u001b[0m Trial 443 finished with value: 6.2517953553457275 and parameters: {'n_hidden': 4, 'learning_rate': 0.0056616234407492, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1746155665238626, 'dropout_rate_Layer_2': 0.18354870505405133, 'dropout_rate_Layer_3': 0.20819158079079017, 'dropout_rate_Layer_4': 0.032001103808139156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0005660990929916684, 'l1_Layer_2': 0.06179050683935232, 'l1_Layer_3': 0.0021949235160348057, 'l1_Layer_4': 0.00011111399299596869, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 180, 'n_units_Layer_4': 260}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 7.81 | sMAPE for Test Set is: 28.85% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:00:27,946]\u001b[0m Trial 440 finished with value: 6.218913983819204 and parameters: {'n_hidden': 4, 'learning_rate': 0.005240062058093735, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1729970187190003, 'dropout_rate_Layer_2': 0.18081212963574322, 'dropout_rate_Layer_3': 0.2187211328108756, 'dropout_rate_Layer_4': 0.07030792982762911, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.7612543974918874e-05, 'l1_Layer_2': 0.0627783356599247, 'l1_Layer_3': 0.002643630294463393, 'l1_Layer_4': 0.00011742484905308827, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 200, 'n_units_Layer_4': 240}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.55 | sMAPE for Test Set is: 31.00% | rMAE for Test Set is: 1.02\n",
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.86 | sMAPE for Test Set is: 29.04% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:00:40,252]\u001b[0m Trial 449 finished with value: 6.15034632263681 and parameters: {'n_hidden': 4, 'learning_rate': 0.005806478580258182, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1719696166199147, 'dropout_rate_Layer_2': 0.24108887952049388, 'dropout_rate_Layer_3': 0.20893381334490177, 'dropout_rate_Layer_4': 0.10430798967837351, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.5246730021044124e-05, 'l1_Layer_2': 0.04706633224895273, 'l1_Layer_3': 0.004017767649440776, 'l1_Layer_4': 0.00010222768689586002, 'n_units_Layer_1': 225, 'n_units_Layer_2': 145, 'n_units_Layer_3': 180, 'n_units_Layer_4': 210}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:00:58,289]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:01:27,014]\u001b[0m Trial 451 finished with value: 5.666520192174718 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014362361326733222, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3000266418358084, 'dropout_rate_Layer_2': 0.20786868155672975, 'dropout_rate_Layer_3': 0.13644598833759877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017711810421522014, 'l1_Layer_2': 0.0007963300903362603, 'l1_Layer_3': 2.920443376043098e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 95, 'n_units_Layer_3': 210}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 15.98% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 26.56% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:01:32,419]\u001b[0m Trial 450 finished with value: 5.627455997906584 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014976295597759306, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2945500953809935, 'dropout_rate_Layer_2': 0.23676204019018246, 'dropout_rate_Layer_3': 0.137639894106844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019129749274195338, 'l1_Layer_2': 0.0008755380148786574, 'l1_Layer_3': 3.1034836359154866e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 150, 'n_units_Layer_3': 215}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 15.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.26 | sMAPE for Test Set is: 23.86% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:01:37,234]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:01:41,669]\u001b[0m Trial 452 finished with value: 5.62802179256187 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014777707265268484, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3024091007969018, 'dropout_rate_Layer_2': 0.20806251846467524, 'dropout_rate_Layer_3': 0.13649632285662744, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018874090079132094, 'l1_Layer_2': 0.0008457694453803818, 'l1_Layer_3': 3.1222489914831705e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 215}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 15.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 24.74% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:01:49,616]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:01:58,089]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:02:03,368]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:02:06,448]\u001b[0m Trial 454 finished with value: 5.6688564012170515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015132678463511292, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2939476334115866, 'dropout_rate_Layer_2': 0.20735934173438214, 'dropout_rate_Layer_3': 0.1413336940247883, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023925310481497167, 'l1_Layer_2': 0.0008815790109111145, 'l1_Layer_3': 3.059088197794414e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 95, 'n_units_Layer_3': 210}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 15.96% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 24.76% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:02:10,433]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:02:12,908]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:02:16,668]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:02:33,882]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:02:38,532]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:02:45,159]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:03:22,411]\u001b[0m Trial 464 finished with value: 5.708890733310409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015718103867109255, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3044142592517214, 'dropout_rate_Layer_2': 0.20447859249299566, 'dropout_rate_Layer_3': 0.13349455874996582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002462412488386314, 'l1_Layer_2': 1.4056235372342733e-05, 'l1_Layer_3': 4.32990099966993e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 155, 'n_units_Layer_3': 215}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 16.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.70 | sMAPE for Test Set is: 28.63% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:03:31,849]\u001b[0m Trial 458 finished with value: 5.721345172643218 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016278572812373684, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3050887038419053, 'dropout_rate_Layer_2': 0.20633164830311695, 'dropout_rate_Layer_3': 0.15992714091297777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025750757488170765, 'l1_Layer_2': 0.0010238353399380793, 'l1_Layer_3': 2.502239782155406e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 100, 'n_units_Layer_3': 215}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 16.05% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 25.81% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:03:37,780]\u001b[0m Trial 466 finished with value: 5.668886797326015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016381361012679342, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3133656587939216, 'dropout_rate_Layer_2': 0.207904706683081, 'dropout_rate_Layer_3': 0.13815383052336433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002608993737952777, 'l1_Layer_2': 1.0242917195588125e-05, 'l1_Layer_3': 2.4528317657785292e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 155, 'n_units_Layer_3': 215}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 15.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 27.55% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:03:46,121]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:03:56,909]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:04:03,589]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:04:18,164]\u001b[0m Trial 469 finished with value: 5.955979454486287 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036321409495669236, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10659655725684247, 'dropout_rate_Layer_2': 0.2337378203873589, 'dropout_rate_Layer_3': 0.2251353844031796, 'dropout_rate_Layer_4': 0.07858223388446466, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.6524861906079463e-05, 'l1_Layer_2': 0.025918391059963915, 'l1_Layer_3': 0.001169827159891963, 'l1_Layer_4': 6.737040083745298e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 155, 'n_units_Layer_3': 205, 'n_units_Layer_4': 220}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 16.68% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.48 | sMAPE for Test Set is: 27.97% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:04:41,915]\u001b[0m Trial 468 finished with value: 5.800251518814258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038449953814130183, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.051285853589149805, 'dropout_rate_Layer_2': 0.3769850611530243, 'dropout_rate_Layer_3': 0.21450729846537778, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00037511402964218743, 'l1_Layer_2': 0.0011053355389850795, 'l1_Layer_3': 0.00018786838162088704, 'n_units_Layer_1': 195, 'n_units_Layer_2': 135, 'n_units_Layer_3': 125}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 16.25% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.18 | sMAPE for Test Set is: 27.00% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:05:06,850]\u001b[0m Trial 475 finished with value: 5.995984174081954 and parameters: {'n_hidden': 3, 'learning_rate': 0.008445171057094615, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11041915928358662, 'dropout_rate_Layer_2': 0.3153140789162706, 'dropout_rate_Layer_3': 0.19939330413627648, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.2954740496995113e-05, 'l1_Layer_2': 1.3360746404377745e-05, 'l1_Layer_3': 0.00025794992099850337, 'n_units_Layer_1': 85, 'n_units_Layer_2': 75, 'n_units_Layer_3': 115}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 16.70% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.64 | sMAPE for Test Set is: 28.43% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:05:16,164]\u001b[0m Trial 474 finished with value: 5.716088253035449 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016496989272018559, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31526627705872495, 'dropout_rate_Layer_2': 0.20317519521478172, 'dropout_rate_Layer_3': 0.137934379187904, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022661142626546633, 'l1_Layer_2': 1.340135925635312e-05, 'l1_Layer_3': 3.517129916173242e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 215}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 16.02% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.40 | sMAPE for Test Set is: 27.75% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:05:42,595]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:05:57,267]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:06:01,614]\u001b[0m Trial 476 finished with value: 5.7568826959919015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015856027042947525, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3210586516958018, 'dropout_rate_Layer_2': 0.20441010692745623, 'dropout_rate_Layer_3': 0.14032584196063924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023517262186290976, 'l1_Layer_2': 1.5159267730189315e-05, 'l1_Layer_3': 4.6426389892557644e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 100, 'n_units_Layer_3': 215}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 16.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.69 | sMAPE for Test Set is: 28.56% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:06:08,833]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:06:21,035]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:06:28,802]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:07:00,546]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:07:02,704]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 16.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.20 | sMAPE for Test Set is: 27.10% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:07:03,692]\u001b[0m Trial 480 finished with value: 5.705357974463557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011788475348305856, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3366727978747283, 'dropout_rate_Layer_2': 0.21174213071086434, 'dropout_rate_Layer_3': 0.1352880056780294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002772694918580545, 'l1_Layer_2': 1.8529827207842726e-05, 'l1_Layer_3': 4.563468763512239e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:07:12,230]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:07:12,345]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:07:12,850]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:07:27,776]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:07:34,788]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:07:41,591]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:07:42,202]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:07:45,633]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:08:03,945]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:08:50,686]\u001b[0m Trial 490 finished with value: 5.763664901607309 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010583150183632497, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3237887798978143, 'dropout_rate_Layer_2': 0.2127560661482293, 'dropout_rate_Layer_3': 0.12564526931157655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019449441699608007, 'l1_Layer_2': 1.343275189693147e-05, 'l1_Layer_3': 3.367791338258682e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 16.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.09 | sMAPE for Test Set is: 26.72% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:08:53,437]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:09:10,656]\u001b[0m Trial 493 finished with value: 5.979395493644133 and parameters: {'n_hidden': 3, 'learning_rate': 0.011864888967704133, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1163948881937107, 'dropout_rate_Layer_2': 0.3501558137809621, 'dropout_rate_Layer_3': 0.24156585851575943, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00046891519581018483, 'l1_Layer_2': 0.021784010665929186, 'l1_Layer_3': 0.000325951335411717, 'n_units_Layer_1': 165, 'n_units_Layer_2': 95, 'n_units_Layer_3': 115}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 16.65% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.31 | sMAPE for Test Set is: 30.33% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:09:14,643]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:09:33,153]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:09:53,043]\u001b[0m Trial 499 finished with value: 5.674998339603289 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035103900325072677, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20821842210482058, 'dropout_rate_Layer_2': 0.3974415956116524, 'dropout_rate_Layer_3': 0.18770303599716376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.072019213660273e-05, 'l1_Layer_2': 0.0028664999975008543, 'l1_Layer_3': 4.479455573751826e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 60, 'n_units_Layer_3': 150}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 16.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.23 | sMAPE for Test Set is: 30.21% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:09:58,663]\u001b[0m Trial 495 finished with value: 5.705799388059692 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009915829472263223, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35020797582040214, 'dropout_rate_Layer_2': 0.21339995211244114, 'dropout_rate_Layer_3': 0.12658635430649326, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019217250653903442, 'l1_Layer_2': 1.3262369213738646e-05, 'l1_Layer_3': 3.861572510519078e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 80, 'n_units_Layer_3': 200}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 16.02% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 26.47% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:11:01,098]\u001b[0m Trial 498 finished with value: 5.643447833380886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009126183155140793, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3087232510372499, 'dropout_rate_Layer_2': 0.21562790898845624, 'dropout_rate_Layer_3': 0.14483031234462035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001956609074596043, 'l1_Layer_2': 1.9553929651262598e-05, 'l1_Layer_3': 2.6337305710540984e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 90, 'n_units_Layer_3': 190}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 15.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 27.01% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:11:15,485]\u001b[0m Trial 501 finished with value: 5.697244831863062 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012542685700475808, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3397159055976021, 'dropout_rate_Layer_2': 0.21489303846101449, 'dropout_rate_Layer_3': 0.14471322788953692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020213234454988897, 'l1_Layer_2': 1.9336359473314402e-05, 'l1_Layer_3': 2.7265949281851518e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 85, 'n_units_Layer_3': 205}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 15.97% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 27.39% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:11:24,834]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:11:32,084]\u001b[0m Trial 502 finished with value: 5.68896932293805 and parameters: {'n_hidden': 3, 'learning_rate': 0.001055789079505178, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3591550106569641, 'dropout_rate_Layer_2': 0.21633358173490902, 'dropout_rate_Layer_3': 0.14581036274747805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018162230810491197, 'l1_Layer_2': 2.062414196603091e-05, 'l1_Layer_3': 6.301775763482767e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 16.03% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.35 | sMAPE for Test Set is: 27.51% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:11:48,727]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:11:49,403]\u001b[0m Trial 503 finished with value: 5.679935853956354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012077855425713922, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.340483005827757, 'dropout_rate_Layer_2': 0.21468305720701109, 'dropout_rate_Layer_3': 0.12409194836049485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018215697781792217, 'l1_Layer_2': 2.029852944757697e-05, 'l1_Layer_3': 5.946966722510616e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 80, 'n_units_Layer_3': 195}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 16.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.26 | sMAPE for Test Set is: 27.31% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:11:57,414]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:11:57,692]\u001b[0m Trial 504 finished with value: 5.646309692428988 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028757370985752137, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22088704537046777, 'dropout_rate_Layer_2': 0.3756183396209092, 'dropout_rate_Layer_3': 0.18939576231993238, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 9.241170597169033e-05, 'l1_Layer_2': 0.0027823120178736773, 'l1_Layer_3': 0.0004734386434519342, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 170}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 15.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.53 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:12:22,137]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:12:31,946]\u001b[0m Trial 506 finished with value: 5.724452106735117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009133139129012703, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35135048292987864, 'dropout_rate_Layer_2': 0.21501457194685503, 'dropout_rate_Layer_3': 0.12159169545398031, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001909906396239796, 'l1_Layer_2': 1.9524943002967137e-05, 'l1_Layer_3': 4.5745625172172125e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 85, 'n_units_Layer_3': 195}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 16.10% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.25 | sMAPE for Test Set is: 27.26% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:12:42,392]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:12:55,498]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:13:48,086]\u001b[0m Trial 514 finished with value: 6.0825659781283745 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023880678443547513, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0856776310231451, 'dropout_rate_Layer_2': 0.2119717905701138, 'dropout_rate_Layer_3': 0.25238640437535537, 'dropout_rate_Layer_4': 0.01915079740994185, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.298073808466714e-05, 'l1_Layer_2': 0.013825565457159949, 'l1_Layer_3': 0.0012059610022316885, 'l1_Layer_4': 6.725467965089285e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 125, 'n_units_Layer_3': 180, 'n_units_Layer_4': 245}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 17.03% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.87 | sMAPE for Test Set is: 29.13% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:13:53,317]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:14:07,125]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:14:17,096]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:14:17,619]\u001b[0m Trial 511 finished with value: 5.693337317094678 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009247242931561991, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3480674077730918, 'dropout_rate_Layer_2': 0.21382551689525028, 'dropout_rate_Layer_3': 0.12646368761866184, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018431669469983851, 'l1_Layer_2': 1.2592446579088576e-05, 'l1_Layer_3': 4.5242966496837435e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 70, 'n_units_Layer_3': 195}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 16.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.11 | sMAPE for Test Set is: 26.86% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:14:22,864]\u001b[0m Trial 515 finished with value: 6.043310630112832 and parameters: {'n_hidden': 4, 'learning_rate': 0.001998282125231366, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10890727560300958, 'dropout_rate_Layer_2': 0.19251719632029643, 'dropout_rate_Layer_3': 0.24765283732485374, 'dropout_rate_Layer_4': 0.04203596872854957, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.3700376657690325e-05, 'l1_Layer_2': 0.024844602267191544, 'l1_Layer_3': 0.0011721441770442976, 'l1_Layer_4': 6.855998872459241e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 125, 'n_units_Layer_3': 185, 'n_units_Layer_4': 150}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 16.92% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 29.23% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:14:26,853]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:14:30,121]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:14:46,458]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 15.97% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.06 | sMAPE for Test Set is: 26.63% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:14:58,796]\u001b[0m Trial 512 finished with value: 5.688015151814153 and parameters: {'n_hidden': 3, 'learning_rate': 0.000939775761159709, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3513780723733843, 'dropout_rate_Layer_2': 0.21554390154125694, 'dropout_rate_Layer_3': 0.12647431946250048, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018454067912478936, 'l1_Layer_2': 1.836418832074801e-05, 'l1_Layer_3': 4.106205613019661e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 65, 'n_units_Layer_3': 190}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:15:32,948]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:15:51,874]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:16:01,330]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:16:20,683]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:16:32,035]\u001b[0m Trial 525 finished with value: 5.6710453847933096 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009405108095915832, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3641766672688729, 'dropout_rate_Layer_2': 0.202160365273181, 'dropout_rate_Layer_3': 0.10839551410488994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016967814815246885, 'l1_Layer_2': 1.97218116273327e-05, 'l1_Layer_3': 5.456650506830677e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 85, 'n_units_Layer_3': 190}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 15.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.36 | sMAPE for Test Set is: 27.63% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:16:32,899]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:16:43,962]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:16:50,532]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:16:54,560]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:17:07,249]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:17:13,344]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:17:17,005]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:17:24,399]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:17:48,395]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:17:54,401]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:18:34,886]\u001b[0m Trial 529 finished with value: 5.664011399825859 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007091488889289869, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35695979172808956, 'dropout_rate_Layer_2': 0.2229724214939274, 'dropout_rate_Layer_3': 0.1324732212688261, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001743384805662941, 'l1_Layer_2': 2.676451462508722e-05, 'l1_Layer_3': 4.315351615060218e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 75, 'n_units_Layer_3': 200}. Best is trial 435 with value: 5.623345480799897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 15.99% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 24.89% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:18:41,139]\u001b[0m Trial 523 finished with value: 5.564719139654987 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009296163672841744, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3696567129172214, 'dropout_rate_Layer_2': 0.191627824679463, 'dropout_rate_Layer_3': 0.13314189523126058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016541438987748432, 'l1_Layer_2': 1.983478111824843e-05, 'l1_Layer_3': 4.1111737696148484e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 523 with value: 5.564719139654987.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 15.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.23 | sMAPE for Test Set is: 27.29% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:19:08,999]\u001b[0m Trial 537 finished with value: 5.693200977714369 and parameters: {'n_hidden': 3, 'learning_rate': 0.00084216045009639, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36276862964998274, 'dropout_rate_Layer_2': 0.20312816322453187, 'dropout_rate_Layer_3': 0.11601919999367921, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018060713838672139, 'l1_Layer_2': 1.0009332738194314e-05, 'l1_Layer_3': 3.043143048685644e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200}. Best is trial 523 with value: 5.564719139654987.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 15.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 24.55% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:19:25,177]\u001b[0m Trial 542 finished with value: 5.741472418801078 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027785142041568257, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20847913614664304, 'dropout_rate_Layer_2': 0.3889636777699809, 'dropout_rate_Layer_3': 0.1715714695617879, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 5.710165451256e-05, 'l1_Layer_2': 0.002134077225768082, 'l1_Layer_3': 0.0003649456496260427, 'n_units_Layer_1': 175, 'n_units_Layer_2': 70, 'n_units_Layer_3': 170}. Best is trial 523 with value: 5.564719139654987.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 16.27% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.02 | sMAPE for Test Set is: 26.69% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:19:30,123]\u001b[0m Trial 541 finished with value: 5.6640680652490545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019496261602095387, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20410663625571637, 'dropout_rate_Layer_2': 0.388229438468725, 'dropout_rate_Layer_3': 0.13439686991406732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 5.2237677720202964e-05, 'l1_Layer_2': 0.0013598579769735662, 'l1_Layer_3': 0.0006194448856971988, 'n_units_Layer_1': 175, 'n_units_Layer_2': 70, 'n_units_Layer_3': 210}. Best is trial 523 with value: 5.564719139654987.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 15.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 26.44% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:19:35,721]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:19:36,207]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:20:34,162]\u001b[0m Trial 540 finished with value: 5.556149059389779 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008792257706318013, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35083134749787076, 'dropout_rate_Layer_2': 0.19289933490017705, 'dropout_rate_Layer_3': 0.11538453901361201, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002073293664065754, 'l1_Layer_2': 1.0259443416849482e-05, 'l1_Layer_3': 3.9378575200472655e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 90, 'n_units_Layer_3': 195}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 15.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.14 | sMAPE for Test Set is: 26.98% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:20:38,192]\u001b[0m Trial 543 finished with value: 5.57075356370688 and parameters: {'n_hidden': 3, 'learning_rate': 0.005660905653703269, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22843816999795252, 'dropout_rate_Layer_2': 0.39151245992686695, 'dropout_rate_Layer_3': 0.1714811931201192, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00010588896024294352, 'l1_Layer_2': 0.0060718221512005704, 'l1_Layer_3': 0.000613831119065197, 'n_units_Layer_1': 175, 'n_units_Layer_2': 70, 'n_units_Layer_3': 170}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 15.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 26.80% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:20:40,624]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:20:44,524]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:21:43,888]\u001b[0m Trial 551 finished with value: 6.265378221355559 and parameters: {'n_hidden': 4, 'learning_rate': 0.0042422128937757144, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13815346075292093, 'dropout_rate_Layer_2': 0.2191908164141369, 'dropout_rate_Layer_3': 0.21980155300064555, 'dropout_rate_Layer_4': 0.07697875184717047, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.9089881263446446e-05, 'l1_Layer_2': 0.04146671608734836, 'l1_Layer_3': 0.002648330215324682, 'l1_Layer_4': 5.575108543463772e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 120, 'n_units_Layer_3': 195, 'n_units_Layer_4': 245}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.95 | sMAPE for Test Set is: 32.15% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:21:44,695]\u001b[0m Trial 547 finished with value: 5.646251135383018 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006391632283321106, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36573600911104315, 'dropout_rate_Layer_2': 0.19339874534504706, 'dropout_rate_Layer_3': 0.11323540229360944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002289474354510327, 'l1_Layer_2': 1.0066894413563163e-05, 'l1_Layer_3': 5.5119295970708586e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 23.58% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:22:08,982]\u001b[0m Trial 546 finished with value: 5.6821924209949914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008633664965334349, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37996286588871553, 'dropout_rate_Layer_2': 0.20700840393350675, 'dropout_rate_Layer_3': 0.11362251230258164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002182750029824067, 'l1_Layer_2': 1.0403482537282746e-05, 'l1_Layer_3': 5.2679751313745655e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 16.06% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.18 | sMAPE for Test Set is: 27.03% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:22:19,715]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:22:35,568]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:22:54,626]\u001b[0m Trial 550 finished with value: 5.599498363313729 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007304442663038395, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38324139562307263, 'dropout_rate_Layer_2': 0.19561722888110303, 'dropout_rate_Layer_3': 0.11590514347738762, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021524740479168503, 'l1_Layer_2': 1.0248748573232182e-05, 'l1_Layer_3': 5.6413705437679974e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 90, 'n_units_Layer_3': 190}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 15.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 26.46% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:23:24,215]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:23:56,257]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:24:01,257]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:24:11,754]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:24:21,181]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:24:27,468]\u001b[0m Trial 555 finished with value: 5.691927887740749 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006459104117413617, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38458257071199925, 'dropout_rate_Layer_2': 0.19350817296820644, 'dropout_rate_Layer_3': 0.11218473963688509, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002136252219017177, 'l1_Layer_2': 1.0011002902917798e-05, 'l1_Layer_3': 5.426718314634554e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 16.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 26.75% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:24:36,456]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:24:40,600]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:24:50,413]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:25:00,929]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:25:09,168]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:25:29,094]\u001b[0m Trial 558 finished with value: 5.702682721255212 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006606949808366923, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3635733366247253, 'dropout_rate_Layer_2': 0.19561350043590162, 'dropout_rate_Layer_3': 0.10561835413394303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015967664137712134, 'l1_Layer_2': 1.0140714323897485e-05, 'l1_Layer_3': 5.442692568214885e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 50, 'n_units_Layer_3': 190}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 16.10% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.00 | sMAPE for Test Set is: 26.51% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:25:38,792]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:25:48,197]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:25:52,018]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:26:02,949]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:26:03,252]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:26:17,703]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:26:26,660]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:26:48,370]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:27:10,349]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:27:18,639]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:27:22,933]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:27:27,113]\u001b[0m Trial 571 finished with value: 5.656397482811627 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007956622409792573, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36594344059606937, 'dropout_rate_Layer_2': 0.1821571033629529, 'dropout_rate_Layer_3': 0.1130206176884385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015215491072111933, 'l1_Layer_2': 1.2032850760364317e-05, 'l1_Layer_3': 8.707695143084157e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 55, 'n_units_Layer_3': 185}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 15.91% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 27.02% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:28:06,839]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:28:27,288]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:28:31,301]\u001b[0m Trial 580 finished with value: 5.6059420209312805 and parameters: {'n_hidden': 3, 'learning_rate': 0.002705282946425033, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20456784793211105, 'dropout_rate_Layer_2': 0.3742587301702127, 'dropout_rate_Layer_3': 0.15879762954493612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00010673269977510357, 'l1_Layer_2': 0.0025493510299773726, 'l1_Layer_3': 0.0013438239627641807, 'n_units_Layer_1': 160, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 15.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 25.27% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:28:39,034]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:28:57,733]\u001b[0m Trial 577 finished with value: 5.700207498610797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007722291897824986, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3624969286486802, 'dropout_rate_Layer_2': 0.1837864289431206, 'dropout_rate_Layer_3': 0.11483987788918235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014964547709752525, 'l1_Layer_2': 2.5078963542823325e-05, 'l1_Layer_3': 5.5267165666503734e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 16.02% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 26.35% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:29:04,613]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:29:09,622]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:29:10,157]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:29:23,731]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:29:27,478]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:29:32,333]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:30:01,472]\u001b[0m Trial 581 finished with value: 5.67400639575731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006616809031659387, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3800812179793058, 'dropout_rate_Layer_2': 0.22342063720760827, 'dropout_rate_Layer_3': 0.11503920197455922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014642962223385706, 'l1_Layer_2': 1.6881728136767775e-05, 'l1_Layer_3': 6.596244797470589e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 55, 'n_units_Layer_3': 180}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 15.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 25.77% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:30:29,159]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:30:39,188]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:30:44,171]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:30:55,590]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:31:16,048]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:31:33,803]\u001b[0m Trial 591 finished with value: 5.707088279804037 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007349003715551496, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3981909005180391, 'dropout_rate_Layer_2': 0.22235956142373428, 'dropout_rate_Layer_3': 0.09520496449336105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015145278724892305, 'l1_Layer_2': 1.7302843089203568e-05, 'l1_Layer_3': 8.82841179578085e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 90, 'n_units_Layer_3': 180}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 16.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.25 | sMAPE for Test Set is: 27.24% | rMAE for Test Set is: 0.86\n",
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 17.17% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.81 | sMAPE for Test Set is: 28.95% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:31:36,062]\u001b[0m Trial 593 finished with value: 6.134575942663729 and parameters: {'n_hidden': 4, 'learning_rate': 0.003594806143575975, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10191690004949364, 'dropout_rate_Layer_2': 0.2401864523608198, 'dropout_rate_Layer_3': 0.13621816002630302, 'dropout_rate_Layer_4': 0.07551663990133342, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.7314720182579285e-05, 'l1_Layer_2': 0.03246351633386753, 'l1_Layer_3': 0.0029643735265392577, 'l1_Layer_4': 6.332645976955578e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 160, 'n_units_Layer_3': 185, 'n_units_Layer_4': 170}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:31:58,566]\u001b[0m Trial 589 finished with value: 5.641155224308178 and parameters: {'n_hidden': 3, 'learning_rate': 0.002852115709341629, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2030031438484364, 'dropout_rate_Layer_2': 0.37590934774227946, 'dropout_rate_Layer_3': 0.15833049689819123, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 5.6647004351052194e-05, 'l1_Layer_2': 0.0028830233867690926, 'l1_Layer_3': 0.0013806177571350753, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 210}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 15.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 26.36% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:32:04,131]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:32:17,347]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:32:26,127]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:32:34,095]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:32:34,648]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:32:45,719]\u001b[0m Trial 599 finished with value: 5.662263054377097 and parameters: {'n_hidden': 3, 'learning_rate': 0.002890230205956124, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19051668305569935, 'dropout_rate_Layer_2': 0.3986695358266251, 'dropout_rate_Layer_3': 0.16006596429439623, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.655025711858053e-05, 'l1_Layer_2': 0.004310012522726764, 'l1_Layer_3': 0.00048433340827947196, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 15.91% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.55 | sMAPE for Test Set is: 28.34% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:32:54,080]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:33:02,914]\u001b[0m Trial 598 finished with value: 5.682987200108321 and parameters: {'n_hidden': 3, 'learning_rate': 0.00344962186847007, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22926812508167382, 'dropout_rate_Layer_2': 0.3937728915525801, 'dropout_rate_Layer_3': 0.15871667229948092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 6.084537973517501e-05, 'l1_Layer_2': 0.00436126400013112, 'l1_Layer_3': 0.0004950695950031003, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 175}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 15.99% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.25 | sMAPE for Test Set is: 27.43% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:33:25,324]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:33:48,489]\u001b[0m Trial 605 finished with value: 5.633700097792642 and parameters: {'n_hidden': 3, 'learning_rate': 0.002814400706335173, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24517742374437118, 'dropout_rate_Layer_2': 0.3996201529380835, 'dropout_rate_Layer_3': 0.16027386288568235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 6.056490393055307e-05, 'l1_Layer_2': 0.0028252465158476055, 'l1_Layer_3': 0.0009034136625228632, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 205}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 15.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.11 | sMAPE for Test Set is: 26.92% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:34:06,331]\u001b[0m Trial 608 finished with value: 5.621448641649171 and parameters: {'n_hidden': 3, 'learning_rate': 0.002695389679465304, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19684581886374422, 'dropout_rate_Layer_2': 0.3996634458816731, 'dropout_rate_Layer_3': 0.16072635882008285, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.5036256387808215e-05, 'l1_Layer_2': 0.0030641886188939736, 'l1_Layer_3': 0.0019433013203680473, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 180}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 15.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.37 | sMAPE for Test Set is: 24.50% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:34:21,717]\u001b[0m Trial 606 finished with value: 6.161640052404707 and parameters: {'n_hidden': 4, 'learning_rate': 0.00417115426781916, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0968710914620136, 'dropout_rate_Layer_2': 0.2563964575774019, 'dropout_rate_Layer_3': 0.13159709725425284, 'dropout_rate_Layer_4': 0.07836315325178034, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.1368215563425605e-05, 'l1_Layer_2': 0.049874287333826914, 'l1_Layer_3': 0.0027100348413340064, 'l1_Layer_4': 6.445388262610836e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 165, 'n_units_Layer_3': 50, 'n_units_Layer_4': 230}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.21 | sMAPE for Test Set is: 30.06% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:34:54,601]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:34:58,410]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:35:36,326]\u001b[0m Trial 613 finished with value: 6.18389711529183 and parameters: {'n_hidden': 4, 'learning_rate': 0.004125903200262068, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10101031050527332, 'dropout_rate_Layer_2': 0.26011214811885053, 'dropout_rate_Layer_3': 0.1212942349115767, 'dropout_rate_Layer_4': 0.07435010144780749, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.332775654209756e-05, 'l1_Layer_2': 0.05055796181193998, 'l1_Layer_3': 0.003977297375451603, 'l1_Layer_4': 6.747976393833708e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 190, 'n_units_Layer_4': 230}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 30.35% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:35:56,651]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:36:01,878]\u001b[0m Trial 610 finished with value: 5.5939479030577175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008503739914816833, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36181261485949906, 'dropout_rate_Layer_2': 0.21949267948444587, 'dropout_rate_Layer_3': 0.11610946678822018, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001445473450304108, 'l1_Layer_2': 1.4139680670650208e-05, 'l1_Layer_3': 4.1021972883966204e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 70, 'n_units_Layer_3': 170}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 15.82% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 26.41% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:36:15,162]\u001b[0m Trial 615 finished with value: 5.588147812413548 and parameters: {'n_hidden': 3, 'learning_rate': 0.002854381619847694, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24610761415905502, 'dropout_rate_Layer_2': 0.39522463151698994, 'dropout_rate_Layer_3': 0.15995461220605628, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 5.814104760035412e-05, 'l1_Layer_2': 0.0029184684709117653, 'l1_Layer_3': 0.0018357900163160983, 'n_units_Layer_1': 185, 'n_units_Layer_2': 55, 'n_units_Layer_3': 210}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 15.74% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.08 | sMAPE for Test Set is: 26.89% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:36:23,966]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:36:37,351]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:36:59,520]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:37:07,590]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:37:14,592]\u001b[0m Trial 616 finished with value: 5.677663234572172 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007469445568430684, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3458719459042922, 'dropout_rate_Layer_2': 0.20820759846535292, 'dropout_rate_Layer_3': 0.113429633371365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017121672253882446, 'l1_Layer_2': 2.151625204044206e-05, 'l1_Layer_3': 4.94134157334249e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 65, 'n_units_Layer_3': 195}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 27.22% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:37:26,031]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:38:09,375]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:38:20,234]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:38:25,762]\u001b[0m Trial 624 finished with value: 5.652405871963147 and parameters: {'n_hidden': 3, 'learning_rate': 0.00275271202554128, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24587363845158372, 'dropout_rate_Layer_2': 0.3976920310657202, 'dropout_rate_Layer_3': 0.15906866622035504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.965222713472909e-05, 'l1_Layer_2': 0.002940507715685571, 'l1_Layer_3': 0.0037919507985927792, 'n_units_Layer_1': 185, 'n_units_Layer_2': 55, 'n_units_Layer_3': 210}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 15.89% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 26.49% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:38:31,593]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:38:42,018]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:39:10,302]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:39:55,944]\u001b[0m Trial 629 finished with value: 5.979441845963122 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026869242793373365, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10768981429253383, 'dropout_rate_Layer_2': 0.24033610567006874, 'dropout_rate_Layer_3': 0.11540565017151787, 'dropout_rate_Layer_4': 0.09055031582883157, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.896864237521179e-05, 'l1_Layer_2': 0.031789774675354675, 'l1_Layer_3': 0.0014968847996639492, 'l1_Layer_4': 4.042076175305119e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135, 'n_units_Layer_4': 240}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 16.65% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.64 | sMAPE for Test Set is: 28.56% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:40:12,882]\u001b[0m Trial 630 finished with value: 5.733974803359815 and parameters: {'n_hidden': 3, 'learning_rate': 0.003392764232153155, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26099046358873046, 'dropout_rate_Layer_2': 0.3986021048875203, 'dropout_rate_Layer_3': 0.15452654403272978, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.0516885999573947e-05, 'l1_Layer_2': 0.0040948223977136915, 'l1_Layer_3': 0.004439161356895698, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 16.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.48 | sMAPE for Test Set is: 28.10% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:40:21,507]\u001b[0m Trial 627 finished with value: 5.776429500242408 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012040150232067494, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33947240251618727, 'dropout_rate_Layer_2': 0.2071939954435634, 'dropout_rate_Layer_3': 0.11010345403298441, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022051005445382402, 'l1_Layer_2': 1.6739492038530695e-05, 'l1_Layer_3': 2.65231772804636e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 80, 'n_units_Layer_3': 195}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 16.25% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 28.27% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:40:27,910]\u001b[0m Trial 631 finished with value: 6.09193299699762 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026561184839771234, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10658055652619497, 'dropout_rate_Layer_2': 0.24423358535483003, 'dropout_rate_Layer_3': 0.13093954387310264, 'dropout_rate_Layer_4': 0.09121153740847798, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.9828941887829925e-05, 'l1_Layer_2': 0.03404618226516781, 'l1_Layer_3': 0.0016039615715898756, 'l1_Layer_4': 4.009780938084904e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 175, 'n_units_Layer_3': 115, 'n_units_Layer_4': 240}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 17.07% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.70 | sMAPE for Test Set is: 28.62% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:40:40,812]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:40:45,047]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:40:57,747]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:40:57,911]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:41:08,939]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:41:19,611]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:42:24,486]\u001b[0m Trial 639 finished with value: 6.036630058008865 and parameters: {'n_hidden': 4, 'learning_rate': 0.001976961851714464, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09069208253121608, 'dropout_rate_Layer_2': 0.24285659418792296, 'dropout_rate_Layer_3': 0.1351824589106355, 'dropout_rate_Layer_4': 0.09939010480493138, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.945271833927576e-05, 'l1_Layer_2': 0.029981121984969095, 'l1_Layer_3': 0.0013225783749138517, 'l1_Layer_4': 3.983734786983275e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 120, 'n_units_Layer_4': 240}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 16.94% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 28.31% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:42:30,648]\u001b[0m Trial 641 finished with value: 6.044401466575638 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019984441859791126, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1125972243545986, 'dropout_rate_Layer_2': 0.25316182010048804, 'dropout_rate_Layer_3': 0.13360752733972123, 'dropout_rate_Layer_4': 0.09617327609997867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.4904708042665092e-05, 'l1_Layer_2': 0.021498973025826013, 'l1_Layer_3': 0.0016075099778542034, 'l1_Layer_4': 3.2917135837256547e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 175, 'n_units_Layer_3': 130, 'n_units_Layer_4': 230}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 16.88% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.67 | sMAPE for Test Set is: 31.26% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:42:34,226]\u001b[0m Trial 637 finished with value: 5.974315752547991 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021033910154942934, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015784531474306078, 'dropout_rate_Layer_2': 0.2901290309484725, 'dropout_rate_Layer_3': 0.14220019462934919, 'dropout_rate_Layer_4': 0.09845818734361708, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.9744480643227034e-05, 'l1_Layer_2': 0.030220768425593052, 'l1_Layer_3': 0.0014563277081891938, 'l1_Layer_4': 3.979975191918207e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 130, 'n_units_Layer_4': 240}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 16.74% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.34 | sMAPE for Test Set is: 27.59% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:42:41,913]\u001b[0m Trial 638 finished with value: 6.025538060989239 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022607803402325223, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1145945150621368, 'dropout_rate_Layer_2': 0.2466087389677065, 'dropout_rate_Layer_3': 0.1320823844175855, 'dropout_rate_Layer_4': 0.10083119650760754, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.854917216964711e-05, 'l1_Layer_2': 0.03001438505104643, 'l1_Layer_3': 0.0013423433378970517, 'l1_Layer_4': 4.526915647252122e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 180, 'n_units_Layer_3': 130, 'n_units_Layer_4': 240}. Best is trial 540 with value: 5.556149059389779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 28.17% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:42:45,796]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:43:16,105]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:44:33,775]\u001b[0m Trial 643 finished with value: 5.549222480686905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007020606630437056, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38268569466707336, 'dropout_rate_Layer_2': 0.19854819760424658, 'dropout_rate_Layer_3': 0.12026238904122506, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001357193477308679, 'l1_Layer_2': 1.3780113318379903e-05, 'l1_Layer_3': 3.277598484170793e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 15.63% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.06 | sMAPE for Test Set is: 26.72% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:44:36,627]\u001b[0m Trial 647 finished with value: 5.972278936575246 and parameters: {'n_hidden': 4, 'learning_rate': 0.002029253076223743, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03042453130641519, 'dropout_rate_Layer_2': 0.24733186836896584, 'dropout_rate_Layer_3': 0.13491093025283438, 'dropout_rate_Layer_4': 0.12268617913906268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.5249670741622155e-05, 'l1_Layer_2': 0.019180443187796044, 'l1_Layer_3': 0.0012084643180198266, 'l1_Layer_4': 3.275873139010563e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125, 'n_units_Layer_4': 250}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 16.75% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.61 | sMAPE for Test Set is: 28.34% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:44:45,417]\u001b[0m Trial 646 finished with value: 5.690005915395819 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007821726592514383, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3338569483245059, 'dropout_rate_Layer_2': 0.21592889350836933, 'dropout_rate_Layer_3': 0.12189842697336888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010381339009293926, 'l1_Layer_2': 2.7072195695028922e-05, 'l1_Layer_3': 4.417921029400951e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 185}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 16.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.39 | sMAPE for Test Set is: 27.74% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:44:51,080]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:44:57,495]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:44:57,841]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:45:15,285]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:45:33,390]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:45:33,668]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:46:25,383]\u001b[0m Trial 652 finished with value: 6.099131600950018 and parameters: {'n_hidden': 4, 'learning_rate': 0.002061808573999091, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11359769929151753, 'dropout_rate_Layer_2': 0.2660388819953733, 'dropout_rate_Layer_3': 0.13843274154558716, 'dropout_rate_Layer_4': 0.11480340401069969, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.5204815062456884e-05, 'l1_Layer_2': 0.01935212237719544, 'l1_Layer_3': 0.001298621002863173, 'l1_Layer_4': 3.0016928123745693e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125, 'n_units_Layer_4': 245}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 28.08% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:47:14,214]\u001b[0m Trial 657 finished with value: 5.638502174293973 and parameters: {'n_hidden': 3, 'learning_rate': 0.002902147917788742, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25746814619907543, 'dropout_rate_Layer_2': 0.3817226372710247, 'dropout_rate_Layer_3': 0.1415891571859672, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.741537030450203e-05, 'l1_Layer_2': 0.0017963287652748331, 'l1_Layer_3': 0.001741223802011615, 'n_units_Layer_1': 180, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 15.79% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.01 | sMAPE for Test Set is: 26.63% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:47:23,100]\u001b[0m Trial 656 finished with value: 5.6521828591845775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006309935740429043, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3314130827433909, 'dropout_rate_Layer_2': 0.21765299074990327, 'dropout_rate_Layer_3': 0.13322472889409132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011374900635098759, 'l1_Layer_2': 2.2763431701284643e-05, 'l1_Layer_3': 3.883661141969473e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 55, 'n_units_Layer_3': 175}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 15.89% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.11 | sMAPE for Test Set is: 26.85% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:47:26,263]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:47:30,248]\u001b[0m Trial 655 finished with value: 5.712217217987921 and parameters: {'n_hidden': 3, 'learning_rate': 0.000616044276171237, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39372386411718285, 'dropout_rate_Layer_2': 0.21639571292026172, 'dropout_rate_Layer_3': 0.09674500733063678, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011372243816131747, 'l1_Layer_2': 2.879251512222427e-05, 'l1_Layer_3': 0.0001613129643344312, 'n_units_Layer_1': 90, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 16.05% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 24.99% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:47:33,822]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:47:42,282]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:47:47,963]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:47:55,528]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:47:59,925]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:48:11,897]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:48:17,332]\u001b[0m Trial 650 finished with value: 5.793243254416482 and parameters: {'n_hidden': 4, 'learning_rate': 0.001967169612774636, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11111530031506618, 'dropout_rate_Layer_2': 0.251802492143103, 'dropout_rate_Layer_3': 0.13165345885645022, 'dropout_rate_Layer_4': 0.10253968282133234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.5511515041228194e-05, 'l1_Layer_2': 0.015624032881316115, 'l1_Layer_3': 0.0012447371657029714, 'l1_Layer_4': 1.896022649939851e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125, 'n_units_Layer_4': 250}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 16.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.34 | sMAPE for Test Set is: 27.54% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:48:33,299]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:48:37,235]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:48:37,425]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:48:38,182]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:49:17,168]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:49:29,125]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:49:39,191]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:49:45,412]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:50:07,513]\u001b[0m Trial 671 finished with value: 6.010126649232329 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018045358236269318, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11820042974256163, 'dropout_rate_Layer_2': 0.2497554378497438, 'dropout_rate_Layer_3': 0.14909580214370852, 'dropout_rate_Layer_4': 0.10620675960236038, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.7367351418337374e-05, 'l1_Layer_2': 0.01852374945303359, 'l1_Layer_3': 0.0012843838970081397, 'l1_Layer_4': 2.662467618751014e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 180, 'n_units_Layer_3': 130, 'n_units_Layer_4': 255}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 16.82% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 27.44% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:50:12,512]\u001b[0m Trial 672 finished with value: 5.862364745841568 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023143283401745214, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12054897413781718, 'dropout_rate_Layer_2': 0.24619327734376817, 'dropout_rate_Layer_3': 0.11927091943556889, 'dropout_rate_Layer_4': 0.09695539334981715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.6812640326420933e-05, 'l1_Layer_2': 0.018967754647477145, 'l1_Layer_3': 0.0012016310661354735, 'l1_Layer_4': 2.4130887272960705e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 135, 'n_units_Layer_4': 255}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 16.47% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.61 | sMAPE for Test Set is: 28.30% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:50:21,289]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:50:52,864]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:51:03,261]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:51:24,005]\u001b[0m Trial 676 finished with value: 5.682095222433187 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010940112414642663, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3362658858785456, 'dropout_rate_Layer_2': 0.17500704128247724, 'dropout_rate_Layer_3': 0.13545719817905125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001579547114111292, 'l1_Layer_2': 1.1968270311683564e-05, 'l1_Layer_3': 6.185753411645952e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 55, 'n_units_Layer_3': 195}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 15.98% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.40 | sMAPE for Test Set is: 27.79% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:52:45,216]\u001b[0m Trial 680 finished with value: 5.659887473498865 and parameters: {'n_hidden': 3, 'learning_rate': 0.000701872330085279, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3274927165584984, 'dropout_rate_Layer_2': 0.1752885055875567, 'dropout_rate_Layer_3': 0.13569685694587158, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015872637475383092, 'l1_Layer_2': 1.1614645584149347e-05, 'l1_Layer_3': 6.049882756925991e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 55, 'n_units_Layer_3': 195}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.27 | sMAPE for Test Set is: 27.40% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:52:49,435]\u001b[0m Trial 673 finished with value: 5.635077915426962 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005433889386826742, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35421653815027687, 'dropout_rate_Layer_2': 0.18927703594052214, 'dropout_rate_Layer_3': 0.13238392791468262, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013537857289737296, 'l1_Layer_2': 2.503591103233879e-05, 'l1_Layer_3': 3.948132563019676e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 15.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 25.67% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:53:11,968]\u001b[0m Trial 681 finished with value: 5.8996390944219845 and parameters: {'n_hidden': 4, 'learning_rate': 0.002230414282262362, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1066107698545711, 'dropout_rate_Layer_2': 0.2473748816589039, 'dropout_rate_Layer_3': 0.1421588606324228, 'dropout_rate_Layer_4': 0.0979598231338224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.955613947086529e-05, 'l1_Layer_2': 0.01972638648170871, 'l1_Layer_3': 0.0008630797167869869, 'l1_Layer_4': 3.505631539404257e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 180, 'n_units_Layer_3': 120, 'n_units_Layer_4': 265}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 16.55% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.43 | sMAPE for Test Set is: 27.81% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:53:25,154]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:53:38,468]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:53:39,215]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:53:45,461]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:54:00,846]\u001b[0m Trial 682 finished with value: 5.708691709597684 and parameters: {'n_hidden': 3, 'learning_rate': 0.002622967736553141, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2612217652396722, 'dropout_rate_Layer_2': 0.39251989000059456, 'dropout_rate_Layer_3': 0.11600715994984667, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.422805281307208e-05, 'l1_Layer_2': 0.0013535211610607853, 'l1_Layer_3': 0.0025583941091240968, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 16.43% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.65 | sMAPE for Test Set is: 22.37% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:54:51,411]\u001b[0m Trial 688 finished with value: 5.990034322836323 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022987058526582793, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11094925295278545, 'dropout_rate_Layer_2': 0.2516548721137233, 'dropout_rate_Layer_3': 0.10736053361713178, 'dropout_rate_Layer_4': 0.09845683803368377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.8885906870009137e-05, 'l1_Layer_2': 0.013136668051919147, 'l1_Layer_3': 0.0007037793745066355, 'l1_Layer_4': 3.716262423504695e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 180, 'n_units_Layer_3': 115, 'n_units_Layer_4': 260}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.99 | sMAPE for Validation Set is: 16.75% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.26 | sMAPE for Test Set is: 30.16% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:54:58,057]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:54:59,152]\u001b[0m Trial 685 finished with value: 5.821979001345359 and parameters: {'n_hidden': 4, 'learning_rate': 0.00213116040272889, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10978106573296562, 'dropout_rate_Layer_2': 0.24929342151471837, 'dropout_rate_Layer_3': 0.10798347822815743, 'dropout_rate_Layer_4': 0.09659858742118492, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.8657575884354754e-05, 'l1_Layer_2': 0.013188579843776842, 'l1_Layer_3': 0.0008290333137869497, 'l1_Layer_4': 3.5907403822007585e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 180, 'n_units_Layer_3': 145, 'n_units_Layer_4': 265}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 16.33% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.60 | sMAPE for Test Set is: 28.28% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:55:11,492]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:55:24,864]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:55:29,526]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:55:34,841]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:55:39,529]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:55:46,969]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:55:47,680]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:55:54,226]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:56:02,121]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:56:20,500]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:56:24,145]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:56:38,225]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:56:44,439]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:56:54,776]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:57:15,397]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:57:40,786]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:57:43,415]\u001b[0m Trial 700 finished with value: 5.760145095140852 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022389606973187426, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19935070182077436, 'dropout_rate_Layer_2': 0.3920776588711796, 'dropout_rate_Layer_3': 0.12850658246965777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.393645219982886e-05, 'l1_Layer_2': 0.0024837743967844224, 'l1_Layer_3': 0.005740414207444678, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 210}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 16.57% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 22.59% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 03:57:43,590]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:57:51,145]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:57:58,897]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:57:59,562]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:58:09,819]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:58:12,902]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:58:36,630]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:58:39,976]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:58:44,298]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:58:51,001]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:58:55,724]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:59:00,080]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:59:03,483]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:59:05,597]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:59:12,787]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:59:18,158]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 03:59:21,668]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:00:01,221]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:00:11,737]\u001b[0m Trial 722 finished with value: 5.765957222144699 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009053693186509667, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33813741569037864, 'dropout_rate_Layer_2': 0.2029612667356083, 'dropout_rate_Layer_3': 0.1246553857297325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003659669615399063, 'l1_Layer_2': 1.5488362095419188e-05, 'l1_Layer_3': 8.786342283972181e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 70, 'n_units_Layer_3': 190}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 16.17% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 26.11% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:00:20,164]\u001b[0m Trial 714 finished with value: 5.7643171121998655 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017823940963409106, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09990535170714995, 'dropout_rate_Layer_2': 0.25576059999628276, 'dropout_rate_Layer_3': 0.10343118520054514, 'dropout_rate_Layer_4': 0.09729421087805612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.058760501894456e-05, 'l1_Layer_2': 0.015559039195710528, 'l1_Layer_3': 0.0007228734720933351, 'l1_Layer_4': 1.5748614377525233e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 140, 'n_units_Layer_4': 265}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 16.22% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 26.16% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:00:33,111]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:00:54,344]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:01:31,043]\u001b[0m Trial 727 finished with value: 5.659670311263599 and parameters: {'n_hidden': 3, 'learning_rate': 0.000843743183977367, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3377335950675567, 'dropout_rate_Layer_2': 0.22226322834190126, 'dropout_rate_Layer_3': 0.10684607989213124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028345911053371765, 'l1_Layer_2': 2.5299635554411114e-05, 'l1_Layer_3': 4.594655760943252e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 55, 'n_units_Layer_3': 205}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 15.79% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.68 | sMAPE for Test Set is: 25.32% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:01:35,260]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:01:41,780]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:01:54,005]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:01:57,929]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:02:06,787]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:02:11,018]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:02:16,416]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:02:57,611]\u001b[0m Trial 731 finished with value: 5.786292854687356 and parameters: {'n_hidden': 4, 'learning_rate': 0.001913367391922627, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09067900560496292, 'dropout_rate_Layer_2': 0.2499613192697563, 'dropout_rate_Layer_3': 0.09707194847039319, 'dropout_rate_Layer_4': 0.10720689600219442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.6365334665477016e-05, 'l1_Layer_2': 0.011207697049237086, 'l1_Layer_3': 0.0009096856122992051, 'l1_Layer_4': 2.7183571432485162e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 180, 'n_units_Layer_3': 115, 'n_units_Layer_4': 265}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 16.18% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.52 | sMAPE for Test Set is: 28.11% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:03:05,764]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:03:22,343]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:04:11,455]\u001b[0m Trial 729 finished with value: 5.584753750627045 and parameters: {'n_hidden': 3, 'learning_rate': 0.002558895500773801, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2698212911325109, 'dropout_rate_Layer_2': 0.3994445029372259, 'dropout_rate_Layer_3': 0.11482604624019432, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.86355037807838e-05, 'l1_Layer_2': 0.002024033015123272, 'l1_Layer_3': 0.0037126196035537095, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 15.69% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.36 | sMAPE for Test Set is: 27.71% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:04:15,315]\u001b[0m Trial 738 finished with value: 5.685583996772768 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024048648245857816, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2756755732468142, 'dropout_rate_Layer_2': 0.37856710578829633, 'dropout_rate_Layer_3': 0.1650425324002699, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.362986362911522e-05, 'l1_Layer_2': 0.001997859100620815, 'l1_Layer_3': 0.0010649640377963137, 'n_units_Layer_1': 170, 'n_units_Layer_2': 65, 'n_units_Layer_3': 190}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 16.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 27.53% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:04:17,889]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:05:03,529]\u001b[0m Trial 740 finished with value: 5.839162385707906 and parameters: {'n_hidden': 4, 'learning_rate': 0.001969929382162105, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.100108425269733, 'dropout_rate_Layer_2': 0.26144924017691784, 'dropout_rate_Layer_3': 0.14849367505599298, 'dropout_rate_Layer_4': 0.09930863447818108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.130592526035322e-05, 'l1_Layer_2': 0.015511103681317528, 'l1_Layer_3': 0.0009091653746364447, 'l1_Layer_4': 3.9879779028337006e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145, 'n_units_Layer_4': 265}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 16.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.45 | sMAPE for Test Set is: 27.81% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:05:44,955]\u001b[0m Trial 743 finished with value: 5.614484691255808 and parameters: {'n_hidden': 3, 'learning_rate': 0.002448342975304661, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2906937088704763, 'dropout_rate_Layer_2': 0.3772421792219444, 'dropout_rate_Layer_3': 0.17928171644849494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.68574823113685e-05, 'l1_Layer_2': 0.0036572169697591146, 'l1_Layer_3': 0.0012801155181929422, 'n_units_Layer_1': 170, 'n_units_Layer_2': 65, 'n_units_Layer_3': 190}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 15.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.94 | sMAPE for Test Set is: 26.45% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:06:08,431]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:06:27,639]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:07:08,179]\u001b[0m Trial 745 finished with value: 5.727375065321364 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011997599704869708, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11769757753663906, 'dropout_rate_Layer_2': 0.2349821339807235, 'dropout_rate_Layer_3': 0.11243529148434481, 'dropout_rate_Layer_4': 0.10091114829767724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.64152702788436e-05, 'l1_Layer_2': 0.013074790799508169, 'l1_Layer_3': 0.0006518006651651028, 'l1_Layer_4': 2.371344319608833e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 180, 'n_units_Layer_3': 145, 'n_units_Layer_4': 255}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 16.04% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 26.81% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:07:19,219]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:07:25,112]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:07:32,035]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:07:40,228]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:07:45,143]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:07:49,771]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:07:53,209]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:07:53,702]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:07:54,645]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:08:03,565]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:08:07,065]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:08:18,265]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:08:39,819]\u001b[0m Trial 748 finished with value: 5.821562201670429 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016926779528025398, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07933892590087413, 'dropout_rate_Layer_2': 0.25199822611010203, 'dropout_rate_Layer_3': 0.1504042139008731, 'dropout_rate_Layer_4': 0.0989157742459914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.5732539843382268e-05, 'l1_Layer_2': 0.013778428376172333, 'l1_Layer_3': 0.0007438760059400129, 'l1_Layer_4': 2.5321361983699638e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 180, 'n_units_Layer_3': 145, 'n_units_Layer_4': 275}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 16.29% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.53 | sMAPE for Test Set is: 28.17% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:08:57,838]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:09:21,801]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:09:43,589]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:09:47,178]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:09:52,246]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:09:56,881]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:09:57,857]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:10:02,458]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:10:12,946]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:10:33,728]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:10:40,919]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:10:50,080]\u001b[0m Trial 760 finished with value: 5.655454564618442 and parameters: {'n_hidden': 3, 'learning_rate': 0.002936385576090358, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3131348155038969, 'dropout_rate_Layer_2': 0.36023681183668393, 'dropout_rate_Layer_3': 0.1473606091040625, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00011575287235649848, 'l1_Layer_2': 0.0036946081467284044, 'l1_Layer_3': 0.000890136370465556, 'n_units_Layer_1': 175, 'n_units_Layer_2': 75, 'n_units_Layer_3': 175}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 15.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.73 | sMAPE for Test Set is: 28.79% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:10:59,945]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:11:04,148]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:11:22,652]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:11:28,324]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:11:35,286]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:12:00,396]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:12:05,124]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:12:31,440]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:12:35,257]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:12:45,092]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:12:51,100]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:12:52,019]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:12:58,734]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:12:59,748]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:13:09,808]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:13:14,833]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:13:23,297]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:13:25,709]\u001b[0m Trial 780 finished with value: 5.719098839453479 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007086292576584355, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31618850899597734, 'dropout_rate_Layer_2': 0.21542350812244437, 'dropout_rate_Layer_3': 0.1332372801375222, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025824799316869532, 'l1_Layer_2': 1.0148927147281685e-05, 'l1_Layer_3': 4.764003935733123e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 65, 'n_units_Layer_3': 195}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 16.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 26.26% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:13:33,377]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:13:41,084]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:13:45,124]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:13:57,898]\u001b[0m Trial 781 finished with value: 5.785893848390775 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014832658893869646, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08049236613226253, 'dropout_rate_Layer_2': 0.2616798267018318, 'dropout_rate_Layer_3': 0.1430827779808649, 'dropout_rate_Layer_4': 0.10552949078799165, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.8654639173633202e-05, 'l1_Layer_2': 0.01798942047897114, 'l1_Layer_3': 0.0004918732287542835, 'l1_Layer_4': 3.041262522524322e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150, 'n_units_Layer_4': 260}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 16.23% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 26.55% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:14:02,170]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:14:15,351]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:14:23,911]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:14:24,952]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:14:32,346]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:14:38,901]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:15:21,972]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:15:59,647]\u001b[0m Trial 800 finished with value: 5.599744359332534 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015499599411228388, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30843530110506523, 'dropout_rate_Layer_2': 0.3856437061740454, 'dropout_rate_Layer_3': 0.12555325591330968, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00011138212456281897, 'l1_Layer_2': 0.00505698668279829, 'l1_Layer_3': 0.000889087190579316, 'n_units_Layer_1': 165, 'n_units_Layer_2': 65, 'n_units_Layer_3': 200}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 15.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.26 | sMAPE for Test Set is: 27.47% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:16:05,371]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:16:13,741]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:16:17,143]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:16:22,670]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:16:28,393]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:16:39,055]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:17:13,230]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:17:22,070]\u001b[0m Trial 804 finished with value: 5.802587727283854 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017343364197933788, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0650949709223867, 'dropout_rate_Layer_2': 0.23724556898621113, 'dropout_rate_Layer_3': 0.08379702145689183, 'dropout_rate_Layer_4': 0.08706979715847908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.3443137840927822e-05, 'l1_Layer_2': 0.013173552858478408, 'l1_Layer_3': 0.0005257557700666524, 'l1_Layer_4': 1.6030748020391532e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 180, 'n_units_Layer_3': 110, 'n_units_Layer_4': 255}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 16.21% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.11 | sMAPE for Test Set is: 26.84% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:17:28,039]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:17:31,365]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:17:33,077]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:17:42,284]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:17:46,265]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:17:52,883]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:17:58,577]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:18:05,965]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:18:10,737]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:18:17,539]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:18:25,367]\u001b[0m Trial 806 finished with value: 5.635845950293586 and parameters: {'n_hidden': 3, 'learning_rate': 0.001563823905024322, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3306460495720966, 'dropout_rate_Layer_2': 0.3991451317649651, 'dropout_rate_Layer_3': 0.134160106630109, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.855967472437098e-05, 'l1_Layer_2': 0.0037335951842869786, 'l1_Layer_3': 0.0010426065595550134, 'n_units_Layer_1': 55, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.14 | sMAPE for Test Set is: 26.94% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:18:30,579]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:18:47,844]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:18:51,929]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:18:54,874]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:19:00,170]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:19:03,020]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:19:27,564]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:19:35,164]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:19:41,102]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:19:46,257]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:19:51,391]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:19:58,238]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:19:58,411]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:19:59,694]\u001b[0m Trial 825 finished with value: 5.863440904386439 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019429360123466148, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08165845149512399, 'dropout_rate_Layer_2': 0.2462015021535555, 'dropout_rate_Layer_3': 0.09942776884264763, 'dropout_rate_Layer_4': 0.08596368036437504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.4729381660778875e-05, 'l1_Layer_2': 0.015419857541263949, 'l1_Layer_3': 0.0006138205528038994, 'l1_Layer_4': 1.1576638557231364e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 195, 'n_units_Layer_3': 110, 'n_units_Layer_4': 255}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 16.39% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 28.23% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:20:06,922]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:20:07,454]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:20:13,168]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:20:17,482]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:20:17,588]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:20:23,506]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:20:39,724]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:20:40,651]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:20:40,923]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:20:42,969]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:20:55,313]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:20:59,830]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:00,509]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:08,664]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:08,779]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:18,825]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:23,616]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:23,904]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:24,000]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:34,011]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:37,713]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:41,558]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:42,059]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:44,414]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:49,001]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:21:56,381]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:22:01,490]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:22:08,096]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:22:14,599]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:22:21,802]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:22:25,866]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:22:44,733]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:22:49,992]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:23:10,273]\u001b[0m Trial 864 finished with value: 5.596006179956973 and parameters: {'n_hidden': 3, 'learning_rate': 0.002334882017628238, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3255981979599627, 'dropout_rate_Layer_2': 0.39834403164642723, 'dropout_rate_Layer_3': 0.1718851039172219, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.514325801379621e-05, 'l1_Layer_2': 0.00292979874590738, 'l1_Layer_3': 0.001184489351796784, 'n_units_Layer_1': 50, 'n_units_Layer_2': 55, 'n_units_Layer_3': 200}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 15.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 27.05% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:23:19,801]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:23:24,710]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:23:46,599]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:23:56,006]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:24:00,512]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:24:07,075]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 16.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.53 | sMAPE for Test Set is: 28.02% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:24:11,949]\u001b[0m Trial 868 finished with value: 5.772359468577295 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018703334535508263, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08795259384149585, 'dropout_rate_Layer_2': 0.23714577520467967, 'dropout_rate_Layer_3': 0.14578236255105645, 'dropout_rate_Layer_4': 0.08578154913062759, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.2434627552787628e-05, 'l1_Layer_2': 0.021555240018516067, 'l1_Layer_3': 0.00042853037868382837, 'l1_Layer_4': 1.0054729225053274e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 180, 'n_units_Layer_3': 120, 'n_units_Layer_4': 280}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:24:15,970]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:24:20,209]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:24:24,005]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:24:39,356]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:24:43,703]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:24:50,266]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:25:07,492]\u001b[0m Trial 872 finished with value: 5.71945464043644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008679037681261575, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38554458167583233, 'dropout_rate_Layer_2': 0.24237108016230977, 'dropout_rate_Layer_3': 0.14395579215181772, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002161566676958923, 'l1_Layer_2': 1.8674310852974578e-05, 'l1_Layer_3': 0.00037629549014227915, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 190}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 16.08% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.43 | sMAPE for Test Set is: 27.73% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:25:20,987]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:25:43,046]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:25:43,732]\u001b[0m Trial 882 finished with value: 5.663086308980122 and parameters: {'n_hidden': 3, 'learning_rate': 0.002345224376858625, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3232599506373771, 'dropout_rate_Layer_2': 0.36986299555342517, 'dropout_rate_Layer_3': 0.15372231463706387, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 6.808416405287703e-05, 'l1_Layer_2': 0.0022408825638067734, 'l1_Layer_3': 0.0012243279278167133, 'n_units_Layer_1': 50, 'n_units_Layer_2': 50, 'n_units_Layer_3': 210}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 16.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 26.48% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:25:50,413]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:25:55,530]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:26:07,616]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:26:12,584]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:26:20,263]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:26:24,221]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:26:28,723]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:26:31,704]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:26:34,280]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:26:38,068]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:26:43,618]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:26:48,024]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:26:49,057]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:26:49,164]\u001b[0m Trial 881 finished with value: 5.780237283839861 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014771418525977636, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013581059400679288, 'dropout_rate_Layer_2': 0.25084538168602755, 'dropout_rate_Layer_3': 0.15415073178323707, 'dropout_rate_Layer_4': 0.09197308416264144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.1561527937195376e-05, 'l1_Layer_2': 0.017075595050736084, 'l1_Layer_3': 0.0005052610807043413, 'l1_Layer_4': 1.097905204290005e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155, 'n_units_Layer_4': 270}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 16.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 26.30% | rMAE for Test Set is: 0.83\n",
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 15.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.54 | sMAPE for Test Set is: 28.25% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:26:49,320]\u001b[0m Trial 886 finished with value: 5.638100956600694 and parameters: {'n_hidden': 3, 'learning_rate': 0.002262608530256197, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.326821733960334, 'dropout_rate_Layer_2': 0.37192979431024126, 'dropout_rate_Layer_3': 0.15522429408524663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 6.734319490114273e-05, 'l1_Layer_2': 0.002244811908208939, 'l1_Layer_3': 0.0012094535372691008, 'n_units_Layer_1': 55, 'n_units_Layer_2': 50, 'n_units_Layer_3': 210}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:02,251]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:07,097]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:07,843]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:08,484]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:17,140]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:19,879]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:27,312]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:33,670]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:38,138]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:40,902]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:41,823]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:48,059]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:27:54,916]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:28:04,862]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:28:35,746]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:28:56,961]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:28:57,352]\u001b[0m Trial 914 finished with value: 5.859172586622186 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015368635462206226, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034207920817543785, 'dropout_rate_Layer_2': 0.2517403792815456, 'dropout_rate_Layer_3': 0.1376916718882368, 'dropout_rate_Layer_4': 0.10214381358523544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0009174979152596983, 'l1_Layer_2': 0.016930282445857748, 'l1_Layer_3': 0.0005396637908344365, 'l1_Layer_4': 2.1661055914186223e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 155, 'n_units_Layer_4': 280}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 16.46% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 25.94% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:29:03,729]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:29:04,028]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:29:10,373]\u001b[0m Trial 906 finished with value: 5.928790015819131 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013060558748742355, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0339192837345573, 'dropout_rate_Layer_2': 0.2517038390909517, 'dropout_rate_Layer_3': 0.14031312520574254, 'dropout_rate_Layer_4': 0.10053206911146724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.3390037461603649e-05, 'l1_Layer_2': 0.01531072207338604, 'l1_Layer_3': 0.0005740196711428425, 'l1_Layer_4': 1.0557911518331135e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 180, 'n_units_Layer_3': 115, 'n_units_Layer_4': 280}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 16.62% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 27.13% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:29:17,935]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:29:20,965]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:29:22,456]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:29:34,096]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:29:42,782]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:29:53,048]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:29:54,026]\u001b[0m Trial 919 finished with value: 5.631106581195108 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006689207117229148, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38044667628008094, 'dropout_rate_Layer_2': 0.18313526675581102, 'dropout_rate_Layer_3': 0.14014260382411864, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001358907680092251, 'l1_Layer_2': 1.798842160500513e-05, 'l1_Layer_3': 2.1004570999536408e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 155, 'n_units_Layer_3': 195}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 15.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.94 | sMAPE for Test Set is: 26.21% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:30:01,393]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:30:03,662]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:30:12,729]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:30:30,606]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:31:04,011]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:31:14,186]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:31:23,293]\u001b[0m Trial 933 finished with value: 5.665488501616252 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005398531050214193, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3534100803242558, 'dropout_rate_Layer_2': 0.16686177713586173, 'dropout_rate_Layer_3': 0.14384552226286296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009647087444133823, 'l1_Layer_2': 2.071638297290891e-05, 'l1_Layer_3': 2.4661119755614662e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 155, 'n_units_Layer_3': 210}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 15.98% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 24.94% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:31:34,084]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:31:39,650]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:31:47,519]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:31:53,182]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:31:55,514]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:31:55,597]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:31:57,073]\u001b[0m Trial 935 finished with value: 5.65541621944314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031945427801136944, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3311947811093151, 'dropout_rate_Layer_2': 0.36323924739518754, 'dropout_rate_Layer_3': 0.1598576708087694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 6.979650135092485e-05, 'l1_Layer_2': 0.0039848688740466145, 'l1_Layer_3': 0.001526188186713805, 'n_units_Layer_1': 50, 'n_units_Layer_2': 60, 'n_units_Layer_3': 165}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 16.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.23 | sMAPE for Test Set is: 27.34% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:31:57,379]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:32:04,337]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:32:04,548]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:32:11,261]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:32:11,592]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:32:16,543]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:32:25,239]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:32:26,016]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:32:36,972]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:32:37,124]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:32:58,494]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:33:08,662]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:33:22,197]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:33:31,020]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:33:33,842]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:33:33,979]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:33:52,120]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:34:18,522]\u001b[0m Trial 948 finished with value: 5.708148600562325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005205238800351256, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3049763204975142, 'dropout_rate_Layer_2': 0.13940201110782735, 'dropout_rate_Layer_3': 0.14156215631260727, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001284213149917098, 'l1_Layer_2': 2.377483353596798e-05, 'l1_Layer_3': 1.8893037005644416e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 155, 'n_units_Layer_3': 210}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 16.07% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 24.67% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:34:23,527]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:34:33,516]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:34:37,840]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:34:46,246]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:35:23,301]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:35:26,321]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:35:35,417]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:35:37,938]\u001b[0m Trial 961 finished with value: 5.670779435923204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007380875175552118, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3859948620707198, 'dropout_rate_Layer_2': 0.13396434948149283, 'dropout_rate_Layer_3': 0.13916337760321026, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001247040631632311, 'l1_Layer_2': 1.5889128258828173e-05, 'l1_Layer_3': 1.96993633386998e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 155, 'n_units_Layer_3': 220}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 15.83% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.06 | sMAPE for Test Set is: 26.73% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:35:45,761]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:35:52,044]\u001b[0m Trial 958 finished with value: 5.609366301975215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037232163169626064, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3389123338667489, 'dropout_rate_Layer_2': 0.3809157512077492, 'dropout_rate_Layer_3': 0.14471254992655466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 5.68060404288644e-05, 'l1_Layer_2': 0.002604474764121665, 'l1_Layer_3': 0.0018560306054777333, 'n_units_Layer_1': 55, 'n_units_Layer_2': 70, 'n_units_Layer_3': 215}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 15.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.62 | sMAPE for Test Set is: 28.55% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:35:55,368]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:36:03,550]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:36:16,586]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:36:21,122]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:36:25,032]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:36:50,511]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:36:58,267]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:37:06,425]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:37:10,674]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:37:15,528]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:37:20,326]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:37:24,681]\u001b[0m Trial 972 finished with value: 5.664929328275572 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007756402825399466, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39160095410573864, 'dropout_rate_Layer_2': 0.19180393484607808, 'dropout_rate_Layer_3': 0.15597935933620447, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010145639291810693, 'l1_Layer_2': 1.4008164390206392e-05, 'l1_Layer_3': 1.889974761269561e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 225}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 16.06% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 25.59% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:37:35,695]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:37:36,118]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:37:49,819]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:38:22,111]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:38:40,307]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:38:43,239]\u001b[0m Trial 979 finished with value: 5.673740828725435 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005940739213808908, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3926822936237538, 'dropout_rate_Layer_2': 0.19450366668864796, 'dropout_rate_Layer_3': 0.1563756676096249, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001174375269592629, 'l1_Layer_2': 1.8548515395088277e-05, 'l1_Layer_3': 1.7758904471132097e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 100, 'n_units_Layer_3': 220}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 26.19% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:38:48,722]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:38:55,664]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:39:15,132]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:39:15,463]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:39:33,644]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:39:38,239]\u001b[0m Trial 978 finished with value: 5.661005712700956 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005799895518625226, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3979191217771977, 'dropout_rate_Layer_2': 0.19312811907783609, 'dropout_rate_Layer_3': 0.1598738378138328, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013656239559070036, 'l1_Layer_2': 0.0015804535719650447, 'l1_Layer_3': 3.023605332266026e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 160, 'n_units_Layer_3': 220}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 15.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 25.09% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:39:41,293]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:39:44,761]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:39:49,566]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:39:50,449]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:39:56,392]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:39:57,203]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:40:02,167]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:40:07,508]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:40:14,707]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:40:30,321]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:40:36,935]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:40:53,824]\u001b[0m Trial 1007 finished with value: 6.106108583631463 and parameters: {'n_hidden': 4, 'learning_rate': 0.002538299624927268, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08398699556490816, 'dropout_rate_Layer_2': 0.35606160072967935, 'dropout_rate_Layer_3': 0.16255226138097034, 'dropout_rate_Layer_4': 0.07805901584444136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.1902286266081705e-05, 'l1_Layer_2': 0.007336342192349197, 'l1_Layer_3': 0.00083816753355436, 'l1_Layer_4': 2.0411816027781773e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 185, 'n_units_Layer_3': 140, 'n_units_Layer_4': 245}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.09 | sMAPE for Test Set is: 29.72% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:41:43,199]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:41:52,169]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:42:14,267]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:42:19,603]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:42:20,644]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:42:32,252]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:42:39,147]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:42:48,154]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:42:51,911]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:42:56,648]\u001b[0m Trial 1009 finished with value: 5.874585887386812 and parameters: {'n_hidden': 4, 'learning_rate': 0.001989827024104937, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09003475349623521, 'dropout_rate_Layer_2': 0.3559521140518081, 'dropout_rate_Layer_3': 0.1645908931601064, 'dropout_rate_Layer_4': 0.0793127177961064, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.2268088409046917e-05, 'l1_Layer_2': 0.015188530292481258, 'l1_Layer_3': 0.0011456767656693972, 'l1_Layer_4': 2.0426257867683675e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 175, 'n_units_Layer_3': 115, 'n_units_Layer_4': 245}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 16.43% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 29.35% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:42:59,066]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:43:03,604]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:43:04,107]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:43:18,055]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:43:23,478]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:43:28,152]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:43:28,857]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:43:35,265]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:43:44,213]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:43:47,612]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:43:49,090]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:44:03,707]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:44:24,710]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:44:34,942]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:44:48,835]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:44:52,184]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:44:58,503]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:45:02,661]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:45:03,082]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:45:10,126]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:45:14,187]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:45:18,714]\u001b[0m Trial 1021 finished with value: 5.612936544906717 and parameters: {'n_hidden': 3, 'learning_rate': 0.00298636411390322, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3504330870118121, 'dropout_rate_Layer_2': 0.3834590988057181, 'dropout_rate_Layer_3': 0.17134199209551537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 5.667662189188183e-05, 'l1_Layer_2': 0.005005591703758836, 'l1_Layer_3': 0.0021060131666620968, 'n_units_Layer_1': 75, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 15.75% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 26.54% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:45:23,893]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:45:28,281]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:45:33,130]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:45:39,663]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:45:42,816]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:45:50,004]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:45:57,511]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:46:29,218]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:46:49,234]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:46:49,558]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:46:57,863]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:47:22,379]\u001b[0m Trial 1043 finished with value: 5.597457867419031 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006664108461814591, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3564406897128, 'dropout_rate_Layer_2': 0.18012125059777248, 'dropout_rate_Layer_3': 0.12414124119397116, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018787679523515133, 'l1_Layer_2': 3.6141287197419965e-05, 'l1_Layer_3': 2.1816730950111252e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 140, 'n_units_Layer_3': 205}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 15.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 25.56% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:47:24,428]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:47:33,519]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:47:37,249]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:47:39,727]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:47:46,661]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:47:52,346]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:47:53,664]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:47:55,987]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:48:07,189]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:48:08,104]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:48:27,577]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:48:34,121]\u001b[0m Trial 1048 finished with value: 5.686580652915343 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006756725089201884, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3827295488702052, 'dropout_rate_Layer_2': 0.18698300113590938, 'dropout_rate_Layer_3': 0.13799852355578351, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007298247137360874, 'l1_Layer_2': 1.2038103466402642e-05, 'l1_Layer_3': 3.4378911587341726e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 155, 'n_units_Layer_3': 225}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 16.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.77 | sMAPE for Test Set is: 25.79% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:48:38,307]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:48:42,599]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:48:46,111]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:48:47,565]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:48:49,575]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:48:53,906]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:48:57,737]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:01,976]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:02,269]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:02,632]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:04,909]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:10,774]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:15,068]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:16,143]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:22,447]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:27,575]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:27,805]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:27,914]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:45,348]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:46,126]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:46,268]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:49:54,456]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:50:01,871]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:50:19,039]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:50:21,783]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:50:27,132]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:50:37,789]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:50:46,559]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:50:56,920]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:51:07,544]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:51:18,139]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:51:21,881]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:51:25,122]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:51:25,809]\u001b[0m Trial 1078 finished with value: 5.801391850254834 and parameters: {'n_hidden': 4, 'learning_rate': 0.001669516201973294, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11315340064974143, 'dropout_rate_Layer_2': 0.23971639097894012, 'dropout_rate_Layer_3': 0.14625382766222078, 'dropout_rate_Layer_4': 0.12296728042327831, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.2033503875858044e-05, 'l1_Layer_2': 0.01656753059695301, 'l1_Layer_3': 6.401647373377942e-05, 'l1_Layer_4': 2.4316260834397025e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 130, 'n_units_Layer_4': 255}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 16.28% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 26.54% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:51:26,030]\u001b[0m Trial 1087 finished with value: 5.966194130544113 and parameters: {'n_hidden': 4, 'learning_rate': 0.002518708202673017, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11148564991124746, 'dropout_rate_Layer_2': 0.2352971788113276, 'dropout_rate_Layer_3': 0.14311313631063272, 'dropout_rate_Layer_4': 0.09923015866054094, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.6949985370272715e-05, 'l1_Layer_2': 0.01461175240905502, 'l1_Layer_3': 0.0007822777994302068, 'l1_Layer_4': 2.4935041282281376e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 165, 'n_units_Layer_3': 130, 'n_units_Layer_4': 145}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 16.70% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.62 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:51:36,212]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:51:40,271]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:51:43,377]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:51:51,051]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:51:58,251]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:52:10,098]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:52:16,121]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:52:31,856]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:52:32,308]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:53:04,442]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:53:27,737]\u001b[0m Trial 1099 finished with value: 5.562416074604518 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007162184693386473, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31638806209633075, 'dropout_rate_Layer_2': 0.2096757547511549, 'dropout_rate_Layer_3': 0.11499601619588584, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2201352635957522e-05, 'l1_Layer_2': 2.1818634100341347e-05, 'l1_Layer_3': 4.791964679811503e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 160, 'n_units_Layer_3': 170}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 15.70% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 26.64% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:53:27,988]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:53:35,112]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:53:35,225]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:53:53,238]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:53:56,397]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:53:59,048]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:00,524]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:04,079]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:10,462]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:11,278]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:14,266]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:22,914]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:23,535]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:24,518]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:31,301]\u001b[0m Trial 1107 finished with value: 5.599804290184539 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006490369502579834, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3412265369797679, 'dropout_rate_Layer_2': 0.2095551277421934, 'dropout_rate_Layer_3': 0.11045387822225479, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028087637527506827, 'l1_Layer_2': 0.0006855327829649433, 'l1_Layer_3': 2.4016900042204874e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 150, 'n_units_Layer_3': 185}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 15.79% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 25.26% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:54:33,712]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:39,010]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:40,337]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:48,019]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:50,911]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:52,873]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:54:52,960]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:55:04,930]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:55:07,102]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:55:08,134]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:55:15,887]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:55:22,103]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:55:41,874]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:56:15,975]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:56:17,060]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:56:27,823]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:56:35,483]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 15.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 27.64% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:56:39,406]\u001b[0m Trial 1135 finished with value: 5.656537549011758 and parameters: {'n_hidden': 3, 'learning_rate': 0.002935361294648995, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2667633714901515, 'dropout_rate_Layer_2': 0.3990876308345559, 'dropout_rate_Layer_3': 0.16668616729830094, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 9.01417337657688e-05, 'l1_Layer_2': 0.004774481006737662, 'l1_Layer_3': 0.0011185118051385491, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:56:43,748]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:56:46,447]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:56:48,244]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:57:04,029]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:57:08,662]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:57:26,134]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:57:28,500]\u001b[0m Trial 1131 finished with value: 5.594832875750806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029886155415841708, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19638243019217905, 'dropout_rate_Layer_2': 0.39947258169855726, 'dropout_rate_Layer_3': 0.16063186333767573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.989773678398984e-05, 'l1_Layer_2': 0.004663554525608131, 'l1_Layer_3': 0.0015157263604877662, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 15.70% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 26.35% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:57:33,440]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:57:37,034]\u001b[0m Trial 1141 finished with value: 5.630079763392941 and parameters: {'n_hidden': 3, 'learning_rate': 0.003183978623764302, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2562003324024058, 'dropout_rate_Layer_2': 0.38611249859361857, 'dropout_rate_Layer_3': 0.16126587195748962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 5.882905838952956e-05, 'l1_Layer_2': 0.0022842755122738914, 'l1_Layer_3': 0.0005179416216389102, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 220}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 15.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.42 | sMAPE for Test Set is: 27.94% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 04:57:40,220]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:57:41,214]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:57:43,747]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:57:50,634]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:57:54,278]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:57:55,072]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:57:56,998]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:58:10,936]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:58:12,000]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:58:12,634]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:58:24,098]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:58:28,812]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:58:34,155]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:58:39,752]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:58:41,962]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:58:53,759]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:58:59,283]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:58:59,957]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:59:51,109]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 04:59:57,539]\u001b[0m Trial 1159 finished with value: 5.840674162097485 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020593759700802674, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09736346754513761, 'dropout_rate_Layer_2': 0.24704800798145524, 'dropout_rate_Layer_3': 0.12956175906656042, 'dropout_rate_Layer_4': 0.08234681916635227, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.4953309008363358e-05, 'l1_Layer_2': 0.021262685641284255, 'l1_Layer_3': 0.0005243365495422565, 'l1_Layer_4': 2.885021267373254e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 105, 'n_units_Layer_4': 280}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 16.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.48 | sMAPE for Test Set is: 27.89% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:00:08,007]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:00:08,922]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:00:11,122]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:00:21,028]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:00:38,856]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:01:22,719]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:01:28,501]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:01:37,126]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:01:42,655]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:01:46,156]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:01:58,534]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:02:07,918]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:02:15,776]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:02:40,114]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:02:50,180]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:03:52,710]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:04:08,446]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:04:12,978]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:04:18,815]\u001b[0m Trial 1187 finished with value: 5.691641124244953 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021892262807997466, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20847808504249918, 'dropout_rate_Layer_2': 0.368390770632384, 'dropout_rate_Layer_3': 0.138872104205301, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.9559758982278736e-05, 'l1_Layer_2': 0.0016006438351209662, 'l1_Layer_3': 0.0008776771442545609, 'n_units_Layer_1': 155, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 15.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 23.83% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:04:27,502]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:04:31,788]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:04:36,080]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:04:36,441]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:04:47,581]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:04:51,370]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:04:56,141]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:05:00,579]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:05:03,080]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:05:07,423]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:05:13,363]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:05:20,715]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:05:25,788]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:05:26,993]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:05:27,865]\u001b[0m Trial 1186 finished with value: 5.626989529671451 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021868539787887, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2585550898963368, 'dropout_rate_Layer_2': 0.3921900401196421, 'dropout_rate_Layer_3': 0.13788356326851403, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001046224287969594, 'l1_Layer_2': 0.001626261981434612, 'l1_Layer_3': 0.0012612198529562677, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 200}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 23.91% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:05:33,355]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:05:40,999]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:05:52,742]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:05:59,375]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:06:03,174]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:06:03,379]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:06:12,203]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:06:26,578]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:06:30,854]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:06:44,349]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:06:49,129]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:06:49,770]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:06:50,318]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:01,570]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:05,159]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:06,371]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:09,503]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:17,478]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:19,581]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:24,857]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:29,439]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:32,594]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:33,039]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:34,281]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:41,981]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:46,969]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:47,406]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:07:57,077]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:08:00,477]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:08:02,697]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:08:03,408]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:08:07,464]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:08:09,535]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:08:14,181]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:08:18,403]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:08:20,545]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:08:34,185]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:08:44,194]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:08:47,964]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:09:07,486]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:09:58,839]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:10:05,634]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:10:31,996]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:10:36,697]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:10:44,216]\u001b[0m Trial 1248 finished with value: 5.627416553967937 and parameters: {'n_hidden': 3, 'learning_rate': 0.002349687118085193, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26575510596930796, 'dropout_rate_Layer_2': 0.37278610656193517, 'dropout_rate_Layer_3': 0.13451999575635915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00011755896046560947, 'l1_Layer_2': 0.003114001106845595, 'l1_Layer_3': 0.0008162847899633507, 'n_units_Layer_1': 160, 'n_units_Layer_2': 70, 'n_units_Layer_3': 190}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 15.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 28.36% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:10:59,894]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:11:05,177]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:11:12,390]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:11:27,079]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:11:35,035]\u001b[0m Trial 1247 finished with value: 5.603401112565337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023945889330260896, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3209894604331896, 'dropout_rate_Layer_2': 0.37383279376708944, 'dropout_rate_Layer_3': 0.13729924926400933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001228708333674734, 'l1_Layer_2': 0.003166317284937028, 'l1_Layer_3': 0.0007988426190654501, 'n_units_Layer_1': 160, 'n_units_Layer_2': 70, 'n_units_Layer_3': 190}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 15.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 27.57% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:11:39,054]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:11:49,315]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:11:54,481]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:11:55,352]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:12:01,303]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:12:01,884]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:12:02,507]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:12:12,871]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:12:21,615]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:12:30,155]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:12:33,592]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:12:49,829]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:13:00,411]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:13:25,551]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:13:25,849]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:13:38,469]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:13:54,261]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:13:58,397]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:14:03,822]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:14:09,602]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:14:15,552]\u001b[0m Trial 1263 finished with value: 5.623868814469272 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020945432506005264, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2756639929842552, 'dropout_rate_Layer_2': 0.3747478728989924, 'dropout_rate_Layer_3': 0.12040463692694406, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001971740260948533, 'l1_Layer_2': 0.00152331858293751, 'l1_Layer_3': 0.0007353798597021784, 'n_units_Layer_1': 160, 'n_units_Layer_2': 70, 'n_units_Layer_3': 195}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 25.05% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:14:21,985]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:14:36,466]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:15:17,283]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:15:20,821]\u001b[0m Trial 1254 finished with value: 5.625009977142682 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005428188606446022, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3917650797834431, 'dropout_rate_Layer_2': 0.18950272929591216, 'dropout_rate_Layer_3': 0.11462394024407443, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001631156025035139, 'l1_Layer_2': 1.9755511791505625e-05, 'l1_Layer_3': 3.1572351417495264e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 100, 'n_units_Layer_3': 175}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 15.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 24.66% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:15:33,880]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:15:39,476]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:15:45,766]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:15:54,334]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:16:00,673]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:16:05,886]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:16:09,099]\u001b[0m Trial 1281 finished with value: 5.860322521856157 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019021672145543463, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07035127819510414, 'dropout_rate_Layer_2': 0.24537283148837408, 'dropout_rate_Layer_3': 0.2634759227733846, 'dropout_rate_Layer_4': 0.08159345780535697, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0006811156402850398, 'l1_Layer_2': 0.014387008431116014, 'l1_Layer_3': 0.00047817804953886303, 'l1_Layer_4': 1.6895797404782938e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135, 'n_units_Layer_4': 265}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:16:09,155]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 16.45% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.69 | sMAPE for Test Set is: 28.61% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:16:18,293]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:16:19,802]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:16:20,216]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:16:28,037]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:16:33,849]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:16:54,730]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:17:00,613]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:17:13,764]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:17:50,115]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:17:56,041]\u001b[0m Trial 1293 finished with value: 5.677712582334238 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017290720985369652, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2856943450773296, 'dropout_rate_Layer_2': 0.39435566633546293, 'dropout_rate_Layer_3': 0.10022505913046943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001465049839624495, 'l1_Layer_2': 0.0015092415911093506, 'l1_Layer_3': 0.0008712466171978214, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 16.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.26 | sMAPE for Test Set is: 27.47% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:18:02,184]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:18:08,929]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:18:16,391]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:18:23,691]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:18:30,746]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:18:34,172]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:18:43,202]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:18:51,943]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:19:08,729]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:19:14,787]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:19:25,235]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:19:25,531]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:19:33,746]\u001b[0m Trial 1302 finished with value: 6.0227001933057 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010444453345751206, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07338305207333543, 'dropout_rate_Layer_2': 0.2358247783494079, 'dropout_rate_Layer_3': 0.2637139300371061, 'dropout_rate_Layer_4': 0.07354643389911145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0005854952846318659, 'l1_Layer_2': 0.011262926707215539, 'l1_Layer_3': 0.0004835692290713042, 'l1_Layer_4': 1.4802995729616395e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 145, 'n_units_Layer_4': 270}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 25.67% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:19:34,100]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:19:39,811]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:19:51,324]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:19:55,891]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:20:06,503]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:20:27,663]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:20:34,544]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:20:34,985]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:20:35,851]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:20:46,853]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:20:50,248]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:20:54,263]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:20:56,004]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:21:03,566]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:21:06,735]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:21:18,312]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:21:38,579]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:21:45,284]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:21:49,037]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:21:59,872]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:22:03,621]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:22:10,704]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:22:30,596]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:22:36,301]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:22:45,706]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:22:54,363]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:23:01,074]\u001b[0m Trial 1318 finished with value: 5.58718780347533 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007251474547002322, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11272994619273792, 'dropout_rate_Layer_2': 0.2121549203161462, 'dropout_rate_Layer_3': 0.08662175654935084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018610891532025902, 'l1_Layer_2': 1.7671266235179103e-05, 'l1_Layer_3': 0.0001308008829894979, 'n_units_Layer_1': 120, 'n_units_Layer_2': 100, 'n_units_Layer_3': 185}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 15.75% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 25.15% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:23:34,304]\u001b[0m Trial 1325 finished with value: 5.631027100312643 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011424389274775318, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2646920051573332, 'dropout_rate_Layer_2': 0.36957492697183975, 'dropout_rate_Layer_3': 0.14357742591103434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 5.131957617517286e-05, 'l1_Layer_2': 0.00245173484704119, 'l1_Layer_3': 0.0009917641628840869, 'n_units_Layer_1': 90, 'n_units_Layer_2': 50, 'n_units_Layer_3': 215}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 15.91% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 26.11% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:23:39,537]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:23:43,824]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:23:49,590]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:23:58,332]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:24:02,226]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:24:02,816]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:24:48,827]\u001b[0m Trial 1341 finished with value: 5.71354454732252 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013226543728190872, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2540273930932397, 'dropout_rate_Layer_2': 0.3858141881871206, 'dropout_rate_Layer_3': 0.13353794879384936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.55199056273405e-05, 'l1_Layer_2': 0.005034412848550922, 'l1_Layer_3': 0.0009518258593141443, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 16.05% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 25.89% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:24:54,472]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:25:00,198]\u001b[0m Trial 1337 finished with value: 5.874312858741377 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016932981755490243, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09566645565302001, 'dropout_rate_Layer_2': 0.22980111644826573, 'dropout_rate_Layer_3': 0.11626085012436213, 'dropout_rate_Layer_4': 0.08505668553263725, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0011643426896024885, 'l1_Layer_2': 0.01577394962602873, 'l1_Layer_3': 0.0007241549220239337, 'l1_Layer_4': 1.6823811524785852e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140, 'n_units_Layer_4': 270}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 16.45% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.40 | sMAPE for Test Set is: 27.63% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:25:21,779]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:25:32,546]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:25:36,874]\u001b[0m Trial 1348 finished with value: 5.873809542611546 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021977119104431217, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08423099887283549, 'dropout_rate_Layer_2': 0.2639285984895918, 'dropout_rate_Layer_3': 0.1037747038507227, 'dropout_rate_Layer_4': 0.08023429767553071, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00020356729055199537, 'l1_Layer_2': 0.012186890873772149, 'l1_Layer_3': 0.0008612899998941478, 'l1_Layer_4': 4.082161327699859e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 130, 'n_units_Layer_4': 270}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 16.42% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.52 | sMAPE for Test Set is: 28.11% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:25:48,753]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:25:57,509]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:26:17,291]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:26:22,750]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:26:26,872]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:26:30,364]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:26:40,487]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:27:25,753]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:27:34,569]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:27:43,135]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:27:53,845]\u001b[0m Trial 1350 finished with value: 5.701251407641938 and parameters: {'n_hidden': 3, 'learning_rate': 0.000915133774586002, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26199521758631356, 'dropout_rate_Layer_2': 0.36547555907566504, 'dropout_rate_Layer_3': 0.14247665100731868, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.902195881910908e-05, 'l1_Layer_2': 0.002821767417808582, 'l1_Layer_3': 0.0012955066851694503, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 16.07% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 24.90% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:28:00,922]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:04,822]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:11,930]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:12,729]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:16,819]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:21,779]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:24,764]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:26,165]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:31,414]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:31,520]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:31,752]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:41,679]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:46,708]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:52,693]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:28:57,621]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:29:05,345]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:29:06,099]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:29:16,431]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:29:35,855]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:29:38,452]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:29:43,455]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:29:49,662]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:29:53,131]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:30:02,529]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:30:26,689]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:30:45,101]\u001b[0m Trial 1378 finished with value: 5.634875791434691 and parameters: {'n_hidden': 3, 'learning_rate': 0.002652119537960605, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2341280289020806, 'dropout_rate_Layer_2': 0.3911198626295172, 'dropout_rate_Layer_3': 0.16758590159134612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.260939283740803e-05, 'l1_Layer_2': 0.0021007772707407825, 'l1_Layer_3': 0.0007533475870348949, 'n_units_Layer_1': 160, 'n_units_Layer_2': 70, 'n_units_Layer_3': 205}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 15.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.31 | sMAPE for Test Set is: 24.35% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:31:08,068]\u001b[0m Trial 1387 finished with value: 5.652701710633504 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033052437541399183, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3239542887930617, 'dropout_rate_Layer_2': 0.39958952147128307, 'dropout_rate_Layer_3': 0.11344560940874121, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 7.342379330583146e-05, 'l1_Layer_2': 0.0033767649150839517, 'l1_Layer_3': 0.000776460830780168, 'n_units_Layer_1': 170, 'n_units_Layer_2': 65, 'n_units_Layer_3': 210}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 15.91% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.41 | sMAPE for Test Set is: 27.82% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:31:16,123]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:31:24,812]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:31:30,149]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:31:35,569]\u001b[0m Trial 1383 finished with value: 5.772020501602074 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014414559903946458, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07633573322004585, 'dropout_rate_Layer_2': 0.24280815047036616, 'dropout_rate_Layer_3': 0.12338224327151748, 'dropout_rate_Layer_4': 0.07098355185101783, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.2913021671788394e-05, 'l1_Layer_2': 0.0012549160518678126, 'l1_Layer_3': 0.000805843719851522, 'l1_Layer_4': 3.412974273500268e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110, 'n_units_Layer_4': 280}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 16.13% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.29 | sMAPE for Test Set is: 27.43% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:31:44,893]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:32:02,905]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:32:10,318]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:32:25,637]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:32:28,443]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:32:34,339]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:32:41,215]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:32:47,829]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:32:53,281]\u001b[0m Trial 1390 finished with value: 5.611099407442012 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007130049490492273, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36007183830713396, 'dropout_rate_Layer_2': 0.18198708850563972, 'dropout_rate_Layer_3': 0.12110855253211444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016670772235406715, 'l1_Layer_2': 3.547028234609667e-05, 'l1_Layer_3': 4.141223868207593e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 180, 'n_units_Layer_3': 185}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 15.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.62 | sMAPE for Test Set is: 28.52% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:32:58,592]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:33:06,307]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:33:14,516]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:33:22,073]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:33:57,884]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:34:08,747]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:34:11,689]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:34:31,931]\u001b[0m Trial 1392 finished with value: 5.777957319973569 and parameters: {'n_hidden': 4, 'learning_rate': 0.002094787996597187, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0764665341265994, 'dropout_rate_Layer_2': 0.24824778645548226, 'dropout_rate_Layer_3': 0.11152640449499895, 'dropout_rate_Layer_4': 0.07944738210805721, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003030979473597514, 'l1_Layer_2': 0.020106475610525296, 'l1_Layer_3': 0.001063574424043566, 'l1_Layer_4': 1.6148619331223965e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 220, 'n_units_Layer_3': 110, 'n_units_Layer_4': 255}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 16.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.38 | sMAPE for Test Set is: 27.73% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:34:32,400]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:34:44,376]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:34:45,535]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:34:54,728]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:34:57,123]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:35:04,240]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:35:41,982]\u001b[0m Trial 1406 finished with value: 5.563488471960889 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007952717388373021, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21870653492132391, 'dropout_rate_Layer_2': 0.1822585054464677, 'dropout_rate_Layer_3': 0.10062724503815497, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016476101822658319, 'l1_Layer_2': 3.0121706368370614e-05, 'l1_Layer_3': 5.4219815202615275e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 175, 'n_units_Layer_3': 175}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 15.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 26.15% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:35:53,353]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:35:59,009]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:36:06,200]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:36:07,304]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:36:19,302]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:36:23,660]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:36:25,006]\u001b[0m Trial 1417 finished with value: 5.854821375370914 and parameters: {'n_hidden': 4, 'learning_rate': 0.001615853496967767, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08137421524776849, 'dropout_rate_Layer_2': 0.2641252623447588, 'dropout_rate_Layer_3': 0.11939685518864912, 'dropout_rate_Layer_4': 0.07204827285051468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0001568897500385286, 'l1_Layer_2': 0.003886230649615115, 'l1_Layer_3': 0.0008347538481462242, 'l1_Layer_4': 1.6358900250814072e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 225, 'n_units_Layer_3': 95, 'n_units_Layer_4': 270}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 16.47% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.23 | sMAPE for Test Set is: 27.20% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:36:25,371]\u001b[0m Trial 1411 finished with value: 5.656164326179407 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007729884779973962, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36212321361118516, 'dropout_rate_Layer_2': 0.18576632282883224, 'dropout_rate_Layer_3': 0.11280180034406646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012983955959980553, 'l1_Layer_2': 3.4470627324982644e-05, 'l1_Layer_3': 0.0004594775286950525, 'n_units_Layer_1': 110, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 15.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 27.37% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:36:27,454]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:36:36,511]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:36:40,956]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:37:17,461]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:37:18,835]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:37:20,304]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:37:31,482]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:37:31,732]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:37:36,907]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:37:40,212]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:37:42,538]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:37:47,596]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:38:07,832]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:38:13,936]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:38:20,842]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:38:24,028]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:38:40,307]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:38:55,762]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:39:04,479]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:39:12,568]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:39:15,554]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:39:20,378]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 16.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.06 | sMAPE for Test Set is: 26.64% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:39:21,952]\u001b[0m Trial 1440 finished with value: 5.858942190628478 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017648287065279765, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0914599125897958, 'dropout_rate_Layer_2': 0.27011562859767074, 'dropout_rate_Layer_3': 0.11847517752008419, 'dropout_rate_Layer_4': 0.06855712285523483, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00014501712350586, 'l1_Layer_2': 0.0008193732217557028, 'l1_Layer_3': 0.0007972559763415572, 'l1_Layer_4': 2.903650420049234e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 230, 'n_units_Layer_3': 100, 'n_units_Layer_4': 255}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:39:29,316]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:39:32,348]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:39:45,312]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:39:50,280]\u001b[0m Trial 1443 finished with value: 5.902870109875998 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017934422861369211, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06244841535636318, 'dropout_rate_Layer_2': 0.2686401879559908, 'dropout_rate_Layer_3': 0.11702090450645998, 'dropout_rate_Layer_4': 0.06420073473303115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.000252835673050335, 'l1_Layer_2': 0.001056317026663646, 'l1_Layer_3': 0.0012688135054209839, 'l1_Layer_4': 2.8003670979741084e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 230, 'n_units_Layer_3': 110, 'n_units_Layer_4': 275}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 16.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.41 | sMAPE for Test Set is: 27.68% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:39:54,194]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:40:04,238]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:40:15,610]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:40:24,340]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:40:28,132]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:40:31,540]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:40:37,433]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:40:39,116]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:40:42,799]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:40:49,113]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:40:51,794]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:40:55,033]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:41:02,430]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:41:08,922]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:41:16,236]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:41:28,447]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:41:29,499]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:41:29,695]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:41:37,630]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:41:41,608]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:41:41,799]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:41:48,660]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:41:51,702]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:41:55,169]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:42:00,971]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:42:04,154]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:42:05,271]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:42:12,327]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:42:17,424]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:42:18,701]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:42:25,050]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:42:29,994]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:42:32,772]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:42:40,189]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:42:57,557]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:42:57,983]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:43:22,825]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:43:27,979]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:43:28,972]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:43:40,109]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:43:50,058]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:43:55,858]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:44:05,734]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:44:10,353]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:44:15,633]\u001b[0m Trial 1465 finished with value: 5.658516161641597 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006082405052654139, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2543550122361477, 'dropout_rate_Layer_2': 0.2030317548389755, 'dropout_rate_Layer_3': 0.11608020501982057, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0038161717707841927, 'l1_Layer_2': 7.921444221743156e-05, 'l1_Layer_3': 0.00039597597544661163, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 160}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 15.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 25.62% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:44:15,823]\u001b[0m Trial 1490 finished with value: 5.893231850238709 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020289244547055164, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09347689393769194, 'dropout_rate_Layer_2': 0.2596662943276112, 'dropout_rate_Layer_3': 0.06981563510839577, 'dropout_rate_Layer_4': 0.07484278144299965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00026262904143775054, 'l1_Layer_2': 0.015718731078643612, 'l1_Layer_3': 0.0005382889359330445, 'l1_Layer_4': 1.2905637255879402e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 220, 'n_units_Layer_3': 150, 'n_units_Layer_4': 250}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 16.48% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.57 | sMAPE for Test Set is: 28.18% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 05:44:19,444]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 05:45:08,386]\u001b[0m Trial 1499 finished with value: 5.74843085023944 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016824938610788677, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0842873273714284, 'dropout_rate_Layer_2': 0.27449382590077465, 'dropout_rate_Layer_3': 0.08370195584211779, 'dropout_rate_Layer_4': 0.10061422702324135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003075771033910488, 'l1_Layer_2': 0.010350541876640708, 'l1_Layer_3': 0.0008150350121977808, 'l1_Layer_4': 3.353688450087299e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 170, 'n_units_Layer_3': 115, 'n_units_Layer_4': 260}. Best is trial 643 with value: 5.549222480686905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 16.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.16 | sMAPE for Test Set is: 27.07% | rMAE for Test Set is: 0.85\n",
      "for 2020-01-01, MAE is:9.06 & sMAPE is:29.29% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :9.06 & 29.29% & 0.73\n",
      "for 2020-01-02, MAE is:4.11 & sMAPE is:11.26% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 20.28% & 0.62\n",
      "for 2020-01-03, MAE is:2.71 & sMAPE is:7.67% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 16.08% & 0.66\n",
      "for 2020-01-04, MAE is:3.34 & sMAPE is:8.80% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 14.26% & 0.74\n",
      "for 2020-01-05, MAE is:3.56 & sMAPE is:10.50% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 13.51% & 0.75\n",
      "for 2020-01-06, MAE is:3.90 & sMAPE is:10.42% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 12.99% & 0.80\n",
      "for 2020-01-07, MAE is:5.33 & sMAPE is:13.64% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 13.08% & 0.80\n",
      "for 2020-01-08, MAE is:6.53 & sMAPE is:16.61% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 13.52% & 0.78\n",
      "for 2020-01-09, MAE is:7.55 & sMAPE is:18.76% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 14.11% & 0.91\n",
      "for 2020-01-10, MAE is:8.24 & sMAPE is:22.18% & rMAE is:2.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 14.91% & 1.07\n",
      "for 2020-01-11, MAE is:3.70 & sMAPE is:10.52% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 14.51% & 1.04\n",
      "for 2020-01-12, MAE is:5.77 & sMAPE is:19.38% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 14.92% & 1.03\n",
      "for 2020-01-13, MAE is:5.58 & sMAPE is:14.93% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 14.92% & 1.06\n",
      "for 2020-01-14, MAE is:3.59 & sMAPE is:15.65% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 14.97% & 1.01\n",
      "for 2020-01-15, MAE is:5.26 & sMAPE is:19.21% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 15.26% & 0.98\n",
      "for 2020-01-16, MAE is:7.19 & sMAPE is:21.72% & rMAE is:3.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 15.66% & 1.12\n",
      "for 2020-01-17, MAE is:2.96 & sMAPE is:8.49% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 15.24% & 1.11\n",
      "for 2020-01-18, MAE is:4.27 & sMAPE is:12.95% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 15.11% & 1.10\n",
      "for 2020-01-19, MAE is:3.19 & sMAPE is:10.08% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 14.85% & 1.08\n",
      "for 2020-01-20, MAE is:5.77 & sMAPE is:13.94% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 14.80% & 1.07\n",
      "for 2020-01-21, MAE is:5.22 & sMAPE is:10.94% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 14.62% & 1.03\n",
      "for 2020-01-22, MAE is:5.88 & sMAPE is:12.20% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 14.51% & 1.00\n",
      "for 2020-01-23, MAE is:5.83 & sMAPE is:11.82% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 14.39% & 0.97\n",
      "for 2020-01-24, MAE is:4.98 & sMAPE is:9.95% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 14.20% & 0.95\n",
      "for 2020-01-25, MAE is:3.35 & sMAPE is:7.65% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 13.94% & 0.93\n",
      "for 2020-01-26, MAE is:4.62 & sMAPE is:13.01% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 13.91% & 0.93\n",
      "for 2020-01-27, MAE is:3.56 & sMAPE is:9.15% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 13.73% & 0.92\n",
      "for 2020-01-28, MAE is:7.12 & sMAPE is:19.02% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 13.92% & 0.90\n",
      "for 2020-01-29, MAE is:3.82 & sMAPE is:11.26% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 13.83% & 0.88\n",
      "for 2020-01-30, MAE is:3.75 & sMAPE is:10.45% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 13.71% & 0.86\n",
      "for 2020-01-31, MAE is:7.75 & sMAPE is:25.73% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 14.10% & 0.84\n",
      "for 2020-02-01, MAE is:7.62 & sMAPE is:47.99% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 15.16% & 0.82\n",
      "for 2020-02-02, MAE is:7.30 & sMAPE is:32.61% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 15.69% & 0.83\n",
      "for 2020-02-03, MAE is:6.46 & sMAPE is:26.95% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 16.02% & 0.82\n",
      "for 2020-02-04, MAE is:5.06 & sMAPE is:19.48% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 16.12% & 0.82\n",
      "for 2020-02-05, MAE is:5.45 & sMAPE is:15.44% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 16.10% & 0.84\n",
      "for 2020-02-06, MAE is:2.66 & sMAPE is:7.36% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 15.86% & 0.84\n",
      "for 2020-02-07, MAE is:5.26 & sMAPE is:14.49% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 15.83% & 0.84\n",
      "for 2020-02-08, MAE is:3.65 & sMAPE is:12.64% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 15.75% & 0.83\n",
      "for 2020-02-09, MAE is:6.66 & sMAPE is:34.70% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 16.22% & 0.83\n",
      "for 2020-02-10, MAE is:8.33 & sMAPE is:42.45% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 16.86% & 0.86\n",
      "for 2020-02-11, MAE is:4.24 & sMAPE is:16.78% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 16.86% & 0.87\n",
      "for 2020-02-12, MAE is:5.43 & sMAPE is:18.68% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 16.90% & 0.87\n",
      "for 2020-02-13, MAE is:3.71 & sMAPE is:11.03% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 16.77% & 0.87\n",
      "for 2020-02-14, MAE is:3.86 & sMAPE is:11.64% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 16.65% & 0.88\n",
      "for 2020-02-15, MAE is:3.66 & sMAPE is:15.21% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 16.62% & 0.87\n",
      "for 2020-02-16, MAE is:10.47 & sMAPE is:73.68% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 17.84% & 0.89\n",
      "for 2020-02-17, MAE is:4.67 & sMAPE is:25.81% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 18.00% & 0.90\n",
      "for 2020-02-18, MAE is:4.90 & sMAPE is:19.39% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 18.03% & 0.92\n",
      "for 2020-02-19, MAE is:3.92 & sMAPE is:13.16% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 17.93% & 0.92\n",
      "for 2020-02-20, MAE is:3.39 & sMAPE is:11.11% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 17.80% & 0.92\n",
      "for 2020-02-21, MAE is:3.82 & sMAPE is:12.51% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 17.70% & 0.92\n",
      "for 2020-02-22, MAE is:6.43 & sMAPE is:23.16% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 17.80% & 0.92\n",
      "for 2020-02-23, MAE is:6.86 & sMAPE is:28.26% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 17.99% & 0.92\n",
      "for 2020-02-24, MAE is:5.90 & sMAPE is:18.26% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 18.00% & 0.91\n",
      "for 2020-02-25, MAE is:4.09 & sMAPE is:14.21% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 17.93% & 0.92\n",
      "for 2020-02-26, MAE is:2.91 & sMAPE is:9.96% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 17.79% & 0.93\n",
      "for 2020-02-27, MAE is:5.57 & sMAPE is:16.58% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 17.77% & 0.93\n",
      "for 2020-02-28, MAE is:5.34 & sMAPE is:17.37% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 17.76% & 0.94\n",
      "for 2020-02-29, MAE is:5.84 & sMAPE is:29.12% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 17.95% & 0.94\n",
      "for 2020-03-01, MAE is:6.82 & sMAPE is:38.19% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 18.28% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-02, MAE is:3.82 & sMAPE is:11.88% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 18.18% & 0.93\n",
      "for 2020-03-03, MAE is:6.04 & sMAPE is:17.06% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 18.16% & 0.92\n",
      "for 2020-03-04, MAE is:5.47 & sMAPE is:13.13% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 18.09% & 0.92\n",
      "for 2020-03-05, MAE is:4.80 & sMAPE is:13.45% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 18.01% & 0.92\n",
      "for 2020-03-06, MAE is:1.96 & sMAPE is:6.80% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 17.84% & 0.91\n",
      "for 2020-03-07, MAE is:6.21 & sMAPE is:23.63% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 17.93% & 0.91\n",
      "for 2020-03-08, MAE is:7.48 & sMAPE is:41.20% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 18.27% & 0.93\n",
      "for 2020-03-09, MAE is:5.25 & sMAPE is:14.81% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 18.22% & 0.93\n",
      "for 2020-03-10, MAE is:9.16 & sMAPE is:30.47% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 18.40% & 0.93\n",
      "for 2020-03-11, MAE is:5.52 & sMAPE is:21.14% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 18.44% & 0.93\n",
      "for 2020-03-12, MAE is:7.29 & sMAPE is:35.44% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 18.67% & 0.92\n",
      "for 2020-03-13, MAE is:5.65 & sMAPE is:19.91% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 18.69% & 0.93\n",
      "for 2020-03-14, MAE is:6.32 & sMAPE is:22.97% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 18.75% & 0.95\n",
      "for 2020-03-15, MAE is:5.91 & sMAPE is:34.26% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 18.95% & 0.96\n",
      "for 2020-03-16, MAE is:5.70 & sMAPE is:17.44% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 18.93% & 0.96\n",
      "for 2020-03-17, MAE is:4.95 & sMAPE is:17.28% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 18.91% & 0.96\n",
      "for 2020-03-18, MAE is:4.22 & sMAPE is:15.47% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 18.87% & 0.96\n",
      "for 2020-03-19, MAE is:4.23 & sMAPE is:15.34% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 18.82% & 0.96\n",
      "for 2020-03-20, MAE is:4.26 & sMAPE is:17.39% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 18.81% & 0.95\n",
      "for 2020-03-21, MAE is:8.36 & sMAPE is:58.06% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 19.29% & 0.95\n",
      "for 2020-03-22, MAE is:16.47 & sMAPE is:102.64% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 20.31% & 0.95\n",
      "for 2020-03-23, MAE is:11.21 & sMAPE is:53.19% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 20.70% & 0.95\n",
      "for 2020-03-24, MAE is:6.55 & sMAPE is:28.76% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 20.80% & 0.95\n",
      "for 2020-03-25, MAE is:5.35 & sMAPE is:21.68% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 20.81% & 0.95\n",
      "for 2020-03-26, MAE is:5.59 & sMAPE is:23.16% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 20.84% & 0.95\n",
      "for 2020-03-27, MAE is:3.86 & sMAPE is:17.40% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 20.80% & 0.96\n",
      "for 2020-03-28, MAE is:7.34 & sMAPE is:56.65% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 21.20% & 0.96\n",
      "for 2020-03-29, MAE is:14.30 & sMAPE is:118.06% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 22.29% & 0.97\n",
      "for 2020-03-30, MAE is:4.44 & sMAPE is:20.75% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 22.28% & 0.97\n",
      "for 2020-03-31, MAE is:3.93 & sMAPE is:16.83% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 22.22% & 0.97\n",
      "for 2020-04-01, MAE is:3.34 & sMAPE is:14.55% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 22.13% & 0.98\n",
      "for 2020-04-02, MAE is:3.74 & sMAPE is:16.72% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 22.07% & 0.99\n",
      "for 2020-04-03, MAE is:2.94 & sMAPE is:13.30% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 21.98% & 0.99\n",
      "for 2020-04-04, MAE is:3.99 & sMAPE is:22.84% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 21.99% & 0.99\n",
      "for 2020-04-05, MAE is:14.69 & sMAPE is:99.80% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 22.80% & 1.01\n",
      "for 2020-04-06, MAE is:6.55 & sMAPE is:48.20% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 23.06% & 1.01\n",
      "for 2020-04-07, MAE is:4.76 & sMAPE is:23.28% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 23.06% & 1.01\n",
      "for 2020-04-08, MAE is:6.54 & sMAPE is:28.63% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 23.12% & 1.02\n",
      "for 2020-04-09, MAE is:3.48 & sMAPE is:16.71% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 23.06% & 1.02\n",
      "for 2020-04-10, MAE is:4.70 & sMAPE is:24.93% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 23.07% & 1.03\n",
      "for 2020-04-11, MAE is:4.27 & sMAPE is:26.65% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 23.11% & 1.03\n",
      "for 2020-04-12, MAE is:7.22 & sMAPE is:62.22% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 23.49% & 1.03\n",
      "for 2020-04-13, MAE is:36.00 & sMAPE is:154.49% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 24.75% & 1.03\n",
      "for 2020-04-14, MAE is:6.37 & sMAPE is:34.17% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 24.84% & 1.03\n",
      "for 2020-04-15, MAE is:6.35 & sMAPE is:33.40% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 24.92% & 1.04\n",
      "for 2020-04-16, MAE is:4.32 & sMAPE is:22.82% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 24.90% & 1.04\n",
      "for 2020-04-17, MAE is:2.14 & sMAPE is:11.56% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 24.78% & 1.04\n",
      "for 2020-04-18, MAE is:3.36 & sMAPE is:17.34% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 24.71% & 1.04\n",
      "for 2020-04-19, MAE is:10.02 & sMAPE is:73.25% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 25.15% & 1.04\n",
      "for 2020-04-20, MAE is:14.62 & sMAPE is:103.46% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 25.86% & 1.04\n",
      "for 2020-04-21, MAE is:34.50 & sMAPE is:128.08% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 26.77% & 1.04\n",
      "for 2020-04-22, MAE is:14.06 & sMAPE is:101.67% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 27.43% & 1.04\n",
      "for 2020-04-23, MAE is:4.31 & sMAPE is:19.53% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 27.36% & 1.04\n",
      "for 2020-04-24, MAE is:3.72 & sMAPE is:19.20% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 27.29% & 1.04\n",
      "for 2020-04-25, MAE is:2.98 & sMAPE is:18.63% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 27.22% & 1.04\n",
      "for 2020-04-26, MAE is:2.29 & sMAPE is:16.08% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 27.12% & 1.03\n",
      "for 2020-04-27, MAE is:3.40 & sMAPE is:16.63% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 27.03% & 1.03\n",
      "for 2020-04-28, MAE is:1.74 & sMAPE is:7.58% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 26.87% & 1.02\n",
      "for 2020-04-29, MAE is:6.60 & sMAPE is:32.48% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 26.91% & 1.01\n",
      "for 2020-04-30, MAE is:8.16 & sMAPE is:49.58% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 27.10% & 1.01\n",
      "for 2020-05-01, MAE is:11.91 & sMAPE is:102.25% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 27.72% & 1.01\n",
      "for 2020-05-02, MAE is:5.78 & sMAPE is:46.52% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 27.87% & 1.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-03, MAE is:6.38 & sMAPE is:43.32% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 28.00% & 1.03\n",
      "for 2020-05-04, MAE is:3.41 & sMAPE is:15.89% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 27.90% & 1.02\n",
      "for 2020-05-05, MAE is:4.37 & sMAPE is:20.84% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 27.84% & 1.03\n",
      "for 2020-05-06, MAE is:3.64 & sMAPE is:16.82% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 27.76% & 1.03\n",
      "for 2020-05-07, MAE is:3.63 & sMAPE is:16.65% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 27.67% & 1.02\n",
      "for 2020-05-08, MAE is:2.38 & sMAPE is:12.12% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 27.55% & 1.02\n",
      "for 2020-05-09, MAE is:2.40 & sMAPE is:12.08% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 27.43% & 1.01\n",
      "for 2020-05-10, MAE is:7.23 & sMAPE is:54.44% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 27.64% & 1.01\n",
      "for 2020-05-11, MAE is:8.98 & sMAPE is:79.23% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 28.03% & 1.01\n",
      "for 2020-05-12, MAE is:3.49 & sMAPE is:15.38% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 27.93% & 1.02\n",
      "for 2020-05-13, MAE is:4.90 & sMAPE is:20.90% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 27.88% & 1.02\n",
      "for 2020-05-14, MAE is:4.30 & sMAPE is:20.25% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 27.82% & 1.02\n",
      "for 2020-05-15, MAE is:3.30 & sMAPE is:16.04% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 27.74% & 1.02\n",
      "for 2020-05-16, MAE is:4.73 & sMAPE is:25.98% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 27.72% & 1.02\n",
      "for 2020-05-17, MAE is:8.00 & sMAPE is:70.00% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 28.03% & 1.03\n",
      "for 2020-05-18, MAE is:3.07 & sMAPE is:17.35% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 27.95% & 1.02\n",
      "for 2020-05-19, MAE is:5.75 & sMAPE is:24.84% & rMAE is:2.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 27.93% & 1.04\n",
      "for 2020-05-20, MAE is:4.90 & sMAPE is:21.22% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 27.88% & 1.04\n",
      "for 2020-05-21, MAE is:5.19 & sMAPE is:26.08% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 27.87% & 1.04\n",
      "for 2020-05-22, MAE is:6.60 & sMAPE is:50.38% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 28.03% & 1.04\n",
      "for 2020-05-23, MAE is:18.26 & sMAPE is:91.00% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 28.46% & 1.04\n",
      "for 2020-05-24, MAE is:29.94 & sMAPE is:153.07% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 29.32% & 1.04\n",
      "for 2020-05-25, MAE is:4.85 & sMAPE is:27.20% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 29.31% & 1.05\n",
      "for 2020-05-26, MAE is:5.05 & sMAPE is:23.36% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 29.27% & 1.06\n",
      "for 2020-05-27, MAE is:6.75 & sMAPE is:27.62% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 29.26% & 1.07\n",
      "for 2020-05-28, MAE is:5.54 & sMAPE is:26.87% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 29.24% & 1.07\n",
      "for 2020-05-29, MAE is:3.60 & sMAPE is:20.10% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 29.18% & 1.07\n",
      "for 2020-05-30, MAE is:8.56 & sMAPE is:58.51% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 29.38% & 1.07\n",
      "for 2020-05-31, MAE is:16.48 & sMAPE is:115.73% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 29.94% & 1.07\n",
      "for 2020-06-01, MAE is:10.41 & sMAPE is:85.61% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 30.31% & 1.07\n",
      "for 2020-06-02, MAE is:3.15 & sMAPE is:14.36% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 30.20% & 1.07\n",
      "for 2020-06-03, MAE is:3.08 & sMAPE is:11.08% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 30.08% & 1.06\n",
      "for 2020-06-04, MAE is:4.85 & sMAPE is:20.92% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 30.02% & 1.06\n",
      "for 2020-06-05, MAE is:3.11 & sMAPE is:15.93% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 29.93% & 1.06\n",
      "for 2020-06-06, MAE is:11.21 & sMAPE is:116.20% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 30.48% & 1.07\n",
      "for 2020-06-07, MAE is:3.12 & sMAPE is:17.46% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 30.40% & 1.06\n",
      "for 2020-06-08, MAE is:5.42 & sMAPE is:19.44% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 30.33% & 1.05\n",
      "for 2020-06-09, MAE is:5.37 & sMAPE is:17.15% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 30.25% & 1.05\n",
      "for 2020-06-10, MAE is:2.86 & sMAPE is:9.46% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 30.12% & 1.05\n",
      "for 2020-06-11, MAE is:3.32 & sMAPE is:12.97% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 30.01% & 1.05\n",
      "for 2020-06-12, MAE is:3.04 & sMAPE is:13.86% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 29.91% & 1.05\n",
      "for 2020-06-13, MAE is:2.39 & sMAPE is:12.00% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 29.81% & 1.04\n",
      "for 2020-06-14, MAE is:1.63 & sMAPE is:8.39% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 29.68% & 1.04\n",
      "for 2020-06-15, MAE is:6.50 & sMAPE is:22.10% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 29.63% & 1.05\n",
      "for 2020-06-16, MAE is:4.24 & sMAPE is:13.66% & rMAE is:3.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 29.54% & 1.07\n",
      "for 2020-06-17, MAE is:6.31 & sMAPE is:19.40% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 29.48% & 1.07\n",
      "for 2020-06-18, MAE is:2.31 & sMAPE is:7.53% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 29.35% & 1.06\n",
      "for 2020-06-19, MAE is:4.01 & sMAPE is:13.79% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 29.26% & 1.06\n",
      "for 2020-06-20, MAE is:2.78 & sMAPE is:11.99% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 29.16% & 1.06\n",
      "for 2020-06-21, MAE is:4.16 & sMAPE is:24.93% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 29.13% & 1.06\n",
      "for 2020-06-22, MAE is:3.98 & sMAPE is:13.95% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 29.04% & 1.06\n",
      "for 2020-06-23, MAE is:3.71 & sMAPE is:11.42% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 28.94% & 1.06\n",
      "for 2020-06-24, MAE is:3.33 & sMAPE is:9.99% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 28.84% & 1.06\n",
      "for 2020-06-25, MAE is:3.90 & sMAPE is:12.03% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 28.74% & 1.06\n",
      "for 2020-06-26, MAE is:5.23 & sMAPE is:16.04% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 28.67% & 1.06\n",
      "for 2020-06-27, MAE is:3.10 & sMAPE is:12.29% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 28.58% & 1.06\n",
      "for 2020-06-28, MAE is:7.85 & sMAPE is:55.49% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 28.73% & 1.06\n",
      "for 2020-06-29, MAE is:6.41 & sMAPE is:26.35% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 28.71% & 1.07\n",
      "for 2020-06-30, MAE is:6.25 & sMAPE is:24.95% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 28.69% & 1.06\n",
      "for 2020-07-01, MAE is:4.79 & sMAPE is:15.51% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 28.62% & 1.07\n",
      "for 2020-07-02, MAE is:6.73 & sMAPE is:19.05% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 28.57% & 1.07\n",
      "for 2020-07-03, MAE is:6.29 & sMAPE is:20.25% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 28.52% & 1.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-04, MAE is:5.51 & sMAPE is:25.54% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 28.51% & 1.07\n",
      "for 2020-07-05, MAE is:18.49 & sMAPE is:138.52% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 29.10% & 1.07\n",
      "for 2020-07-06, MAE is:9.81 & sMAPE is:62.84% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 29.28% & 1.07\n",
      "for 2020-07-07, MAE is:5.77 & sMAPE is:19.80% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 29.23% & 1.07\n",
      "for 2020-07-08, MAE is:9.36 & sMAPE is:25.15% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 29.20% & 1.07\n",
      "for 2020-07-09, MAE is:3.34 & sMAPE is:8.41% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 29.10% & 1.06\n",
      "for 2020-07-10, MAE is:3.71 & sMAPE is:10.87% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 29.00% & 1.06\n",
      "for 2020-07-11, MAE is:4.19 & sMAPE is:16.59% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 28.94% & 1.06\n",
      "for 2020-07-12, MAE is:3.79 & sMAPE is:16.80% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 28.87% & 1.06\n",
      "for 2020-07-13, MAE is:4.18 & sMAPE is:12.58% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 28.79% & 1.05\n",
      "for 2020-07-14, MAE is:3.11 & sMAPE is:8.67% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 28.69% & 1.05\n",
      "for 2020-07-15, MAE is:5.59 & sMAPE is:15.04% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 28.62% & 1.06\n",
      "for 2020-07-16, MAE is:7.21 & sMAPE is:18.08% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 28.56% & 1.06\n",
      "for 2020-07-17, MAE is:2.13 & sMAPE is:5.59% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 28.45% & 1.06\n",
      "for 2020-07-18, MAE is:3.57 & sMAPE is:14.21% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 28.38% & 1.07\n",
      "for 2020-07-19, MAE is:4.11 & sMAPE is:16.26% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 28.32% & 1.07\n",
      "for 2020-07-20, MAE is:7.25 & sMAPE is:25.05% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 28.30% & 1.07\n",
      "for 2020-07-21, MAE is:7.54 & sMAPE is:34.54% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 28.33% & 1.07\n",
      "for 2020-07-22, MAE is:6.58 & sMAPE is:22.64% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 28.30% & 1.07\n",
      "for 2020-07-23, MAE is:6.62 & sMAPE is:21.23% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 28.27% & 1.07\n",
      "for 2020-07-24, MAE is:4.47 & sMAPE is:16.01% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 28.21% & 1.07\n",
      "for 2020-07-25, MAE is:5.19 & sMAPE is:23.11% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 28.19% & 1.07\n",
      "for 2020-07-26, MAE is:8.71 & sMAPE is:59.29% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 28.34% & 1.07\n",
      "for 2020-07-27, MAE is:7.85 & sMAPE is:29.72% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 28.34% & 1.07\n",
      "for 2020-07-28, MAE is:5.93 & sMAPE is:25.25% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 28.33% & 1.07\n",
      "for 2020-07-29, MAE is:6.60 & sMAPE is:24.04% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 28.31% & 1.07\n",
      "for 2020-07-30, MAE is:10.32 & sMAPE is:36.72% & rMAE is:2.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 28.35% & 1.08\n",
      "for 2020-07-31, MAE is:7.66 & sMAPE is:23.58% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 28.32% & 1.08\n",
      "for 2020-08-01, MAE is:4.17 & sMAPE is:16.31% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 28.27% & 1.08\n",
      "for 2020-08-02, MAE is:3.62 & sMAPE is:16.46% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 28.21% & 1.07\n",
      "for 2020-08-03, MAE is:8.81 & sMAPE is:26.88% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 28.21% & 1.07\n",
      "for 2020-08-04, MAE is:3.27 & sMAPE is:10.14% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 28.12% & 1.07\n",
      "for 2020-08-05, MAE is:6.80 & sMAPE is:24.25% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 28.11% & 1.07\n",
      "for 2020-08-06, MAE is:6.88 & sMAPE is:21.85% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 28.08% & 1.08\n",
      "for 2020-08-07, MAE is:5.55 & sMAPE is:16.27% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 28.02% & 1.08\n",
      "for 2020-08-08, MAE is:6.56 & sMAPE is:22.54% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 28.00% & 1.08\n",
      "for 2020-08-09, MAE is:5.12 & sMAPE is:19.53% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 27.96% & 1.08\n",
      "for 2020-08-10, MAE is:5.88 & sMAPE is:16.51% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 27.91% & 1.09\n",
      "for 2020-08-11, MAE is:5.52 & sMAPE is:14.26% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 27.85% & 1.08\n",
      "for 2020-08-12, MAE is:4.94 & sMAPE is:11.71% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 27.78% & 1.08\n",
      "for 2020-08-13, MAE is:2.92 & sMAPE is:7.08% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 27.69% & 1.08\n",
      "for 2020-08-14, MAE is:4.57 & sMAPE is:12.67% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 27.62% & 1.08\n",
      "for 2020-08-15, MAE is:4.08 & sMAPE is:14.13% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 27.56% & 1.08\n",
      "for 2020-08-16, MAE is:3.76 & sMAPE is:13.81% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 27.50% & 1.09\n",
      "for 2020-08-17, MAE is:6.93 & sMAPE is:18.08% & rMAE is:2.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 27.46% & 1.09\n",
      "for 2020-08-18, MAE is:3.95 & sMAPE is:9.43% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 27.38% & 1.09\n",
      "for 2020-08-19, MAE is:4.15 & sMAPE is:10.89% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 27.31% & 1.09\n",
      "for 2020-08-20, MAE is:4.22 & sMAPE is:10.40% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 27.24% & 1.09\n",
      "for 2020-08-21, MAE is:5.18 & sMAPE is:16.87% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 27.19% & 1.09\n",
      "for 2020-08-22, MAE is:5.08 & sMAPE is:29.30% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 27.20% & 1.09\n",
      "for 2020-08-23, MAE is:6.52 & sMAPE is:38.29% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 27.25% & 1.09\n",
      "for 2020-08-24, MAE is:9.63 & sMAPE is:21.86% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 27.23% & 1.09\n",
      "for 2020-08-25, MAE is:9.74 & sMAPE is:23.47% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 27.21% & 1.09\n",
      "for 2020-08-26, MAE is:8.60 & sMAPE is:35.50% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 27.25% & 1.09\n",
      "for 2020-08-27, MAE is:17.91 & sMAPE is:37.84% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 27.29% & 1.09\n",
      "for 2020-08-28, MAE is:10.13 & sMAPE is:23.94% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 27.28% & 1.09\n",
      "for 2020-08-29, MAE is:5.30 & sMAPE is:16.32% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 27.23% & 1.09\n",
      "for 2020-08-30, MAE is:4.17 & sMAPE is:13.66% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 27.17% & 1.09\n",
      "for 2020-08-31, MAE is:15.14 & sMAPE is:29.74% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 27.18% & 1.09\n",
      "for 2020-09-01, MAE is:4.42 & sMAPE is:8.96% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 27.11% & 1.09\n",
      "for 2020-09-02, MAE is:7.68 & sMAPE is:16.08% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 27.07% & 1.08\n",
      "for 2020-09-03, MAE is:9.95 & sMAPE is:21.93% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 27.04% & 1.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-04, MAE is:6.12 & sMAPE is:15.23% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 27.00% & 1.08\n",
      "for 2020-09-05, MAE is:4.14 & sMAPE is:13.65% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 26.94% & 1.08\n",
      "for 2020-09-06, MAE is:6.95 & sMAPE is:22.06% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 26.92% & 1.09\n",
      "for 2020-09-07, MAE is:6.07 & sMAPE is:13.79% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 26.87% & 1.09\n",
      "for 2020-09-08, MAE is:5.86 & sMAPE is:12.95% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 26.82% & 1.09\n",
      "for 2020-09-09, MAE is:4.56 & sMAPE is:10.40% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 26.75% & 1.08\n",
      "for 2020-09-10, MAE is:6.69 & sMAPE is:13.38% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 26.70% & 1.08\n",
      "for 2020-09-11, MAE is:8.75 & sMAPE is:19.17% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 26.67% & 1.08\n",
      "for 2020-09-12, MAE is:5.69 & sMAPE is:17.81% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 26.63% & 1.08\n",
      "for 2020-09-13, MAE is:8.42 & sMAPE is:38.47% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 26.68% & 1.08\n",
      "for 2020-09-14, MAE is:14.41 & sMAPE is:26.70% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 26.68% & 1.09\n",
      "for 2020-09-15, MAE is:19.81 & sMAPE is:25.08% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 26.67% & 1.08\n",
      "for 2020-09-16, MAE is:17.10 & sMAPE is:28.16% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 26.68% & 1.09\n",
      "for 2020-09-17, MAE is:9.62 & sMAPE is:21.04% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 26.66% & 1.09\n",
      "for 2020-09-18, MAE is:8.65 & sMAPE is:22.43% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 26.64% & 1.09\n",
      "for 2020-09-19, MAE is:7.02 & sMAPE is:21.33% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 26.62% & 1.09\n",
      "for 2020-09-20, MAE is:8.58 & sMAPE is:26.26% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 26.62% & 1.09\n",
      "for 2020-09-21, MAE is:19.61 & sMAPE is:30.35% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 26.64% & 1.09\n",
      "for 2020-09-22, MAE is:14.55 & sMAPE is:24.18% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 26.63% & 1.09\n",
      "for 2020-09-23, MAE is:18.94 & sMAPE is:41.99% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 26.68% & 1.09\n",
      "for 2020-09-24, MAE is:8.96 & sMAPE is:24.11% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 26.67% & 1.09\n",
      "for 2020-09-25, MAE is:6.16 & sMAPE is:15.61% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 26.63% & 1.09\n",
      "for 2020-09-26, MAE is:2.94 & sMAPE is:8.75% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 26.57% & 1.09\n",
      "for 2020-09-27, MAE is:7.78 & sMAPE is:27.53% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 26.57% & 1.09\n",
      "for 2020-09-28, MAE is:4.10 & sMAPE is:8.71% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 26.50% & 1.09\n",
      "for 2020-09-29, MAE is:8.97 & sMAPE is:13.68% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 26.46% & 1.09\n",
      "for 2020-09-30, MAE is:6.55 & sMAPE is:13.00% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 26.41% & 1.09\n",
      "for 2020-10-01, MAE is:3.85 & sMAPE is:8.49% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 26.34% & 1.08\n",
      "for 2020-10-02, MAE is:5.06 & sMAPE is:13.56% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 26.30% & 1.08\n",
      "for 2020-10-03, MAE is:6.70 & sMAPE is:18.30% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 26.27% & 1.08\n",
      "for 2020-10-04, MAE is:9.94 & sMAPE is:49.05% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 26.35% & 1.08\n",
      "for 2020-10-05, MAE is:7.11 & sMAPE is:28.80% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 26.36% & 1.08\n",
      "for 2020-10-06, MAE is:7.64 & sMAPE is:22.51% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 26.34% & 1.08\n",
      "for 2020-10-07, MAE is:5.53 & sMAPE is:14.46% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 26.30% & 1.08\n",
      "for 2020-10-08, MAE is:8.09 & sMAPE is:19.16% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 26.28% & 1.08\n",
      "for 2020-10-09, MAE is:6.20 & sMAPE is:13.65% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 26.23% & 1.08\n",
      "for 2020-10-10, MAE is:2.48 & sMAPE is:7.16% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 26.17% & 1.07\n",
      "for 2020-10-11, MAE is:3.85 & sMAPE is:12.20% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 26.12% & 1.07\n",
      "for 2020-10-12, MAE is:5.83 & sMAPE is:11.98% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 26.07% & 1.07\n",
      "for 2020-10-13, MAE is:5.84 & sMAPE is:12.58% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 26.02% & 1.07\n",
      "for 2020-10-14, MAE is:6.11 & sMAPE is:13.59% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.98% & 1.07\n",
      "for 2020-10-15, MAE is:6.68 & sMAPE is:15.50% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.94% & 1.06\n",
      "for 2020-10-16, MAE is:5.41 & sMAPE is:11.38% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.89% & 1.06\n",
      "for 2020-10-17, MAE is:3.68 & sMAPE is:8.83% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 25.83% & 1.06\n",
      "for 2020-10-18, MAE is:5.35 & sMAPE is:13.61% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 25.79% & 1.06\n",
      "for 2020-10-19, MAE is:10.78 & sMAPE is:21.94% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.78% & 1.06\n",
      "for 2020-10-20, MAE is:3.45 & sMAPE is:8.94% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 25.72% & 1.06\n",
      "for 2020-10-21, MAE is:5.11 & sMAPE is:13.00% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 25.68% & 1.06\n",
      "for 2020-10-22, MAE is:4.69 & sMAPE is:11.45% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 25.63% & 1.06\n",
      "for 2020-10-23, MAE is:6.28 & sMAPE is:14.60% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 25.59% & 1.06\n",
      "for 2020-10-24, MAE is:9.59 & sMAPE is:27.57% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 25.60% & 1.06\n",
      "for 2020-10-25, MAE is:12.83 & sMAPE is:77.77% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 25.77% & 1.06\n",
      "for 2020-10-26, MAE is:5.13 & sMAPE is:14.70% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 25.74% & 1.05\n",
      "for 2020-10-27, MAE is:6.64 & sMAPE is:15.38% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 25.70% & 1.06\n",
      "for 2020-10-28, MAE is:4.78 & sMAPE is:12.43% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.66% & 1.06\n",
      "for 2020-10-29, MAE is:5.93 & sMAPE is:18.56% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.63% & 1.05\n",
      "for 2020-10-30, MAE is:6.88 & sMAPE is:28.30% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.64% & 1.05\n",
      "for 2020-10-31, MAE is:4.88 & sMAPE is:15.57% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.61% & 1.05\n",
      "for 2020-11-01, MAE is:8.88 & sMAPE is:47.12% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.68% & 1.05\n",
      "for 2020-11-02, MAE is:11.18 & sMAPE is:58.62% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 25.79% & 1.05\n",
      "for 2020-11-03, MAE is:5.22 & sMAPE is:15.19% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 25.75% & 1.05\n",
      "for 2020-11-04, MAE is:5.35 & sMAPE is:13.87% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 25.71% & 1.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-05, MAE is:4.68 & sMAPE is:12.28% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 25.67% & 1.05\n",
      "for 2020-11-06, MAE is:4.79 & sMAPE is:11.70% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.63% & 1.05\n",
      "for 2020-11-07, MAE is:5.17 & sMAPE is:15.57% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.59% & 1.05\n",
      "for 2020-11-08, MAE is:5.07 & sMAPE is:15.57% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 25.56% & 1.05\n",
      "for 2020-11-09, MAE is:4.79 & sMAPE is:10.68% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 25.51% & 1.05\n",
      "for 2020-11-10, MAE is:5.02 & sMAPE is:10.97% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 25.47% & 1.04\n",
      "for 2020-11-11, MAE is:6.85 & sMAPE is:17.90% & rMAE is:2.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 25.44% & 1.05\n",
      "for 2020-11-12, MAE is:4.22 & sMAPE is:10.61% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 25.40% & 1.05\n",
      "for 2020-11-13, MAE is:3.36 & sMAPE is:8.41% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 25.34% & 1.05\n",
      "for 2020-11-14, MAE is:5.21 & sMAPE is:14.22% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 25.31% & 1.05\n",
      "for 2020-11-15, MAE is:13.01 & sMAPE is:84.16% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 25.49% & 1.05\n",
      "for 2020-11-16, MAE is:9.14 & sMAPE is:55.10% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.59% & 1.05\n",
      "for 2020-11-17, MAE is:4.07 & sMAPE is:10.50% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 25.54% & 1.05\n",
      "for 2020-11-18, MAE is:5.08 & sMAPE is:12.77% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 25.50% & 1.05\n",
      "for 2020-11-19, MAE is:7.24 & sMAPE is:32.06% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 25.52% & 1.05\n",
      "for 2020-11-20, MAE is:5.93 & sMAPE is:14.84% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 25.49% & 1.05\n",
      "for 2020-11-21, MAE is:4.30 & sMAPE is:11.32% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 25.44% & 1.05\n",
      "for 2020-11-22, MAE is:7.18 & sMAPE is:19.41% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 25.42% & 1.04\n",
      "for 2020-11-23, MAE is:6.34 & sMAPE is:14.32% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 25.39% & 1.04\n",
      "for 2020-11-24, MAE is:7.47 & sMAPE is:17.25% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 25.37% & 1.04\n",
      "for 2020-11-25, MAE is:10.10 & sMAPE is:24.85% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 25.36% & 1.05\n",
      "for 2020-11-26, MAE is:13.27 & sMAPE is:24.54% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 25.36% & 1.04\n",
      "for 2020-11-27, MAE is:11.41 & sMAPE is:18.22% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 25.34% & 1.04\n",
      "for 2020-11-28, MAE is:5.54 & sMAPE is:11.87% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 25.30% & 1.04\n",
      "for 2020-11-29, MAE is:4.48 & sMAPE is:11.06% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 25.26% & 1.04\n",
      "for 2020-11-30, MAE is:11.50 & sMAPE is:21.35% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 25.25% & 1.04\n",
      "for 2020-12-01, MAE is:6.01 & sMAPE is:11.32% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 25.20% & 1.04\n",
      "for 2020-12-02, MAE is:24.67 & sMAPE is:36.74% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 25.24% & 1.04\n",
      "for 2020-12-03, MAE is:20.94 & sMAPE is:39.94% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 25.28% & 1.04\n",
      "for 2020-12-04, MAE is:6.94 & sMAPE is:16.53% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 25.26% & 1.04\n",
      "for 2020-12-05, MAE is:7.22 & sMAPE is:16.01% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 25.23% & 1.04\n",
      "for 2020-12-06, MAE is:5.76 & sMAPE is:12.34% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 25.19% & 1.04\n",
      "for 2020-12-07, MAE is:17.12 & sMAPE is:25.00% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 25.19% & 1.04\n",
      "for 2020-12-08, MAE is:12.62 & sMAPE is:17.11% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 25.17% & 1.04\n",
      "for 2020-12-09, MAE is:20.00 & sMAPE is:26.82% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 25.17% & 1.04\n",
      "for 2020-12-10, MAE is:19.02 & sMAPE is:26.98% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 25.18% & 1.04\n",
      "for 2020-12-11, MAE is:11.80 & sMAPE is:21.83% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 25.17% & 1.04\n",
      "for 2020-12-12, MAE is:3.94 & sMAPE is:8.63% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 25.12% & 1.04\n",
      "for 2020-12-13, MAE is:3.97 & sMAPE is:9.63% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 25.07% & 1.04\n",
      "for 2020-12-14, MAE is:10.28 & sMAPE is:21.67% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 25.07% & 1.04\n",
      "for 2020-12-15, MAE is:6.00 & sMAPE is:12.22% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 25.03% & 1.04\n",
      "for 2020-12-16, MAE is:8.11 & sMAPE is:15.77% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 25.00% & 1.04\n",
      "for 2020-12-17, MAE is:6.72 & sMAPE is:13.19% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 24.97% & 1.04\n",
      "for 2020-12-18, MAE is:11.90 & sMAPE is:23.16% & rMAE is:2.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 24.96% & 1.04\n",
      "for 2020-12-19, MAE is:4.21 & sMAPE is:10.94% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 24.92% & 1.04\n",
      "for 2020-12-20, MAE is:8.57 & sMAPE is:23.31% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 24.92% & 1.04\n",
      "for 2020-12-21, MAE is:4.51 & sMAPE is:9.89% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 24.88% & 1.04\n",
      "for 2020-12-22, MAE is:11.36 & sMAPE is:49.38% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 24.95% & 1.04\n",
      "for 2020-12-23, MAE is:6.81 & sMAPE is:17.47% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 24.92% & 1.04\n",
      "for 2020-12-24, MAE is:10.10 & sMAPE is:45.62% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 24.98% & 1.04\n",
      "for 2020-12-25, MAE is:8.09 & sMAPE is:28.91% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 24.99% & 1.04\n",
      "for 2020-12-26, MAE is:8.25 & sMAPE is:29.38% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 25.01% & 1.04\n",
      "for 2020-12-27, MAE is:13.17 & sMAPE is:84.53% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 25.17% & 1.03\n",
      "for 2020-12-28, MAE is:13.57 & sMAPE is:36.25% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 25.20% & 1.04\n",
      "for 2020-12-29, MAE is:10.86 & sMAPE is:24.91% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 25.20% & 1.04\n",
      "for 2020-12-30, MAE is:3.52 & sMAPE is:7.01% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 25.15% & 1.03\n",
      "for 2020-12-31, MAE is:4.59 & sMAPE is:9.55% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 25.11% & 1.03\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.2 - (Calib Year = 3)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:08:32,382]\u001b[0m A new study created in RDB with name: BE_2021\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:08:52,519]\u001b[0m Trial 1 finished with value: 9.909039195750527 and parameters: {'n_hidden': 3, 'learning_rate': 0.040918455181815576, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3472365192738855, 'dropout_rate_Layer_2': 0.2738253325400156, 'dropout_rate_Layer_3': 0.368448911006289, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012536389841914459, 'l1_Layer_2': 0.013798438781641519, 'l1_Layer_3': 0.07509340363213175, 'n_units_Layer_1': 235, 'n_units_Layer_2': 75, 'n_units_Layer_3': 145}. Best is trial 1 with value: 9.909039195750527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.91 | sMAPE for Validation Set is: 34.32% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 52.73 | sMAPE for Test Set is: 50.57% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:08:59,472]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:09:03,911]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:09:11,216]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:09:14,826]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:09:15,714]\u001b[0m Trial 0 finished with value: 7.371286576146204 and parameters: {'n_hidden': 3, 'learning_rate': 0.01737472286879931, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10411250994790687, 'dropout_rate_Layer_2': 0.22388677362085915, 'dropout_rate_Layer_3': 0.29714557038638373, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011949852349836467, 'l1_Layer_2': 0.021833213122179475, 'l1_Layer_3': 8.174593767642018e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 55, 'n_units_Layer_3': 255}. Best is trial 0 with value: 7.371286576146204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.37 | sMAPE for Validation Set is: 27.57% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 51.12 | sMAPE for Test Set is: 49.34% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:09:20,476]\u001b[0m Trial 3 finished with value: 9.127182206788767 and parameters: {'n_hidden': 4, 'learning_rate': 0.004518289474066352, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3336423822281091, 'dropout_rate_Layer_2': 0.20994523339772178, 'dropout_rate_Layer_3': 0.08258281841787306, 'dropout_rate_Layer_4': 0.22189021789866303, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003577248256190862, 'l1_Layer_2': 0.055362825902709356, 'l1_Layer_3': 0.0013451385299910745, 'l1_Layer_4': 0.026729525911163995, 'n_units_Layer_1': 185, 'n_units_Layer_2': 120, 'n_units_Layer_3': 130, 'n_units_Layer_4': 195}. Best is trial 0 with value: 7.371286576146204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.13 | sMAPE for Validation Set is: 32.36% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 54.32 | sMAPE for Test Set is: 53.26% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:09:22,674]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:09:25,374]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:09:26,739]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:09:28,942]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:09:53,267]\u001b[0m Trial 2 finished with value: 10.616721983876843 and parameters: {'n_hidden': 4, 'learning_rate': 0.033695013653501936, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32198295863822224, 'dropout_rate_Layer_2': 0.34425327512740117, 'dropout_rate_Layer_3': 0.21857493658506633, 'dropout_rate_Layer_4': 0.31229995867028937, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0008889805765492182, 'l1_Layer_2': 1.5527834469577197e-05, 'l1_Layer_3': 3.539917697143823e-05, 'l1_Layer_4': 0.004358953291539783, 'n_units_Layer_1': 255, 'n_units_Layer_2': 145, 'n_units_Layer_3': 135, 'n_units_Layer_4': 90}. Best is trial 0 with value: 7.371286576146204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.62 | sMAPE for Validation Set is: 36.46% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 57.60 | sMAPE for Test Set is: 59.04% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:09:58,629]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.06 | sMAPE for Validation Set is: 26.37% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 49.03 | sMAPE for Test Set is: 47.11% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:10:00,704]\u001b[0m Trial 12 finished with value: 7.057152288272189 and parameters: {'n_hidden': 4, 'learning_rate': 0.006405776940198212, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025015263183949223, 'dropout_rate_Layer_2': 0.37791739622931714, 'dropout_rate_Layer_3': 0.13562790706736153, 'dropout_rate_Layer_4': 0.022935146616855074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012389130712027461, 'l1_Layer_2': 0.044519634707480056, 'l1_Layer_3': 0.0007935209620052769, 'l1_Layer_4': 0.03341035112722921, 'n_units_Layer_1': 95, 'n_units_Layer_2': 280, 'n_units_Layer_3': 100, 'n_units_Layer_4': 285}. Best is trial 12 with value: 7.057152288272189.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:10:07,315]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:10:09,516]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:10:17,288]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:10:20,544]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:10:25,303]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:10:29,669]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:10:32,596]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:10:39,599]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:10:44,235]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:10:48,813]\u001b[0m Trial 13 finished with value: 8.897218913828318 and parameters: {'n_hidden': 4, 'learning_rate': 0.031617974478565555, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02582221569012937, 'dropout_rate_Layer_2': 0.1378398755553034, 'dropout_rate_Layer_3': 0.32927032216031293, 'dropout_rate_Layer_4': 0.277047751947675, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.016124923051582977, 'l1_Layer_2': 0.01320758589931374, 'l1_Layer_3': 7.377802926871406e-05, 'l1_Layer_4': 1.0075574146529488e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 280, 'n_units_Layer_3': 85, 'n_units_Layer_4': 115}. Best is trial 12 with value: 7.057152288272189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.90 | sMAPE for Validation Set is: 31.82% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 54.72 | sMAPE for Test Set is: 54.15% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:10:55,070]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:10:55,389]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:11:02,439]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:11:02,652]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:11:10,452]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:11:11,289]\u001b[0m Trial 14 finished with value: 6.924536302751595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017562839967556203, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2431238767494473, 'dropout_rate_Layer_2': 0.04976719557004468, 'dropout_rate_Layer_3': 0.27868340760385196, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0048335068207748565, 'l1_Layer_2': 8.021062936613564e-05, 'l1_Layer_3': 0.06153857680660975, 'n_units_Layer_1': 135, 'n_units_Layer_2': 255, 'n_units_Layer_3': 125}. Best is trial 14 with value: 6.924536302751595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 25.83% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 49.91 | sMAPE for Test Set is: 47.86% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:11:18,498]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:11:19,110]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:11:25,943]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:11:26,979]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:11:32,918]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:11:36,326]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:11:47,846]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:11:58,610]\u001b[0m Trial 36 finished with value: 7.693376408411379 and parameters: {'n_hidden': 4, 'learning_rate': 0.002516137925239102, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1707333526307338, 'dropout_rate_Layer_2': 0.047802012061358305, 'dropout_rate_Layer_3': 0.2630185253328944, 'dropout_rate_Layer_4': 0.22541980716254992, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010112377865733041, 'l1_Layer_2': 0.00014365289897542462, 'l1_Layer_3': 0.0054869936356882806, 'l1_Layer_4': 0.004527336293850969, 'n_units_Layer_1': 195, 'n_units_Layer_2': 225, 'n_units_Layer_3': 170, 'n_units_Layer_4': 255}. Best is trial 14 with value: 6.924536302751595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.69 | sMAPE for Validation Set is: 28.40% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 50.85 | sMAPE for Test Set is: 48.48% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:12:04,112]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:08,092]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:13,545]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:13,890]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:19,574]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:19,858]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:26,810]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:30,601]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:34,550]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:35,968]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:44,707]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:45,397]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:53,844]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:12:54,620]\u001b[0m Trial 25 finished with value: 10.267187521853932 and parameters: {'n_hidden': 3, 'learning_rate': 0.001814194626137113, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2809184898342234, 'dropout_rate_Layer_2': 0.12335141348506827, 'dropout_rate_Layer_3': 0.3822363063318656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.08044295303305182, 'l1_Layer_2': 0.004334445917038243, 'l1_Layer_3': 0.05021669007334306, 'n_units_Layer_1': 150, 'n_units_Layer_2': 240, 'n_units_Layer_3': 205}. Best is trial 14 with value: 6.924536302751595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.27 | sMAPE for Validation Set is: 35.10% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 47.65 | sMAPE for Test Set is: 44.50% | rMAE for Test Set is: 1.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:12:58,676]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:04,198]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:04,944]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:11,925]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:19,800]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:23,041]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:24,357]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:29,656]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:30,033]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:34,840]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:41,856]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:43,562]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:45,978]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:49,139]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:53,802]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:54,060]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:13:55,021]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:01,452]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:02,095]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:03,740]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:03,809]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:11,745]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:14,341]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:19,476]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:23,931]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:29,036]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:33,899]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:42,431]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:47,803]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:14:51,760]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:00,164]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:00,334]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:07,927]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:08,178]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:20,057]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:20,653]\u001b[0m Trial 79 finished with value: 7.144788068418937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014502157255863372, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22114061150957992, 'dropout_rate_Layer_2': 0.10412553818532568, 'dropout_rate_Layer_3': 0.31069181680012814, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006169152054983349, 'l1_Layer_2': 0.03333891935410788, 'l1_Layer_3': 0.00038044357655795026, 'n_units_Layer_1': 215, 'n_units_Layer_2': 240, 'n_units_Layer_3': 215}. Best is trial 14 with value: 6.924536302751595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.14 | sMAPE for Validation Set is: 26.74% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 47.02 | sMAPE for Test Set is: 43.76% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:15:25,544]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:32,515]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:34,917]\u001b[0m Trial 77 finished with value: 6.500728807451555 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009809662874943584, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33644564432074714, 'dropout_rate_Layer_2': 0.13392651107667813, 'dropout_rate_Layer_3': 0.23798671379454178, 'dropout_rate_Layer_4': 0.37069511305113445, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012972851708807568, 'l1_Layer_2': 0.038204608045246294, 'l1_Layer_3': 0.01054823608501746, 'l1_Layer_4': 0.0011451890600743253, 'n_units_Layer_1': 130, 'n_units_Layer_2': 55, 'n_units_Layer_3': 235, 'n_units_Layer_4': 180}. Best is trial 77 with value: 6.500728807451555.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 24.49% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 51.00 | sMAPE for Test Set is: 49.08% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:15:35,473]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:36,313]\u001b[0m Trial 90 finished with value: 9.256198394947175 and parameters: {'n_hidden': 3, 'learning_rate': 0.046204697112091304, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2662555625100395, 'dropout_rate_Layer_2': 0.16958268033586538, 'dropout_rate_Layer_3': 0.3646157563094016, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 5.283291939444734e-05, 'l1_Layer_2': 0.005013909060324907, 'l1_Layer_3': 0.00011322201963616603, 'n_units_Layer_1': 80, 'n_units_Layer_2': 55, 'n_units_Layer_3': 160}. Best is trial 77 with value: 6.500728807451555.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.26 | sMAPE for Validation Set is: 32.54% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 53.81 | sMAPE for Test Set is: 54.01% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:15:37,876]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:41,104]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:48,150]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:53,678]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:56,107]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:15:59,994]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:16:08,076]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:16:16,113]\u001b[0m Trial 95 finished with value: 6.7623884088902315 and parameters: {'n_hidden': 3, 'learning_rate': 0.002296816717805328, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.189380252195034, 'dropout_rate_Layer_2': 0.11598780695885855, 'dropout_rate_Layer_3': 0.0983578434729536, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001633512641892946, 'l1_Layer_2': 0.006119091664012129, 'l1_Layer_3': 0.0016568713585417498, 'n_units_Layer_1': 160, 'n_units_Layer_2': 210, 'n_units_Layer_3': 105}. Best is trial 77 with value: 6.500728807451555.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 25.44% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 49.04 | sMAPE for Test Set is: 46.27% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:16:16,611]\u001b[0m Trial 96 finished with value: 6.442637624266864 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007321490067195223, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34328690345582935, 'dropout_rate_Layer_2': 0.14860324784132067, 'dropout_rate_Layer_3': 0.1779938375944336, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016404928287674182, 'l1_Layer_2': 0.005985141358156659, 'l1_Layer_3': 0.0001595466434544743, 'n_units_Layer_1': 190, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 96 with value: 6.442637624266864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 24.41% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 47.01 | sMAPE for Test Set is: 43.83% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:16:21,607]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:16:27,022]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:16:32,114]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:16:35,865]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:16:37,791]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:16:41,488]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:16:43,253]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:16:47,435]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:16:47,760]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:16:52,982]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:16:54,498]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:00,149]\u001b[0m Trial 110 finished with value: 6.191625467257137 and parameters: {'n_hidden': 3, 'learning_rate': 0.01671172966790169, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27856106072293024, 'dropout_rate_Layer_2': 0.0727835268974279, 'dropout_rate_Layer_3': 0.27864321673032694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002205404306791885, 'l1_Layer_2': 0.0003461730253872179, 'l1_Layer_3': 0.00584766544617037, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 275}. Best is trial 110 with value: 6.191625467257137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 23.98% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 26.20 | sMAPE for Test Set is: 29.53% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:17:03,246]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:04,031]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:10,939]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:15,425]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:18,275]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:20,154]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:23,506]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:24,610]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:27,192]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:33,282]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:34,890]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:50,159]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:17:59,183]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:18:04,916]\u001b[0m Trial 126 finished with value: 6.611849780388198 and parameters: {'n_hidden': 3, 'learning_rate': 0.0046095201555361245, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27673203160088755, 'dropout_rate_Layer_2': 0.13838030118265957, 'dropout_rate_Layer_3': 0.15178430453850886, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019765444082697758, 'l1_Layer_2': 0.005993035768773404, 'l1_Layer_3': 2.502456809535148e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 215, 'n_units_Layer_3': 215}. Best is trial 110 with value: 6.191625467257137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 25.00% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 49.09 | sMAPE for Test Set is: 46.19% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:18:10,509]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:18:25,897]\u001b[0m Trial 131 finished with value: 8.485477692923727 and parameters: {'n_hidden': 3, 'learning_rate': 0.010650017003548198, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3701415740112885, 'dropout_rate_Layer_2': 0.27061448900310414, 'dropout_rate_Layer_3': 0.21413782180501803, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.010261807226967033, 'l1_Layer_2': 0.00399276215568126, 'l1_Layer_3': 0.0011239243038446336, 'n_units_Layer_1': 185, 'n_units_Layer_2': 110, 'n_units_Layer_3': 115}. Best is trial 110 with value: 6.191625467257137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 30.63% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 51.60 | sMAPE for Test Set is: 49.42% | rMAE for Test Set is: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:18:29,521]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:18:34,851]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:18:40,005]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:18:46,731]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:18:51,131]\u001b[0m Trial 132 finished with value: 7.092866909386609 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009848761341068539, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04029350480054522, 'dropout_rate_Layer_2': 0.35914793225128927, 'dropout_rate_Layer_3': 0.3394659967839465, 'dropout_rate_Layer_4': 0.24252613176700102, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.046313790106301184, 'l1_Layer_2': 0.0345922191050965, 'l1_Layer_3': 0.004729899618281017, 'l1_Layer_4': 4.9870894501050814e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 115, 'n_units_Layer_3': 150, 'n_units_Layer_4': 230}. Best is trial 110 with value: 6.191625467257137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 26.47% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 48.74 | sMAPE for Test Set is: 46.22% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:18:54,992]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:18:58,923]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:19:02,393]\u001b[0m Trial 118 finished with value: 5.487790396511279 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005232288558382028, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27055486562081665, 'dropout_rate_Layer_2': 0.07326234298274395, 'dropout_rate_Layer_3': 0.12986129664113022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008714058668851592, 'l1_Layer_2': 0.0002289641766202895, 'l1_Layer_3': 0.008650901936194265, 'n_units_Layer_1': 265, 'n_units_Layer_2': 205, 'n_units_Layer_3': 300}. Best is trial 118 with value: 5.487790396511279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 21.44% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.57 | sMAPE for Test Set is: 26.22% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:19:05,640]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:19:10,611]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:19:16,516]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:19:21,938]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:19:22,188]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:19:29,058]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:19:37,587]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:19:40,106]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:19:43,705]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:19:49,449]\u001b[0m Trial 141 finished with value: 7.06036391634463 and parameters: {'n_hidden': 4, 'learning_rate': 0.04453735413994927, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10075817715933284, 'dropout_rate_Layer_2': 0.1288578513266869, 'dropout_rate_Layer_3': 0.07431093245019907, 'dropout_rate_Layer_4': 0.3158898510094892, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.018047774106693792, 'l1_Layer_2': 0.017555870676796457, 'l1_Layer_3': 0.008828787687611347, 'l1_Layer_4': 0.015819286867063614, 'n_units_Layer_1': 55, 'n_units_Layer_2': 75, 'n_units_Layer_3': 235, 'n_units_Layer_4': 160}. Best is trial 118 with value: 5.487790396511279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.06 | sMAPE for Validation Set is: 27.03% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 57.68 | sMAPE for Test Set is: 60.06% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:19:49,685]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:19:55,674]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:19:59,131]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:20:08,798]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:20:15,590]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:20:15,677]\u001b[0m Trial 137 finished with value: 5.590886440553817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006751249714554195, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28101134738238237, 'dropout_rate_Layer_2': 0.06563274400563729, 'dropout_rate_Layer_3': 0.1365785896714757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007977835409364422, 'l1_Layer_2': 0.00024077869791572017, 'l1_Layer_3': 0.008971074186003503, 'n_units_Layer_1': 265, 'n_units_Layer_2': 210, 'n_units_Layer_3': 300}. Best is trial 118 with value: 5.487790396511279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 21.92% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.72 | sMAPE for Test Set is: 26.44% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:20:35,948]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:20:41,755]\u001b[0m Trial 150 finished with value: 6.253675377700986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019510972747644308, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2155510452517982, 'dropout_rate_Layer_2': 0.16378225430489277, 'dropout_rate_Layer_3': 0.23477109661860432, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002775477515476713, 'l1_Layer_2': 0.0005191387903082916, 'l1_Layer_3': 1.20708175374078e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 75, 'n_units_Layer_3': 225}. Best is trial 118 with value: 5.487790396511279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 24.00% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 48.53 | sMAPE for Test Set is: 45.89% | rMAE for Test Set is: 1.66\n",
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 25.59% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 48.06 | sMAPE for Test Set is: 45.39% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:20:42,067]\u001b[0m Trial 157 finished with value: 6.851977450703733 and parameters: {'n_hidden': 4, 'learning_rate': 0.002515714241160847, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06916186976054214, 'dropout_rate_Layer_2': 0.3606035544583062, 'dropout_rate_Layer_3': 0.3227776590529705, 'dropout_rate_Layer_4': 0.27369419152410746, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.056462732561687184, 'l1_Layer_2': 0.015927925143697737, 'l1_Layer_3': 0.0015819697703937951, 'l1_Layer_4': 1.0297071082880894e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185, 'n_units_Layer_4': 215}. Best is trial 118 with value: 5.487790396511279.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:20:54,403]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:21:02,725]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:21:09,914]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:21:13,421]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:21:22,438]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:21:25,346]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:21:29,127]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:21:32,169]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:21:35,567]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:21:36,423]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:21:38,549]\u001b[0m Trial 152 finished with value: 6.313674269428161 and parameters: {'n_hidden': 4, 'learning_rate': 0.005864215025659232, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08691517961841103, 'dropout_rate_Layer_2': 0.2201017050563876, 'dropout_rate_Layer_3': 0.2554333691741832, 'dropout_rate_Layer_4': 0.36989963791993163, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.014001909971583945, 'l1_Layer_2': 0.0010184489077479679, 'l1_Layer_3': 2.111642831397709e-05, 'l1_Layer_4': 0.0001212765418639415, 'n_units_Layer_1': 190, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285, 'n_units_Layer_4': 230}. Best is trial 118 with value: 5.487790396511279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 24.10% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 32.30 | sMAPE for Test Set is: 32.02% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:21:45,528]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:21:48,934]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:21:49,401]\u001b[0m Trial 170 finished with value: 12.875733598086606 and parameters: {'n_hidden': 3, 'learning_rate': 0.01342807863315584, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.378091655922664, 'dropout_rate_Layer_2': 0.3200840777239569, 'dropout_rate_Layer_3': 0.28057360175536317, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.014737239811653221, 'l1_Layer_2': 4.197983848190001e-05, 'l1_Layer_3': 0.0012611487020978615, 'n_units_Layer_1': 290, 'n_units_Layer_2': 190, 'n_units_Layer_3': 135}. Best is trial 118 with value: 5.487790396511279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.88 | sMAPE for Validation Set is: 41.08% | rMAE for Validation Set is: 1.53\n",
      "MAE for Test Set is: 67.95 | sMAPE for Test Set is: 75.29% | rMAE for Test Set is: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:21:52,676]\u001b[0m Trial 167 finished with value: 6.036496364293325 and parameters: {'n_hidden': 3, 'learning_rate': 0.005193904051912349, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015083016856682155, 'dropout_rate_Layer_2': 0.18309071215019404, 'dropout_rate_Layer_3': 0.07964896830152807, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037981980445661335, 'l1_Layer_2': 0.006044727947072299, 'l1_Layer_3': 1.917140324900667e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 75, 'n_units_Layer_3': 235}. Best is trial 118 with value: 5.487790396511279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 22.98% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 47.62 | sMAPE for Test Set is: 44.49% | rMAE for Test Set is: 1.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:21:58,045]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:03,499]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:04,790]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:05,827]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:11,281]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:12,230]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:12,312]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:19,277]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:19,358]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:19,849]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:31,675]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:35,360]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:41,738]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:22:55,526]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:23:00,303]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:23:07,217]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:23:11,599]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:23:20,802]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:23:26,871]\u001b[0m Trial 183 finished with value: 5.643781722763014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010113714264385547, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3247719802073091, 'dropout_rate_Layer_2': 0.038218631446152035, 'dropout_rate_Layer_3': 0.16727256698988216, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011250042805468618, 'l1_Layer_2': 1.1367004750327532e-05, 'l1_Layer_3': 0.0004347276548056227, 'n_units_Layer_1': 205, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270}. Best is trial 118 with value: 5.487790396511279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 22.31% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.53 | sMAPE for Test Set is: 24.31% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:23:41,628]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:23:45,641]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:23:59,748]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:24:02,481]\u001b[0m Trial 194 finished with value: 5.543184750159804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010326291174491166, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33054283761453496, 'dropout_rate_Layer_2': 0.030943451177918968, 'dropout_rate_Layer_3': 0.1738618783282842, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001142710470388973, 'l1_Layer_2': 1.679193603199591e-05, 'l1_Layer_3': 0.000353115307098652, 'n_units_Layer_1': 215, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270}. Best is trial 118 with value: 5.487790396511279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 21.83% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 27.28% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:24:04,972]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:24:07,339]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:24:10,738]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:24:10,968]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:24:11,576]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:24:20,115]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:24:23,536]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:24:26,904]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:24:46,158]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:24:51,303]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:24:54,601]\u001b[0m Trial 206 finished with value: 6.563592750319974 and parameters: {'n_hidden': 3, 'learning_rate': 0.003238446588432022, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013347728264615102, 'dropout_rate_Layer_2': 0.15067393787062186, 'dropout_rate_Layer_3': 0.29059197897061345, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00040246206860674135, 'l1_Layer_2': 0.0061827956819503396, 'l1_Layer_3': 0.004634646611900572, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 240}. Best is trial 118 with value: 5.487790396511279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 24.64% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 50.32 | sMAPE for Test Set is: 47.64% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:24:57,870]\u001b[0m Trial 195 finished with value: 5.368911881035086 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005075922694505168, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29718981349693646, 'dropout_rate_Layer_2': 0.028695696729248113, 'dropout_rate_Layer_3': 0.14464250271896992, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014207821313260082, 'l1_Layer_2': 3.2453922442313976e-05, 'l1_Layer_3': 0.004695060760226008, 'n_units_Layer_1': 270, 'n_units_Layer_2': 220, 'n_units_Layer_3': 280}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 21.19% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.36 | sMAPE for Test Set is: 25.52% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:24:58,865]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:25:02,802]\u001b[0m Trial 205 finished with value: 6.1403671173531365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032676230960050293, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010645908617307258, 'dropout_rate_Layer_2': 0.15353158374272907, 'dropout_rate_Layer_3': 0.3321392847591489, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004756326728849956, 'l1_Layer_2': 4.293890086060606e-05, 'l1_Layer_3': 0.004113336787001097, 'n_units_Layer_1': 275, 'n_units_Layer_2': 120, 'n_units_Layer_3': 240}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 23.39% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 46.32 | sMAPE for Test Set is: 42.88% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:25:06,613]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:25:08,629]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:25:11,334]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:25:14,215]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:25:15,964]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:25:42,495]\u001b[0m Trial 212 finished with value: 6.847927898249364 and parameters: {'n_hidden': 4, 'learning_rate': 0.000960862674791013, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02717919606312969, 'dropout_rate_Layer_2': 0.3500413567258748, 'dropout_rate_Layer_3': 0.3554177343782298, 'dropout_rate_Layer_4': 0.23137400665981328, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06904244173059805, 'l1_Layer_2': 0.010984051241696538, 'l1_Layer_3': 0.0028446762216755264, 'l1_Layer_4': 1.4218566269639725e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 180, 'n_units_Layer_3': 195, 'n_units_Layer_4': 220}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 25.64% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 49.22 | sMAPE for Test Set is: 47.03% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:25:46,406]\u001b[0m Trial 209 finished with value: 5.990621747682797 and parameters: {'n_hidden': 3, 'learning_rate': 0.001921103244366901, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01947797398537807, 'dropout_rate_Layer_2': 0.1487157767108499, 'dropout_rate_Layer_3': 0.2994090166237867, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003815305214293263, 'l1_Layer_2': 0.005590174908819439, 'l1_Layer_3': 0.0002971291238103159, 'n_units_Layer_1': 255, 'n_units_Layer_2': 115, 'n_units_Layer_3': 235}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.99 | sMAPE for Validation Set is: 22.94% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 44.02 | sMAPE for Test Set is: 40.76% | rMAE for Test Set is: 1.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:25:48,172]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:25:53,639]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:25:57,784]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:26:04,752]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:26:11,734]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:26:19,932]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:26:59,005]\u001b[0m Trial 225 finished with value: 5.949317758391054 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013046508588923022, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020283108148615656, 'dropout_rate_Layer_2': 0.1646633814136009, 'dropout_rate_Layer_3': 0.35066721613347324, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005128710082609653, 'l1_Layer_2': 1.4090939820960278e-05, 'l1_Layer_3': 0.0002100650024389256, 'n_units_Layer_1': 250, 'n_units_Layer_2': 100, 'n_units_Layer_3': 255}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 22.95% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 46.43 | sMAPE for Test Set is: 42.94% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:27:02,220]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:27:25,751]\u001b[0m Trial 227 finished with value: 6.019080595779774 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011367375520344874, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05468232973348514, 'dropout_rate_Layer_2': 0.1785661512462719, 'dropout_rate_Layer_3': 0.3418698970114211, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006541191652174951, 'l1_Layer_2': 1.37154873734738e-05, 'l1_Layer_3': 0.00018657489063142612, 'n_units_Layer_1': 245, 'n_units_Layer_2': 105, 'n_units_Layer_3': 255}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 22.97% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 44.93 | sMAPE for Test Set is: 41.27% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:27:30,825]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:27:39,671]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:27:46,480]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:27:50,397]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:27:55,114]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:28:27,575]\u001b[0m Trial 233 finished with value: 5.985113809294688 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016957076819021561, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05749835945594757, 'dropout_rate_Layer_2': 0.1658749248684036, 'dropout_rate_Layer_3': 0.297982987696965, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007230811772499317, 'l1_Layer_2': 2.555856358959455e-05, 'l1_Layer_3': 0.0003277047252402197, 'n_units_Layer_1': 125, 'n_units_Layer_2': 80, 'n_units_Layer_3': 275}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.99 | sMAPE for Validation Set is: 23.03% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 49.10 | sMAPE for Test Set is: 46.64% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:28:31,842]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:28:50,314]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:28:57,253]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:29:03,675]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:29:03,789]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:29:09,617]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:29:14,394]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:29:27,771]\u001b[0m Trial 240 finished with value: 6.209498682177056 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019122550353013214, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06135121245440162, 'dropout_rate_Layer_2': 0.11203370575499924, 'dropout_rate_Layer_3': 0.2704436339262223, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026132748606646046, 'l1_Layer_2': 2.8098604232557788e-05, 'l1_Layer_3': 0.00042010780391326, 'n_units_Layer_1': 125, 'n_units_Layer_2': 100, 'n_units_Layer_3': 270}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 23.45% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 48.19 | sMAPE for Test Set is: 45.29% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:29:32,839]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:29:37,157]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:29:45,097]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:30:04,574]\u001b[0m Trial 242 finished with value: 6.0296756559914755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017863060192219486, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06527575183728071, 'dropout_rate_Layer_2': 0.11447942187384151, 'dropout_rate_Layer_3': 0.2701231229033571, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009255329173355214, 'l1_Layer_2': 3.076066341898219e-05, 'l1_Layer_3': 0.00031242514904058783, 'n_units_Layer_1': 110, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 23.11% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 46.88 | sMAPE for Test Set is: 43.63% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:30:13,461]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:30:23,097]\u001b[0m Trial 245 finished with value: 7.1611558923836425 and parameters: {'n_hidden': 4, 'learning_rate': 0.001031346149711719, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07007273315433199, 'dropout_rate_Layer_2': 0.38006604948657663, 'dropout_rate_Layer_3': 0.04011637079487196, 'dropout_rate_Layer_4': 0.23454988014733075, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03853884122337309, 'l1_Layer_2': 0.020502426338916833, 'l1_Layer_3': 0.005068840690346689, 'l1_Layer_4': 1.9254619016387633e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 135, 'n_units_Layer_3': 135, 'n_units_Layer_4': 185}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.16 | sMAPE for Validation Set is: 26.76% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 49.59 | sMAPE for Test Set is: 47.37% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:30:31,234]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:30:34,977]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:30:42,979]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:30:56,538]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:31:04,776]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:31:47,839]\u001b[0m Trial 220 finished with value: 6.0853529999100076 and parameters: {'n_hidden': 4, 'learning_rate': 0.005713194455426974, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007633802881416435, 'dropout_rate_Layer_2': 0.04733908466877412, 'dropout_rate_Layer_3': 0.2689334202130291, 'dropout_rate_Layer_4': 0.007391270053929866, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00021671456747569663, 'l1_Layer_2': 0.08865835669965665, 'l1_Layer_3': 0.01586187910499204, 'l1_Layer_4': 0.0006639880804348987, 'n_units_Layer_1': 130, 'n_units_Layer_2': 295, 'n_units_Layer_3': 235, 'n_units_Layer_4': 300}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 23.88% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 49.64 | sMAPE for Test Set is: 47.29% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:31:48,785]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:32:07,441]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:32:11,834]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:32:15,447]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:32:21,602]\u001b[0m Trial 247 finished with value: 6.287528640221088 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013783951569721938, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.125255982662037, 'dropout_rate_Layer_2': 0.2914862268792594, 'dropout_rate_Layer_3': 0.26704052258673594, 'dropout_rate_Layer_4': 0.03704566940624501, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00024109762295507025, 'l1_Layer_2': 0.07670193250698565, 'l1_Layer_3': 0.0001126414153373481, 'l1_Layer_4': 2.7928931676105914e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 100, 'n_units_Layer_3': 195, 'n_units_Layer_4': 115}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 24.74% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 48.48 | sMAPE for Test Set is: 46.33% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:32:30,481]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:32:31,662]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:32:44,528]\u001b[0m Trial 217 finished with value: 6.18904403402004 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012614906997439632, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021389787417715467, 'dropout_rate_Layer_2': 0.014078184666668214, 'dropout_rate_Layer_3': 0.16033797887036666, 'dropout_rate_Layer_4': 0.2476384569883481, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003504489589243723, 'l1_Layer_2': 0.08746892626741982, 'l1_Layer_3': 0.02122821809578196, 'l1_Layer_4': 0.0006223154232231913, 'n_units_Layer_1': 130, 'n_units_Layer_2': 300, 'n_units_Layer_3': 250, 'n_units_Layer_4': 195}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 23.88% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 45.53 | sMAPE for Test Set is: 43.28% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:32:50,024]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:33:02,292]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:33:12,421]\u001b[0m Trial 260 finished with value: 5.744832832089789 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025863702232495228, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05954109629208232, 'dropout_rate_Layer_2': 0.14703113361917608, 'dropout_rate_Layer_3': 0.227586042430201, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005058823248245305, 'l1_Layer_2': 0.00010552337114956196, 'l1_Layer_3': 0.00032005645831984116, 'n_units_Layer_1': 125, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 22.56% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 52.76 | sMAPE for Test Set is: 50.71% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:33:19,029]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:33:23,512]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:33:31,831]\u001b[0m Trial 264 finished with value: 6.032048443041141 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015801854855495984, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04632778055154446, 'dropout_rate_Layer_2': 0.09640612363207568, 'dropout_rate_Layer_3': 0.3023438585078291, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006944093529630041, 'l1_Layer_2': 1.1991371489903312e-05, 'l1_Layer_3': 0.00022917531581835026, 'n_units_Layer_1': 125, 'n_units_Layer_2': 80, 'n_units_Layer_3': 260}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 23.10% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 48.65 | sMAPE for Test Set is: 45.50% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:33:41,745]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:33:54,879]\u001b[0m Trial 267 finished with value: 5.676807843625354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025552036637444386, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07824979619541186, 'dropout_rate_Layer_2': 0.11179420635228157, 'dropout_rate_Layer_3': 0.24294026311201933, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00042746911615770583, 'l1_Layer_2': 4.758040866950995e-05, 'l1_Layer_3': 0.00021947722191537322, 'n_units_Layer_1': 125, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:33:54,917]\u001b[0m Trial 265 finished with value: 6.390926800969583 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005730040728517721, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011557478405309527, 'dropout_rate_Layer_2': 0.34332044028818826, 'dropout_rate_Layer_3': 0.3688954084059558, 'dropout_rate_Layer_4': 0.323103539442228, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.056792734508490886, 'l1_Layer_2': 0.007009011715189442, 'l1_Layer_3': 0.004522144811371712, 'l1_Layer_4': 2.6579107914697764e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 155, 'n_units_Layer_3': 135, 'n_units_Layer_4': 210}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 23.31% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 51.22 | sMAPE for Test Set is: 49.13% | rMAE for Test Set is: 1.75\n",
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 24.11% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 46.15 | sMAPE for Test Set is: 43.61% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:34:17,698]\u001b[0m Trial 269 finished with value: 5.764196858555494 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025773790911340663, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06958503037089278, 'dropout_rate_Layer_2': 0.11449261705826931, 'dropout_rate_Layer_3': 0.23757921253140504, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006827325519527321, 'l1_Layer_2': 4.6640348258858235e-05, 'l1_Layer_3': 0.00021969248852098802, 'n_units_Layer_1': 125, 'n_units_Layer_2': 75, 'n_units_Layer_3': 245}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 23.60% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 49.97 | sMAPE for Test Set is: 47.11% | rMAE for Test Set is: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:34:22,157]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:34:35,508]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:34:40,978]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:34:49,580]\u001b[0m Trial 268 finished with value: 5.44765407584836 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012343157041068223, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.256426927350213, 'dropout_rate_Layer_2': 0.09572695319169533, 'dropout_rate_Layer_3': 0.1161060341585938, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000531018043005425, 'l1_Layer_2': 0.00015612363122973635, 'l1_Layer_3': 0.0030534626387224025, 'n_units_Layer_1': 270, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 21.48% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.86 | sMAPE for Test Set is: 25.05% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:35:04,013]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:35:08,608]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:35:19,463]\u001b[0m Trial 271 finished with value: 6.641430149259894 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005357229255552197, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02865632019467236, 'dropout_rate_Layer_2': 0.30190237983556606, 'dropout_rate_Layer_3': 0.3729083448028818, 'dropout_rate_Layer_4': 0.011816176107116882, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.030420426692648116, 'l1_Layer_2': 0.0075036891972881875, 'l1_Layer_3': 0.004497416941033939, 'l1_Layer_4': 0.0017071223028509214, 'n_units_Layer_1': 125, 'n_units_Layer_2': 155, 'n_units_Layer_3': 135, 'n_units_Layer_4': 75}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 24.99% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 48.37 | sMAPE for Test Set is: 45.60% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:35:23,063]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:35:29,510]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:35:38,501]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:35:43,303]\u001b[0m Trial 278 finished with value: 6.437989791871888 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012230494702601088, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36949528084262806, 'dropout_rate_Layer_2': 0.3001233151619823, 'dropout_rate_Layer_3': 0.37010593172379436, 'dropout_rate_Layer_4': 0.34634975224296327, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.027952866325621436, 'l1_Layer_2': 0.007522861600499624, 'l1_Layer_3': 0.0016093789945438928, 'l1_Layer_4': 2.4096989220772534e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 155, 'n_units_Layer_3': 135, 'n_units_Layer_4': 80}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 24.24% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 44.50 | sMAPE for Test Set is: 41.40% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:35:58,656]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:36:06,108]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:36:07,033]\u001b[0m Trial 282 finished with value: 5.97155244474845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013909915328945825, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07652420682514652, 'dropout_rate_Layer_2': 0.16269279505906525, 'dropout_rate_Layer_3': 0.26602704970359153, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008750148410037966, 'l1_Layer_2': 2.6635800464046485e-05, 'l1_Layer_3': 0.0003036462058600245, 'n_units_Layer_1': 115, 'n_units_Layer_2': 80, 'n_units_Layer_3': 235}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 22.84% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 50.72 | sMAPE for Test Set is: 48.39% | rMAE for Test Set is: 1.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:36:13,433]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 21.31% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.44 | sMAPE for Test Set is: 24.34% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:36:15,950]\u001b[0m Trial 275 finished with value: 5.435110991193724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012207096956159602, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25900069288524413, 'dropout_rate_Layer_2': 0.23122043239521942, 'dropout_rate_Layer_3': 0.12067559814343473, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006579984159702869, 'l1_Layer_2': 1.744974126301708e-05, 'l1_Layer_3': 0.0029115229850085107, 'n_units_Layer_1': 275, 'n_units_Layer_2': 260, 'n_units_Layer_3': 245}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:36:21,324]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:36:26,812]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:36:42,848]\u001b[0m Trial 285 finished with value: 5.532560941393773 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005031765073206614, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17884064780415249, 'dropout_rate_Layer_2': 0.24089926699341704, 'dropout_rate_Layer_3': 0.18762050408188086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.9520481477881164e-05, 'l1_Layer_2': 1.7135560131624623e-05, 'l1_Layer_3': 5.9715148522377224e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 190, 'n_units_Layer_3': 285}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 21.64% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.49 | sMAPE for Test Set is: 26.52% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:36:49,512]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:36:58,805]\u001b[0m Trial 289 finished with value: 6.102050774314389 and parameters: {'n_hidden': 3, 'learning_rate': 0.00143218755320028, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0775145612049379, 'dropout_rate_Layer_2': 0.1623298678260134, 'dropout_rate_Layer_3': 0.24257898676792, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011273937640105332, 'l1_Layer_2': 2.7018896044978265e-05, 'l1_Layer_3': 0.0001274153724237773, 'n_units_Layer_1': 130, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 23.43% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 51.47 | sMAPE for Test Set is: 49.74% | rMAE for Test Set is: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:37:03,789]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 23.62% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 47.17 | sMAPE for Test Set is: 44.28% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:37:05,990]\u001b[0m Trial 291 finished with value: 6.276745304503482 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015707464025983644, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07001259407520763, 'dropout_rate_Layer_2': 0.0941303012031568, 'dropout_rate_Layer_3': 0.28206065035568295, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044387021519329327, 'l1_Layer_2': 6.521431444016269e-05, 'l1_Layer_3': 0.00013357871558960932, 'n_units_Layer_1': 130, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:37:12,712]\u001b[0m Trial 281 finished with value: 5.430524054417041 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005026125491464121, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2953818811618695, 'dropout_rate_Layer_2': 0.03393327940495119, 'dropout_rate_Layer_3': 0.18858396365889513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018466184813748863, 'l1_Layer_2': 0.0006402774325574281, 'l1_Layer_3': 0.003094336605348938, 'n_units_Layer_1': 265, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 21.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.52 | sMAPE for Test Set is: 26.47% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:37:12,982]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:37:16,162]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:37:18,839]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:37:24,824]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:37:34,727]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:37:37,345]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:37:46,811]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:37:48,820]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:37:54,578]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:37:56,995]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:38:02,973]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:38:03,344]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:38:09,142]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:38:13,762]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:38:19,091]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:38:23,573]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:38:26,871]\u001b[0m Trial 299 finished with value: 6.079897435717595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012753110467750813, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09722919513490297, 'dropout_rate_Layer_2': 0.09628768974443122, 'dropout_rate_Layer_3': 0.2641255246472174, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011719244012793778, 'l1_Layer_2': 2.045015125957437e-05, 'l1_Layer_3': 0.0002008730272297901, 'n_units_Layer_1': 135, 'n_units_Layer_2': 95, 'n_units_Layer_3': 280}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 23.43% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 47.04 | sMAPE for Test Set is: 44.04% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:38:38,426]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:38:45,895]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:38:46,503]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:38:53,046]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:39:02,841]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:39:06,080]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:39:10,592]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:39:14,157]\u001b[0m Trial 312 finished with value: 6.508369166950661 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006707578662530381, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036019957325725355, 'dropout_rate_Layer_2': 0.3206592517215946, 'dropout_rate_Layer_3': 0.3585053950997197, 'dropout_rate_Layer_4': 0.17513818144622156, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02311727794913479, 'l1_Layer_2': 0.007382956058755977, 'l1_Layer_3': 0.005922700681847319, 'l1_Layer_4': 2.4315150674825105e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 175, 'n_units_Layer_3': 120, 'n_units_Layer_4': 275}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 24.44% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 45.66 | sMAPE for Test Set is: 42.61% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:39:19,149]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:39:26,849]\u001b[0m Trial 314 finished with value: 6.72943548592131 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007854528521751012, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03171295636365487, 'dropout_rate_Layer_2': 0.31706137365783643, 'dropout_rate_Layer_3': 0.36288039498245295, 'dropout_rate_Layer_4': 0.07796740346223015, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.023815699341545878, 'l1_Layer_2': 0.00824969728389827, 'l1_Layer_3': 0.005907310406538179, 'l1_Layer_4': 6.011166868117637e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 180, 'n_units_Layer_3': 120, 'n_units_Layer_4': 230}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.73 | sMAPE for Validation Set is: 25.23% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 47.54 | sMAPE for Test Set is: 44.71% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:39:34,609]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:39:41,792]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:39:47,021]\u001b[0m Trial 318 finished with value: 6.1909088493389675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010780926153725946, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10268723294347393, 'dropout_rate_Layer_2': 0.09780581217647277, 'dropout_rate_Layer_3': 0.25217123436060546, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000658265651752245, 'l1_Layer_2': 2.53645934158687e-05, 'l1_Layer_3': 0.00011570591081977198, 'n_units_Layer_1': 115, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 23.80% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 51.39 | sMAPE for Test Set is: 49.36% | rMAE for Test Set is: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:40:05,489]\u001b[0m Trial 322 finished with value: 5.896043959025885 and parameters: {'n_hidden': 3, 'learning_rate': 0.001269732295769714, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07267131152255411, 'dropout_rate_Layer_2': 0.17417392455724867, 'dropout_rate_Layer_3': 0.25858055026472043, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022339014737214153, 'l1_Layer_2': 1.5140070357764281e-05, 'l1_Layer_3': 0.00022212635465688308, 'n_units_Layer_1': 125, 'n_units_Layer_2': 80, 'n_units_Layer_3': 255}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 49.66 | sMAPE for Test Set is: 46.94% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:40:11,690]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:40:38,115]\u001b[0m Trial 325 finished with value: 5.948408612554121 and parameters: {'n_hidden': 4, 'learning_rate': 0.000742329417908103, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02821752797176369, 'dropout_rate_Layer_2': 0.31467120500184054, 'dropout_rate_Layer_3': 0.3616935450970538, 'dropout_rate_Layer_4': 0.0066868573339162185, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.023659497646808962, 'l1_Layer_2': 0.004299846276703327, 'l1_Layer_3': 0.002574056484046261, 'l1_Layer_4': 6.707851660515154e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110, 'n_units_Layer_4': 275}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 22.62% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 45.69 | sMAPE for Test Set is: 42.29% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:40:48,217]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:41:06,006]\u001b[0m Trial 326 finished with value: 6.136420185919593 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008390226506357426, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.072607162973025, 'dropout_rate_Layer_2': 0.09053724559762491, 'dropout_rate_Layer_3': 0.2590587556674334, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007308503681954782, 'l1_Layer_2': 3.869085914464463e-05, 'l1_Layer_3': 6.60197724238926e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 100, 'n_units_Layer_3': 265}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 23.82% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 47.23 | sMAPE for Test Set is: 44.90% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:41:09,998]\u001b[0m Trial 328 finished with value: 6.101573600118208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008960766176885474, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08753824228127677, 'dropout_rate_Layer_2': 0.16807595416949322, 'dropout_rate_Layer_3': 0.2360060343213872, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003431140898982897, 'l1_Layer_2': 3.05784606731967e-05, 'l1_Layer_3': 0.00018242868393889567, 'n_units_Layer_1': 125, 'n_units_Layer_2': 105, 'n_units_Layer_3': 265}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 23.45% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 44.46 | sMAPE for Test Set is: 41.44% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:41:15,372]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:41:42,307]\u001b[0m Trial 329 finished with value: 5.94473386588535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009223085414774766, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08657160945333156, 'dropout_rate_Layer_2': 0.17155109254799727, 'dropout_rate_Layer_3': 0.2258855277146803, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011410505780535026, 'l1_Layer_2': 3.090929501344584e-05, 'l1_Layer_3': 0.00017040331076820348, 'n_units_Layer_1': 125, 'n_units_Layer_2': 105, 'n_units_Layer_3': 265}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 23.03% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 46.48 | sMAPE for Test Set is: 43.28% | rMAE for Test Set is: 1.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:41:43,467]\u001b[0m Trial 330 finished with value: 6.0680847955657695 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007501267173725287, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030845197366764273, 'dropout_rate_Layer_2': 0.3138890887639016, 'dropout_rate_Layer_3': 0.3597549618258812, 'dropout_rate_Layer_4': 0.019520231364853785, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02400486421742413, 'l1_Layer_2': 0.004548508278703171, 'l1_Layer_3': 0.0022940152128742043, 'l1_Layer_4': 5.589886327643598e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 185, 'n_units_Layer_3': 120, 'n_units_Layer_4': 275}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 23.20% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 45.53 | sMAPE for Test Set is: 42.23% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:41:49,217]\u001b[0m Trial 331 finished with value: 6.170127976943523 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009924624569139506, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08737805246046018, 'dropout_rate_Layer_2': 0.06212905567910514, 'dropout_rate_Layer_3': 0.25200701161850014, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006134649715526533, 'l1_Layer_2': 3.053974773137406e-05, 'l1_Layer_3': 7.639858368254239e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 105, 'n_units_Layer_3': 265}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 23.75% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 47.91 | sMAPE for Test Set is: 45.51% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:41:58,793]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:42:01,084]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:42:18,279]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:42:28,162]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:42:31,679]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:42:44,512]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:42:54,316]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:42:58,692]\u001b[0m Trial 337 finished with value: 6.063737952153553 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007079884442217266, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030978671792406785, 'dropout_rate_Layer_2': 0.31470939279454146, 'dropout_rate_Layer_3': 0.3593985876505261, 'dropout_rate_Layer_4': 3.5621373874101386e-05, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.024006266727972785, 'l1_Layer_2': 0.004167261604040143, 'l1_Layer_3': 0.002547359712800931, 'l1_Layer_4': 6.715162766654344e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110, 'n_units_Layer_4': 275}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 23.00% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 44.30 | sMAPE for Test Set is: 40.85% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:43:00,910]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:43:07,221]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:43:12,556]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:43:16,023]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:43:18,177]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:43:29,962]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:43:39,581]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:43:44,095]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:43:48,704]\u001b[0m Trial 341 finished with value: 6.142604654266975 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007586492958341683, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028293748194321705, 'dropout_rate_Layer_2': 0.31384778863910806, 'dropout_rate_Layer_3': 0.36247663428975935, 'dropout_rate_Layer_4': 0.004142513792988716, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02371076715524364, 'l1_Layer_2': 0.004680978545506346, 'l1_Layer_3': 0.0024641661886028437, 'l1_Layer_4': 7.964604352244223e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110, 'n_units_Layer_4': 270}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 23.49% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 46.81 | sMAPE for Test Set is: 43.68% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:43:51,036]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:43:55,638]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:44:02,096]\u001b[0m Trial 344 finished with value: 6.023083706486524 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007667483420882084, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05808087059787653, 'dropout_rate_Layer_2': 0.19012897238043952, 'dropout_rate_Layer_3': 0.2582294158850896, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005448712784325353, 'l1_Layer_2': 1.955535752293357e-05, 'l1_Layer_3': 0.00015835061958610852, 'n_units_Layer_1': 100, 'n_units_Layer_2': 100, 'n_units_Layer_3': 275}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 23.09% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 50.38 | sMAPE for Test Set is: 47.71% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:44:04,379]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:44:07,773]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:44:15,749]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:44:17,515]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:44:24,552]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:44:26,453]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:44:37,128]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:44:42,707]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:44:47,488]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:44:53,651]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:44:55,703]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:45:00,447]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:45:01,537]\u001b[0m Trial 348 finished with value: 5.96208885712876 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007448454296759391, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05931622747194238, 'dropout_rate_Layer_2': 0.17985505427453838, 'dropout_rate_Layer_3': 0.34956515902853896, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005393611693737134, 'l1_Layer_2': 2.929919960663976e-05, 'l1_Layer_3': 0.00024179927267137163, 'n_units_Layer_1': 135, 'n_units_Layer_2': 105, 'n_units_Layer_3': 265}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 23.02% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 51.04 | sMAPE for Test Set is: 48.77% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:45:06,498]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:45:11,592]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:45:26,282]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:45:31,317]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:45:41,636]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:45:47,777]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:45:56,598]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:46:07,897]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:46:13,941]\u001b[0m Trial 363 finished with value: 5.757133767894828 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006381074902780948, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.058451370924521996, 'dropout_rate_Layer_2': 0.1815525408627036, 'dropout_rate_Layer_3': 0.2345924644462408, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008600874989255946, 'l1_Layer_2': 1.29935428891049e-05, 'l1_Layer_3': 0.00010949641945620962, 'n_units_Layer_1': 285, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 22.43% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 47.04 | sMAPE for Test Set is: 44.00% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:46:16,157]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:46:18,531]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:46:21,739]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:46:34,509]\u001b[0m Trial 370 finished with value: 6.169634175548538 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006461183105014183, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04520304542548601, 'dropout_rate_Layer_2': 0.3287096283266856, 'dropout_rate_Layer_3': 0.35962210094706293, 'dropout_rate_Layer_4': 0.04601807060597045, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03036248918464946, 'l1_Layer_2': 0.004818143668236158, 'l1_Layer_3': 0.0017786803240389022, 'l1_Layer_4': 2.3932465962768313e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 175, 'n_units_Layer_3': 110, 'n_units_Layer_4': 300}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 23.58% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 44.80 | sMAPE for Test Set is: 41.47% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:46:39,028]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:46:40,065]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:46:51,906]\u001b[0m Trial 380 finished with value: 7.109320070475699 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017931392307729377, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06971088849175797, 'dropout_rate_Layer_2': 0.034432102998543906, 'dropout_rate_Layer_3': 0.39425811383634995, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.007321156877820932, 'l1_Layer_2': 0.00456097678228827, 'l1_Layer_3': 0.030789100521343166, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 255}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 26.35% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 49.84 | sMAPE for Test Set is: 46.89% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:46:56,629]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:46:56,847]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:46:56,952]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:47:06,689]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:47:07,562]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:47:07,849]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:47:23,552]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:47:29,271]\u001b[0m Trial 373 finished with value: 5.6147984574609255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008655997116236714, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30705781551290523, 'dropout_rate_Layer_2': 0.12807657806152745, 'dropout_rate_Layer_3': 0.22086923008847653, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.0964620511741066e-05, 'l1_Layer_2': 0.00040502652773915506, 'l1_Layer_3': 0.0007199501204357497, 'n_units_Layer_1': 265, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 21.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.35 | sMAPE for Test Set is: 23.54% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:47:36,960]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:47:43,569]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:47:48,097]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:47:51,823]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:47:53,956]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:47:57,751]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:02,310]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:02,811]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:13,975]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:22,117]\u001b[0m Trial 390 finished with value: 6.073635214798519 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006930429587295167, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036873135404685294, 'dropout_rate_Layer_2': 0.3040481989183428, 'dropout_rate_Layer_3': 0.3437829900959245, 'dropout_rate_Layer_4': 0.010145994189388455, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.032334576265861364, 'l1_Layer_2': 0.0076556150629850115, 'l1_Layer_3': 0.0012953633479185602, 'l1_Layer_4': 0.00036340533627555094, 'n_units_Layer_1': 105, 'n_units_Layer_2': 175, 'n_units_Layer_3': 115, 'n_units_Layer_4': 255}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 23.20% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 45.95 | sMAPE for Test Set is: 42.58% | rMAE for Test Set is: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:48:23,917]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:28,398]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:32,574]\u001b[0m Trial 400 finished with value: 5.910322285889474 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009379835275346585, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0959676483437655, 'dropout_rate_Layer_2': 0.1778474304742924, 'dropout_rate_Layer_3': 0.2454682055387081, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008802856116432164, 'l1_Layer_2': 1.0018057005231706e-05, 'l1_Layer_3': 7.794495621250555e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 110, 'n_units_Layer_3': 270}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 47.62 | sMAPE for Test Set is: 44.76% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:48:37,745]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:41,322]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:42,130]\u001b[0m Trial 403 finished with value: 6.0164502552469905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015893403686521067, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08216056977877424, 'dropout_rate_Layer_2': 0.19687631584905563, 'dropout_rate_Layer_3': 0.26370549559994516, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041116868549087083, 'l1_Layer_2': 2.377499358000269e-05, 'l1_Layer_3': 6.840994764149242e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 110, 'n_units_Layer_3': 270}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 22.95% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 50.03 | sMAPE for Test Set is: 47.74% | rMAE for Test Set is: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:48:46,199]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:49,148]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:54,245]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:54,625]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:55,321]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:48:56,040]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:08,672]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:14,728]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:17,888]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:19,916]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:23,392]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:28,406]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:34,167]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:36,228]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:40,150]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:40,905]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:41,694]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:48,914]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:56,926]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:49:57,433]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:50:08,296]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:50:15,557]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:50:29,831]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:50:42,909]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:50:48,103]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:50:56,398]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:51:01,738]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:51:08,677]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:51:20,029]\u001b[0m Trial 431 finished with value: 6.000908918407302 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010499485197012204, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.091760423328273, 'dropout_rate_Layer_2': 0.17201500664375496, 'dropout_rate_Layer_3': 0.2471205765685708, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008222140553261684, 'l1_Layer_2': 2.6190891750894646e-05, 'l1_Layer_3': 7.11649588501157e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 23.21% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 50.04 | sMAPE for Test Set is: 47.70% | rMAE for Test Set is: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:51:25,021]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:51:28,673]\u001b[0m Trial 419 finished with value: 5.909673989299502 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006940155447117556, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2040363911352558, 'dropout_rate_Layer_2': 0.1699014088086669, 'dropout_rate_Layer_3': 0.2394912457395317, 'dropout_rate_Layer_4': 0.19369587560797552, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00041223127179122987, 'l1_Layer_2': 0.0024909300106011347, 'l1_Layer_3': 4.233668665440895e-05, 'l1_Layer_4': 0.005697954251320837, 'n_units_Layer_1': 145, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150, 'n_units_Layer_4': 265}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 23.00% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 43.79 | sMAPE for Test Set is: 41.14% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:51:28,830]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:51:29,214]\u001b[0m Trial 437 finished with value: 6.027381410089599 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011534386070132798, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11520409645084681, 'dropout_rate_Layer_2': 0.10712506275730488, 'dropout_rate_Layer_3': 0.2439025473858557, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00043250213652834573, 'l1_Layer_2': 3.57990145945092e-05, 'l1_Layer_3': 0.00020467291917827956, 'n_units_Layer_1': 130, 'n_units_Layer_2': 70, 'n_units_Layer_3': 260}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 23.13% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 48.29 | sMAPE for Test Set is: 45.49% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:51:36,242]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:51:36,986]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:51:41,667]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:51:45,709]\u001b[0m Trial 427 finished with value: 5.9510540237876155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010200400471098111, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08955446949813385, 'dropout_rate_Layer_2': 0.16397853406314392, 'dropout_rate_Layer_3': 0.2427154578959451, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007925817923910105, 'l1_Layer_2': 3.524207061487974e-05, 'l1_Layer_3': 7.617202885954603e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 75, 'n_units_Layer_3': 280}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 23.04% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 48.03 | sMAPE for Test Set is: 45.39% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:51:51,489]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:51:54,514]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:52:25,378]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:52:32,731]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:52:40,145]\u001b[0m Trial 442 finished with value: 5.846261199465924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011326619716337323, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11461975731175603, 'dropout_rate_Layer_2': 0.10942229043232388, 'dropout_rate_Layer_3': 0.2227840284039912, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009829450602739406, 'l1_Layer_2': 2.0322786884625726e-05, 'l1_Layer_3': 0.0001971355664326969, 'n_units_Layer_1': 135, 'n_units_Layer_2': 70, 'n_units_Layer_3': 290}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 47.99 | sMAPE for Test Set is: 45.38% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:52:45,361]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:52:51,724]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:53:00,469]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:53:05,841]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:53:09,804]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:53:15,833]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:53:26,349]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:53:32,773]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:53:37,042]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:53:46,014]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:53:59,689]\u001b[0m Trial 447 finished with value: 5.916689969829199 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008850701754345286, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1028013270998412, 'dropout_rate_Layer_2': 0.10171355464684559, 'dropout_rate_Layer_3': 0.37714603250627743, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009904761033499897, 'l1_Layer_2': 3.4083398526803706e-05, 'l1_Layer_3': 4.587296711675705e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 70, 'n_units_Layer_3': 280}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 22.86% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 45.56 | sMAPE for Test Set is: 42.46% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:54:05,544]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:54:06,980]\u001b[0m Trial 461 finished with value: 5.61763676292385 and parameters: {'n_hidden': 3, 'learning_rate': 0.000986095646505447, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29150393879097913, 'dropout_rate_Layer_2': 0.04371648101686787, 'dropout_rate_Layer_3': 0.14267616787199464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019776356799305428, 'l1_Layer_2': 0.0001993317293790139, 'l1_Layer_3': 2.8769293593192257e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 21.95% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.23 | sMAPE for Test Set is: 26.34% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:54:12,812]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:54:19,664]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:54:25,151]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:54:29,028]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:54:33,503]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:54:34,273]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:54:39,542]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:54:40,361]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:54:45,353]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:54:50,629]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:54:51,180]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:54:56,524]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:55:00,476]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:55:07,458]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:55:07,986]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:55:16,454]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:55:18,386]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:55:20,989]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:55:23,062]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:55:25,582]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:55:27,188]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:55:28,045]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:55:36,777]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:55:44,334]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:56:39,853]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:56:40,383]\u001b[0m Trial 484 finished with value: 6.212182011754844 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008120415145788421, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06189319628924904, 'dropout_rate_Layer_2': 0.3394480472994443, 'dropout_rate_Layer_3': 0.33651992558997373, 'dropout_rate_Layer_4': 0.12169682754097236, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0339475620675796, 'l1_Layer_2': 0.011619752546623752, 'l1_Layer_3': 0.0015770647059954567, 'l1_Layer_4': 3.5223720448787716e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 190, 'n_units_Layer_3': 135, 'n_units_Layer_4': 280}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 23.63% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 45.73 | sMAPE for Test Set is: 42.49% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:56:46,755]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:56:49,444]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:56:53,150]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:56:56,371]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:00,195]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:02,574]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:06,283]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:10,363]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:15,675]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:19,640]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:20,374]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:29,507]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:36,740]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:40,829]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:43,810]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:43,880]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:44,012]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:50,080]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:53,295]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:55,617]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:58,163]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:57:58,198]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:01,992]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:05,729]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:05,760]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:09,232]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:12,832]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:13,543]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:14,359]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:19,659]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:21,079]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:22,705]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:28,901]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:29,141]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:33,888]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:34,205]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:37,915]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:39,587]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:41,824]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:42,794]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:46,743]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:48,314]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:52,947]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:53,397]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:58:59,671]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:00,119]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:02,899]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:04,602]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:05,213]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:07,916]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:14,704]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:17,141]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:18,219]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:20,479]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:28,789]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:33,893]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:41,441]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:49,651]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:54,706]\u001b[0m Trial 537 finished with value: 6.488503618621118 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010094844659203621, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09360105504349689, 'dropout_rate_Layer_2': 0.2092440831527588, 'dropout_rate_Layer_3': 0.218873550419285, 'dropout_rate_Layer_4': 0.357552125315041, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005483302367613042, 'l1_Layer_2': 0.0012269702012738769, 'l1_Layer_3': 1.9803480614270468e-05, 'l1_Layer_4': 0.00011888970090154346, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300, 'n_units_Layer_4': 235}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 24.88% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 20.37 | sMAPE for Test Set is: 24.40% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 10:59:55,031]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 10:59:55,614]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:00:05,519]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 22.76% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 47.71 | sMAPE for Test Set is: 44.79% | rMAE for Test Set is: 1.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:00:08,205]\u001b[0m Trial 543 finished with value: 5.876484460048136 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012524104427218338, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11347398044019452, 'dropout_rate_Layer_2': 0.13278744390495448, 'dropout_rate_Layer_3': 0.24031296295970975, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009423842585164162, 'l1_Layer_2': 2.6843502700560436e-05, 'l1_Layer_3': 0.00017564814715097265, 'n_units_Layer_1': 110, 'n_units_Layer_2': 80, 'n_units_Layer_3': 255}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:00:11,561]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:00:15,916]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:00:16,545]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:00:16,885]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:00:24,914]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:00:26,943]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:00:29,665]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:00:42,146]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:00:44,728]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:00:58,136]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:01:04,612]\u001b[0m Trial 555 finished with value: 6.102432218765844 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026964067541184384, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32039990273286323, 'dropout_rate_Layer_2': 0.013151857477784128, 'dropout_rate_Layer_3': 0.14819929519483535, 'dropout_rate_Layer_4': 0.33789971361269644, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.000671840695640508, 'l1_Layer_2': 0.00019581311013198183, 'l1_Layer_3': 0.00874322050212189, 'l1_Layer_4': 0.0001414785754389238, 'n_units_Layer_1': 225, 'n_units_Layer_2': 165, 'n_units_Layer_3': 270, 'n_units_Layer_4': 210}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 24.02% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 41.25 | sMAPE for Test Set is: 40.70% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:01:08,226]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:01:09,478]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:01:15,606]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:01:48,849]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:01:58,313]\u001b[0m Trial 561 finished with value: 5.983051308841067 and parameters: {'n_hidden': 4, 'learning_rate': 0.002751957550234648, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027464698795793545, 'dropout_rate_Layer_2': 0.29438228020602003, 'dropout_rate_Layer_3': 0.1937668265066213, 'dropout_rate_Layer_4': 0.3327474091877406, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007103514025735025, 'l1_Layer_2': 0.0002862721092817069, 'l1_Layer_3': 7.47622669371847e-05, 'l1_Layer_4': 0.00013287395402013415, 'n_units_Layer_1': 190, 'n_units_Layer_2': 185, 'n_units_Layer_3': 270, 'n_units_Layer_4': 260}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 23.95% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 33.81 | sMAPE for Test Set is: 34.09% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:02:01,589]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:04,552]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:07,384]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:10,570]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:11,386]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:14,766]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:17,138]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:19,866]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:21,543]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:24,472]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:28,816]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:33,236]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:36,776]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:02:50,979]\u001b[0m Trial 578 finished with value: 6.165630115063632 and parameters: {'n_hidden': 3, 'learning_rate': 0.001266351494601996, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12035928989137211, 'dropout_rate_Layer_2': 0.14566461258868496, 'dropout_rate_Layer_3': 0.23104562820808708, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005192340443793932, 'l1_Layer_2': 1.7234782251931614e-05, 'l1_Layer_3': 0.00015582445725018535, 'n_units_Layer_1': 130, 'n_units_Layer_2': 90, 'n_units_Layer_3': 280}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 23.42% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 45.51 | sMAPE for Test Set is: 42.28% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:02:59,002]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:03:00,046]\u001b[0m Trial 568 finished with value: 6.883022568440594 and parameters: {'n_hidden': 4, 'learning_rate': 0.002883502222767105, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29479148249814735, 'dropout_rate_Layer_2': 0.018963394409126807, 'dropout_rate_Layer_3': 0.11991503974886678, 'dropout_rate_Layer_4': 0.24353919133554985, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007196642158416056, 'l1_Layer_2': 6.858422245072668e-05, 'l1_Layer_3': 0.04369240949022909, 'l1_Layer_4': 0.024682843639339057, 'n_units_Layer_1': 235, 'n_units_Layer_2': 50, 'n_units_Layer_3': 240, 'n_units_Layer_4': 185}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 25.94% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 53.65 | sMAPE for Test Set is: 52.73% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:03:07,902]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:03:19,009]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:03:23,919]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:03:28,043]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:03:46,821]\u001b[0m Trial 571 finished with value: 6.365667003934431 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021010039420499456, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28229280572550264, 'dropout_rate_Layer_2': 0.029233205188268524, 'dropout_rate_Layer_3': 0.09635142430927891, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.0066425912265625e-05, 'l1_Layer_2': 6.016456859132893e-05, 'l1_Layer_3': 0.0007977008149993064, 'n_units_Layer_1': 205, 'n_units_Layer_2': 190, 'n_units_Layer_3': 255}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 24.52% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 51.71 | sMAPE for Test Set is: 49.27% | rMAE for Test Set is: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:04:14,095]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:04:22,206]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:04:26,637]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:04:32,584]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:04:38,738]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:04:42,633]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:04:47,697]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:04:55,325]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:00,476]\u001b[0m Trial 585 finished with value: 5.384043503981448 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006734931109415034, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2745725234234599, 'dropout_rate_Layer_2': 0.04840861054131937, 'dropout_rate_Layer_3': 0.16042467403620958, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000854706877935228, 'l1_Layer_2': 1.3073599103256562e-05, 'l1_Layer_3': 0.003703804698582781, 'n_units_Layer_1': 230, 'n_units_Layer_2': 250, 'n_units_Layer_3': 155}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 22.17% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.93 | sMAPE for Test Set is: 25.23% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:05:02,102]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:04,812]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:10,251]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:14,958]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:15,813]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:17,831]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:22,729]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:28,628]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:29,691]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:30,099]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:39,455]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:43,737]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:47,261]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:51,995]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:05:59,013]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:06:03,896]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:06:07,961]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:06:13,303]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:06:17,199]\u001b[0m Trial 607 finished with value: 6.384439168671491 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012736395812824603, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3996330207189906, 'dropout_rate_Layer_2': 0.26745119211700424, 'dropout_rate_Layer_3': 0.20687057662679564, 'dropout_rate_Layer_4': 0.3747247399259753, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0024252511033912116, 'l1_Layer_2': 0.0006759017300246887, 'l1_Layer_3': 8.812529721543294e-05, 'l1_Layer_4': 3.2975926326173924e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280, 'n_units_Layer_4': 220}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 24.32% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 46.13 | sMAPE for Test Set is: 43.22% | rMAE for Test Set is: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:06:17,593]\u001b[0m Trial 604 finished with value: 6.4391354628370765 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008828267537365232, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008827976582855147, 'dropout_rate_Layer_2': 0.32004635761670913, 'dropout_rate_Layer_3': 0.30242804187175465, 'dropout_rate_Layer_4': 0.2868359525919079, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03349383720016706, 'l1_Layer_2': 0.03176902666694032, 'l1_Layer_3': 0.003634113197712117, 'l1_Layer_4': 2.6040269167330302e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 175, 'n_units_Layer_3': 160, 'n_units_Layer_4': 230}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 24.28% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 36.27 | sMAPE for Test Set is: 35.26% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:06:22,789]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:06:26,806]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:06:32,806]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:06:45,209]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:06:49,684]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:06:50,598]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:06:57,694]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:06:59,742]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:07:05,311]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:07:09,077]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:07:19,413]\u001b[0m Trial 608 finished with value: 5.955838967720005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008319162416544762, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06963787685894758, 'dropout_rate_Layer_2': 0.16490235638191553, 'dropout_rate_Layer_3': 0.23892475595863463, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009853893893948876, 'l1_Layer_2': 2.6731334722694835e-05, 'l1_Layer_3': 0.00036966012865336786, 'n_units_Layer_1': 130, 'n_units_Layer_2': 65, 'n_units_Layer_3': 265}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 23.08% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 44.71 | sMAPE for Test Set is: 41.14% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:07:32,772]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:07:42,637]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:07:46,190]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:07:48,946]\u001b[0m Trial 628 finished with value: 5.880621381952682 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011828228614501868, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007556851304308736, 'dropout_rate_Layer_2': 0.16502551184559355, 'dropout_rate_Layer_3': 0.266540213654616, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001476805378454645, 'l1_Layer_2': 0.0008208708534219517, 'l1_Layer_3': 0.00021783617277447865, 'n_units_Layer_1': 115, 'n_units_Layer_2': 85, 'n_units_Layer_3': 280}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 22.69% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 48.70 | sMAPE for Test Set is: 45.90% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:07:55,370]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:08:08,546]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:08:15,703]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:08:27,650]\u001b[0m Trial 630 finished with value: 5.906877340360604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008154307962259226, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.062077476293932975, 'dropout_rate_Layer_2': 0.16142490297811635, 'dropout_rate_Layer_3': 0.23045717452883185, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000750735341556568, 'l1_Layer_2': 3.80468966492004e-05, 'l1_Layer_3': 0.0004232321030322345, 'n_units_Layer_1': 260, 'n_units_Layer_2': 65, 'n_units_Layer_3': 235}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 22.89% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 50.83 | sMAPE for Test Set is: 48.66% | rMAE for Test Set is: 1.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:08:32,728]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:08:38,569]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:08:50,863]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:08:56,924]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:09:00,143]\u001b[0m Trial 634 finished with value: 5.873080877356766 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009474295574638899, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009702252416140424, 'dropout_rate_Layer_2': 0.15367967628317383, 'dropout_rate_Layer_3': 0.22906915667896485, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014688295067807372, 'l1_Layer_2': 7.491459580630281e-05, 'l1_Layer_3': 0.00029009694735048733, 'n_units_Layer_1': 115, 'n_units_Layer_2': 70, 'n_units_Layer_3': 270}. Best is trial 195 with value: 5.368911881035086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 22.55% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 48.45 | sMAPE for Test Set is: 45.61% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:09:00,787]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:09:06,655]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:09:07,431]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:09:12,011]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:09:12,718]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:09:19,960]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:09:24,462]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:09:29,042]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:09:33,901]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:09:39,245]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 21.65% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.16 | sMAPE for Test Set is: 24.87% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:09:41,755]\u001b[0m Trial 629 finished with value: 5.344070879077139 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005008338767974879, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2661441683475858, 'dropout_rate_Layer_2': 0.07153514968763193, 'dropout_rate_Layer_3': 0.1264066964990835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001895787286616537, 'l1_Layer_2': 1.2814842419005548e-05, 'l1_Layer_3': 0.0005115118901516744, 'n_units_Layer_1': 240, 'n_units_Layer_2': 260, 'n_units_Layer_3': 140}. Best is trial 629 with value: 5.344070879077139.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:09:58,918]\u001b[0m Trial 646 finished with value: 11.021021692832534 and parameters: {'n_hidden': 4, 'learning_rate': 0.011260004239592059, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.046558256813184234, 'dropout_rate_Layer_2': 0.32182283244774446, 'dropout_rate_Layer_3': 0.2743493420811135, 'dropout_rate_Layer_4': 0.3977486714080097, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004956286244668585, 'l1_Layer_2': 0.0001351211923405748, 'l1_Layer_3': 7.014978441496173e-05, 'l1_Layer_4': 0.0009254838690857442, 'n_units_Layer_1': 275, 'n_units_Layer_2': 295, 'n_units_Layer_3': 290, 'n_units_Layer_4': 275}. Best is trial 629 with value: 5.344070879077139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.02 | sMAPE for Validation Set is: 37.99% | rMAE for Validation Set is: 1.31\n",
      "MAE for Test Set is: 34.45 | sMAPE for Test Set is: 40.92% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:10:04,905]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:10:10,766]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:10:17,874]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:10:25,431]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:10:38,280]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:10:43,945]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:11:01,976]\u001b[0m Trial 654 finished with value: 5.913719296291568 and parameters: {'n_hidden': 3, 'learning_rate': 0.000618349140609327, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024692601255204658, 'dropout_rate_Layer_2': 0.14633066316913132, 'dropout_rate_Layer_3': 0.23920075844129965, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001151896738079783, 'l1_Layer_2': 4.776144347225894e-05, 'l1_Layer_3': 0.00022252994812597843, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 260}. Best is trial 629 with value: 5.344070879077139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 22.58% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 45.69 | sMAPE for Test Set is: 42.32% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:11:42,780]\u001b[0m Trial 661 finished with value: 5.360109623394554 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005574611170078441, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2654759949014457, 'dropout_rate_Layer_2': 0.2887717904041117, 'dropout_rate_Layer_3': 0.11713790411007749, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.457490308262888e-05, 'l1_Layer_2': 1.2318557189234797e-05, 'l1_Layer_3': 0.0005440604919137158, 'n_units_Layer_1': 205, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 629 with value: 5.344070879077139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 22.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.16 | sMAPE for Test Set is: 24.40% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:11:52,571]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:11:56,266]\u001b[0m Trial 653 finished with value: 5.396445061308899 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005039618504503248, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26454146458909406, 'dropout_rate_Layer_2': 0.2882123244989036, 'dropout_rate_Layer_3': 0.12772752845326812, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021186039085268905, 'l1_Layer_2': 1.0748357286191256e-05, 'l1_Layer_3': 0.0016822700768193886, 'n_units_Layer_1': 205, 'n_units_Layer_2': 215, 'n_units_Layer_3': 200}. Best is trial 629 with value: 5.344070879077139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.61 | sMAPE for Test Set is: 25.68% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:12:05,062]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:12:09,393]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:12:13,604]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:12:21,758]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:12:26,590]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:12:36,006]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:12:44,089]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:12:45,597]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:12:50,328]\u001b[0m Trial 662 finished with value: 5.340275829504267 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005383620634380412, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2658930580418983, 'dropout_rate_Layer_2': 0.29270470583055574, 'dropout_rate_Layer_3': 0.12796855868197463, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001224275077884197, 'l1_Layer_2': 1.356837641713172e-05, 'l1_Layer_3': 0.0005248255063658942, 'n_units_Layer_1': 205, 'n_units_Layer_2': 270, 'n_units_Layer_3': 145}. Best is trial 662 with value: 5.340275829504267.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 21.76% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.39 | sMAPE for Test Set is: 24.35% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:12:50,838]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:12:57,313]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:12:58,001]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:12:58,016]\u001b[0m Trial 647 finished with value: 6.128124495365053 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006670981384651003, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025546982296505222, 'dropout_rate_Layer_2': 0.07561602791685909, 'dropout_rate_Layer_3': 0.2425151421592127, 'dropout_rate_Layer_4': 0.2590079067962856, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0005963082818155072, 'l1_Layer_2': 0.00015427568820527458, 'l1_Layer_3': 0.005756321767348781, 'l1_Layer_4': 1.750608910117595e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 295, 'n_units_Layer_3': 75, 'n_units_Layer_4': 150}. Best is trial 662 with value: 5.340275829504267.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 23.90% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 49.22 | sMAPE for Test Set is: 46.59% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:12:59,073]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:13:07,452]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:13:08,415]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:13:13,824]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:13:17,068]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:13:21,170]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:14:05,205]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:14:12,144]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:14:17,912]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:14:29,067]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:14:40,898]\u001b[0m Trial 683 finished with value: 5.301906648803029 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006515392251051353, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22289083775688975, 'dropout_rate_Layer_2': 0.288836318526423, 'dropout_rate_Layer_3': 0.1258564576407009, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012803195618409633, 'l1_Layer_2': 1.2159348343081529e-05, 'l1_Layer_3': 0.0005001602908795311, 'n_units_Layer_1': 190, 'n_units_Layer_2': 260, 'n_units_Layer_3': 155}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 23.39% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:15:33,110]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:15:38,619]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:15:43,442]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:15:43,880]\u001b[0m Trial 688 finished with value: 5.373943854738633 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005043526616084337, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2763675354161139, 'dropout_rate_Layer_2': 0.30737967855575676, 'dropout_rate_Layer_3': 0.10556624315608328, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002483377176999812, 'l1_Layer_2': 1.1822489887706786e-05, 'l1_Layer_3': 0.0006279615085238214, 'n_units_Layer_1': 65, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 21.60% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.82 | sMAPE for Test Set is: 25.59% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:15:44,114]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:15:53,862]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:15:57,894]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:16:00,865]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:16:06,278]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:16:10,653]\u001b[0m Trial 677 finished with value: 6.597404589241262 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006479513116937199, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015052369582210234, 'dropout_rate_Layer_2': 0.08003062882905389, 'dropout_rate_Layer_3': 0.13328371328403793, 'dropout_rate_Layer_4': 0.1912106339666921, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.001062314416050111, 'l1_Layer_2': 0.00016798380263230417, 'l1_Layer_3': 0.004745543193753167, 'l1_Layer_4': 1.9330579872924407e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 70, 'n_units_Layer_4': 165}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 25.08% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 49.66 | sMAPE for Test Set is: 46.88% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:16:11,264]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:16:17,184]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:16:21,387]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:16:30,576]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:16:41,908]\u001b[0m Trial 700 finished with value: 5.834646822208593 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011955326187914716, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1823104155464057, 'dropout_rate_Layer_2': 0.35944975993564426, 'dropout_rate_Layer_3': 0.08451317063315797, 'dropout_rate_Layer_4': 0.27163406254178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03473550679407046, 'l1_Layer_2': 0.014540479300993532, 'l1_Layer_3': 0.0007935525487462135, 'l1_Layer_4': 5.184979061340245e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 170, 'n_units_Layer_3': 190, 'n_units_Layer_4': 210}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 30.89 | sMAPE for Test Set is: 30.49% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:16:46,473]\u001b[0m Trial 692 finished with value: 5.911792580981774 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007731155083270453, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08859504427262989, 'dropout_rate_Layer_2': 0.1869930019728267, 'dropout_rate_Layer_3': 0.2337535615833004, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012836752274902003, 'l1_Layer_2': 3.291829090138128e-05, 'l1_Layer_3': 0.0001409527526345349, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 235}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 49.28 | sMAPE for Test Set is: 46.25% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:16:49,375]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:16:51,820]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:16:58,982]\u001b[0m Trial 704 finished with value: 12.260656979754776 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012916702394474267, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06678444936018889, 'dropout_rate_Layer_2': 0.07182172168834614, 'dropout_rate_Layer_3': 0.1743187761810615, 'dropout_rate_Layer_4': 0.3294893344391742, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0005361069651297921, 'l1_Layer_2': 0.09833488198013807, 'l1_Layer_3': 0.01060260438523494, 'l1_Layer_4': 4.530172505780342e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 290, 'n_units_Layer_3': 175, 'n_units_Layer_4': 210}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.26 | sMAPE for Validation Set is: 40.08% | rMAE for Validation Set is: 1.46\n",
      "MAE for Test Set is: 72.81 | sMAPE for Test Set is: 84.33% | rMAE for Test Set is: 2.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:17:00,295]\u001b[0m Trial 702 finished with value: 6.727403555638058 and parameters: {'n_hidden': 4, 'learning_rate': 0.001025007057809566, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00015375111037874492, 'dropout_rate_Layer_2': 0.06967688370063321, 'dropout_rate_Layer_3': 0.20172386793140962, 'dropout_rate_Layer_4': 0.26662117018955467, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00054814122821068, 'l1_Layer_2': 0.00036118258733911217, 'l1_Layer_3': 0.010122565823769733, 'l1_Layer_4': 1.3542070025750525e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 275, 'n_units_Layer_3': 95, 'n_units_Layer_4': 130}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.73 | sMAPE for Validation Set is: 25.38% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 52.83 | sMAPE for Test Set is: 50.94% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:17:08,530]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:17:11,408]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:17:17,010]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:17:17,654]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:17:25,014]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:17:29,909]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:17:59,959]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:18:03,308]\u001b[0m Trial 706 finished with value: 7.1429513055434795 and parameters: {'n_hidden': 4, 'learning_rate': 0.00114366527237536, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18544824083010297, 'dropout_rate_Layer_2': 0.06627797042824114, 'dropout_rate_Layer_3': 0.29259410111591194, 'dropout_rate_Layer_4': 0.3732696425701827, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0023719774500934525, 'l1_Layer_2': 0.00032560932951887235, 'l1_Layer_3': 0.009359224151466772, 'l1_Layer_4': 4.414658126818421e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 290, 'n_units_Layer_3': 50, 'n_units_Layer_4': 155}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.14 | sMAPE for Validation Set is: 26.65% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 52.82 | sMAPE for Test Set is: 50.83% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:18:05,711]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:18:10,771]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:18:10,963]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:18:33,893]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:18:34,830]\u001b[0m Trial 707 finished with value: 5.384474657687638 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007358246945877342, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26553542386564977, 'dropout_rate_Layer_2': 0.3333300761603062, 'dropout_rate_Layer_3': 0.1347493847272198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.697979038574375e-05, 'l1_Layer_2': 1.4492884009224358e-05, 'l1_Layer_3': 0.0009184886767116488, 'n_units_Layer_1': 85, 'n_units_Layer_2': 280, 'n_units_Layer_3': 200}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 21.90% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.90 | sMAPE for Test Set is: 24.76% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:18:41,340]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:18:41,839]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:18:46,316]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:18:50,087]\u001b[0m Trial 720 finished with value: 5.730967874186064 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013902408731159533, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03516900460051689, 'dropout_rate_Layer_2': 0.30984954008737975, 'dropout_rate_Layer_3': 0.0710770130447486, 'dropout_rate_Layer_4': 0.02670966379287109, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04774655427920748, 'l1_Layer_2': 0.008945174220322458, 'l1_Layer_3': 0.0030842959592350338, 'l1_Layer_4': 0.00010097779554590416, 'n_units_Layer_1': 100, 'n_units_Layer_2': 180, 'n_units_Layer_3': 125, 'n_units_Layer_4': 280}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 22.06% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 34.94 | sMAPE for Test Set is: 32.71% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:18:54,755]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:18:55,776]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:19:03,158]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:19:06,355]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:19:13,649]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:19:19,032]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:19:43,106]\u001b[0m Trial 726 finished with value: 5.539583964906392 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007615340546062919, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20640658607656448, 'dropout_rate_Layer_2': 0.32772359344081015, 'dropout_rate_Layer_3': 0.09386635846118899, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.310466153884966e-05, 'l1_Layer_2': 1.3447060310202628e-05, 'l1_Layer_3': 0.0001968971527871507, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 200}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.47 | sMAPE for Test Set is: 25.24% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:20:03,523]\u001b[0m Trial 713 finished with value: 5.4134890726439755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005043378036212889, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2620007310486992, 'dropout_rate_Layer_2': 0.3367005910646262, 'dropout_rate_Layer_3': 0.14365258867767447, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016814417938698, 'l1_Layer_2': 1.0011570781893344e-05, 'l1_Layer_3': 0.0006386893856627948, 'n_units_Layer_1': 50, 'n_units_Layer_2': 275, 'n_units_Layer_3': 165}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 22.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.13 | sMAPE for Test Set is: 24.91% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:20:13,303]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:20:31,622]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:20:37,188]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:20:44,511]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:20:56,359]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:00,643]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:05,337]\u001b[0m Trial 729 finished with value: 5.404648344627717 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005070052708871602, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2690609115269715, 'dropout_rate_Layer_2': 0.3312732716503565, 'dropout_rate_Layer_3': 0.09251134345216028, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.49199421284813e-05, 'l1_Layer_2': 1.5450205245569756e-05, 'l1_Layer_3': 0.00019275962992412475, 'n_units_Layer_1': 60, 'n_units_Layer_2': 280, 'n_units_Layer_3': 195}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.62 | sMAPE for Test Set is: 26.22% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:21:08,682]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:14,423]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:19,695]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:24,792]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:31,088]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:34,203]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:36,744]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:40,775]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:43,917]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:47,525]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:47,864]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:48,567]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:54,461]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:56,432]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:21:57,941]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:00,810]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:03,285]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:06,059]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:14,507]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:15,201]\u001b[0m Trial 743 finished with value: 5.732885960239774 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010330912449387326, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04296371989847768, 'dropout_rate_Layer_2': 0.33368103636591234, 'dropout_rate_Layer_3': 0.08480605770278705, 'dropout_rate_Layer_4': 0.019016637068137787, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03268025081412565, 'l1_Layer_2': 0.013009520574822133, 'l1_Layer_3': 0.0026485501787328167, 'l1_Layer_4': 4.124832009624913e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 190, 'n_units_Layer_3': 135, 'n_units_Layer_4': 275}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 22.12% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 33.14 | sMAPE for Test Set is: 31.56% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:22:19,644]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:20,231]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:26,192]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:28,763]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:35,138]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:38,496]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:45,884]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:46,401]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:47,637]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:54,023]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:56,080]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:22:57,954]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:03,070]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:04,911]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:08,418]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:09,802]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:16,717]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:17,940]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:23,940]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:28,031]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:30,495]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:37,916]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:42,027]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:42,831]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:43,373]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:49,880]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:50,949]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:23:51,474]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:24:03,964]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:24:10,170]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:24:10,926]\u001b[0m Trial 757 finished with value: 6.008375807899841 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008076588491575172, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034154604203783065, 'dropout_rate_Layer_2': 0.09598881213243077, 'dropout_rate_Layer_3': 0.22844462905119667, 'dropout_rate_Layer_4': 0.13335303704720045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.183597761839672e-05, 'l1_Layer_2': 0.029479068299810472, 'l1_Layer_3': 3.292471909020117e-05, 'l1_Layer_4': 2.5465373302764407e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 300, 'n_units_Layer_3': 250, 'n_units_Layer_4': 295}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 23.08% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 45.08 | sMAPE for Test Set is: 42.26% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:24:17,819]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:24:19,230]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:24:24,313]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:24:43,690]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:24:45,984]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:24:49,915]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:24:49,977]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:24:58,919]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:25:04,757]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:25:08,544]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:25:09,630]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:25:16,115]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:25:21,629]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:25:46,393]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:26:22,337]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:26:27,836]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:26:31,751]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:26:37,923]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:26:43,058]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:26:43,633]\u001b[0m Trial 789 finished with value: 6.423174593951156 and parameters: {'n_hidden': 4, 'learning_rate': 0.000841076632159194, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05610821687444381, 'dropout_rate_Layer_2': 0.04077117482260864, 'dropout_rate_Layer_3': 0.24632012219269847, 'dropout_rate_Layer_4': 0.14097733853877292, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00027388459185302054, 'l1_Layer_2': 0.07285900366877676, 'l1_Layer_3': 0.024938657901672524, 'l1_Layer_4': 2.9606822286124344e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 220, 'n_units_Layer_3': 205, 'n_units_Layer_4': 300}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 24.55% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 48.30 | sMAPE for Test Set is: 46.13% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:26:49,336]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:26:49,895]\u001b[0m Trial 805 finished with value: 6.039257389509579 and parameters: {'n_hidden': 4, 'learning_rate': 0.000770130202735991, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3238267933425294, 'dropout_rate_Layer_2': 0.09608792520556252, 'dropout_rate_Layer_3': 0.06955758469633885, 'dropout_rate_Layer_4': 0.15563411247963926, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.334635189358974e-05, 'l1_Layer_2': 0.001173498845614151, 'l1_Layer_3': 2.760888418250812e-05, 'l1_Layer_4': 2.488810712341708e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280, 'n_units_Layer_4': 295}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 23.34% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 46.70 | sMAPE for Test Set is: 43.73% | rMAE for Test Set is: 1.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:26:50,055]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:26:58,483]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:02,313]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:02,350]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:07,500]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:10,564]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:11,290]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:14,395]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:17,012]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:18,939]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:24,724]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:24,887]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:25,463]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:32,607]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:33,299]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:33,988]\u001b[0m Trial 804 finished with value: 6.106062287505071 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008897746007836089, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016150146046820663, 'dropout_rate_Layer_2': 0.19133520480611346, 'dropout_rate_Layer_3': 0.18690405280150899, 'dropout_rate_Layer_4': 0.13444355256540286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020391757913353955, 'l1_Layer_2': 0.006886193246969664, 'l1_Layer_3': 3.3800810324281716e-05, 'l1_Layer_4': 0.002467319904245155, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 280, 'n_units_Layer_4': 295}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 23.44% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 46.61 | sMAPE for Test Set is: 43.67% | rMAE for Test Set is: 1.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:27:44,253]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:50,926]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:55,867]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:27:58,408]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:06,964]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:08,215]\u001b[0m Trial 828 finished with value: 5.95067476043462 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009281412382220089, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0801641135936895, 'dropout_rate_Layer_2': 0.11695060028458407, 'dropout_rate_Layer_3': 0.2457891124825062, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006170322926944826, 'l1_Layer_2': 3.092020834753158e-05, 'l1_Layer_3': 3.66164619948887e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 80, 'n_units_Layer_3': 250}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 49.09 | sMAPE for Test Set is: 46.04% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:28:16,498]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:25,702]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:26,487]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:31,464]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:31,949]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:38,080]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:38,957]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:39,435]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:44,576]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:49,185]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:52,484]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:54,734]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:57,673]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:28:59,584]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:02,999]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:09,018]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:09,205]\u001b[0m Trial 833 finished with value: 5.899172042418988 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010317229837931913, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04739636297937206, 'dropout_rate_Layer_2': 0.3430377673164598, 'dropout_rate_Layer_3': 0.08728224558214406, 'dropout_rate_Layer_4': 0.05003116564226068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02048447554947319, 'l1_Layer_2': 0.003637369628981674, 'l1_Layer_3': 0.0016696920013950865, 'l1_Layer_4': 4.388967224653013e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 170, 'n_units_Layer_3': 130, 'n_units_Layer_4': 285}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 22.71% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 35.30 | sMAPE for Test Set is: 32.97% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:29:16,950]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:17,121]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:21,367]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:28,934]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:29,640]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:32,876]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:37,451]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:42,938]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:43,264]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:51,353]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:29:58,890]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:30:01,785]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:30:08,805]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:30:13,459]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:30:17,703]\u001b[0m Trial 858 finished with value: 5.911238795123725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015460870534485603, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016050886786525723, 'dropout_rate_Layer_2': 0.12438226831446546, 'dropout_rate_Layer_3': 0.22003758307762775, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00055286848568856, 'l1_Layer_2': 0.00010396315168452137, 'l1_Layer_3': 4.80710987523813e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 65, 'n_units_Layer_3': 240}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 22.99% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 50.22 | sMAPE for Test Set is: 47.66% | rMAE for Test Set is: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:30:24,468]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:30:45,843]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:30:53,672]\u001b[0m Trial 850 finished with value: 5.466444721379584 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005711980327088474, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23963140128690016, 'dropout_rate_Layer_2': 0.28580985471607945, 'dropout_rate_Layer_3': 0.10963212681936957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000168558095771531, 'l1_Layer_2': 1.3294318895687819e-05, 'l1_Layer_3': 0.0009440950964707797, 'n_units_Layer_1': 55, 'n_units_Layer_2': 275, 'n_units_Layer_3': 195}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 21.87% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.99 | sMAPE for Test Set is: 26.69% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:30:59,494]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:31:05,124]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:31:09,072]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:31:14,509]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:31:14,723]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:31:22,906]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:31:35,382]\u001b[0m Trial 864 finished with value: 5.404304935136394 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005656984183847422, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23699801682028077, 'dropout_rate_Layer_2': 0.35141748853795785, 'dropout_rate_Layer_3': 0.10998836265731218, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.9619077451822395e-05, 'l1_Layer_2': 1.2991656110079349e-05, 'l1_Layer_3': 0.0005020292196837314, 'n_units_Layer_1': 55, 'n_units_Layer_2': 250, 'n_units_Layer_3': 195}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.89% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 24.68 | sMAPE for Test Set is: 27.28% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:31:40,439]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:31:41,135]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:31:41,872]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:31:49,771]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:31:55,843]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:32:02,372]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:32:11,830]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:32:16,498]\u001b[0m Trial 876 finished with value: 6.099618537738131 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007169197077145187, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30466872167684245, 'dropout_rate_Layer_2': 0.18517295952648705, 'dropout_rate_Layer_3': 0.015742131678036363, 'dropout_rate_Layer_4': 0.1259967983755514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.194443891889364e-05, 'l1_Layer_2': 0.005396841244033555, 'l1_Layer_3': 2.966870951413195e-05, 'l1_Layer_4': 2.4211479794960183e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280, 'n_units_Layer_4': 290}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 23.35% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 48.26 | sMAPE for Test Set is: 45.41% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:32:21,479]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:32:29,034]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:32:34,876]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:32:40,711]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:32:47,713]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 24.34% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 47.41 | sMAPE for Test Set is: 44.67% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:32:50,119]\u001b[0m Trial 881 finished with value: 6.431074233218932 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007212320915128591, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3350806395403514, 'dropout_rate_Layer_2': 0.09583941922358379, 'dropout_rate_Layer_3': 0.0476064709648204, 'dropout_rate_Layer_4': 0.12747106190010213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.6599258504297172e-05, 'l1_Layer_2': 0.006352120226532552, 'l1_Layer_3': 2.6689204421341496e-05, 'l1_Layer_4': 0.0025338158154398953, 'n_units_Layer_1': 105, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290, 'n_units_Layer_4': 285}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:32:53,491]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:32:57,165]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:02,176]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:05,929]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:23,624]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:29,229]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:32,060]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:34,063]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:34,955]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:39,107]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:40,035]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:40,485]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:45,303]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:51,675]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:33:57,463]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:01,313]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:01,999]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:03,418]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:10,981]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:11,482]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:13,662]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:20,774]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:24,344]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:28,869]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:29,391]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:36,760]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:37,425]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:43,362]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:44,515]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:50,786]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:51,335]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:59,194]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:34:59,700]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:00,000]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:10,500]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:12,895]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:15,277]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:18,550]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:19,196]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:20,697]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:25,383]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:28,435]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:35,292]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:36,045]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:37,244]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:47,022]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:49,933]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:53,116]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:56,349]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:35:57,080]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:02,292]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:03,881]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:07,386]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:12,127]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:13,123]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:18,556]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:19,852]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:21,427]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:24,730]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:29,384]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:37,424]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:41,217]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:47,546]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:50,294]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:36:57,585]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:37:04,811]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:37:19,682]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:37:25,487]\u001b[0m Trial 941 finished with value: 6.090833376514325 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008627277306912277, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2723153226588412, 'dropout_rate_Layer_2': 0.14194643062622575, 'dropout_rate_Layer_3': 0.07361258543208837, 'dropout_rate_Layer_4': 0.09079928441087927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.046205777194771e-05, 'l1_Layer_2': 0.001113297320817988, 'l1_Layer_3': 1.342890618351484e-05, 'l1_Layer_4': 2.565301176026192e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 255, 'n_units_Layer_3': 265, 'n_units_Layer_4': 270}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 23.36% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 47.37 | sMAPE for Test Set is: 44.28% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:37:25,725]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:37:26,760]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:37:37,243]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:37:57,869]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:38:05,384]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:38:10,570]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:38:15,294]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:38:21,618]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:38:28,590]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:38:37,160]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:38:38,414]\u001b[0m Trial 963 finished with value: 6.140416265446054 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007813201530149892, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25397360493407667, 'dropout_rate_Layer_2': 0.12336807033094334, 'dropout_rate_Layer_3': 0.07407692598270436, 'dropout_rate_Layer_4': 0.07759733490362687, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.313059548676745e-05, 'l1_Layer_2': 0.0010746211642022852, 'l1_Layer_3': 1.0224689087932881e-05, 'l1_Layer_4': 1.1880472014707361e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295, 'n_units_Layer_4': 265}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 23.32% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 48.45 | sMAPE for Test Set is: 45.94% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:38:41,233]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:38:48,842]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:39:01,796]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:39:05,901]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:39:12,737]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:39:30,011]\u001b[0m Trial 955 finished with value: 5.444889241707414 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007347069405392271, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23298661278264818, 'dropout_rate_Layer_2': 0.3225416851394758, 'dropout_rate_Layer_3': 0.102554566654318, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021162085072741967, 'l1_Layer_2': 1.5526053476487358e-05, 'l1_Layer_3': 0.0007458439374357707, 'n_units_Layer_1': 160, 'n_units_Layer_2': 270, 'n_units_Layer_3': 180}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 22.30% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.40 | sMAPE for Test Set is: 25.59% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:39:33,876]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:39:39,133]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:39:42,926]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:39:44,434]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:39:50,722]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:39:52,130]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:39:52,359]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:39:53,304]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:39:55,701]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:01,830]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:03,961]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:07,353]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:09,158]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:10,374]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:10,579]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:19,084]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:21,013]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:25,954]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:26,683]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:28,003]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:33,192]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:39,889]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:44,475]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:46,281]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:50,541]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:52,161]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:54,567]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:40:57,568]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:03,976]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:04,019]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:08,569]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:12,583]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:15,333]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:16,205]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:17,675]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:24,619]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:28,580]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:33,094]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:37,362]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:38,568]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:46,615]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:41:50,790]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:42:09,516]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:42:15,538]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:42:20,279]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:42:24,483]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:42:29,725]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:42:32,584]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:42:39,590]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:42:44,771]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:42:46,736]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:42:52,402]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:42:55,830]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:43:02,523]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:43:18,864]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:43:23,483]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:43:28,286]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:43:33,126]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:43:37,933]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:43:44,540]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:00,273]\u001b[0m Trial 1016 finished with value: 5.999744544201907 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011492560572726408, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34254612680564006, 'dropout_rate_Layer_2': 0.10181106667592135, 'dropout_rate_Layer_3': 0.04573969242025408, 'dropout_rate_Layer_4': 0.08885932921466218, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013014745609174664, 'l1_Layer_2': 0.013354943166868551, 'l1_Layer_3': 4.2797574740348227e-05, 'l1_Layer_4': 2.3606589401976275e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 270, 'n_units_Layer_3': 270, 'n_units_Layer_4': 255}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 23.11% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 43.37 | sMAPE for Test Set is: 40.21% | rMAE for Test Set is: 1.48\n",
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 21.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.04 | sMAPE for Test Set is: 25.94% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:44:03,857]\u001b[0m Trial 1019 finished with value: 5.383315519287755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005809719144354838, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27583007019958744, 'dropout_rate_Layer_2': 0.3291947807677335, 'dropout_rate_Layer_3': 0.12992218083676121, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7344359575073255e-05, 'l1_Layer_2': 1.4339807324900067e-05, 'l1_Layer_3': 0.0004412910419222828, 'n_units_Layer_1': 60, 'n_units_Layer_2': 250, 'n_units_Layer_3': 145}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:09,617]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:09,900]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:10,091]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:19,765]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:22,554]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:28,164]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:35,124]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:35,517]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:42,930]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:44,315]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:48,633]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:52,973]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:55,542]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:44:58,545]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:45:01,508]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:45:04,567]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:45:10,810]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:45:15,270]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:45:20,896]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:45:26,710]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:45:31,563]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:45:35,703]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:45:40,304]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:45:46,874]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:45:58,721]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:45:58,928]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:46:09,520]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:46:30,549]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:46:35,764]\u001b[0m Trial 1063 finished with value: 5.893298927194674 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007780499220301145, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05920459633667764, 'dropout_rate_Layer_2': 0.09767222591713558, 'dropout_rate_Layer_3': 0.2355374564811042, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9122775468430288e-05, 'l1_Layer_2': 3.556256379752486e-05, 'l1_Layer_3': 0.00022258817336475784, 'n_units_Layer_1': 110, 'n_units_Layer_2': 60, 'n_units_Layer_3': 255}. Best is trial 683 with value: 5.301906648803029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 22.57% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 50.69 | sMAPE for Test Set is: 48.09% | rMAE for Test Set is: 1.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:46:40,072]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:46:45,814]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:46:50,170]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:46:50,779]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:46:57,060]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:01,246]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:04,761]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:06,728]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:12,191]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:13,371]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 21.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.94 | sMAPE for Test Set is: 24.13% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:47:15,888]\u001b[0m Trial 1053 finished with value: 5.280548689895299 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005608995064559424, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27270636642649, 'dropout_rate_Layer_2': 0.30579688837996777, 'dropout_rate_Layer_3': 0.14221676750815393, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.12583265404486e-05, 'l1_Layer_2': 1.446101612940505e-05, 'l1_Layer_3': 0.0005388318888385049, 'n_units_Layer_1': 60, 'n_units_Layer_2': 240, 'n_units_Layer_3': 165}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:17,115]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:21,921]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:25,818]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:30,041]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:33,788]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:38,108]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:49,175]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:47:59,692]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:48:06,242]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:48:07,536]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:48:14,488]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:48:16,649]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 22.80% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 40.43 | sMAPE for Test Set is: 37.94% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:48:18,801]\u001b[0m Trial 1080 finished with value: 5.954778830090826 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009296028780658517, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021066443765888312, 'dropout_rate_Layer_2': 0.16276363746045208, 'dropout_rate_Layer_3': 0.057500951617078, 'dropout_rate_Layer_4': 0.06731604424945163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.016539802333345382, 'l1_Layer_2': 0.017768995055730513, 'l1_Layer_3': 0.00526998043982897, 'l1_Layer_4': 1.2106529180649642e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 145, 'n_units_Layer_4': 265}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:48:27,418]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:48:32,660]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:48:42,067]\u001b[0m Trial 1084 finished with value: 5.373865308502521 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005590360014641917, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24647001442968944, 'dropout_rate_Layer_2': 0.30188571909045836, 'dropout_rate_Layer_3': 0.08839898792485074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.731476062786158e-05, 'l1_Layer_2': 1.314456831225573e-05, 'l1_Layer_3': 0.0003090226184513088, 'n_units_Layer_1': 65, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 22.06% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.50 | sMAPE for Test Set is: 25.59% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:48:45,783]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:48:46,914]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:48:51,936]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:48:54,548]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:48:58,406]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:49:01,690]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:49:02,912]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:49:04,315]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:49:10,748]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:49:19,808]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:49:23,271]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:49:28,178]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:49:33,178]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:49:37,337]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:49:42,475]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:49:53,544]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:50:01,779]\u001b[0m Trial 1094 finished with value: 6.21419935055098 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009597014199862113, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006826553027021464, 'dropout_rate_Layer_2': 0.13818844781868067, 'dropout_rate_Layer_3': 0.05837277524457734, 'dropout_rate_Layer_4': 0.06486268633012851, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014791939093884958, 'l1_Layer_2': 0.024016008817189675, 'l1_Layer_3': 0.0073067688637025886, 'l1_Layer_4': 1.2019782791200944e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150, 'n_units_Layer_4': 270}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 23.72% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 40.37 | sMAPE for Test Set is: 37.47% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:50:15,729]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:50:24,786]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:50:47,717]\u001b[0m Trial 1113 finished with value: 5.451606100120219 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006798481012310143, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25527579014029617, 'dropout_rate_Layer_2': 0.2786808447269524, 'dropout_rate_Layer_3': 0.14660009026139445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011359009877964042, 'l1_Layer_2': 1.258655130358966e-05, 'l1_Layer_3': 0.00023430215035843198, 'n_units_Layer_1': 60, 'n_units_Layer_2': 245, 'n_units_Layer_3': 185}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 22.08% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.79 | sMAPE for Test Set is: 25.78% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:51:01,552]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:51:02,389]\u001b[0m Trial 1111 finished with value: 6.171364015545575 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007984074958160183, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3604671189994483, 'dropout_rate_Layer_2': 0.11391449288347771, 'dropout_rate_Layer_3': 0.017329191351169476, 'dropout_rate_Layer_4': 0.15391477301650425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017735305975556412, 'l1_Layer_2': 0.0008476151007012895, 'l1_Layer_3': 1.363253599208321e-05, 'l1_Layer_4': 2.419837483726622e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 160, 'n_units_Layer_3': 245, 'n_units_Layer_4': 280}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 23.51% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 47.27 | sMAPE for Test Set is: 44.37% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:51:09,802]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:51:11,096]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:51:15,289]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:51:26,086]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:51:38,884]\u001b[0m Trial 1108 finished with value: 5.857738341004516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009873607192509562, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06329620649112702, 'dropout_rate_Layer_2': 0.17720439283633804, 'dropout_rate_Layer_3': 0.235651206003906, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00097528182035021, 'l1_Layer_2': 1.4778608866578435e-05, 'l1_Layer_3': 0.00031643064522773683, 'n_units_Layer_1': 125, 'n_units_Layer_2': 160, 'n_units_Layer_3': 125}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 22.93% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 48.16 | sMAPE for Test Set is: 45.14% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:51:45,838]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:51:54,854]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:51:59,816]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:03,368]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:07,203]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:11,355]\u001b[0m Trial 1118 finished with value: 6.036210870899974 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006297004280492201, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3786557762657732, 'dropout_rate_Layer_2': 0.22823609257296226, 'dropout_rate_Layer_3': 0.048530080015200934, 'dropout_rate_Layer_4': 0.18250411407433326, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003954522969857216, 'l1_Layer_2': 0.03040848295865503, 'l1_Layer_3': 3.914656250955944e-05, 'l1_Layer_4': 3.848458630803415e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 275, 'n_units_Layer_3': 270, 'n_units_Layer_4': 270}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 23.04% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 46.25 | sMAPE for Test Set is: 43.20% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:52:11,686]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:14,222]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:23,608]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:24,081]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:30,386]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:31,649]\u001b[0m Trial 1119 finished with value: 6.020241141890417 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006251878215858781, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38054270028859394, 'dropout_rate_Layer_2': 0.12486757398199719, 'dropout_rate_Layer_3': 0.018576109249633432, 'dropout_rate_Layer_4': 0.18585849595309745, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011880414232026345, 'l1_Layer_2': 0.026667426190083367, 'l1_Layer_3': 6.604097158580385e-05, 'l1_Layer_4': 3.8788871417016686e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 230, 'n_units_Layer_3': 270, 'n_units_Layer_4': 270}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 23.18% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 44.43 | sMAPE for Test Set is: 41.18% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:52:35,645]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:40,111]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:42,564]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:47,889]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:48,367]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:50,427]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:52:56,867]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:00,854]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:03,080]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:04,956]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:12,762]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:16,930]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:21,090]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:26,484]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:27,310]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:34,767]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:41,386]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:47,139]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:52,475]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:53:55,836]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:54:02,031]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:54:07,082]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:54:11,836]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:54:18,966]\u001b[0m Trial 1145 finished with value: 6.0598040951593335 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009068415178694585, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3822019612535405, 'dropout_rate_Layer_2': 0.15311807668338878, 'dropout_rate_Layer_3': 0.023154835318689355, 'dropout_rate_Layer_4': 0.20029284075401294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001201958764540243, 'l1_Layer_2': 0.021515437399526095, 'l1_Layer_3': 6.0628385699291254e-05, 'l1_Layer_4': 5.4337828517239826e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 235, 'n_units_Layer_3': 235, 'n_units_Layer_4': 265}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 23.30% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 45.86 | sMAPE for Test Set is: 42.69% | rMAE for Test Set is: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:54:23,700]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:54:28,850]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:54:32,876]\u001b[0m Trial 1144 finished with value: 5.356145633248719 and parameters: {'n_hidden': 3, 'learning_rate': 0.000616040912326999, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.281462093829722, 'dropout_rate_Layer_2': 0.3155214732387826, 'dropout_rate_Layer_3': 0.11265948520047558, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.224748491289277e-05, 'l1_Layer_2': 1.4939756234080408e-05, 'l1_Layer_3': 0.0006386139311559909, 'n_units_Layer_1': 90, 'n_units_Layer_2': 215, 'n_units_Layer_3': 160}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 22.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.00 | sMAPE for Test Set is: 24.28% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:54:41,547]\u001b[0m Trial 1153 finished with value: 5.404998876254318 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007893179674956034, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28483805261109046, 'dropout_rate_Layer_2': 0.3129998828272486, 'dropout_rate_Layer_3': 0.11316648383586733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017848992997764542, 'l1_Layer_2': 1.5497013637265505e-05, 'l1_Layer_3': 0.0006540137770220528, 'n_units_Layer_1': 70, 'n_units_Layer_2': 215, 'n_units_Layer_3': 145}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.50 | sMAPE for Test Set is: 25.57% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:54:48,049]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:54:52,821]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:54:54,903]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:55:00,082]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:55:31,064]\u001b[0m Trial 1157 finished with value: 5.399207726614196 and parameters: {'n_hidden': 3, 'learning_rate': 0.000814205346379033, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2887563522838711, 'dropout_rate_Layer_2': 0.31662949847598143, 'dropout_rate_Layer_3': 0.1309097376406925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.600094357530477e-05, 'l1_Layer_2': 1.5332393580716908e-05, 'l1_Layer_3': 0.0006029133860611224, 'n_units_Layer_1': 100, 'n_units_Layer_2': 235, 'n_units_Layer_3': 145}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 22.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.51 | sMAPE for Test Set is: 24.60% | rMAE for Test Set is: 0.73\n",
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 21.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 24.65 | sMAPE for Test Set is: 27.54% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:55:31,348]\u001b[0m Trial 1164 finished with value: 5.417454464905236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006138352671623556, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2781082598286484, 'dropout_rate_Layer_2': 0.3292237847154905, 'dropout_rate_Layer_3': 0.0743548647557549, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.448621343477309e-05, 'l1_Layer_2': 2.1522126727469706e-05, 'l1_Layer_3': 0.0003461297879955556, 'n_units_Layer_1': 90, 'n_units_Layer_2': 220, 'n_units_Layer_3': 120}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:55:42,345]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:55:42,505]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:55:49,560]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:55:50,685]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:55:59,230]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:56:09,718]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:56:18,713]\u001b[0m Trial 1166 finished with value: 6.060833820995626 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006011433236865344, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38443575236806443, 'dropout_rate_Layer_2': 0.1273398849496169, 'dropout_rate_Layer_3': 0.02372074258185293, 'dropout_rate_Layer_4': 0.20127004632008388, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00039742255215841744, 'l1_Layer_2': 0.027204752589897803, 'l1_Layer_3': 6.353169915251193e-05, 'l1_Layer_4': 3.720040393969162e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 225, 'n_units_Layer_3': 230, 'n_units_Layer_4': 260}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 23.34% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 44.81 | sMAPE for Test Set is: 41.49% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:56:23,316]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:56:34,108]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:56:39,993]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:56:43,796]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:56:48,008]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:56:52,219]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:56:57,359]\u001b[0m Trial 1161 finished with value: 5.883821880204212 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007332435674335243, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07016552272167594, 'dropout_rate_Layer_2': 0.18926816491777795, 'dropout_rate_Layer_3': 0.2332175875956352, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008104160979732978, 'l1_Layer_2': 9.450696982866408e-05, 'l1_Layer_3': 0.00032276674932959695, 'n_units_Layer_1': 135, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 22.73% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 51.27 | sMAPE for Test Set is: 48.80% | rMAE for Test Set is: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:56:58,112]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:57:07,942]\u001b[0m Trial 1174 finished with value: 5.972096000313207 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005852125469041484, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3819750285942393, 'dropout_rate_Layer_2': 0.12100785638048168, 'dropout_rate_Layer_3': 0.021851639615046572, 'dropout_rate_Layer_4': 0.20677737948407138, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011692608730895083, 'l1_Layer_2': 0.03025916542300103, 'l1_Layer_3': 6.601041102475427e-05, 'l1_Layer_4': 5.7907029749950794e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 225, 'n_units_Layer_4': 260}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 22.84% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 45.81 | sMAPE for Test Set is: 42.87% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:57:08,992]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:57:09,507]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:57:15,095]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:57:27,102]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:57:32,183]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:57:38,413]\u001b[0m Trial 1180 finished with value: 5.826089331187245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013225054297410813, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09941659445153844, 'dropout_rate_Layer_2': 0.18492166218702052, 'dropout_rate_Layer_3': 0.368818481645076, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008043580815960667, 'l1_Layer_2': 2.6195382514961548e-05, 'l1_Layer_3': 4.914641847576581e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 65, 'n_units_Layer_3': 125}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 22.45% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 52.01 | sMAPE for Test Set is: 49.76% | rMAE for Test Set is: 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:57:45,149]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:57:50,094]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 21.66% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.99 | sMAPE for Test Set is: 24.87% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:57:59,568]\u001b[0m Trial 1186 finished with value: 5.342488498396917 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005974340011599723, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27557610868965415, 'dropout_rate_Layer_2': 0.2999511383072331, 'dropout_rate_Layer_3': 0.11504175370146433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.6568755767918786e-05, 'l1_Layer_2': 1.4584880345683843e-05, 'l1_Layer_3': 0.0003827886245068149, 'n_units_Layer_1': 105, 'n_units_Layer_2': 250, 'n_units_Layer_3': 220}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:58:12,704]\u001b[0m Trial 1187 finished with value: 5.953494511582615 and parameters: {'n_hidden': 4, 'learning_rate': 0.000604608528823414, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3888683166069248, 'dropout_rate_Layer_2': 0.12120239661548579, 'dropout_rate_Layer_3': 0.02325964845407029, 'dropout_rate_Layer_4': 0.20264046490476548, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011924577196811445, 'l1_Layer_2': 0.03296085054996018, 'l1_Layer_3': 6.109911626904571e-05, 'l1_Layer_4': 5.717994475198527e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 210, 'n_units_Layer_3': 225, 'n_units_Layer_4': 245}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 22.72% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 45.19 | sMAPE for Test Set is: 42.11% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:58:19,758]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:58:26,770]\u001b[0m Trial 1191 finished with value: 5.443948800539393 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005735207662497842, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2813638204769693, 'dropout_rate_Layer_2': 0.3013396597665834, 'dropout_rate_Layer_3': 0.11472668956752267, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.575616179155492e-05, 'l1_Layer_2': 2.3259154350524805e-05, 'l1_Layer_3': 0.00036690826296576715, 'n_units_Layer_1': 85, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 21.80% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.66 | sMAPE for Test Set is: 25.23% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:58:33,350]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:58:38,232]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:58:46,250]\u001b[0m Trial 1192 finished with value: 5.880179324088101 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011064778407958865, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04333682588719992, 'dropout_rate_Layer_2': 0.20296370822774842, 'dropout_rate_Layer_3': 0.3516977252190371, 'dropout_rate_Layer_4': 0.05094049592253575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.025991121307742, 'l1_Layer_2': 0.0041662165284202515, 'l1_Layer_3': 0.002451984987873199, 'l1_Layer_4': 3.550762706963682e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155, 'n_units_Layer_4': 270}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 22.57% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 39.07 | sMAPE for Test Set is: 36.91% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 11:58:48,871]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:58:56,720]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:59:12,698]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:59:12,949]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:59:22,929]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:59:25,083]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:59:26,637]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:59:28,987]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:59:41,710]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:59:42,130]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:59:51,571]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:59:57,351]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 11:59:58,590]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:05,382]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:08,460]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:11,652]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:15,210]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:21,279]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:26,586]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:30,371]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:33,371]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:37,605]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:41,739]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:44,928]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:47,962]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:00:51,639]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:01:01,367]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:01:06,124]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:01:11,216]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:01:16,725]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:01:25,969]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:01:31,315]\u001b[0m Trial 1215 finished with value: 5.9763880335631585 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006315442191641347, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3840986653137176, 'dropout_rate_Layer_2': 0.15099871373609727, 'dropout_rate_Layer_3': 0.05838330797386463, 'dropout_rate_Layer_4': 0.19289429727656324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012735330010981124, 'l1_Layer_2': 0.019286580289072246, 'l1_Layer_3': 9.1136236213567e-05, 'l1_Layer_4': 5.687112080132314e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 210, 'n_units_Layer_3': 250, 'n_units_Layer_4': 250}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 22.98% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 46.40 | sMAPE for Test Set is: 43.61% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:01:36,880]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:01:37,988]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:01:44,491]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:01:44,938]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:01:49,132]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:01:57,137]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:01:59,870]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:03,193]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:09,023]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:14,131]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:14,946]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:22,483]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:23,183]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:24,587]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:29,605]\u001b[0m Trial 1224 finished with value: 5.842370091945682 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006066762337327696, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38075558643400714, 'dropout_rate_Layer_2': 0.15385536367481495, 'dropout_rate_Layer_3': 0.0545214779729728, 'dropout_rate_Layer_4': 0.1825524508762249, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001263361385364585, 'l1_Layer_2': 0.021142869180733596, 'l1_Layer_3': 0.00013707284597809386, 'l1_Layer_4': 5.500571396058023e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 215, 'n_units_Layer_3': 225, 'n_units_Layer_4': 245}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 22.57% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 44.56 | sMAPE for Test Set is: 41.17% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:02:31,475]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:32,253]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:36,657]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:42,644]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:47,433]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:48,251]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:52,045]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:57,148]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:57,776]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:02:57,933]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:03:24,951]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:03:25,440]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:03:34,269]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:03:34,704]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:03:38,802]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:03:45,974]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:03:52,405]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:03:56,737]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:01,146]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:03,479]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:06,720]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:10,836]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:11,545]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:13,399]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:18,310]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:21,460]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:24,735]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:32,592]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:33,302]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:33,785]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:34,947]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:42,544]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:45,180]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:46,086]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:50,523]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:51,542]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:04:57,718]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:05:04,754]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:05:05,426]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:05:07,429]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:05:25,991]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:05:26,611]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:05:37,406]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:05:42,066]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:05:48,460]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:05:53,863]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:05:59,636]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:06:06,710]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:06:07,316]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:06:12,983]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:06:14,600]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:06:21,767]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:06:27,449]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:06:45,651]\u001b[0m Trial 1279 finished with value: 5.3037758051102495 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006594819067010654, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.248961058667812, 'dropout_rate_Layer_2': 0.042030663729019424, 'dropout_rate_Layer_3': 0.13190360920968347, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024739191785083664, 'l1_Layer_2': 1.730460215910523e-05, 'l1_Layer_3': 0.00013812912933984362, 'n_units_Layer_1': 90, 'n_units_Layer_2': 265, 'n_units_Layer_3': 175}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.82 | sMAPE for Test Set is: 23.80% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:06:52,986]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:06:59,552]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:07:11,863]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:07:14,648]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:07:18,894]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:07:23,876]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:07:27,234]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:07:31,601]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:07:37,175]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:07:44,854]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:07:50,877]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:08:03,795]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:08:09,671]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:08:19,033]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:08:24,086]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:08:27,963]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 22.44% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 44.03 | sMAPE for Test Set is: 40.71% | rMAE for Test Set is: 1.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:08:29,126]\u001b[0m Trial 1299 finished with value: 5.7769778333445245 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006891834952319293, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37400892894348353, 'dropout_rate_Layer_2': 0.17338837366395105, 'dropout_rate_Layer_3': 0.04820143815641363, 'dropout_rate_Layer_4': 0.2198474598102364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.493839743897293e-05, 'l1_Layer_2': 0.014879928975279441, 'l1_Layer_3': 0.00018345837556417246, 'l1_Layer_4': 0.0001019800694112125, 'n_units_Layer_1': 155, 'n_units_Layer_2': 185, 'n_units_Layer_3': 255, 'n_units_Layer_4': 225}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:08:33,522]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:08:37,533]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:08:45,057]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:08:49,903]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:08:50,490]\u001b[0m Trial 1295 finished with value: 5.889627871075049 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006859244349736413, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3886143269393407, 'dropout_rate_Layer_2': 0.13786654197361928, 'dropout_rate_Layer_3': 0.04026329507213722, 'dropout_rate_Layer_4': 0.21665825226790764, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011980983261314373, 'l1_Layer_2': 0.04737019155263373, 'l1_Layer_3': 8.063539694174743e-05, 'l1_Layer_4': 4.382403369722737e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 180, 'n_units_Layer_3': 250, 'n_units_Layer_4': 225}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 23.06% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 41.95 | sMAPE for Test Set is: 38.53% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:08:58,685]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:01,695]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:06,561]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:07,299]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:14,826]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:15,048]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:15,488]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:16,989]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:28,028]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:31,241]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:35,035]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:39,669]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:44,828]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:09:50,483]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:10:04,081]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:10:11,490]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:10:18,202]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:10:24,132]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:10:29,906]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:10:35,374]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:10:40,906]\u001b[0m Trial 1328 finished with value: 5.89223858668169 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008965244669589869, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38817117432222314, 'dropout_rate_Layer_2': 0.1370174404900877, 'dropout_rate_Layer_3': 0.029498119253319022, 'dropout_rate_Layer_4': 0.22042365061315433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.561540475881173e-05, 'l1_Layer_2': 0.01913932907113539, 'l1_Layer_3': 0.0002855786318845035, 'l1_Layer_4': 5.4682692402348296e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 200, 'n_units_Layer_3': 240, 'n_units_Layer_4': 235}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 22.71% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 44.87 | sMAPE for Test Set is: 41.64% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:10:44,427]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:10:44,548]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:10:46,448]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:10:55,980]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:10:56,210]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:10:58,039]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:00,073]\u001b[0m Trial 1330 finished with value: 6.095391874406332 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009528904556061759, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3852368640976517, 'dropout_rate_Layer_2': 0.13193074008711395, 'dropout_rate_Layer_3': 0.03069017765089914, 'dropout_rate_Layer_4': 0.22541500528913655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.724278142779505e-05, 'l1_Layer_2': 0.02143730658698015, 'l1_Layer_3': 5.215145047863865e-05, 'l1_Layer_4': 4.852076840110796e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 205, 'n_units_Layer_3': 240, 'n_units_Layer_4': 235}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 23.34% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 45.02 | sMAPE for Test Set is: 41.38% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:11:07,792]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:11,345]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:14,486]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:14,614]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:14,746]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:16,265]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:27,783]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:27,972]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:35,061]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:39,158]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:44,112]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:45,365]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:11:55,903]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:12:02,685]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:12:08,399]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:12:13,613]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:12:17,697]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:12:22,242]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:12:28,670]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:12:34,728]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:12:39,753]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:12:55,928]\u001b[0m Trial 1356 finished with value: 5.9180049515456785 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011944936032762543, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3897995540517551, 'dropout_rate_Layer_2': 0.13600082532347885, 'dropout_rate_Layer_3': 0.03717353079583746, 'dropout_rate_Layer_4': 0.22369906123522695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.007104138647179e-05, 'l1_Layer_2': 0.04461149964240587, 'l1_Layer_3': 0.0002167246956511144, 'l1_Layer_4': 5.869134645454045e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 195, 'n_units_Layer_3': 230, 'n_units_Layer_4': 225}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 22.80% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 42.41 | sMAPE for Test Set is: 39.06% | rMAE for Test Set is: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:13:01,200]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:13:06,534]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:13:09,239]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:13:18,668]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:13:24,858]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:13:25,122]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:13:35,302]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:13:35,799]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:13:44,962]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:13:45,138]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:13:55,200]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:14:01,763]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:14:10,538]\u001b[0m Trial 1367 finished with value: 5.95474887582336 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011864354650498881, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3910157179263538, 'dropout_rate_Layer_2': 0.16967398414530674, 'dropout_rate_Layer_3': 0.08477118498087446, 'dropout_rate_Layer_4': 0.20806524144695696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.346029428300568e-05, 'l1_Layer_2': 0.04405743528821699, 'l1_Layer_3': 0.0002493228143413041, 'l1_Layer_4': 5.632043189461282e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 195, 'n_units_Layer_3': 230, 'n_units_Layer_4': 225}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 23.35% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 41.65 | sMAPE for Test Set is: 38.56% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:14:14,626]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:14:23,420]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:14:28,274]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:14:33,995]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:14:38,894]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:14:43,048]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:14:46,862]\u001b[0m Trial 1384 finished with value: 5.452371494238341 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006680452323671016, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2454235662210043, 'dropout_rate_Layer_2': 0.3040957001305937, 'dropout_rate_Layer_3': 0.11173240817594587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010100392460200392, 'l1_Layer_2': 1.397975140851256e-05, 'l1_Layer_3': 0.00018852044976514325, 'n_units_Layer_1': 65, 'n_units_Layer_2': 240, 'n_units_Layer_3': 195}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 22.35% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.30 | sMAPE for Test Set is: 24.70% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:14:47,845]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:14:53,350]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:14:56,518]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:14:59,951]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:15:07,841]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:15:08,666]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:15:15,229]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:15:16,459]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:15:18,730]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:15:26,711]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:15:42,684]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:15:48,538]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:15:52,488]\u001b[0m Trial 1374 finished with value: 5.316139533632093 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005358764851454118, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26468731374015936, 'dropout_rate_Layer_2': 0.1354945087372909, 'dropout_rate_Layer_3': 0.09831239043234918, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.823582849778582e-05, 'l1_Layer_2': 1.6259909769214775e-05, 'l1_Layer_3': 0.0001937551923112344, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 195}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 22.07% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 19.67 | sMAPE for Test Set is: 23.20% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:15:53,283]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:15:58,965]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:16:00,437]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:16:05,259]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:16:08,625]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:16:09,371]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:16:12,001]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:16:18,492]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:16:22,521]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:16:26,878]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:16:33,401]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:16:37,783]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:16:42,103]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:17:02,220]\u001b[0m Trial 1404 finished with value: 5.372493347421067 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006350918823982729, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27108513624489045, 'dropout_rate_Layer_2': 0.31853727369543006, 'dropout_rate_Layer_3': 0.11908063937941374, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.264977750807791e-05, 'l1_Layer_2': 2.0569753745010467e-05, 'l1_Layer_3': 0.00015345540197976362, 'n_units_Layer_1': 50, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 21.63% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.06 | sMAPE for Test Set is: 24.77% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:17:03,570]\u001b[0m Trial 1411 finished with value: 5.3922765465455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007954247096129191, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25351037382095254, 'dropout_rate_Layer_2': 0.186636303568681, 'dropout_rate_Layer_3': 0.12096990996870628, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.932114633013103e-05, 'l1_Layer_2': 2.0880227591219996e-05, 'l1_Layer_3': 0.0003108789824753339, 'n_units_Layer_1': 210, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 21.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.18 | sMAPE for Test Set is: 25.03% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:17:08,234]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:17:11,931]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:17:15,249]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:17:18,266]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:17:26,322]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:17:31,157]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:17:36,878]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:17:42,589]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:17:46,943]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:17:51,723]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:17:51,755]\u001b[0m Trial 1418 finished with value: 5.330761447371631 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006478437419424186, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2524764204523123, 'dropout_rate_Layer_2': 0.1243120325224889, 'dropout_rate_Layer_3': 0.11972641898445358, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011658920409450206, 'l1_Layer_2': 2.067463434725649e-05, 'l1_Layer_3': 0.0001540439379464529, 'n_units_Layer_1': 85, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 21.68% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.11 | sMAPE for Test Set is: 24.00% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:17:56,878]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:18:04,850]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:18:05,277]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:18:12,385]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:18:16,534]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:18:21,407]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:18:27,770]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:18:29,073]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:18:32,708]\u001b[0m Trial 1423 finished with value: 5.460026571241138 and parameters: {'n_hidden': 3, 'learning_rate': 0.000685764042609885, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2742196045783317, 'dropout_rate_Layer_2': 0.21327097842821857, 'dropout_rate_Layer_3': 0.12195479507089946, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011255816478715427, 'l1_Layer_2': 2.8047280170974976e-05, 'l1_Layer_3': 0.00021170884461373194, 'n_units_Layer_1': 210, 'n_units_Layer_2': 270, 'n_units_Layer_3': 165}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 22.25% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 27.34% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:18:34,998]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:18:37,353]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:18:44,951]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:18:48,285]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:18:50,927]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:03,258]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:07,781]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:15,906]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:19,644]\u001b[0m Trial 1430 finished with value: 5.917518823204378 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008199052609931965, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04952854990084358, 'dropout_rate_Layer_2': 0.12250451256115674, 'dropout_rate_Layer_3': 0.22830638163346453, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003863927502958499, 'l1_Layer_2': 0.0005338944682166745, 'l1_Layer_3': 3.365692637879823e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 65, 'n_units_Layer_3': 115}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 22.70% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 48.14 | sMAPE for Test Set is: 44.87% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:19:20,425]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:27,047]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:31,273]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:35,356]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:36,037]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:42,499]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:43,928]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:48,036]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:48,757]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:54,736]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:19:59,340]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:20:03,875]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:20:08,168]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:20:13,064]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:20:19,708]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:20:30,537]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:20:35,805]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:20:40,805]\u001b[0m Trial 1450 finished with value: 5.403417376077898 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007900270862951594, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25076146847765435, 'dropout_rate_Layer_2': 0.04972238962892443, 'dropout_rate_Layer_3': 0.1046370183110927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.774200071075146e-05, 'l1_Layer_2': 4.105900402818795e-05, 'l1_Layer_3': 0.00011100520623954265, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.06 | sMAPE for Test Set is: 25.60% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:20:44,476]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:20:52,170]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:21:06,254]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:21:10,672]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:21:14,210]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:21:18,381]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:21:19,189]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:21:24,735]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:21:27,341]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:21:32,009]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:21:37,003]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:22:16,023]\u001b[0m Trial 1474 finished with value: 5.867354629278847 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006894076016479279, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3660978585529993, 'dropout_rate_Layer_2': 0.14502488536211808, 'dropout_rate_Layer_3': 0.001008748759285881, 'dropout_rate_Layer_4': 0.22401352031401442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001487589602237342, 'l1_Layer_2': 0.015535352160006951, 'l1_Layer_3': 0.0002887630780908139, 'l1_Layer_4': 5.667888649413731e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 200, 'n_units_Layer_3': 245, 'n_units_Layer_4': 240}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 44.95 | sMAPE for Test Set is: 41.63% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:22:16,250]\u001b[0m Trial 1475 finished with value: 5.379133866736416 and parameters: {'n_hidden': 3, 'learning_rate': 0.000551330332631835, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27322240071778187, 'dropout_rate_Layer_2': 0.15595361575057257, 'dropout_rate_Layer_3': 0.14352278632306856, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012439555711981368, 'l1_Layer_2': 1.858811156921822e-05, 'l1_Layer_3': 0.00021559178015055007, 'n_units_Layer_1': 220, 'n_units_Layer_2': 255, 'n_units_Layer_3': 140}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 22.33% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.11 | sMAPE for Test Set is: 25.23% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:22:25,445]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:22:25,774]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:22:27,658]\u001b[0m Trial 1467 finished with value: 5.8445097188498 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014080894948274724, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34980858470360227, 'dropout_rate_Layer_2': 0.1471762560438588, 'dropout_rate_Layer_3': 0.06418696340102575, 'dropout_rate_Layer_4': 0.20875753968641705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00014706630802507108, 'l1_Layer_2': 0.008109920018378628, 'l1_Layer_3': 0.00020439490378179045, 'l1_Layer_4': 0.00019087839239142565, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 235, 'n_units_Layer_4': 195}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 22.72% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 42.65 | sMAPE for Test Set is: 39.40% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:22:38,497]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:22:42,610]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:22:45,238]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:22:48,539]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:22:57,357]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:22:57,832]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:22:59,076]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:23:06,598]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:23:12,414]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:23:14,796]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:23:16,132]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:23:18,108]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:23:26,252]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:23:30,957]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:23:36,527]\u001b[0m Trial 1485 finished with value: 6.134090507333769 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008504602101461851, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05372058593827919, 'dropout_rate_Layer_2': 0.3333763570611814, 'dropout_rate_Layer_3': 0.012181549957104229, 'dropout_rate_Layer_4': 0.310255666650637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.015649636017252812, 'l1_Layer_2': 0.0335480682848576, 'l1_Layer_3': 0.002459078605499428, 'l1_Layer_4': 3.269378856573482e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 165, 'n_units_Layer_3': 180, 'n_units_Layer_4': 265}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 23.30% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 31.49 | sMAPE for Test Set is: 31.33% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 12:23:36,970]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:23:43,838]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:23:45,155]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:23:58,823]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 12:24:00,078]\u001b[0m Trial 1498 finished with value: 6.251919905008158 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007980900190158936, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05625871558019453, 'dropout_rate_Layer_2': 0.3257418592450685, 'dropout_rate_Layer_3': 0.02935602356542661, 'dropout_rate_Layer_4': 0.2916131118436553, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.050861988735889464, 'l1_Layer_2': 0.03727823179448023, 'l1_Layer_3': 0.0024143809710164966, 'l1_Layer_4': 3.220003280002824e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 155, 'n_units_Layer_3': 180, 'n_units_Layer_4': 270}. Best is trial 1053 with value: 5.280548689895299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 23.65% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.48 | sMAPE for Test Set is: 28.87% | rMAE for Test Set is: 0.97\n",
      "for 2021-01-01, MAE is:6.32 & sMAPE is:13.88% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 13.88% & 0.34\n",
      "for 2021-01-02, MAE is:3.83 & sMAPE is:7.77% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 10.82% & 0.25\n",
      "for 2021-01-03, MAE is:9.16 & sMAPE is:22.76% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 14.80% & 0.28\n",
      "for 2021-01-04, MAE is:8.63 & sMAPE is:19.72% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 16.03% & 0.45\n",
      "for 2021-01-05, MAE is:15.67 & sMAPE is:27.96% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 18.42% & 0.58\n",
      "for 2021-01-06, MAE is:19.39 & sMAPE is:23.21% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 19.21% & 0.59\n",
      "for 2021-01-07, MAE is:14.09 & sMAPE is:20.52% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :11.01 & 19.40% & 0.61\n",
      "for 2021-01-08, MAE is:23.34 & sMAPE is:29.61% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :12.55 & 20.68% & 0.62\n",
      "for 2021-01-09, MAE is:10.46 & sMAPE is:15.11% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :12.32 & 20.06% & 0.66\n",
      "for 2021-01-10, MAE is:7.88 & sMAPE is:13.85% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :11.88 & 19.44% & 0.64\n",
      "for 2021-01-11, MAE is:18.53 & sMAPE is:29.30% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :12.48 & 20.33% & 0.67\n",
      "for 2021-01-12, MAE is:7.94 & sMAPE is:12.73% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :12.10 & 19.70% & 0.68\n",
      "for 2021-01-13, MAE is:10.56 & sMAPE is:14.08% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :11.98 & 19.27% & 0.67\n",
      "for 2021-01-14, MAE is:7.86 & sMAPE is:10.58% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :11.69 & 18.65% & 0.67\n",
      "for 2021-01-15, MAE is:6.55 & sMAPE is:9.00% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :11.35 & 18.00% & 0.66\n",
      "for 2021-01-16, MAE is:7.09 & sMAPE is:11.85% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 17.62% & 0.71\n",
      "for 2021-01-17, MAE is:5.58 & sMAPE is:9.98% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.76 & 17.17% & 0.71\n",
      "for 2021-01-18, MAE is:16.98 & sMAPE is:26.47% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :11.10 & 17.69% & 0.79\n",
      "for 2021-01-19, MAE is:7.59 & sMAPE is:13.56% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 17.47% & 0.78\n",
      "for 2021-01-20, MAE is:10.75 & sMAPE is:21.03% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.91 & 17.65% & 0.77\n",
      "for 2021-01-21, MAE is:10.35 & sMAPE is:36.18% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.88 & 18.53% & 0.75\n",
      "for 2021-01-22, MAE is:9.05 & sMAPE is:18.92% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :10.80 & 18.55% & 0.73\n",
      "for 2021-01-23, MAE is:3.03 & sMAPE is:5.99% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 18.00% & 0.72\n",
      "for 2021-01-24, MAE is:3.42 & sMAPE is:6.76% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :10.17 & 17.53% & 0.71\n",
      "for 2021-01-25, MAE is:4.38 & sMAPE is:7.55% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 17.13% & 0.70\n",
      "for 2021-01-26, MAE is:5.82 & sMAPE is:9.51% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :9.78 & 16.84% & 0.69\n",
      "for 2021-01-27, MAE is:3.53 & sMAPE is:5.94% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 16.44% & 0.68\n",
      "for 2021-01-28, MAE is:3.55 & sMAPE is:6.32% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 16.08% & 0.66\n",
      "for 2021-01-29, MAE is:3.71 & sMAPE is:7.57% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.14 & 15.78% & 0.66\n",
      "for 2021-01-30, MAE is:2.97 & sMAPE is:6.04% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :8.93 & 15.46% & 0.67\n",
      "for 2021-01-31, MAE is:3.62 & sMAPE is:7.85% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 15.21% & 0.71\n",
      "for 2021-02-01, MAE is:4.27 & sMAPE is:7.62% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :8.62 & 14.97% & 0.71\n",
      "for 2021-02-02, MAE is:7.58 & sMAPE is:14.16% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 14.95% & 0.71\n",
      "for 2021-02-03, MAE is:6.29 & sMAPE is:16.45% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 14.99% & 0.70\n",
      "for 2021-02-04, MAE is:7.21 & sMAPE is:14.41% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 14.98% & 0.72\n",
      "for 2021-02-05, MAE is:2.85 & sMAPE is:5.71% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 14.72% & 0.72\n",
      "for 2021-02-06, MAE is:8.57 & sMAPE is:20.37% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 14.87% & 0.72\n",
      "for 2021-02-07, MAE is:13.95 & sMAPE is:77.70% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 16.53% & 0.72\n",
      "for 2021-02-08, MAE is:8.94 & sMAPE is:32.24% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 16.93% & 0.72\n",
      "for 2021-02-09, MAE is:15.66 & sMAPE is:28.58% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :8.67 & 17.22% & 0.73\n",
      "for 2021-02-10, MAE is:13.71 & sMAPE is:18.95% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 17.26% & 0.73\n",
      "for 2021-02-11, MAE is:14.07 & sMAPE is:15.96% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.92 & 17.23% & 0.72\n",
      "for 2021-02-12, MAE is:7.72 & sMAPE is:12.31% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 17.12% & 0.72\n",
      "for 2021-02-13, MAE is:6.86 & sMAPE is:13.56% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.85 & 17.04% & 0.72\n",
      "for 2021-02-14, MAE is:5.12 & sMAPE is:11.72% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 16.92% & 0.71\n",
      "for 2021-02-15, MAE is:4.78 & sMAPE is:10.45% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 16.78% & 0.70\n",
      "for 2021-02-16, MAE is:6.39 & sMAPE is:12.94% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 16.70% & 0.70\n",
      "for 2021-02-17, MAE is:4.91 & sMAPE is:9.66% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.55 & 16.55% & 0.69\n",
      "for 2021-02-18, MAE is:6.36 & sMAPE is:13.32% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 16.48% & 0.68\n",
      "for 2021-02-19, MAE is:5.38 & sMAPE is:11.46% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 16.38% & 0.67\n",
      "for 2021-02-20, MAE is:8.48 & sMAPE is:24.12% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 16.53% & 0.67\n",
      "for 2021-02-21, MAE is:7.82 & sMAPE is:25.77% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 16.71% & 0.67\n",
      "for 2021-02-22, MAE is:6.66 & sMAPE is:14.63% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 16.67% & 0.69\n",
      "for 2021-02-23, MAE is:4.75 & sMAPE is:10.42% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 16.56% & 0.69\n",
      "for 2021-02-24, MAE is:10.22 & sMAPE is:30.95% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 16.82% & 0.69\n",
      "for 2021-02-25, MAE is:9.70 & sMAPE is:23.34% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 16.94% & 0.70\n",
      "for 2021-02-26, MAE is:7.00 & sMAPE is:15.78% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 16.91% & 0.72\n",
      "for 2021-02-27, MAE is:5.53 & sMAPE is:12.27% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 16.83% & 0.72\n",
      "for 2021-02-28, MAE is:4.85 & sMAPE is:12.23% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 16.76% & 0.71\n",
      "for 2021-03-01, MAE is:8.32 & sMAPE is:16.41% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 16.75% & 0.74\n",
      "for 2021-03-02, MAE is:9.13 & sMAPE is:17.39% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 16.76% & 0.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-03, MAE is:8.32 & sMAPE is:16.73% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 16.76% & 0.74\n",
      "for 2021-03-04, MAE is:5.59 & sMAPE is:11.09% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.23 & 16.67% & 0.74\n",
      "for 2021-03-05, MAE is:6.05 & sMAPE is:12.11% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 16.60% & 0.75\n",
      "for 2021-03-06, MAE is:4.14 & sMAPE is:9.23% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 16.49% & 0.76\n",
      "for 2021-03-07, MAE is:4.75 & sMAPE is:10.72% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 16.40% & 0.77\n",
      "for 2021-03-08, MAE is:10.62 & sMAPE is:16.59% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.12 & 16.40% & 0.77\n",
      "for 2021-03-09, MAE is:6.67 & sMAPE is:10.44% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.10 & 16.31% & 0.77\n",
      "for 2021-03-10, MAE is:12.61 & sMAPE is:26.49% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :8.17 & 16.46% & 0.78\n",
      "for 2021-03-11, MAE is:38.67 & sMAPE is:141.48% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.60 & 18.25% & 0.78\n",
      "for 2021-03-12, MAE is:34.21 & sMAPE is:168.20% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :8.96 & 20.36% & 0.80\n",
      "for 2021-03-13, MAE is:20.10 & sMAPE is:94.35% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.12 & 21.39% & 0.80\n",
      "for 2021-03-14, MAE is:13.70 & sMAPE is:75.62% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :9.18 & 22.13% & 0.80\n",
      "for 2021-03-15, MAE is:6.80 & sMAPE is:14.69% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.15 & 22.03% & 0.79\n",
      "for 2021-03-16, MAE is:7.40 & sMAPE is:13.79% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :9.12 & 21.92% & 0.80\n",
      "for 2021-03-17, MAE is:7.63 & sMAPE is:13.71% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.10 & 21.81% & 0.80\n",
      "for 2021-03-18, MAE is:16.13 & sMAPE is:27.44% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.20 & 21.88% & 0.79\n",
      "for 2021-03-19, MAE is:13.21 & sMAPE is:26.34% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :9.25 & 21.94% & 0.79\n",
      "for 2021-03-20, MAE is:9.30 & sMAPE is:19.92% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.25 & 21.92% & 0.78\n",
      "for 2021-03-21, MAE is:7.01 & sMAPE is:18.09% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 21.87% & 0.78\n",
      "for 2021-03-22, MAE is:10.12 & sMAPE is:17.45% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :9.23 & 21.81% & 0.78\n",
      "for 2021-03-23, MAE is:7.84 & sMAPE is:13.68% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.21 & 21.71% & 0.79\n",
      "for 2021-03-24, MAE is:10.87 & sMAPE is:19.84% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.23 & 21.69% & 0.81\n",
      "for 2021-03-25, MAE is:9.94 & sMAPE is:17.59% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :9.24 & 21.64% & 0.81\n",
      "for 2021-03-26, MAE is:10.44 & sMAPE is:22.75% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.26 & 21.66% & 0.82\n",
      "for 2021-03-27, MAE is:21.52 & sMAPE is:67.91% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :9.40 & 22.19% & 0.82\n",
      "for 2021-03-28, MAE is:19.57 & sMAPE is:65.18% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 22.69% & 0.82\n",
      "for 2021-03-29, MAE is:16.71 & sMAPE is:48.32% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.60 & 22.98% & 0.82\n",
      "for 2021-03-30, MAE is:13.00 & sMAPE is:25.43% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.64 & 23.01% & 0.83\n",
      "for 2021-03-31, MAE is:8.62 & sMAPE is:15.92% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 22.93% & 0.84\n",
      "for 2021-04-01, MAE is:6.10 & sMAPE is:12.12% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.59 & 22.81% & 0.84\n",
      "for 2021-04-02, MAE is:12.24 & sMAPE is:35.29% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 22.95% & 0.84\n",
      "for 2021-04-03, MAE is:6.17 & sMAPE is:21.98% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 22.93% & 0.84\n",
      "for 2021-04-04, MAE is:10.05 & sMAPE is:51.18% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 23.24% & 0.84\n",
      "for 2021-04-05, MAE is:43.78 & sMAPE is:161.55% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 24.69% & 0.84\n",
      "for 2021-04-06, MAE is:17.81 & sMAPE is:43.90% & rMAE is:2.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.02 & 24.89% & 0.86\n",
      "for 2021-04-07, MAE is:13.57 & sMAPE is:23.28% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 24.87% & 0.87\n",
      "for 2021-04-08, MAE is:9.74 & sMAPE is:14.25% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 24.77% & 0.87\n",
      "for 2021-04-09, MAE is:11.29 & sMAPE is:18.76% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 24.71% & 0.86\n",
      "for 2021-04-10, MAE is:9.02 & sMAPE is:16.30% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 24.62% & 0.86\n",
      "for 2021-04-11, MAE is:11.59 & sMAPE is:22.96% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :10.08 & 24.61% & 0.85\n",
      "for 2021-04-12, MAE is:12.56 & sMAPE is:19.16% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 24.55% & 0.85\n",
      "for 2021-04-13, MAE is:12.48 & sMAPE is:17.36% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :10.12 & 24.48% & 0.84\n",
      "for 2021-04-14, MAE is:11.62 & sMAPE is:15.15% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 24.39% & 0.84\n",
      "for 2021-04-15, MAE is:14.44 & sMAPE is:21.51% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :10.18 & 24.36% & 0.86\n",
      "for 2021-04-16, MAE is:9.45 & sMAPE is:15.07% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :10.17 & 24.28% & 0.86\n",
      "for 2021-04-17, MAE is:12.90 & sMAPE is:22.82% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 24.26% & 0.88\n",
      "for 2021-04-18, MAE is:8.16 & sMAPE is:13.70% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :10.18 & 24.17% & 0.88\n",
      "for 2021-04-19, MAE is:13.81 & sMAPE is:18.23% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 24.11% & 0.88\n",
      "for 2021-04-20, MAE is:14.48 & sMAPE is:19.83% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 24.07% & 0.89\n",
      "for 2021-04-21, MAE is:13.93 & sMAPE is:23.93% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 24.07% & 0.89\n",
      "for 2021-04-22, MAE is:15.81 & sMAPE is:29.24% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 24.12% & 0.89\n",
      "for 2021-04-23, MAE is:9.00 & sMAPE is:14.83% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 24.03% & 0.90\n",
      "for 2021-04-24, MAE is:8.51 & sMAPE is:19.00% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 23.99% & 0.90\n",
      "for 2021-04-25, MAE is:16.60 & sMAPE is:55.88% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 24.27% & 0.90\n",
      "for 2021-04-26, MAE is:10.55 & sMAPE is:18.31% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 24.22% & 0.89\n",
      "for 2021-04-27, MAE is:9.78 & sMAPE is:15.55% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 24.14% & 0.89\n",
      "for 2021-04-28, MAE is:14.12 & sMAPE is:23.79% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :10.39 & 24.14% & 0.90\n",
      "for 2021-04-29, MAE is:8.95 & sMAPE is:14.39% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 24.06% & 0.90\n",
      "for 2021-04-30, MAE is:14.72 & sMAPE is:23.14% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 24.05% & 0.91\n",
      "for 2021-05-01, MAE is:3.97 & sMAPE is:7.09% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 23.91% & 0.90\n",
      "for 2021-05-02, MAE is:10.97 & sMAPE is:35.05% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 24.00% & 0.91\n",
      "for 2021-05-03, MAE is:8.05 & sMAPE is:12.40% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 23.91% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-04, MAE is:18.51 & sMAPE is:67.93% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 24.26% & 0.91\n",
      "for 2021-05-05, MAE is:17.91 & sMAPE is:36.51% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 24.36% & 0.91\n",
      "for 2021-05-06, MAE is:13.82 & sMAPE is:21.06% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 24.33% & 0.91\n",
      "for 2021-05-07, MAE is:9.51 & sMAPE is:13.61% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 24.25% & 0.92\n",
      "for 2021-05-08, MAE is:22.81 & sMAPE is:52.61% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :10.59 & 24.47% & 0.92\n",
      "for 2021-05-09, MAE is:39.99 & sMAPE is:146.31% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :10.81 & 25.42% & 0.92\n",
      "for 2021-05-10, MAE is:21.19 & sMAPE is:43.56% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.89 & 25.55% & 0.92\n",
      "for 2021-05-11, MAE is:14.23 & sMAPE is:22.06% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 25.53% & 0.92\n",
      "for 2021-05-12, MAE is:5.78 & sMAPE is:8.77% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :10.88 & 25.40% & 0.92\n",
      "for 2021-05-13, MAE is:7.41 & sMAPE is:12.34% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.85 & 25.30% & 0.91\n",
      "for 2021-05-14, MAE is:10.18 & sMAPE is:15.30% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.85 & 25.23% & 0.92\n",
      "for 2021-05-15, MAE is:6.83 & sMAPE is:11.68% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.82 & 25.13% & 0.92\n",
      "for 2021-05-16, MAE is:21.04 & sMAPE is:61.93% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :10.89 & 25.40% & 0.91\n",
      "for 2021-05-17, MAE is:11.22 & sMAPE is:17.18% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.90 & 25.34% & 0.91\n",
      "for 2021-05-18, MAE is:8.80 & sMAPE is:12.50% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.88 & 25.25% & 0.92\n",
      "for 2021-05-19, MAE is:9.29 & sMAPE is:12.75% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.87 & 25.16% & 0.93\n",
      "for 2021-05-20, MAE is:8.57 & sMAPE is:12.58% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :10.85 & 25.07% & 0.93\n",
      "for 2021-05-21, MAE is:29.56 & sMAPE is:83.64% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 25.48% & 0.93\n",
      "for 2021-05-22, MAE is:28.05 & sMAPE is:124.03% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 26.18% & 0.92\n",
      "for 2021-05-23, MAE is:32.82 & sMAPE is:98.63% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 26.68% & 0.93\n",
      "for 2021-05-24, MAE is:19.17 & sMAPE is:54.52% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :11.31 & 26.88% & 0.93\n",
      "for 2021-05-25, MAE is:9.39 & sMAPE is:16.11% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 26.80% & 0.93\n",
      "for 2021-05-26, MAE is:11.21 & sMAPE is:16.06% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 26.73% & 0.93\n",
      "for 2021-05-27, MAE is:6.43 & sMAPE is:9.06% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 26.61% & 0.93\n",
      "for 2021-05-28, MAE is:9.88 & sMAPE is:14.18% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 26.52% & 0.92\n",
      "for 2021-05-29, MAE is:12.86 & sMAPE is:26.34% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 26.52% & 0.92\n",
      "for 2021-05-30, MAE is:16.89 & sMAPE is:61.33% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :11.31 & 26.75% & 0.92\n",
      "for 2021-05-31, MAE is:13.93 & sMAPE is:22.74% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :11.32 & 26.73% & 0.92\n",
      "for 2021-06-01, MAE is:9.36 & sMAPE is:14.30% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :11.31 & 26.65% & 0.92\n",
      "for 2021-06-02, MAE is:7.53 & sMAPE is:11.67% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :11.28 & 26.55% & 0.92\n",
      "for 2021-06-03, MAE is:6.29 & sMAPE is:9.52% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :11.25 & 26.44% & 0.92\n",
      "for 2021-06-04, MAE is:5.62 & sMAPE is:8.15% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 26.32% & 0.92\n",
      "for 2021-06-05, MAE is:5.51 & sMAPE is:8.60% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 26.21% & 0.92\n",
      "for 2021-06-06, MAE is:3.78 & sMAPE is:6.54% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 26.08% & 0.92\n",
      "for 2021-06-07, MAE is:8.77 & sMAPE is:12.06% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :11.12 & 25.99% & 0.91\n",
      "for 2021-06-08, MAE is:8.49 & sMAPE is:11.80% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :11.10 & 25.90% & 0.92\n",
      "for 2021-06-09, MAE is:7.38 & sMAPE is:10.01% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 25.80% & 0.91\n",
      "for 2021-06-10, MAE is:8.25 & sMAPE is:11.00% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 25.71% & 0.91\n",
      "for 2021-06-11, MAE is:7.77 & sMAPE is:10.41% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 25.62% & 0.92\n",
      "for 2021-06-12, MAE is:25.54 & sMAPE is:57.18% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 25.81% & 0.92\n",
      "for 2021-06-13, MAE is:40.68 & sMAPE is:106.07% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :11.31 & 26.30% & 0.92\n",
      "for 2021-06-14, MAE is:15.84 & sMAPE is:22.83% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :11.34 & 26.28% & 0.92\n",
      "for 2021-06-15, MAE is:8.56 & sMAPE is:10.78% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :11.32 & 26.19% & 0.93\n",
      "for 2021-06-16, MAE is:12.57 & sMAPE is:15.01% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :11.33 & 26.12% & 0.93\n",
      "for 2021-06-17, MAE is:10.53 & sMAPE is:12.91% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.32 & 26.04% & 0.93\n",
      "for 2021-06-18, MAE is:8.45 & sMAPE is:10.76% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :11.31 & 25.95% & 0.94\n",
      "for 2021-06-19, MAE is:7.38 & sMAPE is:10.82% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :11.28 & 25.86% & 0.93\n",
      "for 2021-06-20, MAE is:9.35 & sMAPE is:17.98% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 25.81% & 0.93\n",
      "for 2021-06-21, MAE is:5.42 & sMAPE is:7.27% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 25.71% & 0.93\n",
      "for 2021-06-22, MAE is:9.42 & sMAPE is:12.13% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :11.23 & 25.63% & 0.94\n",
      "for 2021-06-23, MAE is:10.94 & sMAPE is:13.37% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 25.56% & 0.94\n",
      "for 2021-06-24, MAE is:13.81 & sMAPE is:16.49% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 25.51% & 0.94\n",
      "for 2021-06-25, MAE is:10.67 & sMAPE is:13.44% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 25.44% & 0.95\n",
      "for 2021-06-26, MAE is:6.34 & sMAPE is:8.36% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :11.21 & 25.34% & 0.95\n",
      "for 2021-06-27, MAE is:15.96 & sMAPE is:32.47% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 25.38% & 0.95\n",
      "for 2021-06-28, MAE is:14.63 & sMAPE is:17.76% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :11.25 & 25.34% & 0.95\n",
      "for 2021-06-29, MAE is:7.81 & sMAPE is:9.20% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 25.25% & 0.95\n",
      "for 2021-06-30, MAE is:10.83 & sMAPE is:12.91% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :11.23 & 25.18% & 0.96\n",
      "for 2021-07-01, MAE is:8.30 & sMAPE is:10.26% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 25.10% & 0.97\n",
      "for 2021-07-02, MAE is:12.04 & sMAPE is:13.51% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 25.04% & 0.97\n",
      "for 2021-07-03, MAE is:8.61 & sMAPE is:10.44% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :11.21 & 24.96% & 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-04, MAE is:6.41 & sMAPE is:8.14% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 24.86% & 0.97\n",
      "for 2021-07-05, MAE is:5.46 & sMAPE is:6.04% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 24.76% & 0.97\n",
      "for 2021-07-06, MAE is:20.81 & sMAPE is:33.89% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :11.20 & 24.81% & 0.97\n",
      "for 2021-07-07, MAE is:15.83 & sMAPE is:17.39% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :11.23 & 24.77% & 0.97\n",
      "for 2021-07-08, MAE is:6.23 & sMAPE is:7.08% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :11.20 & 24.68% & 0.97\n",
      "for 2021-07-09, MAE is:5.07 & sMAPE is:5.75% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 24.58% & 0.97\n",
      "for 2021-07-10, MAE is:5.52 & sMAPE is:6.87% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :11.14 & 24.49% & 0.97\n",
      "for 2021-07-11, MAE is:5.59 & sMAPE is:7.09% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 24.40% & 0.97\n",
      "for 2021-07-12, MAE is:8.22 & sMAPE is:9.14% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :11.09 & 24.32% & 0.98\n",
      "for 2021-07-13, MAE is:9.47 & sMAPE is:10.84% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :11.09 & 24.25% & 0.98\n",
      "for 2021-07-14, MAE is:9.33 & sMAPE is:13.61% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 24.19% & 0.98\n",
      "for 2021-07-15, MAE is:14.98 & sMAPE is:22.43% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :11.10 & 24.18% & 0.98\n",
      "for 2021-07-16, MAE is:8.10 & sMAPE is:10.46% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 24.11% & 0.98\n",
      "for 2021-07-17, MAE is:11.00 & sMAPE is:22.38% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 24.11% & 0.97\n",
      "for 2021-07-18, MAE is:23.03 & sMAPE is:58.56% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :11.14 & 24.28% & 0.97\n",
      "for 2021-07-19, MAE is:19.92 & sMAPE is:24.60% & rMAE is:4.44 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 24.28% & 0.99\n",
      "for 2021-07-20, MAE is:8.64 & sMAPE is:9.90% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 24.21% & 0.99\n",
      "for 2021-07-21, MAE is:15.18 & sMAPE is:18.26% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 24.18% & 0.99\n",
      "for 2021-07-22, MAE is:8.43 & sMAPE is:10.11% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 24.11% & 0.99\n",
      "for 2021-07-23, MAE is:13.47 & sMAPE is:16.76% & rMAE is:3.05 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 24.07% & 1.00\n",
      "for 2021-07-24, MAE is:6.50 & sMAPE is:8.75% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 24.00% & 1.00\n",
      "for 2021-07-25, MAE is:11.91 & sMAPE is:19.54% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 23.98% & 0.99\n",
      "for 2021-07-26, MAE is:14.55 & sMAPE is:18.06% & rMAE is:3.77 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 23.95% & 1.01\n",
      "for 2021-07-27, MAE is:7.62 & sMAPE is:9.25% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 23.88% & 1.01\n",
      "for 2021-07-28, MAE is:17.20 & sMAPE is:34.12% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :11.20 & 23.93% & 1.01\n",
      "for 2021-07-29, MAE is:41.38 & sMAPE is:88.99% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :11.34 & 24.24% & 1.01\n",
      "for 2021-07-30, MAE is:24.81 & sMAPE is:67.48% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :11.41 & 24.44% & 1.00\n",
      "for 2021-07-31, MAE is:27.50 & sMAPE is:104.75% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :11.48 & 24.82% & 1.00\n",
      "for 2021-08-01, MAE is:10.95 & sMAPE is:22.02% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :11.48 & 24.81% & 1.00\n",
      "for 2021-08-02, MAE is:12.84 & sMAPE is:14.59% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :11.49 & 24.76% & 1.00\n",
      "for 2021-08-03, MAE is:18.30 & sMAPE is:21.33% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :11.52 & 24.74% & 1.01\n",
      "for 2021-08-04, MAE is:20.35 & sMAPE is:23.46% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :11.56 & 24.74% & 1.00\n",
      "for 2021-08-05, MAE is:18.86 & sMAPE is:22.26% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :11.59 & 24.73% & 1.00\n",
      "for 2021-08-06, MAE is:40.43 & sMAPE is:113.53% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :11.72 & 25.13% & 1.00\n",
      "for 2021-08-07, MAE is:13.37 & sMAPE is:39.93% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :11.73 & 25.20% & 1.00\n",
      "for 2021-08-08, MAE is:48.48 & sMAPE is:159.83% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :11.90 & 25.81% & 1.00\n",
      "for 2021-08-09, MAE is:26.50 & sMAPE is:45.82% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.97 & 25.90% & 1.00\n",
      "for 2021-08-10, MAE is:20.96 & sMAPE is:26.71% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :12.01 & 25.91% & 1.01\n",
      "for 2021-08-11, MAE is:18.72 & sMAPE is:19.97% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :12.04 & 25.88% & 1.01\n",
      "for 2021-08-12, MAE is:18.77 & sMAPE is:19.09% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :12.07 & 25.85% & 1.01\n",
      "for 2021-08-13, MAE is:13.54 & sMAPE is:14.92% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :12.07 & 25.80% & 1.01\n",
      "for 2021-08-14, MAE is:15.73 & sMAPE is:30.83% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :12.09 & 25.82% & 1.00\n",
      "for 2021-08-15, MAE is:9.00 & sMAPE is:19.95% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :12.08 & 25.80% & 1.00\n",
      "for 2021-08-16, MAE is:17.64 & sMAPE is:36.89% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :12.10 & 25.85% & 1.00\n",
      "for 2021-08-17, MAE is:11.13 & sMAPE is:18.58% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :12.10 & 25.82% & 1.00\n",
      "for 2021-08-18, MAE is:11.10 & sMAPE is:13.87% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :12.09 & 25.76% & 1.00\n",
      "for 2021-08-19, MAE is:19.91 & sMAPE is:20.82% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :12.12 & 25.74% & 1.00\n",
      "for 2021-08-20, MAE is:15.08 & sMAPE is:15.99% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :12.14 & 25.70% & 1.00\n",
      "for 2021-08-21, MAE is:9.60 & sMAPE is:10.99% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :12.13 & 25.64% & 1.00\n",
      "for 2021-08-22, MAE is:4.52 & sMAPE is:6.08% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :12.09 & 25.55% & 1.00\n",
      "for 2021-08-23, MAE is:15.33 & sMAPE is:17.63% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :12.11 & 25.52% & 0.99\n",
      "for 2021-08-24, MAE is:14.50 & sMAPE is:18.39% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :12.12 & 25.49% & 0.99\n",
      "for 2021-08-25, MAE is:15.22 & sMAPE is:17.01% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :12.13 & 25.45% & 0.99\n",
      "for 2021-08-26, MAE is:6.88 & sMAPE is:7.54% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :12.11 & 25.38% & 0.99\n",
      "for 2021-08-27, MAE is:8.51 & sMAPE is:9.46% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :12.09 & 25.31% & 1.00\n",
      "for 2021-08-28, MAE is:6.81 & sMAPE is:9.50% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :12.07 & 25.25% & 0.99\n",
      "for 2021-08-29, MAE is:6.41 & sMAPE is:8.91% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :12.05 & 25.18% & 1.00\n",
      "for 2021-08-30, MAE is:26.22 & sMAPE is:27.17% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :12.11 & 25.19% & 1.00\n",
      "for 2021-08-31, MAE is:19.59 & sMAPE is:19.08% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :12.14 & 25.16% & 1.00\n",
      "for 2021-09-01, MAE is:25.67 & sMAPE is:23.75% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :12.19 & 25.16% & 1.00\n",
      "for 2021-09-02, MAE is:30.68 & sMAPE is:26.66% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :12.27 & 25.16% & 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-03, MAE is:18.87 & sMAPE is:17.16% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :12.30 & 25.13% & 1.00\n",
      "for 2021-09-04, MAE is:17.96 & sMAPE is:17.64% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :12.32 & 25.10% & 0.99\n",
      "for 2021-09-05, MAE is:15.45 & sMAPE is:16.22% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :12.33 & 25.06% & 0.99\n",
      "for 2021-09-06, MAE is:26.51 & sMAPE is:20.64% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :12.39 & 25.05% & 0.99\n",
      "for 2021-09-07, MAE is:24.09 & sMAPE is:19.56% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :12.44 & 25.02% & 0.99\n",
      "for 2021-09-08, MAE is:19.45 & sMAPE is:16.43% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :12.46 & 24.99% & 1.00\n",
      "for 2021-09-09, MAE is:27.95 & sMAPE is:21.75% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :12.52 & 24.98% & 1.00\n",
      "for 2021-09-10, MAE is:22.25 & sMAPE is:17.45% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :12.56 & 24.95% & 1.00\n",
      "for 2021-09-11, MAE is:16.24 & sMAPE is:13.51% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :12.58 & 24.90% & 1.00\n",
      "for 2021-09-12, MAE is:14.63 & sMAPE is:13.52% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :12.59 & 24.86% & 1.00\n",
      "for 2021-09-13, MAE is:31.51 & sMAPE is:23.63% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :12.66 & 24.85% & 1.00\n",
      "for 2021-09-14, MAE is:26.84 & sMAPE is:19.35% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :12.71 & 24.83% & 1.01\n",
      "for 2021-09-15, MAE is:41.84 & sMAPE is:28.37% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :12.83 & 24.84% & 1.01\n",
      "for 2021-09-16, MAE is:31.03 & sMAPE is:19.70% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :12.90 & 24.82% & 1.01\n",
      "for 2021-09-17, MAE is:19.23 & sMAPE is:12.74% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :12.92 & 24.78% & 1.00\n",
      "for 2021-09-18, MAE is:14.37 & sMAPE is:10.46% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :12.93 & 24.72% & 1.01\n",
      "for 2021-09-19, MAE is:29.20 & sMAPE is:27.64% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :12.99 & 24.73% & 1.01\n",
      "for 2021-09-20, MAE is:36.55 & sMAPE is:26.25% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :13.08 & 24.74% & 1.01\n",
      "for 2021-09-21, MAE is:18.84 & sMAPE is:13.06% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :13.10 & 24.70% & 1.02\n",
      "for 2021-09-22, MAE is:29.39 & sMAPE is:18.89% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :13.16 & 24.67% & 1.02\n",
      "for 2021-09-23, MAE is:37.57 & sMAPE is:28.30% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :13.25 & 24.69% & 1.02\n",
      "for 2021-09-24, MAE is:26.80 & sMAPE is:17.79% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :13.31 & 24.66% & 1.02\n",
      "for 2021-09-25, MAE is:21.16 & sMAPE is:14.71% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :13.33 & 24.62% & 1.02\n",
      "for 2021-09-26, MAE is:15.93 & sMAPE is:12.45% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :13.34 & 24.58% & 1.02\n",
      "for 2021-09-27, MAE is:26.39 & sMAPE is:20.24% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :13.39 & 24.56% & 1.02\n",
      "for 2021-09-28, MAE is:40.02 & sMAPE is:27.45% & rMAE is:2.77 ||| daily mean of MAE & sMAPE & rMAE till now are :13.49 & 24.57% & 1.03\n",
      "for 2021-09-29, MAE is:31.89 & sMAPE is:24.69% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :13.56 & 24.57% & 1.03\n",
      "for 2021-09-30, MAE is:38.76 & sMAPE is:29.51% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :13.65 & 24.59% & 1.03\n",
      "for 2021-10-01, MAE is:36.68 & sMAPE is:36.88% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :13.73 & 24.64% & 1.03\n",
      "for 2021-10-02, MAE is:39.61 & sMAPE is:42.75% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :13.83 & 24.70% & 1.03\n",
      "for 2021-10-03, MAE is:39.25 & sMAPE is:92.62% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :13.92 & 24.95% & 1.02\n",
      "for 2021-10-04, MAE is:62.73 & sMAPE is:47.55% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :14.10 & 25.03% & 1.03\n",
      "for 2021-10-05, MAE is:42.35 & sMAPE is:27.50% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :14.20 & 25.04% & 1.03\n",
      "for 2021-10-06, MAE is:78.93 & sMAPE is:49.82% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :14.43 & 25.13% & 1.03\n",
      "for 2021-10-07, MAE is:159.08 & sMAPE is:71.23% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :14.95 & 25.29% & 1.03\n",
      "for 2021-10-08, MAE is:31.07 & sMAPE is:15.03% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :15.00 & 25.26% & 1.03\n",
      "for 2021-10-09, MAE is:46.51 & sMAPE is:30.92% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :15.12 & 25.28% & 1.03\n",
      "for 2021-10-10, MAE is:26.96 & sMAPE is:18.79% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :15.16 & 25.25% & 1.03\n",
      "for 2021-10-11, MAE is:51.97 & sMAPE is:30.86% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :15.29 & 25.27% & 1.03\n",
      "for 2021-10-12, MAE is:34.76 & sMAPE is:19.17% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :15.36 & 25.25% & 1.03\n",
      "for 2021-10-13, MAE is:37.14 & sMAPE is:19.77% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :15.43 & 25.23% & 1.03\n",
      "for 2021-10-14, MAE is:22.40 & sMAPE is:11.45% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :15.46 & 25.19% & 1.03\n",
      "for 2021-10-15, MAE is:43.71 & sMAPE is:22.06% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :15.55 & 25.17% & 1.03\n",
      "for 2021-10-16, MAE is:30.78 & sMAPE is:16.66% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :15.61 & 25.14% & 1.03\n",
      "for 2021-10-17, MAE is:26.12 & sMAPE is:16.06% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :15.64 & 25.11% & 1.03\n",
      "for 2021-10-18, MAE is:33.06 & sMAPE is:17.30% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :15.70 & 25.09% & 1.03\n",
      "for 2021-10-19, MAE is:39.46 & sMAPE is:25.93% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :15.78 & 25.09% & 1.03\n",
      "for 2021-10-20, MAE is:48.47 & sMAPE is:68.05% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :15.90 & 25.24% & 1.03\n",
      "for 2021-10-21, MAE is:81.12 & sMAPE is:91.15% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :16.12 & 25.46% & 1.03\n",
      "for 2021-10-22, MAE is:39.19 & sMAPE is:24.64% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :16.20 & 25.46% & 1.03\n",
      "for 2021-10-23, MAE is:42.17 & sMAPE is:21.26% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :16.28 & 25.44% & 1.03\n",
      "for 2021-10-24, MAE is:44.13 & sMAPE is:31.00% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :16.38 & 25.46% & 1.03\n",
      "for 2021-10-25, MAE is:53.93 & sMAPE is:29.43% & rMAE is:2.65 ||| daily mean of MAE & sMAPE & rMAE till now are :16.50 & 25.48% & 1.03\n",
      "for 2021-10-26, MAE is:45.07 & sMAPE is:23.72% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :16.60 & 25.47% & 1.03\n",
      "for 2021-10-27, MAE is:31.27 & sMAPE is:18.76% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :16.65 & 25.45% & 1.03\n",
      "for 2021-10-28, MAE is:36.44 & sMAPE is:21.55% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :16.71 & 25.43% & 1.03\n",
      "for 2021-10-29, MAE is:41.33 & sMAPE is:29.56% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :16.80 & 25.45% & 1.03\n",
      "for 2021-10-30, MAE is:28.54 & sMAPE is:23.51% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :16.83 & 25.44% & 1.03\n",
      "for 2021-10-31, MAE is:73.50 & sMAPE is:67.70% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :17.02 & 25.58% & 1.03\n",
      "for 2021-11-01, MAE is:35.46 & sMAPE is:42.00% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :17.08 & 25.63% & 1.03\n",
      "for 2021-11-02, MAE is:82.93 & sMAPE is:48.54% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :17.30 & 25.71% & 1.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-03, MAE is:18.63 & sMAPE is:9.93% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :17.30 & 25.66% & 1.03\n",
      "for 2021-11-04, MAE is:18.44 & sMAPE is:11.13% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :17.30 & 25.61% & 1.03\n",
      "for 2021-11-05, MAE is:37.59 & sMAPE is:21.89% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :17.37 & 25.60% & 1.03\n",
      "for 2021-11-06, MAE is:28.50 & sMAPE is:18.65% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :17.41 & 25.58% & 1.03\n",
      "for 2021-11-07, MAE is:40.34 & sMAPE is:35.42% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :17.48 & 25.61% & 1.03\n",
      "for 2021-11-08, MAE is:80.15 & sMAPE is:46.49% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :17.68 & 25.67% & 1.03\n",
      "for 2021-11-09, MAE is:27.08 & sMAPE is:15.44% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :17.71 & 25.64% & 1.03\n",
      "for 2021-11-10, MAE is:50.60 & sMAPE is:26.01% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :17.82 & 25.64% & 1.03\n",
      "for 2021-11-11, MAE is:21.68 & sMAPE is:11.88% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :17.83 & 25.60% & 1.03\n",
      "for 2021-11-12, MAE is:26.51 & sMAPE is:15.83% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :17.86 & 25.57% & 1.03\n",
      "for 2021-11-13, MAE is:25.82 & sMAPE is:16.12% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :17.88 & 25.54% & 1.03\n",
      "for 2021-11-14, MAE is:15.60 & sMAPE is:9.86% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :17.87 & 25.49% & 1.03\n",
      "for 2021-11-15, MAE is:62.44 & sMAPE is:30.08% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :18.01 & 25.50% & 1.03\n",
      "for 2021-11-16, MAE is:53.70 & sMAPE is:24.43% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :18.12 & 25.50% & 1.03\n",
      "for 2021-11-17, MAE is:28.11 & sMAPE is:13.88% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :18.16 & 25.46% & 1.03\n",
      "for 2021-11-18, MAE is:51.50 & sMAPE is:24.13% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :18.26 & 25.46% & 1.03\n",
      "for 2021-11-19, MAE is:22.98 & sMAPE is:11.50% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :18.27 & 25.42% & 1.03\n",
      "for 2021-11-20, MAE is:27.32 & sMAPE is:13.51% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :18.30 & 25.38% & 1.03\n",
      "for 2021-11-21, MAE is:18.28 & sMAPE is:9.86% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :18.30 & 25.33% & 1.03\n",
      "for 2021-11-22, MAE is:59.69 & sMAPE is:27.71% & rMAE is:3.02 ||| daily mean of MAE & sMAPE & rMAE till now are :18.43 & 25.34% & 1.04\n",
      "for 2021-11-23, MAE is:65.44 & sMAPE is:26.26% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :18.57 & 25.34% & 1.04\n",
      "for 2021-11-24, MAE is:63.73 & sMAPE is:23.89% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :18.71 & 25.34% & 1.04\n",
      "for 2021-11-25, MAE is:39.94 & sMAPE is:16.88% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :18.77 & 25.31% & 1.04\n",
      "for 2021-11-26, MAE is:21.00 & sMAPE is:10.16% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :18.78 & 25.27% & 1.04\n",
      "for 2021-11-27, MAE is:26.26 & sMAPE is:12.78% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :18.80 & 25.23% & 1.04\n",
      "for 2021-11-28, MAE is:16.49 & sMAPE is:8.52% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :18.80 & 25.18% & 1.04\n",
      "for 2021-11-29, MAE is:72.36 & sMAPE is:28.06% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :18.96 & 25.19% & 1.04\n",
      "for 2021-11-30, MAE is:34.68 & sMAPE is:15.61% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :19.00 & 25.16% & 1.04\n",
      "for 2021-12-01, MAE is:45.04 & sMAPE is:26.56% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :19.08 & 25.16% & 1.04\n",
      "for 2021-12-02, MAE is:57.19 & sMAPE is:24.90% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :19.20 & 25.16% & 1.04\n",
      "for 2021-12-03, MAE is:31.30 & sMAPE is:13.71% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :19.23 & 25.13% & 1.04\n",
      "for 2021-12-04, MAE is:19.51 & sMAPE is:9.34% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :19.23 & 25.08% & 1.04\n",
      "for 2021-12-05, MAE is:25.10 & sMAPE is:13.51% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :19.25 & 25.05% & 1.04\n",
      "for 2021-12-06, MAE is:69.58 & sMAPE is:28.58% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :19.40 & 25.06% & 1.04\n",
      "for 2021-12-07, MAE is:43.60 & sMAPE is:21.71% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :19.47 & 25.05% & 1.04\n",
      "for 2021-12-08, MAE is:49.82 & sMAPE is:25.26% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :19.56 & 25.05% & 1.05\n",
      "for 2021-12-09, MAE is:77.99 & sMAPE is:30.42% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :19.73 & 25.06% & 1.05\n",
      "for 2021-12-10, MAE is:31.81 & sMAPE is:13.61% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :19.76 & 25.03% & 1.05\n",
      "for 2021-12-11, MAE is:37.15 & sMAPE is:16.45% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :19.81 & 25.01% & 1.05\n",
      "for 2021-12-12, MAE is:32.91 & sMAPE is:15.07% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :19.85 & 24.98% & 1.05\n",
      "for 2021-12-13, MAE is:61.90 & sMAPE is:25.04% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :19.97 & 24.98% & 1.05\n",
      "for 2021-12-14, MAE is:95.70 & sMAPE is:35.49% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :20.19 & 25.01% & 1.05\n",
      "for 2021-12-15, MAE is:45.16 & sMAPE is:16.56% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :20.26 & 24.98% & 1.05\n",
      "for 2021-12-16, MAE is:99.64 & sMAPE is:32.51% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :20.49 & 25.00% & 1.05\n",
      "for 2021-12-17, MAE is:77.83 & sMAPE is:25.26% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :20.65 & 25.01% & 1.05\n",
      "for 2021-12-18, MAE is:47.77 & sMAPE is:17.27% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :20.73 & 24.98% & 1.05\n",
      "for 2021-12-19, MAE is:47.44 & sMAPE is:16.14% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :20.80 & 24.96% & 1.05\n",
      "for 2021-12-20, MAE is:84.68 & sMAPE is:25.69% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :20.99 & 24.96% & 1.05\n",
      "for 2021-12-21, MAE is:124.29 & sMAPE is:31.42% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :21.28 & 24.98% & 1.05\n",
      "for 2021-12-22, MAE is:83.51 & sMAPE is:22.40% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :21.45 & 24.97% & 1.05\n",
      "for 2021-12-23, MAE is:88.02 & sMAPE is:25.27% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :21.64 & 24.97% & 1.05\n",
      "for 2021-12-24, MAE is:87.30 & sMAPE is:44.28% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :21.82 & 25.03% & 1.05\n",
      "for 2021-12-25, MAE is:36.36 & sMAPE is:17.93% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :21.86 & 25.01% & 1.05\n",
      "for 2021-12-26, MAE is:35.18 & sMAPE is:18.24% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :21.90 & 24.99% & 1.04\n",
      "for 2021-12-27, MAE is:38.83 & sMAPE is:23.60% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :21.95 & 24.98% & 1.04\n",
      "for 2021-12-28, MAE is:69.21 & sMAPE is:60.18% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :22.08 & 25.08% & 1.04\n",
      "for 2021-12-29, MAE is:40.35 & sMAPE is:26.84% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :22.13 & 25.09% & 1.04\n",
      "for 2021-12-30, MAE is:86.59 & sMAPE is:83.28% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :22.30 & 25.25% & 1.03\n",
      "for 2021-12-31, MAE is:78.29 & sMAPE is:147.56% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :22.46 & 25.58% & 1.03\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.2 - (Calib Year = 3)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:05:02,958]\u001b[0m A new study created in RDB with name: BE_2022\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:05:46,301]\u001b[0m Trial 1 finished with value: 57.539010972364 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015902165302993578, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20199234665986096, 'dropout_rate_Layer_2': 0.02921268606321328, 'dropout_rate_Layer_3': 0.14387834322506007, 'dropout_rate_Layer_4': 0.2513661170384289, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009612004429085673, 'l1_Layer_2': 2.2467787828792035e-05, 'l1_Layer_3': 0.00013005987649100613, 'l1_Layer_4': 0.05297189489657291, 'n_units_Layer_1': 155, 'n_units_Layer_2': 60, 'n_units_Layer_3': 285, 'n_units_Layer_4': 255}. Best is trial 1 with value: 57.539010972364.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.54 | sMAPE for Validation Set is: 58.44% | rMAE for Validation Set is: 1.96\n",
      "MAE for Test Set is: 193.20 | sMAPE for Test Set is: 115.93% | rMAE for Test Set is: 2.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:05:46,837]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 87.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:05:54,973]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:05:58,640]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:06:05,689]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:06:15,418]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.06 | sMAPE for Validation Set is: 51.95% | rMAE for Validation Set is: 1.81\n",
      "MAE for Test Set is: 182.93 | sMAPE for Test Set is: 105.08% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:06:16,756]\u001b[0m Trial 6 finished with value: 53.05810467521127 and parameters: {'n_hidden': 3, 'learning_rate': 0.038654967514301274, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3009812822695625, 'dropout_rate_Layer_2': 0.18515749102556112, 'dropout_rate_Layer_3': 0.17976661611991263, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002046061008438752, 'l1_Layer_2': 4.8011263754320744e-05, 'l1_Layer_3': 0.0028704261153681848, 'n_units_Layer_1': 250, 'n_units_Layer_2': 165, 'n_units_Layer_3': 190}. Best is trial 6 with value: 53.05810467521127.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:06:21,777]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:06:23,759]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:06:26,575]\u001b[0m Trial 0 finished with value: 52.08093111713173 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016533320441402268, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21589577300456886, 'dropout_rate_Layer_2': 0.02207298827672779, 'dropout_rate_Layer_3': 0.37601172048131853, 'dropout_rate_Layer_4': 0.11283170969215428, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.703886864230593e-05, 'l1_Layer_2': 7.126345826122732e-05, 'l1_Layer_3': 0.0004863289653399458, 'l1_Layer_4': 0.012739784998368075, 'n_units_Layer_1': 265, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275, 'n_units_Layer_4': 105}. Best is trial 0 with value: 52.08093111713173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.08 | sMAPE for Validation Set is: 50.04% | rMAE for Validation Set is: 1.78\n",
      "MAE for Test Set is: 184.10 | sMAPE for Test Set is: 106.03% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:06:26,855]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:06:29,266]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:06:36,003]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:06:40,384]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:06:45,578]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:06:50,069]\u001b[0m Trial 14 finished with value: 44.04750939562945 and parameters: {'n_hidden': 3, 'learning_rate': 0.017006595373621623, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1968593761107755, 'dropout_rate_Layer_2': 0.20151055280242747, 'dropout_rate_Layer_3': 0.10009211794529388, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014982664671572342, 'l1_Layer_2': 1.358603389512913e-05, 'l1_Layer_3': 0.00010279680325883192, 'n_units_Layer_1': 245, 'n_units_Layer_2': 275, 'n_units_Layer_3': 270}. Best is trial 14 with value: 44.04750939562945.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.05 | sMAPE for Validation Set is: 42.53% | rMAE for Validation Set is: 1.50\n",
      "MAE for Test Set is: 156.58 | sMAPE for Test Set is: 81.39% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:06:51,924]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:06:55,979]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:06:56,663]\u001b[0m Trial 3 finished with value: 51.36575773321717 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036465430080511053, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3520276432045825, 'dropout_rate_Layer_2': 0.30219998716815333, 'dropout_rate_Layer_3': 0.03928774754018094, 'dropout_rate_Layer_4': 0.023525722051293975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.04702929188969813, 'l1_Layer_2': 0.022684657502776925, 'l1_Layer_3': 0.03294435333223124, 'l1_Layer_4': 1.4318926991996936e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190, 'n_units_Layer_4': 150}. Best is trial 14 with value: 44.04750939562945.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.37 | sMAPE for Validation Set is: 49.40% | rMAE for Validation Set is: 1.75\n",
      "MAE for Test Set is: 181.10 | sMAPE for Test Set is: 102.98% | rMAE for Test Set is: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:07:04,997]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:07:07,987]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:07:10,900]\u001b[0m Trial 20 finished with value: 46.67944778701669 and parameters: {'n_hidden': 3, 'learning_rate': 0.02375518793031809, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08321181007303156, 'dropout_rate_Layer_2': 0.2135234939271139, 'dropout_rate_Layer_3': 0.3794129603158092, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005730081464219675, 'l1_Layer_2': 0.00044609995405298254, 'l1_Layer_3': 1.2155879714653159e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 265, 'n_units_Layer_3': 200}. Best is trial 14 with value: 44.04750939562945.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.68 | sMAPE for Validation Set is: 44.20% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 162.93 | sMAPE for Test Set is: 86.14% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:07:14,203]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:07:17,099]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:07:28,941]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:07:34,661]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:07:40,236]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:07:46,447]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:07:49,498]\u001b[0m Trial 27 finished with value: 54.13465948439622 and parameters: {'n_hidden': 4, 'learning_rate': 0.006616466887400122, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02637975859341464, 'dropout_rate_Layer_2': 0.2997611154289755, 'dropout_rate_Layer_3': 0.2681913917588151, 'dropout_rate_Layer_4': 0.017344939537073414, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001162445603415019, 'l1_Layer_2': 0.00012185647717752717, 'l1_Layer_3': 0.004439593675751882, 'l1_Layer_4': 0.00023388796164267356, 'n_units_Layer_1': 105, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295, 'n_units_Layer_4': 50}. Best is trial 14 with value: 44.04750939562945.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.13 | sMAPE for Validation Set is: 53.32% | rMAE for Validation Set is: 1.85\n",
      "MAE for Test Set is: 187.38 | sMAPE for Test Set is: 109.77% | rMAE for Test Set is: 2.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:07:53,389]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:07:56,235]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:07:58,802]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:07:59,953]\u001b[0m Trial 23 finished with value: 25.766805585469616 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005199469368572841, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25624263923271473, 'dropout_rate_Layer_2': 0.3026468412588261, 'dropout_rate_Layer_3': 0.3491074919241526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006488593354659047, 'l1_Layer_2': 0.03918810268640328, 'l1_Layer_3': 0.021592519759042063, 'n_units_Layer_1': 220, 'n_units_Layer_2': 120, 'n_units_Layer_3': 85}. Best is trial 23 with value: 25.766805585469616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.77 | sMAPE for Validation Set is: 28.10% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 68.94 | sMAPE for Test Set is: 33.80% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:08:01,512]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:08:06,616]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:08:12,551]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:08:12,987]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:08:15,450]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:08:21,473]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:08:29,068]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:08:39,076]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:08:45,454]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:08:49,113]\u001b[0m Trial 43 finished with value: 18.386066070786182 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032461852079338823, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12657275000507556, 'dropout_rate_Layer_2': 0.174583352218144, 'dropout_rate_Layer_3': 0.34748989342084086, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00032955319474283244, 'l1_Layer_2': 4.1151346130570494e-05, 'l1_Layer_3': 0.01141249098032044, 'n_units_Layer_1': 65, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235}. Best is trial 43 with value: 18.386066070786182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.39 | sMAPE for Validation Set is: 22.21% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 48.57 | sMAPE for Test Set is: 24.60% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:08:50,218]\u001b[0m Trial 42 finished with value: 18.131578070331553 and parameters: {'n_hidden': 3, 'learning_rate': 0.003496627577075605, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12251804001387771, 'dropout_rate_Layer_2': 0.20390559195412156, 'dropout_rate_Layer_3': 0.3527919434185812, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00033334575903569636, 'l1_Layer_2': 4.0969715595855975e-05, 'l1_Layer_3': 0.00955236984712532, 'n_units_Layer_1': 55, 'n_units_Layer_2': 225, 'n_units_Layer_3': 240}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.13 | sMAPE for Validation Set is: 21.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 48.74 | sMAPE for Test Set is: 24.57% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:08:56,251]\u001b[0m Trial 16 finished with value: 60.81986345828801 and parameters: {'n_hidden': 3, 'learning_rate': 0.001401676032625054, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.375167920833512, 'dropout_rate_Layer_2': 0.09168572908452487, 'dropout_rate_Layer_3': 0.07438874262505495, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0009225061095937754, 'l1_Layer_2': 0.004308033333188724, 'l1_Layer_3': 0.09839933013993413, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 265}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.82 | sMAPE for Validation Set is: 62.75% | rMAE for Validation Set is: 2.08\n",
      "MAE for Test Set is: 198.38 | sMAPE for Test Set is: 121.72% | rMAE for Test Set is: 2.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:08:57,769]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:08:58,444]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:04,842]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:08,958]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:12,391]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:15,541]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:17,094]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:17,560]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:24,251]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:24,438]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:26,844]\u001b[0m Trial 48 finished with value: 18.431295267270265 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030810266516611107, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09440441779347336, 'dropout_rate_Layer_2': 0.26564196226599657, 'dropout_rate_Layer_3': 0.3620468936264734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020995958919910881, 'l1_Layer_2': 6.495664733995618e-05, 'l1_Layer_3': 0.013294289823523604, 'n_units_Layer_1': 95, 'n_units_Layer_2': 245, 'n_units_Layer_3': 160}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.43 | sMAPE for Validation Set is: 22.59% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 47.60 | sMAPE for Test Set is: 24.42% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:09:28,124]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:30,398]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:36,387]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:37,137]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:39,311]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:44,318]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:46,200]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:49,737]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:50,894]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:54,427]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:09:54,674]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:01,237]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:02,340]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:04,427]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:08,185]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:13,557]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:15,796]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:16,319]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:16,607]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:21,906]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:24,232]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:24,331]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:30,581]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:32,373]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:32,551]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:36,832]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:40,040]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:44,782]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:47,717]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:47,852]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:53,241]\u001b[0m Trial 84 finished with value: 43.82952659350423 and parameters: {'n_hidden': 4, 'learning_rate': 0.0746309404567125, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18992228338612327, 'dropout_rate_Layer_2': 0.39597252921827064, 'dropout_rate_Layer_3': 0.12628093889511174, 'dropout_rate_Layer_4': 0.3893794476421141, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00015661455356766216, 'l1_Layer_2': 1.0360418433636358e-05, 'l1_Layer_3': 0.0003379446008422968, 'l1_Layer_4': 0.0008527945710955511, 'n_units_Layer_1': 205, 'n_units_Layer_2': 60, 'n_units_Layer_3': 285, 'n_units_Layer_4': 55}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.83 | sMAPE for Validation Set is: 41.44% | rMAE for Validation Set is: 1.50\n",
      "MAE for Test Set is: 161.93 | sMAPE for Test Set is: 85.78% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:10:55,478]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:56,082]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:10:58,374]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:02,553]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:03,494]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:03,659]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:08,686]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:11,408]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:12,027]\u001b[0m Trial 76 finished with value: 50.56081013130964 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007253733356660291, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3390611610356003, 'dropout_rate_Layer_2': 0.3088007549923561, 'dropout_rate_Layer_3': 0.3445899045190959, 'dropout_rate_Layer_4': 0.24903400832232886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002031111748150915, 'l1_Layer_2': 0.0001900583208444399, 'l1_Layer_3': 0.03071127190257879, 'l1_Layer_4': 0.001124294100362881, 'n_units_Layer_1': 175, 'n_units_Layer_2': 135, 'n_units_Layer_3': 245, 'n_units_Layer_4': 300}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.56 | sMAPE for Validation Set is: 48.60% | rMAE for Validation Set is: 1.73\n",
      "MAE for Test Set is: 178.16 | sMAPE for Test Set is: 100.59% | rMAE for Test Set is: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:11:14,614]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:16,701]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:19,451]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:24,238]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:26,919]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:27,116]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:31,452]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:33,027]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:37,968]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:39,343]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:45,675]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:50,449]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:50,848]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:56,293]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:11:56,725]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:03,077]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:06,195]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:11,086]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:11,384]\u001b[0m Trial 112 finished with value: 41.208782498689736 and parameters: {'n_hidden': 4, 'learning_rate': 0.032210188970137964, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2047740509190523, 'dropout_rate_Layer_2': 0.3863422344033224, 'dropout_rate_Layer_3': 0.12893972772403664, 'dropout_rate_Layer_4': 0.39778870486506224, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00015649056597371832, 'l1_Layer_2': 5.396144482426892e-05, 'l1_Layer_3': 0.00019390312355235394, 'l1_Layer_4': 0.0012608914117559465, 'n_units_Layer_1': 210, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300, 'n_units_Layer_4': 55}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.21 | sMAPE for Validation Set is: 43.78% | rMAE for Validation Set is: 1.41\n",
      "MAE for Test Set is: 123.47 | sMAPE for Test Set is: 57.67% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:12:23,951]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:28,072]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:28,421]\u001b[0m Trial 104 finished with value: 48.92103124222609 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033816118026604542, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1695311878547912, 'dropout_rate_Layer_2': 0.17497554319277026, 'dropout_rate_Layer_3': 0.23008028491595967, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020785464053012593, 'l1_Layer_2': 0.01863831343894267, 'l1_Layer_3': 0.0015970672897785935, 'n_units_Layer_1': 135, 'n_units_Layer_2': 190, 'n_units_Layer_3': 60}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.92 | sMAPE for Validation Set is: 46.44% | rMAE for Validation Set is: 1.67\n",
      "MAE for Test Set is: 175.43 | sMAPE for Test Set is: 97.72% | rMAE for Test Set is: 2.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:12:29,293]\u001b[0m Trial 117 finished with value: 45.63839995025811 and parameters: {'n_hidden': 4, 'learning_rate': 0.031663598180077475, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21982921916424816, 'dropout_rate_Layer_2': 0.3914378738639305, 'dropout_rate_Layer_3': 0.15810305206266703, 'dropout_rate_Layer_4': 0.39910425993582666, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010686548751194608, 'l1_Layer_2': 5.1571075256212074e-05, 'l1_Layer_3': 0.0014574323616290924, 'l1_Layer_4': 0.000985873029427411, 'n_units_Layer_1': 125, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300, 'n_units_Layer_4': 55}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.64 | sMAPE for Validation Set is: 43.19% | rMAE for Validation Set is: 1.56\n",
      "MAE for Test Set is: 164.29 | sMAPE for Test Set is: 87.77% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:12:34,685]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:38,207]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:38,239]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:39,011]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:46,162]\u001b[0m Trial 120 finished with value: 44.03123791642279 and parameters: {'n_hidden': 3, 'learning_rate': 0.007447296782670578, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11914525819242355, 'dropout_rate_Layer_2': 0.2875377981852418, 'dropout_rate_Layer_3': 0.31082133517094857, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013943157764347664, 'l1_Layer_2': 0.00026701998894345747, 'l1_Layer_3': 0.00047580119346367345, 'n_units_Layer_1': 235, 'n_units_Layer_2': 230, 'n_units_Layer_3': 275}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.03 | sMAPE for Validation Set is: 43.25% | rMAE for Validation Set is: 1.50\n",
      "MAE for Test Set is: 160.80 | sMAPE for Test Set is: 85.11% | rMAE for Test Set is: 2.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:12:46,962]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:51,346]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:54,961]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:55,429]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:12:58,876]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:03,046]\u001b[0m Trial 125 finished with value: 44.86596223911594 and parameters: {'n_hidden': 4, 'learning_rate': 0.09673446218371842, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13184938637335486, 'dropout_rate_Layer_2': 0.39968133111025594, 'dropout_rate_Layer_3': 0.1603573415898013, 'dropout_rate_Layer_4': 0.3096929214854326, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00018379822152904746, 'l1_Layer_2': 5.3967623146836425e-05, 'l1_Layer_3': 0.007277372552218769, 'l1_Layer_4': 0.005243611659564305, 'n_units_Layer_1': 205, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200, 'n_units_Layer_4': 115}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.87 | sMAPE for Validation Set is: 42.89% | rMAE for Validation Set is: 1.53\n",
      "MAE for Test Set is: 157.25 | sMAPE for Test Set is: 81.99% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:13:04,572]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:05,870]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:09,043]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:10,717]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:15,835]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:18,708]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:22,980]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:24,614]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:28,219]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:31,433]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:35,822]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:36,366]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:42,679]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:42,782]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:48,822]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:13:49,040]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:14:12,458]\u001b[0m Trial 140 finished with value: 40.36696138958691 and parameters: {'n_hidden': 4, 'learning_rate': 0.038858246224529346, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24425479996714247, 'dropout_rate_Layer_2': 0.3453250350507831, 'dropout_rate_Layer_3': 0.24318729812816364, 'dropout_rate_Layer_4': 0.1507554251248876, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.051730315964319e-05, 'l1_Layer_2': 7.170877390485087e-05, 'l1_Layer_3': 0.0001155605336549385, 'l1_Layer_4': 9.144504468758674e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 85, 'n_units_Layer_3': 295, 'n_units_Layer_4': 50}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.37 | sMAPE for Validation Set is: 37.93% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 146.77 | sMAPE for Test Set is: 73.87% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:14:24,964]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:14:59,069]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:15:04,850]\u001b[0m Trial 148 finished with value: 28.459629183330566 and parameters: {'n_hidden': 4, 'learning_rate': 0.033016515063264876, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2554341705205353, 'dropout_rate_Layer_2': 0.3485796217292141, 'dropout_rate_Layer_3': 0.25470987738723333, 'dropout_rate_Layer_4': 0.13597355370754738, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.68783033755426e-05, 'l1_Layer_2': 4.191241925637211e-05, 'l1_Layer_3': 0.00010289210471437342, 'l1_Layer_4': 7.893672167858079e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 80, 'n_units_Layer_3': 295, 'n_units_Layer_4': 50}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.46 | sMAPE for Validation Set is: 30.15% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 90.75 | sMAPE for Test Set is: 40.15% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:15:11,852]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:15:18,897]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:15:33,741]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:15:38,699]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:15:44,688]\u001b[0m Trial 153 finished with value: 22.048318425057317 and parameters: {'n_hidden': 4, 'learning_rate': 0.03273062970996902, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23520665733267712, 'dropout_rate_Layer_2': 0.33496163649925403, 'dropout_rate_Layer_3': 0.3111241817975682, 'dropout_rate_Layer_4': 0.3876234976110131, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002251397171588952, 'l1_Layer_2': 0.012526604892503143, 'l1_Layer_3': 0.00022095773649078883, 'l1_Layer_4': 0.03626897270772684, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 240, 'n_units_Layer_4': 155}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.05 | sMAPE for Validation Set is: 26.14% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 60.64 | sMAPE for Test Set is: 29.75% | rMAE for Test Set is: 0.76\n",
      "MAE for Validation Set is: 32.10 | sMAPE for Validation Set is: 34.03% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 89.52 | sMAPE for Test Set is: 41.32% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:15:46,154]\u001b[0m Trial 149 finished with value: 32.09570330194921 and parameters: {'n_hidden': 4, 'learning_rate': 0.04225066932651066, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25533925065432644, 'dropout_rate_Layer_2': 0.36210017056930716, 'dropout_rate_Layer_3': 0.25083919776043295, 'dropout_rate_Layer_4': 0.14327419491850918, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.9480650927928985e-05, 'l1_Layer_2': 4.38548542546201e-05, 'l1_Layer_3': 0.00011285475063175245, 'l1_Layer_4': 8.642562125483955e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 85, 'n_units_Layer_3': 300, 'n_units_Layer_4': 195}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:15:51,446]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:15:56,560]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:07,246]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:11,922]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:15,108]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:16,734]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:21,335]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:24,057]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:27,445]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:32,083]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:32,394]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:38,994]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:41,762]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:46,503]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:48,173]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:52,477]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:16:54,088]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:01,203]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:05,457]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:06,043]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:12,927]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:14,961]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:15,838]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:20,288]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:21,790]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:24,483]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:47,468]\u001b[0m Trial 185 finished with value: 18.266891870558595 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018904651679399439, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3037904870759163, 'dropout_rate_Layer_2': 0.009458506523301102, 'dropout_rate_Layer_3': 0.04767421784996945, 'dropout_rate_Layer_4': 0.009024628117916461, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004133984200529771, 'l1_Layer_2': 5.759174942740908e-05, 'l1_Layer_3': 0.0010187601982971622, 'l1_Layer_4': 0.0002071100121179401, 'n_units_Layer_1': 195, 'n_units_Layer_2': 130, 'n_units_Layer_3': 260, 'n_units_Layer_4': 120}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.27 | sMAPE for Validation Set is: 21.84% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 49.32 | sMAPE for Test Set is: 24.86% | rMAE for Test Set is: 0.62\n",
      "MAE for Validation Set is: 20.86 | sMAPE for Validation Set is: 24.55% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 56.21 | sMAPE for Test Set is: 27.68% | rMAE for Test Set is: 0.70\n",
      "MAE for Validation Set is: 35.84 | sMAPE for Validation Set is: 34.01% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 140.67 | sMAPE for Test Set is: 70.05% | rMAE for Test Set is: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:17:50,584]\u001b[0m Trial 184 finished with value: 20.860700644629848 and parameters: {'n_hidden': 3, 'learning_rate': 0.09207530536165372, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31446518114940997, 'dropout_rate_Layer_2': 0.36996279800085324, 'dropout_rate_Layer_3': 0.06527668407672071, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004401792438054717, 'l1_Layer_2': 5.072021843796915e-05, 'l1_Layer_3': 0.0015033915069007588, 'n_units_Layer_1': 130, 'n_units_Layer_2': 50, 'n_units_Layer_3': 115}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:50,611]\u001b[0m Trial 160 finished with value: 35.84059742721599 and parameters: {'n_hidden': 3, 'learning_rate': 0.016540305082683095, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26530503949784295, 'dropout_rate_Layer_2': 0.26455549213231927, 'dropout_rate_Layer_3': 0.37989320989478076, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023258615202007474, 'l1_Layer_2': 1.2339610649791598e-05, 'l1_Layer_3': 4.7351123534009805e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 145, 'n_units_Layer_3': 210}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:51,995]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:17:58,279]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:18:01,885]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:18:09,313]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:18:16,294]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:18:19,762]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:18:21,418]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:18:30,937]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:18:36,947]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:19:03,474]\u001b[0m Trial 195 finished with value: 18.510017944072654 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010584481352877153, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2938814587366991, 'dropout_rate_Layer_2': 0.021733221799440233, 'dropout_rate_Layer_3': 0.029738667905700653, 'dropout_rate_Layer_4': 0.00043599885444306485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.010736294293719474, 'l1_Layer_2': 2.072205638052802e-05, 'l1_Layer_3': 1.6331391459741992e-05, 'l1_Layer_4': 0.00019965604852007691, 'n_units_Layer_1': 190, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285, 'n_units_Layer_4': 110}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.51 | sMAPE for Validation Set is: 22.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 47.72 | sMAPE for Test Set is: 24.49% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:19:07,392]\u001b[0m Trial 190 finished with value: 19.116205218799507 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019349018898787975, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31043177384079224, 'dropout_rate_Layer_2': 0.30865613329912694, 'dropout_rate_Layer_3': 0.023450063735205195, 'dropout_rate_Layer_4': 0.014775952234990095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004619293381381328, 'l1_Layer_2': 1.9235656986897778e-05, 'l1_Layer_3': 4.848877421744418e-05, 'l1_Layer_4': 0.000344581365244466, 'n_units_Layer_1': 195, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280, 'n_units_Layer_4': 115}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.12 | sMAPE for Validation Set is: 22.68% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 49.42 | sMAPE for Test Set is: 25.16% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:19:21,899]\u001b[0m Trial 197 finished with value: 18.418927012029304 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009016707282904453, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3036602189329528, 'dropout_rate_Layer_2': 0.0054092323074079185, 'dropout_rate_Layer_3': 0.0105943483314321, 'dropout_rate_Layer_4': 0.0050656705467031875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.012804771893454095, 'l1_Layer_2': 2.002263336027025e-05, 'l1_Layer_3': 5.1617041687734743e-05, 'l1_Layer_4': 0.00017661477812754025, 'n_units_Layer_1': 195, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285, 'n_units_Layer_4': 115}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.42 | sMAPE for Validation Set is: 22.25% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 47.87 | sMAPE for Test Set is: 24.44% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:19:24,005]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:19:31,465]\u001b[0m Trial 196 finished with value: 18.83367411678813 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015351324150446638, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30962030595800105, 'dropout_rate_Layer_2': 0.00820263568091209, 'dropout_rate_Layer_3': 0.0017013699459076381, 'dropout_rate_Layer_4': 0.0028410797951751556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00986391161975652, 'l1_Layer_2': 2.375630183047602e-05, 'l1_Layer_3': 3.766023948269264e-05, 'l1_Layer_4': 0.00017763222099578279, 'n_units_Layer_1': 195, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285, 'n_units_Layer_4': 110}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.83 | sMAPE for Validation Set is: 22.19% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 49.44 | sMAPE for Test Set is: 25.07% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:19:34,856]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:19:38,784]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:19:42,723]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:19:46,758]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:19:46,917]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:19:53,214]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:19:58,015]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:20:03,021]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:20:08,313]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:20:31,255]\u001b[0m Trial 199 finished with value: 18.187108558272072 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009226654253390268, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23506921475758963, 'dropout_rate_Layer_2': 0.1489654282686243, 'dropout_rate_Layer_3': 0.36417946121659583, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005952309615561888, 'l1_Layer_2': 7.116008640350012e-05, 'l1_Layer_3': 0.0119533783677255, 'n_units_Layer_1': 90, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.19 | sMAPE for Validation Set is: 22.01% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 47.55 | sMAPE for Test Set is: 24.38% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:20:35,461]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:20:35,674]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:20:42,077]\u001b[0m Trial 210 finished with value: 30.423929196729336 and parameters: {'n_hidden': 4, 'learning_rate': 0.08359427427523253, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2639682042567944, 'dropout_rate_Layer_2': 0.396561850630179, 'dropout_rate_Layer_3': 0.15361062258523103, 'dropout_rate_Layer_4': 0.39950872920800723, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00023943027709652883, 'l1_Layer_2': 0.00011449363884864888, 'l1_Layer_3': 0.00021620362567182868, 'l1_Layer_4': 0.09855775649978431, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195, 'n_units_Layer_4': 140}. Best is trial 42 with value: 18.131578070331553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.42 | sMAPE for Validation Set is: 31.77% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 82.51 | sMAPE for Test Set is: 36.64% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:20:48,246]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:20:59,273]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:21:09,959]\u001b[0m Trial 202 finished with value: 17.999366151172136 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009091484448074512, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20379892156556959, 'dropout_rate_Layer_2': 0.14124419517818104, 'dropout_rate_Layer_3': 0.20334696604933156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006069226452909028, 'l1_Layer_2': 7.217231413610362e-05, 'l1_Layer_3': 0.012471795483378114, 'n_units_Layer_1': 90, 'n_units_Layer_2': 190, 'n_units_Layer_3': 230}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.00 | sMAPE for Validation Set is: 21.74% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 48.61 | sMAPE for Test Set is: 24.61% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:21:13,006]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:21:20,755]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:21:30,413]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:21:37,380]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:21:42,325]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:21:58,161]\u001b[0m Trial 216 finished with value: 22.986486283773814 and parameters: {'n_hidden': 4, 'learning_rate': 0.029436676642703854, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25989873378648165, 'dropout_rate_Layer_2': 0.3256667698333999, 'dropout_rate_Layer_3': 0.29564194797613563, 'dropout_rate_Layer_4': 0.39821083332110707, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002498053181460733, 'l1_Layer_2': 0.0012115988478268794, 'l1_Layer_3': 9.681555195414186e-05, 'l1_Layer_4': 0.0040440115440326255, 'n_units_Layer_1': 75, 'n_units_Layer_2': 100, 'n_units_Layer_3': 225, 'n_units_Layer_4': 160}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.99 | sMAPE for Validation Set is: 26.27% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 63.38 | sMAPE for Test Set is: 31.10% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:22:01,307]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:22:06,861]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:22:23,638]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:22:45,654]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:22:54,754]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:23:00,602]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:23:05,320]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:23:24,932]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.76 | sMAPE for Validation Set is: 22.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 51.73 | sMAPE for Test Set is: 25.77% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:23:28,266]\u001b[0m Trial 219 finished with value: 18.75869633746935 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007242272649559435, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2947335410798605, 'dropout_rate_Layer_2': 0.00025935950746817406, 'dropout_rate_Layer_3': 0.04447975100837625, 'dropout_rate_Layer_4': 0.05623162066344139, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008162688453426336, 'l1_Layer_2': 5.340109015669893e-05, 'l1_Layer_3': 8.038168788331345e-05, 'l1_Layer_4': 0.00031385365932258926, 'n_units_Layer_1': 185, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260, 'n_units_Layer_4': 110}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:23:38,472]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:23:46,560]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:23:51,041]\u001b[0m Trial 231 finished with value: 21.850814435393232 and parameters: {'n_hidden': 4, 'learning_rate': 0.04656982473606789, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2509365176893063, 'dropout_rate_Layer_2': 0.3401179662035521, 'dropout_rate_Layer_3': 0.15230728718789988, 'dropout_rate_Layer_4': 0.24821795382087736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0721606685268044e-05, 'l1_Layer_2': 0.00012108797785099011, 'l1_Layer_3': 0.0002639211209895918, 'l1_Layer_4': 0.006143215715347864, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 140, 'n_units_Layer_4': 95}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.85 | sMAPE for Validation Set is: 25.24% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 59.89 | sMAPE for Test Set is: 29.58% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:23:53,911]\u001b[0m Trial 233 finished with value: 43.62107508896727 and parameters: {'n_hidden': 4, 'learning_rate': 0.026220170095114195, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22587353106759647, 'dropout_rate_Layer_2': 0.36378862096543524, 'dropout_rate_Layer_3': 0.17703924940050997, 'dropout_rate_Layer_4': 0.1578127451623994, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003004329152901745, 'l1_Layer_2': 5.2696039230786254e-05, 'l1_Layer_3': 0.00011279677237033899, 'l1_Layer_4': 0.0032002250318630505, 'n_units_Layer_1': 225, 'n_units_Layer_2': 75, 'n_units_Layer_3': 300, 'n_units_Layer_4': 80}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.62 | sMAPE for Validation Set is: 42.40% | rMAE for Validation Set is: 1.49\n",
      "MAE for Test Set is: 144.85 | sMAPE for Test Set is: 72.55% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:23:56,765]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:00,127]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:02,956]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:03,446]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:03,563]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:10,137]\u001b[0m Trial 232 finished with value: 18.96111255763407 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011630206619383401, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32369589946872307, 'dropout_rate_Layer_2': 0.02601097158587253, 'dropout_rate_Layer_3': 0.07792411690214154, 'dropout_rate_Layer_4': 0.004583821828192832, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008448255327678216, 'l1_Layer_2': 3.641836338936351e-05, 'l1_Layer_3': 7.920654033536816e-05, 'l1_Layer_4': 8.985377753876908e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 90, 'n_units_Layer_3': 300, 'n_units_Layer_4': 135}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.96 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 48.13 | sMAPE for Test Set is: 24.70% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:24:13,616]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:13,743]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:13,957]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:14,610]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:20,511]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:20,819]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:22,077]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:27,441]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:28,376]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:34,192]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:43,228]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:45,877]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:52,346]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:24:53,037]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:25:00,370]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:25:00,704]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:25:07,360]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:25:18,296]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:25:21,282]\u001b[0m Trial 255 finished with value: 20.316019016644145 and parameters: {'n_hidden': 4, 'learning_rate': 0.001971385985024075, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37824544547431005, 'dropout_rate_Layer_2': 0.06111503172840443, 'dropout_rate_Layer_3': 0.055327092586144, 'dropout_rate_Layer_4': 0.0004965501669946274, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.017672824323377256, 'l1_Layer_2': 3.4361226533558695e-05, 'l1_Layer_3': 7.983481186365272e-05, 'l1_Layer_4': 7.722091901751967e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 105, 'n_units_Layer_3': 270, 'n_units_Layer_4': 90}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.32 | sMAPE for Validation Set is: 23.77% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 52.33 | sMAPE for Test Set is: 26.21% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:25:36,250]\u001b[0m Trial 247 finished with value: 18.990971515125405 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008954921918112306, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3821400893696871, 'dropout_rate_Layer_2': 0.06260462969004182, 'dropout_rate_Layer_3': 0.05251225228956733, 'dropout_rate_Layer_4': 0.001157144105347418, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009766319251094774, 'l1_Layer_2': 3.519276175815783e-05, 'l1_Layer_3': 5.89505337683963e-05, 'l1_Layer_4': 8.023834101173708e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 105, 'n_units_Layer_3': 270, 'n_units_Layer_4': 90}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.99 | sMAPE for Validation Set is: 22.28% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 49.67 | sMAPE for Test Set is: 25.17% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:25:39,213]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:25:49,777]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:26:04,556]\u001b[0m Trial 262 finished with value: 19.827791837356997 and parameters: {'n_hidden': 4, 'learning_rate': 0.013152099366993308, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33291479909876104, 'dropout_rate_Layer_2': 0.2344088394541035, 'dropout_rate_Layer_3': 0.10494647506094362, 'dropout_rate_Layer_4': 0.22320794537686015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.0319600917101984e-05, 'l1_Layer_2': 6.617759474179927e-05, 'l1_Layer_3': 0.0008164079721490492, 'l1_Layer_4': 0.0013467638679414606, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 135, 'n_units_Layer_4': 65}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.83 | sMAPE for Validation Set is: 24.16% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 52.64 | sMAPE for Test Set is: 26.41% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:26:14,477]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.78 | sMAPE for Validation Set is: 23.62% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 52.81 | sMAPE for Test Set is: 26.37% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:26:15,995]\u001b[0m Trial 260 finished with value: 19.781236908820976 and parameters: {'n_hidden': 4, 'learning_rate': 0.014674737658285187, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3314651875585566, 'dropout_rate_Layer_2': 0.22892709107338746, 'dropout_rate_Layer_3': 0.10654305571441591, 'dropout_rate_Layer_4': 0.21207410333040527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.9450690346001845e-05, 'l1_Layer_2': 7.876222096563037e-05, 'l1_Layer_3': 0.0009177671489003477, 'l1_Layer_4': 0.0017881021599960912, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 135, 'n_units_Layer_4': 55}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:26:38,628]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:26:56,517]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:26:57,190]\u001b[0m Trial 264 finished with value: 21.70593745513779 and parameters: {'n_hidden': 4, 'learning_rate': 0.0136547729766972, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3423317030771348, 'dropout_rate_Layer_2': 0.24282784297758503, 'dropout_rate_Layer_3': 0.10327868511837901, 'dropout_rate_Layer_4': 0.21733417806328487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0633064086529733e-05, 'l1_Layer_2': 6.352614861661644e-05, 'l1_Layer_3': 0.0009158634051328685, 'l1_Layer_4': 0.0022217260319530893, 'n_units_Layer_1': 155, 'n_units_Layer_2': 100, 'n_units_Layer_3': 130, 'n_units_Layer_4': 50}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.71 | sMAPE for Validation Set is: 24.85% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 56.24 | sMAPE for Test Set is: 27.29% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:27:00,561]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:27:03,089]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:27:07,000]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:27:07,285]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:27:12,661]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:27:14,462]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:27:19,314]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:27:20,584]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:27:31,556]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:27:34,894]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:28:00,023]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:28:06,266]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:28:47,958]\u001b[0m Trial 281 finished with value: 18.72089371616836 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014175094533581166, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32271299758649796, 'dropout_rate_Layer_2': 0.040221928659843344, 'dropout_rate_Layer_3': 0.021183057110408823, 'dropout_rate_Layer_4': 0.001548531705617392, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0105452886717212, 'l1_Layer_2': 1.929681347399026e-05, 'l1_Layer_3': 6.494540850370114e-05, 'l1_Layer_4': 0.0006599108854182601, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280, 'n_units_Layer_4': 120}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.72 | sMAPE for Validation Set is: 22.09% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 48.33 | sMAPE for Test Set is: 24.68% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:28:48,429]\u001b[0m Trial 279 finished with value: 23.364555749763323 and parameters: {'n_hidden': 4, 'learning_rate': 0.01280395214341172, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39911081593365016, 'dropout_rate_Layer_2': 0.1911623683440823, 'dropout_rate_Layer_3': 0.2040325848307041, 'dropout_rate_Layer_4': 0.13256539966046088, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.5226831947127824e-05, 'l1_Layer_2': 0.00045448445654197947, 'l1_Layer_3': 0.009560718424647771, 'l1_Layer_4': 0.00029949240509533255, 'n_units_Layer_1': 95, 'n_units_Layer_2': 140, 'n_units_Layer_3': 160, 'n_units_Layer_4': 100}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.36 | sMAPE for Validation Set is: 27.22% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 66.57 | sMAPE for Test Set is: 31.56% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:29:16,670]\u001b[0m Trial 283 finished with value: 19.009101265544555 and parameters: {'n_hidden': 4, 'learning_rate': 0.001465336475933624, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3196761901596002, 'dropout_rate_Layer_2': 0.040181481522795416, 'dropout_rate_Layer_3': 0.016234116022474716, 'dropout_rate_Layer_4': 0.0033686086320342873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.01065355669681061, 'l1_Layer_2': 1.8023685943907083e-05, 'l1_Layer_3': 6.338276963809635e-05, 'l1_Layer_4': 0.0005322288555338675, 'n_units_Layer_1': 210, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280, 'n_units_Layer_4': 120}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.01 | sMAPE for Validation Set is: 22.84% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 51.91 | sMAPE for Test Set is: 25.96% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:29:23,010]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:29:27,126]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:29:37,063]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:29:41,000]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:29:44,476]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:29:52,025]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:29:52,064]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:29:58,604]\u001b[0m Trial 275 finished with value: 20.31609430397037 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005042320836841108, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3948877274990211, 'dropout_rate_Layer_2': 0.18708426999996514, 'dropout_rate_Layer_3': 0.20554545206367952, 'dropout_rate_Layer_4': 0.1338086480653488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.6877029127270857e-05, 'l1_Layer_2': 0.0004740693939248033, 'l1_Layer_3': 0.014260897810770846, 'l1_Layer_4': 0.00030063059771031345, 'n_units_Layer_1': 95, 'n_units_Layer_2': 145, 'n_units_Layer_3': 160, 'n_units_Layer_4': 100}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.32 | sMAPE for Validation Set is: 24.17% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 57.15 | sMAPE for Test Set is: 27.43% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:30:02,711]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:06,990]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:10,700]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:10,845]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:17,719]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:21,598]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:25,880]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:29,347]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:33,559]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:37,017]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:37,163]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:38,141]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:44,716]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:46,789]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:48,029]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:52,750]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:53,771]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:57,340]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:30:58,401]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:31:03,092]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:31:03,447]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:31:05,990]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:31:12,832]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:31:18,463]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:31:22,748]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:31:26,588]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:31:30,107]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:31:41,311]\u001b[0m Trial 315 finished with value: 20.76487552376405 and parameters: {'n_hidden': 4, 'learning_rate': 0.01646187494365736, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3653519081857409, 'dropout_rate_Layer_2': 0.20802100913449667, 'dropout_rate_Layer_3': 0.11988070243777404, 'dropout_rate_Layer_4': 0.17388993559323423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.2344740083243975e-05, 'l1_Layer_2': 0.00025163876948958245, 'l1_Layer_3': 0.0031631411366180194, 'l1_Layer_4': 0.0010332190216373798, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 210, 'n_units_Layer_4': 85}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.76 | sMAPE for Validation Set is: 24.56% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 56.44 | sMAPE for Test Set is: 27.80% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:31:44,554]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:31:53,644]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:31:57,085]\u001b[0m Trial 320 finished with value: 44.658715165189754 and parameters: {'n_hidden': 4, 'learning_rate': 0.027056678780556905, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23328659584094957, 'dropout_rate_Layer_2': 0.37487021317281166, 'dropout_rate_Layer_3': 0.1830456769986139, 'dropout_rate_Layer_4': 0.16695927261358173, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002419290131456926, 'l1_Layer_2': 7.774652653169682e-05, 'l1_Layer_3': 0.0001304163911789802, 'l1_Layer_4': 0.006398521412206183, 'n_units_Layer_1': 225, 'n_units_Layer_2': 70, 'n_units_Layer_3': 300, 'n_units_Layer_4': 80}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.66 | sMAPE for Validation Set is: 43.26% | rMAE for Validation Set is: 1.52\n",
      "MAE for Test Set is: 142.10 | sMAPE for Test Set is: 70.59% | rMAE for Test Set is: 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:31:59,372]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:32:05,222]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:32:07,440]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:32:08,160]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:32:15,803]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:32:24,002]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:32:27,903]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:32:35,683]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:32:36,842]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:32:45,510]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:32:47,176]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:32:49,911]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:32:52,737]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:33:00,917]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:33:06,723]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:33:09,852]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:33:16,654]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:33:21,238]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:33:25,333]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:33:31,265]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:33:42,604]\u001b[0m Trial 335 finished with value: 55.94272356416038 and parameters: {'n_hidden': 4, 'learning_rate': 0.008525800888407098, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39844134253392827, 'dropout_rate_Layer_2': 0.17257532130683714, 'dropout_rate_Layer_3': 0.16828403308540138, 'dropout_rate_Layer_4': 0.08153454905734021, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.0512339931517508e-05, 'l1_Layer_2': 0.0021270958943243427, 'l1_Layer_3': 0.00048406426146306694, 'l1_Layer_4': 0.001233504961529024, 'n_units_Layer_1': 120, 'n_units_Layer_2': 75, 'n_units_Layer_3': 160, 'n_units_Layer_4': 125}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.94 | sMAPE for Validation Set is: 55.33% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 190.84 | sMAPE for Test Set is: 113.15% | rMAE for Test Set is: 2.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:33:47,038]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:33:53,015]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:33:53,669]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:33:57,718]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:05,182]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:09,077]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:13,179]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:14,006]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:19,772]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:19,939]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:26,412]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:26,840]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:32,377]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:34,056]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:35,361]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:39,851]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:51,243]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:34:58,454]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:35:05,785]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:35:13,028]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:35:17,420]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:35:19,321]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:35:24,160]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:35:25,692]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:35:31,414]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:35:38,788]\u001b[0m Trial 349 finished with value: 22.668916083018768 and parameters: {'n_hidden': 4, 'learning_rate': 0.003977306353939885, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3454498233913964, 'dropout_rate_Layer_2': 0.06954025442187578, 'dropout_rate_Layer_3': 0.21652745992223443, 'dropout_rate_Layer_4': 0.3219184082764732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.430324736181367e-05, 'l1_Layer_2': 0.0002953746722882676, 'l1_Layer_3': 0.002479945878428353, 'l1_Layer_4': 0.000529101819604291, 'n_units_Layer_1': 50, 'n_units_Layer_2': 175, 'n_units_Layer_3': 105, 'n_units_Layer_4': 75}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.67 | sMAPE for Validation Set is: 26.79% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 65.21 | sMAPE for Test Set is: 31.66% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:35:45,213]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:35:46,194]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:35:55,402]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:36:06,618]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:36:10,411]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:36:15,626]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:36:17,489]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:36:19,493]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:36:21,822]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:36:22,176]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:36:28,691]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:36:29,341]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:36:43,395]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:36:49,515]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:36:56,904]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:00,687]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:03,851]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:06,233]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:14,461]\u001b[0m Trial 381 finished with value: 30.45747083382012 and parameters: {'n_hidden': 4, 'learning_rate': 0.014343456400607175, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2496180257121369, 'dropout_rate_Layer_2': 0.08578980304833304, 'dropout_rate_Layer_3': 0.2675403137246056, 'dropout_rate_Layer_4': 0.18873670897628747, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.3407576592110544e-05, 'l1_Layer_2': 2.4763208848682563e-05, 'l1_Layer_3': 0.00028853019477491116, 'l1_Layer_4': 0.001114801397523716, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 280, 'n_units_Layer_4': 280}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.46 | sMAPE for Validation Set is: 31.97% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 104.49 | sMAPE for Test Set is: 48.51% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:37:19,805]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:20,265]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:22,403]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:24,753]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:35,134]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:36,330]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:39,157]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:48,717]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:49,338]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:56,490]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:59,056]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:37:59,775]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:38:06,477]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:38:08,583]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:38:11,164]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:38:15,238]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:38:25,126]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:38:31,134]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:38:45,735]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:38:50,016]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:38:53,587]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:39:05,761]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:39:10,330]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:40:03,231]\u001b[0m Trial 411 finished with value: 20.15537721654334 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016688944723095844, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3484144237954392, 'dropout_rate_Layer_2': 0.06212998290606228, 'dropout_rate_Layer_3': 0.07430367859940096, 'dropout_rate_Layer_4': 0.000140699134955733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.016220857823340495, 'l1_Layer_2': 1.5096414988064189e-05, 'l1_Layer_3': 0.00011569527399707824, 'l1_Layer_4': 0.00015080852743049262, 'n_units_Layer_1': 120, 'n_units_Layer_2': 105, 'n_units_Layer_3': 285, 'n_units_Layer_4': 85}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.16 | sMAPE for Validation Set is: 23.67% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 55.92 | sMAPE for Test Set is: 27.48% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:40:06,968]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:40:10,185]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:40:14,725]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:40:23,888]\u001b[0m Trial 394 finished with value: 29.9649263703196 and parameters: {'n_hidden': 4, 'learning_rate': 0.01615495038358543, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19877557175208932, 'dropout_rate_Layer_2': 0.12846298860139074, 'dropout_rate_Layer_3': 0.2949986796827095, 'dropout_rate_Layer_4': 0.13978117500439063, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4090954347318052e-05, 'l1_Layer_2': 2.8027793840949726e-05, 'l1_Layer_3': 0.00024932754278910596, 'l1_Layer_4': 0.001428241918076535, 'n_units_Layer_1': 245, 'n_units_Layer_2': 115, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.96 | sMAPE for Validation Set is: 30.54% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 106.15 | sMAPE for Test Set is: 47.56% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:40:28,024]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:40:42,720]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:40:55,510]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:40:59,495]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:03,695]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:07,148]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:10,933]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:14,680]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:18,539]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:21,500]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:24,736]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:27,734]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.35 | sMAPE for Validation Set is: 31.99% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 111.48 | sMAPE for Test Set is: 52.40% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:41:29,268]\u001b[0m Trial 396 finished with value: 31.34572148844516 and parameters: {'n_hidden': 4, 'learning_rate': 0.01470346772615693, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1986001536857814, 'dropout_rate_Layer_2': 0.11408775395327467, 'dropout_rate_Layer_3': 0.2912499690782474, 'dropout_rate_Layer_4': 0.13589035786268078, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3786320611921431e-05, 'l1_Layer_2': 1.1798376619734215e-05, 'l1_Layer_3': 0.00019736407633202916, 'l1_Layer_4': 0.0034354600625447567, 'n_units_Layer_1': 250, 'n_units_Layer_2': 110, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:33,890]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:36,416]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:38,803]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:40,536]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:43,595]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:48,271]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:48,974]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:55,763]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:41:58,012]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:42:07,717]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:42:13,361]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:42:22,305]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:42:27,317]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:42:36,984]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:42:39,625]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:42:46,175]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:42:48,542]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:42:55,499]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:42:59,184]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:43:42,435]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:43:46,011]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:43:50,258]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:44:01,708]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:44:06,399]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:44:11,653]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:44:24,087]\u001b[0m Trial 448 finished with value: 21.692277980017263 and parameters: {'n_hidden': 4, 'learning_rate': 0.009454858019095394, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27778708202917035, 'dropout_rate_Layer_2': 0.11763272401302485, 'dropout_rate_Layer_3': 0.3478071372182429, 'dropout_rate_Layer_4': 0.08347114604278932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5807195284252866e-05, 'l1_Layer_2': 1.1025679052250436e-05, 'l1_Layer_3': 0.0004328164398118386, 'l1_Layer_4': 0.00014571199536154322, 'n_units_Layer_1': 275, 'n_units_Layer_2': 130, 'n_units_Layer_3': 245, 'n_units_Layer_4': 275}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.69 | sMAPE for Validation Set is: 24.92% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 60.05 | sMAPE for Test Set is: 29.02% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:44:29,672]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:44:32,885]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:44:47,807]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:44:53,468]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:45:09,488]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:46:03,741]\u001b[0m Trial 432 finished with value: 24.20262982238549 and parameters: {'n_hidden': 4, 'learning_rate': 0.008371168856008377, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32449042629588226, 'dropout_rate_Layer_2': 0.11826749973550994, 'dropout_rate_Layer_3': 0.3579916214299541, 'dropout_rate_Layer_4': 0.09234054328365354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.685371512967688e-05, 'l1_Layer_2': 1.0082889101144189e-05, 'l1_Layer_3': 0.00044871793908046753, 'l1_Layer_4': 0.010118249066034396, 'n_units_Layer_1': 275, 'n_units_Layer_2': 115, 'n_units_Layer_3': 155, 'n_units_Layer_4': 275}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.20 | sMAPE for Validation Set is: 26.76% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 66.69 | sMAPE for Test Set is: 32.24% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:46:09,532]\u001b[0m Trial 463 finished with value: 20.173632402488863 and parameters: {'n_hidden': 4, 'learning_rate': 0.017628569495626172, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37420453952048954, 'dropout_rate_Layer_2': 0.2093042722710075, 'dropout_rate_Layer_3': 0.11237795160181102, 'dropout_rate_Layer_4': 0.1705213790934169, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.7692154720540187e-05, 'l1_Layer_2': 0.0002265086138523634, 'l1_Layer_3': 0.003850151532347559, 'l1_Layer_4': 0.0008867390183712352, 'n_units_Layer_1': 150, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215, 'n_units_Layer_4': 80}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.17 | sMAPE for Validation Set is: 24.31% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 55.39 | sMAPE for Test Set is: 27.22% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:46:13,463]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:46:20,755]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:46:21,095]\u001b[0m Trial 451 finished with value: 21.150904352732375 and parameters: {'n_hidden': 4, 'learning_rate': 0.008815192053997986, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32723215857638943, 'dropout_rate_Layer_2': 0.12115806820346872, 'dropout_rate_Layer_3': 0.34776868844958864, 'dropout_rate_Layer_4': 0.08575777898733436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.566862721233636e-05, 'l1_Layer_2': 2.8476430376134876e-05, 'l1_Layer_3': 0.00017237009744778224, 'l1_Layer_4': 0.00012529790826494458, 'n_units_Layer_1': 285, 'n_units_Layer_2': 130, 'n_units_Layer_3': 240, 'n_units_Layer_4': 275}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.15 | sMAPE for Validation Set is: 24.75% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 60.02 | sMAPE for Test Set is: 28.43% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:46:21,407]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:46:32,596]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:46:33,218]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:46:35,441]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:46:38,202]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:46:40,224]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:46:44,590]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:46:49,628]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:46:54,171]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:46:59,757]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:47:12,572]\u001b[0m Trial 462 finished with value: 21.589122276985723 and parameters: {'n_hidden': 4, 'learning_rate': 0.011118252689330917, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2914455378641617, 'dropout_rate_Layer_2': 0.11465463609548517, 'dropout_rate_Layer_3': 0.28879986708700095, 'dropout_rate_Layer_4': 0.09375303892519683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3004895089803022e-05, 'l1_Layer_2': 1.8776132784699138e-05, 'l1_Layer_3': 0.00017422184172723916, 'l1_Layer_4': 3.37264898480665e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 110, 'n_units_Layer_3': 190, 'n_units_Layer_4': 260}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.59 | sMAPE for Validation Set is: 24.85% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 60.15 | sMAPE for Test Set is: 29.21% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:47:37,195]\u001b[0m Trial 472 finished with value: 19.73476629185721 and parameters: {'n_hidden': 4, 'learning_rate': 0.009504838655507131, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3418243457012658, 'dropout_rate_Layer_2': 0.30524691479751487, 'dropout_rate_Layer_3': 0.07309388497435224, 'dropout_rate_Layer_4': 0.15768738450672842, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.9066141365101915e-05, 'l1_Layer_2': 8.90407875208689e-05, 'l1_Layer_3': 0.005074800928374083, 'l1_Layer_4': 0.001773744790180043, 'n_units_Layer_1': 185, 'n_units_Layer_2': 105, 'n_units_Layer_3': 300, 'n_units_Layer_4': 70}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.73 | sMAPE for Validation Set is: 23.86% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 54.03 | sMAPE for Test Set is: 26.65% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:47:43,115]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:47:56,027]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:48:04,301]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:48:07,627]\u001b[0m Trial 479 finished with value: 21.264706086122622 and parameters: {'n_hidden': 4, 'learning_rate': 0.010020633942704358, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34190581840231726, 'dropout_rate_Layer_2': 0.3115004721992434, 'dropout_rate_Layer_3': 0.07520895818716816, 'dropout_rate_Layer_4': 0.16026947144315842, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005735438297436007, 'l1_Layer_2': 0.00012470547813324065, 'l1_Layer_3': 0.004917688119822082, 'l1_Layer_4': 0.0007524176944080583, 'n_units_Layer_1': 175, 'n_units_Layer_2': 105, 'n_units_Layer_3': 300, 'n_units_Layer_4': 70}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.26 | sMAPE for Validation Set is: 25.08% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 56.78 | sMAPE for Test Set is: 27.98% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:48:16,293]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:48:26,114]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:48:59,182]\u001b[0m Trial 481 finished with value: 18.78557685221554 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009401230375234777, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29672849320176087, 'dropout_rate_Layer_2': 0.005495897235580541, 'dropout_rate_Layer_3': 0.05117614392674758, 'dropout_rate_Layer_4': 0.033971435395999464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005659007387227964, 'l1_Layer_2': 2.0704335185609036e-05, 'l1_Layer_3': 8.531219647265599e-05, 'l1_Layer_4': 0.00010900589321654307, 'n_units_Layer_1': 140, 'n_units_Layer_2': 145, 'n_units_Layer_3': 260, 'n_units_Layer_4': 125}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.79 | sMAPE for Validation Set is: 22.49% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 48.47 | sMAPE for Test Set is: 24.74% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:49:19,045]\u001b[0m Trial 483 finished with value: 18.991558631955048 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008889745581905937, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2942994173713017, 'dropout_rate_Layer_2': 0.013387801931831521, 'dropout_rate_Layer_3': 0.04992875154943173, 'dropout_rate_Layer_4': 0.02808102908004395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005713476946079262, 'l1_Layer_2': 3.3872556094893173e-05, 'l1_Layer_3': 9.427707350895906e-05, 'l1_Layer_4': 2.8649770786190048e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 145, 'n_units_Layer_3': 260, 'n_units_Layer_4': 125}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.99 | sMAPE for Validation Set is: 22.43% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 48.16 | sMAPE for Test Set is: 24.61% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:49:19,786]\u001b[0m Trial 478 finished with value: 21.588807952372946 and parameters: {'n_hidden': 4, 'learning_rate': 0.008887727724510363, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36933064417127615, 'dropout_rate_Layer_2': 0.11127584636574951, 'dropout_rate_Layer_3': 0.3522130919650449, 'dropout_rate_Layer_4': 0.04880878764222076, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3320404097262245e-05, 'l1_Layer_2': 1.0476320515336685e-05, 'l1_Layer_3': 0.0006689525831196957, 'l1_Layer_4': 0.012479366174620938, 'n_units_Layer_1': 260, 'n_units_Layer_2': 150, 'n_units_Layer_3': 160, 'n_units_Layer_4': 260}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.59 | sMAPE for Validation Set is: 25.27% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 61.54 | sMAPE for Test Set is: 29.96% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:49:34,004]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:49:53,893]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:50:04,194]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:50:10,087]\u001b[0m Trial 486 finished with value: 22.24160855800746 and parameters: {'n_hidden': 4, 'learning_rate': 0.009774301424409985, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35803672187425994, 'dropout_rate_Layer_2': 0.06721244030526283, 'dropout_rate_Layer_3': 0.3520344400148013, 'dropout_rate_Layer_4': 0.03449229745484694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0018965299736328e-05, 'l1_Layer_2': 1.8231934966158977e-05, 'l1_Layer_3': 0.0006044178964562577, 'l1_Layer_4': 2.937500754020468e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 140, 'n_units_Layer_3': 160, 'n_units_Layer_4': 260}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.24 | sMAPE for Validation Set is: 25.40% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 64.53 | sMAPE for Test Set is: 31.40% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:50:14,468]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:50:20,322]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:50:23,733]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:50:40,168]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:50:44,151]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:51:02,655]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:51:07,324]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:51:12,163]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:51:27,970]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:51:28,216]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:51:32,866]\u001b[0m Trial 487 finished with value: 18.77229326699033 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009248006712605728, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2946217360797443, 'dropout_rate_Layer_2': 0.0068089934547484725, 'dropout_rate_Layer_3': 0.00020781106556157572, 'dropout_rate_Layer_4': 0.02698949266560993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005882184360298141, 'l1_Layer_2': 1.621960660574129e-05, 'l1_Layer_3': 8.716584515095219e-05, 'l1_Layer_4': 0.00011846695385717796, 'n_units_Layer_1': 190, 'n_units_Layer_2': 145, 'n_units_Layer_3': 260, 'n_units_Layer_4': 125}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.77 | sMAPE for Validation Set is: 22.52% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 52.01 | sMAPE for Test Set is: 25.95% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:51:35,453]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:51:38,709]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:51:41,690]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:51:45,618]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:51:56,061]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:51:58,955]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:52:06,015]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:52:29,492]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:52:35,156]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:52:41,819]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:52:54,091]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:53:00,842]\u001b[0m Trial 514 finished with value: 53.261589377096804 and parameters: {'n_hidden': 4, 'learning_rate': 0.018996383759295448, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2863661363445646, 'dropout_rate_Layer_2': 0.25735402891521564, 'dropout_rate_Layer_3': 0.10642132445735747, 'dropout_rate_Layer_4': 0.2022871634494802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.614155651112304e-05, 'l1_Layer_2': 8.60358417479286e-05, 'l1_Layer_3': 0.0006043725800870034, 'l1_Layer_4': 0.020909496049187615, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 275, 'n_units_Layer_4': 120}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.26 | sMAPE for Validation Set is: 58.47% | rMAE for Validation Set is: 1.82\n",
      "MAE for Test Set is: 174.38 | sMAPE for Test Set is: 97.19% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:53:04,139]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:53:09,272]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:53:14,648]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:53:20,164]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:53:35,668]\u001b[0m Trial 501 finished with value: 18.423224110334726 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005080354270758876, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3026033667993181, 'dropout_rate_Layer_2': 0.013968920322989485, 'dropout_rate_Layer_3': 0.01699215187280894, 'dropout_rate_Layer_4': 0.0371472253738179, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003785478412911854, 'l1_Layer_2': 2.0188782051197134e-05, 'l1_Layer_3': 0.001167226291552846, 'l1_Layer_4': 1.181434170832696e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260, 'n_units_Layer_4': 145}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.42 | sMAPE for Validation Set is: 22.01% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 47.58 | sMAPE for Test Set is: 24.35% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:53:40,444]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:53:41,410]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:53:58,373]\u001b[0m Trial 505 finished with value: 18.52935449131874 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010358150291591291, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30422950456831455, 'dropout_rate_Layer_2': 0.012885625670738955, 'dropout_rate_Layer_3': 0.020725823016451657, 'dropout_rate_Layer_4': 0.03743432922216229, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0038705046498942602, 'l1_Layer_2': 2.0573580286349975e-05, 'l1_Layer_3': 0.0001353110220150602, 'l1_Layer_4': 3.025223896880393e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 160, 'n_units_Layer_3': 260, 'n_units_Layer_4': 140}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.53 | sMAPE for Validation Set is: 22.22% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 49.85 | sMAPE for Test Set is: 25.13% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:54:03,922]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:54:07,045]\u001b[0m Trial 517 finished with value: 20.028732211543197 and parameters: {'n_hidden': 4, 'learning_rate': 0.006896343154512856, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3924798452146453, 'dropout_rate_Layer_2': 0.13818867833146806, 'dropout_rate_Layer_3': 0.3467107909133432, 'dropout_rate_Layer_4': 0.0579619712482328, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3522047946248417e-05, 'l1_Layer_2': 2.9895076778647487e-05, 'l1_Layer_3': 0.0006738183344244682, 'l1_Layer_4': 3.7539049913496995e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 125, 'n_units_Layer_3': 140, 'n_units_Layer_4': 270}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.03 | sMAPE for Validation Set is: 23.84% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 54.39 | sMAPE for Test Set is: 26.69% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:54:10,191]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:54:13,644]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:54:18,200]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:54:22,243]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:54:27,431]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:54:50,404]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:54:55,760]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:54:59,801]\u001b[0m Trial 527 finished with value: 18.370299857302083 and parameters: {'n_hidden': 4, 'learning_rate': 0.000507408603294533, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.282925367555851, 'dropout_rate_Layer_2': 0.008903059155786916, 'dropout_rate_Layer_3': 0.04534924606321072, 'dropout_rate_Layer_4': 0.05203108638423874, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0025415636980554534, 'l1_Layer_2': 3.227361580805208e-05, 'l1_Layer_3': 0.001298250658107923, 'l1_Layer_4': 2.9650444590805393e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 145, 'n_units_Layer_3': 250, 'n_units_Layer_4': 130}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.37 | sMAPE for Validation Set is: 22.19% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 48.96 | sMAPE for Test Set is: 24.68% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:55:02,724]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:55:06,898]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:55:11,215]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:55:15,308]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:55:15,781]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:55:30,688]\u001b[0m Trial 531 finished with value: 20.27782038648701 and parameters: {'n_hidden': 4, 'learning_rate': 0.006966933959200322, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39735997103093734, 'dropout_rate_Layer_2': 0.14022730440826733, 'dropout_rate_Layer_3': 0.350231843990144, 'dropout_rate_Layer_4': 0.06320732856484365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.4731617898500853e-05, 'l1_Layer_2': 1.8988535083840912e-05, 'l1_Layer_3': 0.000699107184456037, 'l1_Layer_4': 1.659606949810146e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 130, 'n_units_Layer_3': 170, 'n_units_Layer_4': 270}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.28 | sMAPE for Validation Set is: 23.76% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 52.99 | sMAPE for Test Set is: 26.57% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:55:34,354]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:55:39,727]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:55:44,192]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:55:44,373]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:55:58,227]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:56:13,436]\u001b[0m Trial 538 finished with value: 18.104650929333776 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005270994161359825, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28161563747597435, 'dropout_rate_Layer_2': 0.00564743385501538, 'dropout_rate_Layer_3': 0.036639041233244136, 'dropout_rate_Layer_4': 0.06909591665017739, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0025904035146028584, 'l1_Layer_2': 5.46478871752331e-05, 'l1_Layer_3': 0.0016207417352198416, 'l1_Layer_4': 1.1218412201410266e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 170, 'n_units_Layer_3': 250, 'n_units_Layer_4': 160}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:56:13,448]\u001b[0m Trial 523 finished with value: 18.448200798500846 and parameters: {'n_hidden': 4, 'learning_rate': 0.000550160981480206, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25755822669513667, 'dropout_rate_Layer_2': 0.03643257456418329, 'dropout_rate_Layer_3': 0.18271865205918203, 'dropout_rate_Layer_4': 0.05173113582457011, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0026619163205306444, 'l1_Layer_2': 1.0389522782812842e-05, 'l1_Layer_3': 0.002182250280063266, 'l1_Layer_4': 3.39848377724061e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 145, 'n_units_Layer_3': 265, 'n_units_Layer_4': 130}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.10 | sMAPE for Validation Set is: 21.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.37 | sMAPE for Test Set is: 25.63% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 18.45 | sMAPE for Validation Set is: 22.04% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 47.97 | sMAPE for Test Set is: 24.50% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:56:18,404]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:56:46,906]\u001b[0m Trial 543 finished with value: 20.782641416384077 and parameters: {'n_hidden': 4, 'learning_rate': 0.006753034118164916, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3979867429296299, 'dropout_rate_Layer_2': 0.14057227796972974, 'dropout_rate_Layer_3': 0.34601025228554044, 'dropout_rate_Layer_4': 0.06088008463402994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.5850250361821225e-05, 'l1_Layer_2': 1.989097750063678e-05, 'l1_Layer_3': 0.0008481044271884125, 'l1_Layer_4': 3.603254577923495e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 130, 'n_units_Layer_3': 170, 'n_units_Layer_4': 270}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.78 | sMAPE for Validation Set is: 24.33% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 53.95 | sMAPE for Test Set is: 26.75% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:56:51,066]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:56:56,013]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:57:06,382]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:57:12,536]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:57:16,211]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:57:20,530]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:57:47,411]\u001b[0m Trial 555 finished with value: 18.04012465576664 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024143573571269615, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3226215293621853, 'dropout_rate_Layer_2': 0.06815184737894259, 'dropout_rate_Layer_3': 0.1358879805671585, 'dropout_rate_Layer_4': 0.10709897014232977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011655593969241589, 'l1_Layer_2': 1.8679426106471703e-05, 'l1_Layer_3': 0.0022442662566879643, 'l1_Layer_4': 0.004174943275231153, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 225, 'n_units_Layer_4': 60}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.04 | sMAPE for Validation Set is: 21.62% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 45.99 | sMAPE for Test Set is: 23.80% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:57:53,689]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:57:56,311]\u001b[0m Trial 553 finished with value: 18.218836199615698 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032281846169369185, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3416817216675689, 'dropout_rate_Layer_2': 0.30616156781706616, 'dropout_rate_Layer_3': 0.003995782261103226, 'dropout_rate_Layer_4': 0.100988895453584, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.74352753923977e-05, 'l1_Layer_2': 0.0051209563189922825, 'l1_Layer_3': 0.004929008937137591, 'l1_Layer_4': 0.0037954222143786235, 'n_units_Layer_1': 185, 'n_units_Layer_2': 125, 'n_units_Layer_3': 175, 'n_units_Layer_4': 50}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.22 | sMAPE for Validation Set is: 22.25% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 47.46 | sMAPE for Test Set is: 24.37% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:58:05,332]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:06,636]\u001b[0m Trial 547 finished with value: 20.73503038688467 and parameters: {'n_hidden': 4, 'learning_rate': 0.00689702496888236, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3968914331235879, 'dropout_rate_Layer_2': 0.13464596420771374, 'dropout_rate_Layer_3': 0.34309618793145125, 'dropout_rate_Layer_4': 0.06070780164813315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.458067395023848e-05, 'l1_Layer_2': 2.1166989286691903e-05, 'l1_Layer_3': 0.0006736579734813167, 'l1_Layer_4': 1.993349987925091e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 130, 'n_units_Layer_3': 170, 'n_units_Layer_4': 270}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.74 | sMAPE for Validation Set is: 24.90% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 55.00 | sMAPE for Test Set is: 27.36% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:58:09,187]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.09 | sMAPE for Validation Set is: 22.91% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 51.64 | sMAPE for Test Set is: 25.59% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:58:14,295]\u001b[0m Trial 546 finished with value: 19.093619270277255 and parameters: {'n_hidden': 4, 'learning_rate': 0.006740514850018915, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3989780393871305, 'dropout_rate_Layer_2': 0.14257475428322014, 'dropout_rate_Layer_3': 0.341372237015077, 'dropout_rate_Layer_4': 0.06004390322139898, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.2801915725057148e-05, 'l1_Layer_2': 1.945929919018214e-05, 'l1_Layer_3': 0.0006695274940587009, 'l1_Layer_4': 1.7359989587769924e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 130, 'n_units_Layer_3': 170, 'n_units_Layer_4': 270}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:16,289]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:17,403]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:18,254]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:20,344]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:29,501]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:31,912]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:36,057]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:36,244]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:37,061]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:44,909]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:51,239]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:53,612]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:53,829]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:58:55,097]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:02,165]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:02,814]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:05,989]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:08,439]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:09,361]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:14,162]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:15,944]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:19,392]\u001b[0m Trial 574 finished with value: 19.897453806370606 and parameters: {'n_hidden': 4, 'learning_rate': 0.007073118510782798, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38604963805444736, 'dropout_rate_Layer_2': 0.196519137385227, 'dropout_rate_Layer_3': 0.3854422419261987, 'dropout_rate_Layer_4': 0.015700641046697758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.48210365374646e-05, 'l1_Layer_2': 2.1024089233950372e-05, 'l1_Layer_3': 0.0007922258687724028, 'l1_Layer_4': 1.6994690586771108e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 140, 'n_units_Layer_4': 270}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.90 | sMAPE for Validation Set is: 23.23% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 58.59 | sMAPE for Test Set is: 27.47% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:59:25,563]\u001b[0m Trial 577 finished with value: 19.072232013440217 and parameters: {'n_hidden': 4, 'learning_rate': 0.007008309727982885, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3885850511740141, 'dropout_rate_Layer_2': 0.13759621002048214, 'dropout_rate_Layer_3': 0.3842084306071502, 'dropout_rate_Layer_4': 0.008616163258865474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009193856932877246, 'l1_Layer_2': 2.241479594666214e-05, 'l1_Layer_3': 0.0006610245937313512, 'l1_Layer_4': 1.635914266861276e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 140, 'n_units_Layer_4': 235}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.07 | sMAPE for Validation Set is: 22.70% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 48.47 | sMAPE for Test Set is: 24.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:59:26,226]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:26,648]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:30,697]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:40,289]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:41,281]\u001b[0m Trial 585 finished with value: 19.458398695298413 and parameters: {'n_hidden': 4, 'learning_rate': 0.006452283140932095, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38829545631029533, 'dropout_rate_Layer_2': 0.19618023525101397, 'dropout_rate_Layer_3': 0.3840908269144131, 'dropout_rate_Layer_4': 0.012879605904634054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010781941113438241, 'l1_Layer_2': 3.259750340668802e-05, 'l1_Layer_3': 0.0018839753500568676, 'l1_Layer_4': 1.7037559958488916e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 135, 'n_units_Layer_3': 140, 'n_units_Layer_4': 300}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.46 | sMAPE for Validation Set is: 22.86% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.74 | sMAPE for Test Set is: 25.24% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 15:59:45,526]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:49,461]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:53,980]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 15:59:56,868]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:00:05,019]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:00:19,872]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:00:24,096]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:00:33,216]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:00:38,241]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:00:43,358]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:00:54,632]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:01:06,338]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:01:15,372]\u001b[0m Trial 601 finished with value: 19.28797932877193 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033250527589504535, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3937374617456398, 'dropout_rate_Layer_2': 0.17801995318696806, 'dropout_rate_Layer_3': 0.31676697142985116, 'dropout_rate_Layer_4': 0.020729698095993856, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005682612712869616, 'l1_Layer_2': 2.9205049382918282e-05, 'l1_Layer_3': 0.000947918261821522, 'l1_Layer_4': 1.9330020750585972e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 135, 'n_units_Layer_3': 120, 'n_units_Layer_4': 270}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.29 | sMAPE for Validation Set is: 22.59% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.78 | sMAPE for Test Set is: 24.77% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:01:19,449]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:01:28,469]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:01:34,642]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:01:41,924]\u001b[0m Trial 588 finished with value: 18.14386222239979 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005037931653421654, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2668566812105263, 'dropout_rate_Layer_2': 0.034933006535641395, 'dropout_rate_Layer_3': 0.05736027210311711, 'dropout_rate_Layer_4': 0.009435700388452636, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007166210322559585, 'l1_Layer_2': 3.2027154922192124e-05, 'l1_Layer_3': 0.0005605945955820098, 'l1_Layer_4': 0.00021883930926643524, 'n_units_Layer_1': 155, 'n_units_Layer_2': 140, 'n_units_Layer_3': 265, 'n_units_Layer_4': 120}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.14 | sMAPE for Validation Set is: 21.68% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 47.92 | sMAPE for Test Set is: 24.43% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:02:01,701]\u001b[0m Trial 606 finished with value: 19.264367219853582 and parameters: {'n_hidden': 4, 'learning_rate': 0.002930842745274838, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3927156426509004, 'dropout_rate_Layer_2': 0.18352073935985339, 'dropout_rate_Layer_3': 0.31978134009610326, 'dropout_rate_Layer_4': 0.017337910562361412, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004860028216119573, 'l1_Layer_2': 3.429522680341075e-05, 'l1_Layer_3': 0.0009188752891033018, 'l1_Layer_4': 1.0402312659355147e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 125, 'n_units_Layer_3': 125, 'n_units_Layer_4': 215}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.26 | sMAPE for Validation Set is: 23.05% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.30 | sMAPE for Test Set is: 24.53% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:02:05,323]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:02:09,996]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:02:22,628]\u001b[0m Trial 591 finished with value: 18.08155600106028 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005059880843513424, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2628351518615683, 'dropout_rate_Layer_2': 0.03415051833055564, 'dropout_rate_Layer_3': 0.055303199427876606, 'dropout_rate_Layer_4': 0.01259210678139812, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0025739851950598923, 'l1_Layer_2': 3.245411094457988e-05, 'l1_Layer_3': 0.0013003037754040758, 'l1_Layer_4': 0.00022747151342600652, 'n_units_Layer_1': 180, 'n_units_Layer_2': 130, 'n_units_Layer_3': 265, 'n_units_Layer_4': 135}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.08 | sMAPE for Validation Set is: 21.86% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 47.20 | sMAPE for Test Set is: 24.21% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:02:23,421]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:02:36,961]\u001b[0m Trial 610 finished with value: 18.35465077970947 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022660653930800783, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3504189142160021, 'dropout_rate_Layer_2': 0.2110466157430744, 'dropout_rate_Layer_3': 0.3235905562138106, 'dropout_rate_Layer_4': 0.022177724560725823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005044048884141157, 'l1_Layer_2': 3.544072161888567e-05, 'l1_Layer_3': 0.001064096475352727, 'l1_Layer_4': 1.1607044960453354e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 150, 'n_units_Layer_3': 120, 'n_units_Layer_4': 220}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.35 | sMAPE for Validation Set is: 22.13% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 48.64 | sMAPE for Test Set is: 24.70% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:03:07,734]\u001b[0m Trial 612 finished with value: 18.20587842965703 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018913795288209802, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060833784891213216, 'dropout_rate_Layer_2': 0.306774056104835, 'dropout_rate_Layer_3': 0.03321078151579014, 'dropout_rate_Layer_4': 0.09923541172260789, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.109913895532514e-05, 'l1_Layer_2': 0.007794657771721605, 'l1_Layer_3': 0.0020373027536310854, 'l1_Layer_4': 0.0057117186273953555, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 240, 'n_units_Layer_4': 60}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.21 | sMAPE for Validation Set is: 21.95% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 46.40 | sMAPE for Test Set is: 23.96% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:03:11,768]\u001b[0m Trial 611 finished with value: 18.04058735347549 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017493994565913485, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06277393573770079, 'dropout_rate_Layer_2': 0.36142977243343927, 'dropout_rate_Layer_3': 0.02902610068249266, 'dropout_rate_Layer_4': 0.10131384113424884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.3216646805972e-05, 'l1_Layer_2': 0.007678308363181227, 'l1_Layer_3': 0.0021665748267902913, 'l1_Layer_4': 0.005775351357260817, 'n_units_Layer_1': 165, 'n_units_Layer_2': 125, 'n_units_Layer_3': 230, 'n_units_Layer_4': 65}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.04 | sMAPE for Validation Set is: 21.83% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 45.66 | sMAPE for Test Set is: 23.80% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:03:13,872]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:03:20,799]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:03:24,051]\u001b[0m Trial 604 finished with value: 18.342111715854767 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009792480606318904, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29109227108599506, 'dropout_rate_Layer_2': 0.01490914940109873, 'dropout_rate_Layer_3': 0.007779109941749036, 'dropout_rate_Layer_4': 0.0414833396305945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003993392131739109, 'l1_Layer_2': 1.6924196964217223e-05, 'l1_Layer_3': 0.000946573872859416, 'l1_Layer_4': 4.2696102805867476e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 135, 'n_units_Layer_3': 260, 'n_units_Layer_4': 155}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.34 | sMAPE for Validation Set is: 22.16% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 49.47 | sMAPE for Test Set is: 25.04% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:03:26,497]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:03:34,308]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:03:45,743]\u001b[0m Trial 615 finished with value: 18.497838842947612 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015335303928927034, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.346856573370949, 'dropout_rate_Layer_2': 0.21325541990564645, 'dropout_rate_Layer_3': 0.32317314840163214, 'dropout_rate_Layer_4': 0.02152329774170179, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004587546906659576, 'l1_Layer_2': 3.3079426207589925e-05, 'l1_Layer_3': 0.0010366322695398436, 'l1_Layer_4': 1.0903483906651138e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 155, 'n_units_Layer_3': 115, 'n_units_Layer_4': 215}. Best is trial 202 with value: 17.999366151172136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.50 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 48.20 | sMAPE for Test Set is: 24.77% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:03:55,711]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:04:02,041]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:04:12,379]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:04:15,149]\u001b[0m Trial 620 finished with value: 17.827916385752307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018587878256734103, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21022473699878236, 'dropout_rate_Layer_2': 0.254361200032233, 'dropout_rate_Layer_3': 0.1051737310908129, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002640363203598194, 'l1_Layer_2': 3.273217097189768e-05, 'l1_Layer_3': 0.003508410021741809, 'n_units_Layer_1': 100, 'n_units_Layer_2': 245, 'n_units_Layer_3': 230}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.83 | sMAPE for Validation Set is: 21.67% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 44.63 | sMAPE for Test Set is: 23.43% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:04:27,000]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:04:36,416]\u001b[0m Trial 613 finished with value: 17.970373417349947 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005044226270898277, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25427665446580994, 'dropout_rate_Layer_2': 0.006468940356354362, 'dropout_rate_Layer_3': 0.0647750508523161, 'dropout_rate_Layer_4': 0.020760992207014224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0023038382028952573, 'l1_Layer_2': 1.4804662768119374e-05, 'l1_Layer_3': 0.0015811244827256433, 'l1_Layer_4': 0.00017288584631096514, 'n_units_Layer_1': 190, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260, 'n_units_Layer_4': 175}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.97 | sMAPE for Validation Set is: 21.46% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 47.70 | sMAPE for Test Set is: 24.25% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:04:47,738]\u001b[0m Trial 624 finished with value: 18.9293740585907 and parameters: {'n_hidden': 4, 'learning_rate': 0.001848061303132756, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06857571877475985, 'dropout_rate_Layer_2': 0.35742538477085567, 'dropout_rate_Layer_3': 0.02935672066040568, 'dropout_rate_Layer_4': 0.10844541496996737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001820065504465591, 'l1_Layer_2': 0.010288646075706391, 'l1_Layer_3': 0.0018791511005113008, 'l1_Layer_4': 0.01848679673653374, 'n_units_Layer_1': 200, 'n_units_Layer_2': 125, 'n_units_Layer_3': 235, 'n_units_Layer_4': 60}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.93 | sMAPE for Validation Set is: 22.71% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 48.09 | sMAPE for Test Set is: 24.67% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:04:52,876]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:00,512]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:01,174]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:10,293]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:19,377]\u001b[0m Trial 628 finished with value: 18.543014737760554 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016905942563902882, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34584101930435196, 'dropout_rate_Layer_2': 0.18339586261081223, 'dropout_rate_Layer_3': 0.31399580546612915, 'dropout_rate_Layer_4': 0.024353572893960757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004458820717911519, 'l1_Layer_2': 4.657684967348257e-05, 'l1_Layer_3': 0.0024123338266020733, 'l1_Layer_4': 1.323081596917229e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 165, 'n_units_Layer_3': 120, 'n_units_Layer_4': 210}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.54 | sMAPE for Validation Set is: 22.33% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 48.91 | sMAPE for Test Set is: 24.86% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:05:27,191]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:30,001]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:30,928]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:35,732]\u001b[0m Trial 619 finished with value: 17.852826281153288 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005493048879516013, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2529821191218059, 'dropout_rate_Layer_2': 0.007453187909424668, 'dropout_rate_Layer_3': 0.03653175337169833, 'dropout_rate_Layer_4': 0.019430460886964148, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0019549523662991852, 'l1_Layer_2': 1.4580969869430543e-05, 'l1_Layer_3': 0.0006761857503956856, 'l1_Layer_4': 0.0002338418649319189, 'n_units_Layer_1': 185, 'n_units_Layer_2': 125, 'n_units_Layer_3': 255, 'n_units_Layer_4': 165}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.85 | sMAPE for Validation Set is: 21.57% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.08 | sMAPE for Test Set is: 24.69% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:05:39,748]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:39,990]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:45,258]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:47,292]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:47,596]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:54,019]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:05:59,367]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:06:03,090]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:06:12,246]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:06:15,063]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:06:19,471]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:06:23,530]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:06:25,827]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:06:30,696]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:06:33,395]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:06:40,645]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:06:44,545]\u001b[0m Trial 645 finished with value: 19.10664828676973 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014471304561213514, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38623308504782383, 'dropout_rate_Layer_2': 0.23844831136180525, 'dropout_rate_Layer_3': 0.38774478337261564, 'dropout_rate_Layer_4': 0.009066132139445935, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01848151406696828, 'l1_Layer_2': 8.961671403340996e-05, 'l1_Layer_3': 0.0009784769129877783, 'l1_Layer_4': 1.2686299489987502e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140, 'n_units_Layer_4': 185}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.11 | sMAPE for Validation Set is: 22.88% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 50.77 | sMAPE for Test Set is: 25.56% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:06:46,854]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:07:06,009]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:07:09,128]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:07:11,567]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:07:13,493]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:07:17,207]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:07:19,408]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:07:24,407]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:07:32,981]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:07:33,453]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:07:41,866]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:07:44,869]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:07:58,252]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:08:03,782]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:08:09,995]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:08:10,506]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:08:18,043]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:08:30,027]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:08:38,305]\u001b[0m Trial 671 finished with value: 18.48939877323265 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015682478692582368, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3371828250908762, 'dropout_rate_Layer_2': 0.21147952412544307, 'dropout_rate_Layer_3': 0.3729009521871063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0032118788341286993, 'l1_Layer_2': 6.273222037467483e-05, 'l1_Layer_3': 0.0010121089029261113, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 145}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.49 | sMAPE for Validation Set is: 22.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 48.66 | sMAPE for Test Set is: 24.72% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:08:41,048]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:08:44,842]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:08:48,537]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:08:52,015]\u001b[0m Trial 643 finished with value: 18.09280777866836 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005038528670171694, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2630617759928102, 'dropout_rate_Layer_2': 0.013473808996001665, 'dropout_rate_Layer_3': 0.0600555672865377, 'dropout_rate_Layer_4': 0.028326145154202946, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002301649836632514, 'l1_Layer_2': 1.7147865306241706e-05, 'l1_Layer_3': 0.0006010050735041952, 'l1_Layer_4': 0.00013770688238739525, 'n_units_Layer_1': 185, 'n_units_Layer_2': 145, 'n_units_Layer_3': 250, 'n_units_Layer_4': 160}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:08:52,049]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.09 | sMAPE for Validation Set is: 21.49% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 47.44 | sMAPE for Test Set is: 24.28% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:09:00,225]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:00,316]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:00,403]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:07,811]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:07,987]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:09,347]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:16,996]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:17,228]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:25,591]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:25,981]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:31,699]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:40,123]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:44,380]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:44,927]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:09:58,557]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:03,862]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:11,036]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:16,963]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.87 | sMAPE for Validation Set is: 22.31% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 48.64 | sMAPE for Test Set is: 24.76% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:10:20,215]\u001b[0m Trial 691 finished with value: 18.86750924509553 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022030735190156476, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036533854329594426, 'dropout_rate_Layer_2': 0.3204300609954916, 'dropout_rate_Layer_3': 0.031888083010018164, 'dropout_rate_Layer_4': 0.050692134292706, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014487730292866183, 'l1_Layer_2': 0.00338112826561743, 'l1_Layer_3': 0.006721635178613813, 'l1_Layer_4': 0.006355305043470122, 'n_units_Layer_1': 170, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260, 'n_units_Layer_4': 90}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:29,013]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:29,413]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:32,976]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.97 | sMAPE for Validation Set is: 21.69% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 46.87 | sMAPE for Test Set is: 24.12% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:10:33,926]\u001b[0m Trial 669 finished with value: 17.97179372693795 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006468430525356798, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24850861460488743, 'dropout_rate_Layer_2': 0.040735764754499026, 'dropout_rate_Layer_3': 0.021384632950191718, 'dropout_rate_Layer_4': 0.010946281002811482, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004714887391921794, 'l1_Layer_2': 1.230465896770525e-05, 'l1_Layer_3': 0.0004839823234953465, 'l1_Layer_4': 0.0003731013408373561, 'n_units_Layer_1': 195, 'n_units_Layer_2': 145, 'n_units_Layer_3': 245, 'n_units_Layer_4': 110}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:43,247]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:43,587]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:44,930]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:49,208]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:49,353]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:50,415]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:10:53,395]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:11:03,079]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:11:03,755]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:11:06,365]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:11:09,320]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:11:16,679]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:11:20,466]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:11:24,778]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:11:31,357]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:11:40,551]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:11:46,720]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:11:53,555]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:02,467]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:06,502]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:10,085]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:10,140]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:18,073]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:23,684]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:28,265]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:35,219]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:39,391]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:42,380]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:43,581]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:48,118]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:52,085]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:12:58,298]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:13:03,360]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:13:12,846]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:13:17,841]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:13:19,234]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:13:28,684]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:13:34,618]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:13:44,470]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:13:54,214]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:13:54,580]\u001b[0m Trial 732 finished with value: 19.006400081900466 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009804071567030832, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00015377581508488336, 'dropout_rate_Layer_2': 0.3337598114423775, 'dropout_rate_Layer_3': 0.27540369357595423, 'dropout_rate_Layer_4': 0.05057228574984194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002865974263974528, 'l1_Layer_2': 0.01217631016652496, 'l1_Layer_3': 0.0011715336443916134, 'l1_Layer_4': 0.01038471586087727, 'n_units_Layer_1': 175, 'n_units_Layer_2': 145, 'n_units_Layer_3': 190, 'n_units_Layer_4': 140}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:13:54,605]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.01 | sMAPE for Validation Set is: 22.72% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 50.25 | sMAPE for Test Set is: 25.29% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:14:06,045]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:08,697]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:11,297]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:14,900]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:18,554]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:19,608]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:27,523]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:31,807]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:37,934]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:43,517]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:43,723]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:50,523]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:50,939]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:51,634]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:14:59,955]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:01,949]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:06,459]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:07,093]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:12,415]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:16,793]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:25,168]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:31,399]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:36,332]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:39,468]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:42,916]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:47,679]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:49,006]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:51,614]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:51,742]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:15:59,018]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:02,978]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:07,305]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:11,121]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:11,978]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:17,541]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:19,583]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:26,106]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:29,522]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:29,836]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:29,966]\u001b[0m Trial 775 finished with value: 20.36933140661685 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028616078571564074, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04392651561299203, 'dropout_rate_Layer_2': 0.3105933830641845, 'dropout_rate_Layer_3': 0.3273694312815083, 'dropout_rate_Layer_4': 0.12017924185869774, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09216760915475661, 'l1_Layer_2': 0.002269721362173765, 'l1_Layer_3': 0.009947586187710572, 'l1_Layer_4': 0.006135074381192172, 'n_units_Layer_1': 225, 'n_units_Layer_2': 60, 'n_units_Layer_3': 280, 'n_units_Layer_4': 110}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.37 | sMAPE for Validation Set is: 23.92% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 53.35 | sMAPE for Test Set is: 26.76% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:16:33,767]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:41,970]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:44,804]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:45,568]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:45,602]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:16:55,232]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:00,149]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:00,345]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:08,551]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:13,531]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:17,323]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:22,710]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:27,018]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:27,387]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:37,017]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:41,604]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:42,622]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:52,571]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:17:53,266]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:18:05,699]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:18:06,441]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:18:12,134]\u001b[0m Trial 799 finished with value: 18.57277680148182 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024129144344751203, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36986342047803755, 'dropout_rate_Layer_2': 0.18160520487588688, 'dropout_rate_Layer_3': 0.27990169299520207, 'dropout_rate_Layer_4': 0.04727111536613442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0028325609776123336, 'l1_Layer_2': 1.4834154081900456e-05, 'l1_Layer_3': 0.0009105205437980019, 'l1_Layer_4': 2.5866724086321117e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 140, 'n_units_Layer_3': 135, 'n_units_Layer_4': 175}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.57 | sMAPE for Validation Set is: 22.21% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 47.95 | sMAPE for Test Set is: 24.59% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:18:15,132]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:18:29,049]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:18:41,490]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:18:41,710]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:18:45,674]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:18:51,576]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:18:59,044]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:19:06,641]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:19:16,744]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:19:24,536]\u001b[0m Trial 789 finished with value: 18.95084772343187 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005588116555230887, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3014205176479881, 'dropout_rate_Layer_2': 0.03517459084916977, 'dropout_rate_Layer_3': 0.1570700437582149, 'dropout_rate_Layer_4': 0.034517298481115545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007430070007570543, 'l1_Layer_2': 1.7827673198411788e-05, 'l1_Layer_3': 6.561892219770368e-05, 'l1_Layer_4': 5.5693845623310155e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 145, 'n_units_Layer_3': 260, 'n_units_Layer_4': 120}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.95 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 50.54 | sMAPE for Test Set is: 25.38% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:19:31,304]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:19:42,769]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.10 | sMAPE for Validation Set is: 22.68% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 50.66 | sMAPE for Test Set is: 25.41% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:19:46,417]\u001b[0m Trial 814 finished with value: 19.100192258742045 and parameters: {'n_hidden': 4, 'learning_rate': 0.003515575893663679, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37369466909502164, 'dropout_rate_Layer_2': 0.17769208647432255, 'dropout_rate_Layer_3': 0.3358009587780286, 'dropout_rate_Layer_4': 0.00010088054508885537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004342816910076416, 'l1_Layer_2': 3.917709160985929e-05, 'l1_Layer_3': 0.0038553541973834066, 'l1_Layer_4': 6.48556792598014e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 135, 'n_units_Layer_3': 105, 'n_units_Layer_4': 175}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:19:51,620]\u001b[0m Trial 808 finished with value: 18.788639692500983 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010479294281804366, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011021947795566096, 'dropout_rate_Layer_2': 0.33174343268194506, 'dropout_rate_Layer_3': 0.2753711430322097, 'dropout_rate_Layer_4': 0.05356260448377929, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002700829934304266, 'l1_Layer_2': 0.013902980574125201, 'l1_Layer_3': 0.0011246970064080534, 'l1_Layer_4': 0.005067695357798283, 'n_units_Layer_1': 175, 'n_units_Layer_2': 140, 'n_units_Layer_3': 220, 'n_units_Layer_4': 165}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.79 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 50.89 | sMAPE for Test Set is: 25.50% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:19:55,541]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:19:59,797]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:06,087]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:07,267]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:10,992]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:11,526]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:12,845]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.25 | sMAPE for Validation Set is: 22.67% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 51.66 | sMAPE for Test Set is: 25.78% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:20:18,316]\u001b[0m Trial 812 finished with value: 19.24540362359869 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009282239921760262, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014388200118281562, 'dropout_rate_Layer_2': 0.3360194167050678, 'dropout_rate_Layer_3': 0.2501508537627941, 'dropout_rate_Layer_4': 0.0364054565312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002642394421795603, 'l1_Layer_2': 0.010148277964281928, 'l1_Layer_3': 0.0014196872462318582, 'l1_Layer_4': 0.02931457824145028, 'n_units_Layer_1': 170, 'n_units_Layer_2': 140, 'n_units_Layer_3': 185, 'n_units_Layer_4': 165}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:21,852]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:23,933]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:28,958]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:29,759]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:36,178]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:41,243]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:41,884]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:50,742]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:51,683]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:56,596]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:20:59,159]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:03,595]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:07,279]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:12,311]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:16,488]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:17,770]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:24,782]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:25,753]\u001b[0m Trial 826 finished with value: 18.617020107789635 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006995091562310346, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022742648628976757, 'dropout_rate_Layer_2': 0.27453042779320275, 'dropout_rate_Layer_3': 0.2743244004664336, 'dropout_rate_Layer_4': 0.14904083437368135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014100005559994667, 'l1_Layer_2': 0.009320542640411681, 'l1_Layer_3': 0.0030077762032604993, 'l1_Layer_4': 0.004281952239800507, 'n_units_Layer_1': 140, 'n_units_Layer_2': 135, 'n_units_Layer_3': 235, 'n_units_Layer_4': 165}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.62 | sMAPE for Validation Set is: 22.22% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 49.82 | sMAPE for Test Set is: 25.17% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:21:26,263]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:33,018]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:41,236]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:41,927]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:49,903]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:52,829]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:53,791]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:21:59,130]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:22:00,205]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:22:03,859]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:22:12,536]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:22:15,088]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:22:25,766]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:22:31,502]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:22:34,143]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:22:40,045]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:22:41,532]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:22:49,337]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:22:52,892]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:22:55,276]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:23:06,792]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:23:15,696]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:23:18,543]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:23:23,564]\u001b[0m Trial 853 finished with value: 18.90552668674032 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007029885809455498, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02649449052550822, 'dropout_rate_Layer_2': 0.27859545123179646, 'dropout_rate_Layer_3': 0.32121275770200597, 'dropout_rate_Layer_4': 0.1258771486828084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012709672921348608, 'l1_Layer_2': 0.015871001342006887, 'l1_Layer_3': 0.003084849420354771, 'l1_Layer_4': 0.0047648733984390875, 'n_units_Layer_1': 140, 'n_units_Layer_2': 95, 'n_units_Layer_3': 220, 'n_units_Layer_4': 185}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.91 | sMAPE for Validation Set is: 22.39% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 50.44 | sMAPE for Test Set is: 25.39% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:23:24,621]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:23:33,191]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:23:38,368]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:23:45,243]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:23:46,615]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:23:55,064]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:24:02,006]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:24:20,593]\u001b[0m Trial 871 finished with value: 18.85375773479153 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007875931310770777, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08879847475402183, 'dropout_rate_Layer_2': 0.31798154866859957, 'dropout_rate_Layer_3': 0.2949751857368302, 'dropout_rate_Layer_4': 0.1481279551459423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010159158010343894, 'l1_Layer_2': 0.0028221843736355033, 'l1_Layer_3': 0.023002930599398962, 'l1_Layer_4': 0.002483700139692391, 'n_units_Layer_1': 155, 'n_units_Layer_2': 120, 'n_units_Layer_3': 255, 'n_units_Layer_4': 170}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.85 | sMAPE for Validation Set is: 22.42% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 50.06 | sMAPE for Test Set is: 25.32% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:24:29,168]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:24:35,025]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.24 | sMAPE for Validation Set is: 21.83% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 50.06 | sMAPE for Test Set is: 25.10% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:24:37,656]\u001b[0m Trial 867 finished with value: 18.236001042960076 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006595857826107473, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08077020702957095, 'dropout_rate_Layer_2': 0.2796569166273563, 'dropout_rate_Layer_3': 0.3204027265689464, 'dropout_rate_Layer_4': 0.12602789249933477, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012580792285745788, 'l1_Layer_2': 0.0013257144403530797, 'l1_Layer_3': 0.0027749125985966593, 'l1_Layer_4': 0.0046054406750610675, 'n_units_Layer_1': 140, 'n_units_Layer_2': 180, 'n_units_Layer_3': 220, 'n_units_Layer_4': 180}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:24:47,427]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:24:53,809]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:24:56,932]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:01,451]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:02,653]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:02,754]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:06,276]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:06,455]\u001b[0m Trial 876 finished with value: 18.884920324511146 and parameters: {'n_hidden': 4, 'learning_rate': 0.001193412492148574, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08782102459983497, 'dropout_rate_Layer_2': 0.3150635056972433, 'dropout_rate_Layer_3': 0.29293637427857466, 'dropout_rate_Layer_4': 0.14364548298856566, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010853240757350417, 'l1_Layer_2': 0.0027725288435977847, 'l1_Layer_3': 0.02116099182968782, 'l1_Layer_4': 0.002128039368507156, 'n_units_Layer_1': 125, 'n_units_Layer_2': 185, 'n_units_Layer_3': 255, 'n_units_Layer_4': 180}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.88 | sMAPE for Validation Set is: 22.49% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 50.30 | sMAPE for Test Set is: 25.39% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:25:14,045]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:15,124]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:21,283]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:24,643]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:24,934]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:32,243]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:33,348]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:35,273]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:38,603]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:42,241]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:45,322]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:48,489]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:48,524]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:49,889]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:25:58,937]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:02,527]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:06,692]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:10,552]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:11,355]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:17,539]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:23,046]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:31,113]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:31,627]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:34,545]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:38,545]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:47,153]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:52,161]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:26:55,470]\u001b[0m Trial 899 finished with value: 18.260547076792246 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008330620414294924, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10852850787986765, 'dropout_rate_Layer_2': 0.2460247874180298, 'dropout_rate_Layer_3': 0.30146575577793966, 'dropout_rate_Layer_4': 0.15526122366577433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010819641505677128, 'l1_Layer_2': 0.0017014609259930322, 'l1_Layer_3': 0.00013724596414875417, 'l1_Layer_4': 0.0025673801591849506, 'n_units_Layer_1': 150, 'n_units_Layer_2': 115, 'n_units_Layer_3': 250, 'n_units_Layer_4': 175}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.26 | sMAPE for Validation Set is: 21.68% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.33 | sMAPE for Test Set is: 25.81% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:26:59,546]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:00,235]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:06,960]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:07,643]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:13,055]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:16,677]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:20,091]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:21,162]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:27,877]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:32,396]\u001b[0m Trial 921 finished with value: 18.86435317521433 and parameters: {'n_hidden': 4, 'learning_rate': 0.005241868425870435, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3862187450213792, 'dropout_rate_Layer_2': 0.21953031067836803, 'dropout_rate_Layer_3': 0.3611132590048795, 'dropout_rate_Layer_4': 0.015449073318021297, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007884749446534943, 'l1_Layer_2': 2.328005679528603e-05, 'l1_Layer_3': 0.0008255074271490904, 'l1_Layer_4': 1.644089595894022e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 150, 'n_units_Layer_3': 105, 'n_units_Layer_4': 250}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.86 | sMAPE for Validation Set is: 22.53% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 49.29 | sMAPE for Test Set is: 25.01% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:27:33,036]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:33,914]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:43,282]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:43,461]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:44,705]\u001b[0m Trial 916 finished with value: 18.789287696550677 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008373807070502689, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10491881591580454, 'dropout_rate_Layer_2': 0.24637365528716867, 'dropout_rate_Layer_3': 0.2747967849653819, 'dropout_rate_Layer_4': 0.12637269492893105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.7858675815290674e-05, 'l1_Layer_2': 0.02896025766712749, 'l1_Layer_3': 5.153356789020525e-05, 'l1_Layer_4': 0.0039285732342642, 'n_units_Layer_1': 140, 'n_units_Layer_2': 135, 'n_units_Layer_3': 220, 'n_units_Layer_4': 175}. Best is trial 620 with value: 17.827916385752307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.79 | sMAPE for Validation Set is: 22.32% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 51.02 | sMAPE for Test Set is: 25.43% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:27:48,268]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:52,226]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:53,481]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:27:54,620]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:06,680]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:10,657]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:14,302]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:21,087]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:23,926]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:24,952]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:27,718]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:29,614]\u001b[0m Trial 932 finished with value: 17.723324731275355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011839813204808636, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2693045780646766, 'dropout_rate_Layer_2': 0.14915818378034462, 'dropout_rate_Layer_3': 0.35147356887443076, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00048135319627875476, 'l1_Layer_2': 2.3911276945829603e-05, 'l1_Layer_3': 0.005765856744996105, 'n_units_Layer_1': 240, 'n_units_Layer_2': 190, 'n_units_Layer_3': 235}. Best is trial 932 with value: 17.723324731275355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.72 | sMAPE for Validation Set is: 21.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 46.55 | sMAPE for Test Set is: 23.87% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:28:32,298]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:32,829]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:34,702]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:35,780]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:41,882]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:43,794]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:49,530]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:50,162]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:28:55,225]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:00,711]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:03,898]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:07,345]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:16,179]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:16,774]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:22,108]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:25,447]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:29,494]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:32,948]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:35,236]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:36,135]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:38,760]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:43,804]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:46,045]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:29:56,130]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:01,102]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:02,028]\u001b[0m Trial 962 finished with value: 18.578633136014478 and parameters: {'n_hidden': 4, 'learning_rate': 0.002397164215051814, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39953036951791726, 'dropout_rate_Layer_2': 0.17437578945361432, 'dropout_rate_Layer_3': 0.2961201187466288, 'dropout_rate_Layer_4': 0.008407178314805377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004644815365104438, 'l1_Layer_2': 2.2841610944162285e-05, 'l1_Layer_3': 0.0005709786037389007, 'l1_Layer_4': 6.773775852832136e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 145, 'n_units_Layer_3': 120, 'n_units_Layer_4': 145}. Best is trial 932 with value: 17.723324731275355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.58 | sMAPE for Validation Set is: 22.52% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 52.48 | sMAPE for Test Set is: 25.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:30:03,375]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:12,166]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:12,553]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:17,544]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:17,666]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:17,960]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:24,743]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:28,529]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:30,757]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:34,366]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:37,083]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:39,569]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:44,350]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:50,601]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:51,423]\u001b[0m Trial 977 finished with value: 18.367771410693447 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034861053078279517, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.388303530543771, 'dropout_rate_Layer_2': 0.1901572475823565, 'dropout_rate_Layer_3': 0.31154547348837597, 'dropout_rate_Layer_4': 0.03849744647947287, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0038434084747579695, 'l1_Layer_2': 2.2706232016361472e-05, 'l1_Layer_3': 0.0007715767521570338, 'l1_Layer_4': 1.4467901061056187e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 135, 'n_units_Layer_3': 120, 'n_units_Layer_4': 145}. Best is trial 932 with value: 17.723324731275355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.37 | sMAPE for Validation Set is: 22.23% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 48.84 | sMAPE for Test Set is: 24.67% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:30:54,736]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:30:58,861]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:31:05,106]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:31:05,396]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:31:10,018]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:31:16,205]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:31:17,587]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:31:21,485]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:31:25,195]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:31:27,820]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:31:35,162]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:31:43,383]\u001b[0m Trial 975 finished with value: 19.199477479435654 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010768991797377588, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0742144537529601, 'dropout_rate_Layer_2': 0.22517658443375793, 'dropout_rate_Layer_3': 0.3707426909429866, 'dropout_rate_Layer_4': 0.12191140545004897, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00022674180663621933, 'l1_Layer_2': 0.00914154823286345, 'l1_Layer_3': 0.0031745215291767133, 'l1_Layer_4': 0.013104467383791807, 'n_units_Layer_1': 135, 'n_units_Layer_2': 100, 'n_units_Layer_3': 245, 'n_units_Layer_4': 185}. Best is trial 932 with value: 17.723324731275355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.20 | sMAPE for Validation Set is: 22.74% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 52.18 | sMAPE for Test Set is: 25.97% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:31:47,582]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:31:51,727]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:04,568]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:04,741]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:14,201]\u001b[0m Trial 993 finished with value: 18.192626538694014 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010817195357841862, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12353889965367623, 'dropout_rate_Layer_2': 0.24433063379394754, 'dropout_rate_Layer_3': 0.2807643221552245, 'dropout_rate_Layer_4': 0.13295274165229426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.516236353811846e-05, 'l1_Layer_2': 0.0005632378545610566, 'l1_Layer_3': 0.0033437905934243194, 'l1_Layer_4': 0.0020704129762148383, 'n_units_Layer_1': 160, 'n_units_Layer_2': 135, 'n_units_Layer_3': 235, 'n_units_Layer_4': 210}. Best is trial 932 with value: 17.723324731275355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.19 | sMAPE for Validation Set is: 21.99% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.34 | sMAPE for Test Set is: 25.35% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:32:18,480]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:20,578]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:24,049]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:26,018]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:31,674]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:37,410]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:41,555]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:44,651]\u001b[0m Trial 1005 finished with value: 17.934313600513967 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034775472284839675, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36720090780231396, 'dropout_rate_Layer_2': 0.16968156401800188, 'dropout_rate_Layer_3': 0.31381445162259847, 'dropout_rate_Layer_4': 0.03394845925894173, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0039271172135889, 'l1_Layer_2': 2.1724160849056995e-05, 'l1_Layer_3': 0.0007532014095027315, 'l1_Layer_4': 7.339231030249299e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 150, 'n_units_Layer_3': 120, 'n_units_Layer_4': 145}. Best is trial 932 with value: 17.723324731275355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.93 | sMAPE for Validation Set is: 21.77% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.01 | sMAPE for Test Set is: 24.70% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:32:47,475]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:50,813]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:53,721]\u001b[0m Trial 1004 finished with value: 18.625989171251017 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017715651944983065, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.366670225269184, 'dropout_rate_Layer_2': 0.16971231833832956, 'dropout_rate_Layer_3': 0.2891578006398028, 'dropout_rate_Layer_4': 0.039482270211829276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004013313543821274, 'l1_Layer_2': 2.4426295791233723e-05, 'l1_Layer_3': 0.0007513118698734589, 'l1_Layer_4': 6.49660371406993e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 150, 'n_units_Layer_3': 110, 'n_units_Layer_4': 140}. Best is trial 932 with value: 17.723324731275355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.63 | sMAPE for Validation Set is: 22.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 48.85 | sMAPE for Test Set is: 24.88% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:32:54,459]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:32:59,013]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:01,377]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:05,322]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:09,658]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:12,127]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:13,257]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:18,443]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:22,215]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:23,019]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:25,369]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:31,001]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:33,321]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:41,828]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:42,938]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:45,998]\u001b[0m Trial 996 finished with value: 17.646504785466238 and parameters: {'n_hidden': 3, 'learning_rate': 0.000814854898609711, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13290665546574287, 'dropout_rate_Layer_2': 0.3531318467794636, 'dropout_rate_Layer_3': 0.13851497413181135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00030919671191465665, 'l1_Layer_2': 6.182926357124805e-05, 'l1_Layer_3': 0.007471322934250679, 'n_units_Layer_1': 300, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265}. Best is trial 996 with value: 17.646504785466238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.65 | sMAPE for Validation Set is: 21.84% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 46.97 | sMAPE for Test Set is: 24.13% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:33:51,304]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:56,327]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:33:57,508]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:34:03,654]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:34:06,430]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:34:07,681]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:34:10,712]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:34:16,528]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:34:21,300]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:34:22,190]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:34:34,509]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:34:43,125]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:34:43,799]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:34:50,949]\u001b[0m Trial 1036 finished with value: 18.314436347977406 and parameters: {'n_hidden': 4, 'learning_rate': 0.001344260434010521, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3665410267200915, 'dropout_rate_Layer_2': 0.12812849301324267, 'dropout_rate_Layer_3': 0.31082874294712687, 'dropout_rate_Layer_4': 0.06858792251601885, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0038000844329795255, 'l1_Layer_2': 2.2520009915170818e-05, 'l1_Layer_3': 0.0007732788002082547, 'l1_Layer_4': 5.669826433757838e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 155, 'n_units_Layer_3': 110, 'n_units_Layer_4': 140}. Best is trial 996 with value: 17.646504785466238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.31 | sMAPE for Validation Set is: 21.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 49.43 | sMAPE for Test Set is: 24.95% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:34:51,172]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:34:53,136]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:00,654]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:01,096]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:01,605]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:02,416]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:10,622]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:12,942]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:17,058]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:17,639]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:19,110]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:25,870]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:30,884]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:33,825]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:34,639]\u001b[0m Trial 1045 finished with value: 18.89364105690791 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010264927227982114, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35884496109165315, 'dropout_rate_Layer_2': 0.12742441668204682, 'dropout_rate_Layer_3': 0.29400837215410425, 'dropout_rate_Layer_4': 0.05555776417395314, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003907386918285813, 'l1_Layer_2': 1.6427829612523583e-05, 'l1_Layer_3': 0.000608999010743608, 'l1_Layer_4': 8.994752887193123e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 150, 'n_units_Layer_3': 110, 'n_units_Layer_4': 140}. Best is trial 996 with value: 17.646504785466238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.89 | sMAPE for Validation Set is: 22.44% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 49.49 | sMAPE for Test Set is: 24.97% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:35:39,252]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:39,656]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:42,362]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:42,543]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:43,988]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:49,158]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:50,710]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:35:55,379]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:00,786]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:04,232]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:04,967]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:09,711]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:17,716]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:20,527]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:26,219]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:27,032]\u001b[0m Trial 1068 finished with value: 18.648254088369825 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009883816876138484, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3627400923641014, 'dropout_rate_Layer_2': 0.15545218846974349, 'dropout_rate_Layer_3': 0.296007619957924, 'dropout_rate_Layer_4': 0.05468679983886837, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0022639416987885316, 'l1_Layer_2': 2.174490405423636e-05, 'l1_Layer_3': 0.0007096870378667403, 'l1_Layer_4': 0.000268447171478772, 'n_units_Layer_1': 55, 'n_units_Layer_2': 165, 'n_units_Layer_3': 110, 'n_units_Layer_4': 125}. Best is trial 996 with value: 17.646504785466238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.65 | sMAPE for Validation Set is: 21.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 53.17 | sMAPE for Test Set is: 26.06% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:36:32,449]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:37,838]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:39,085]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.53 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 49.99 | sMAPE for Test Set is: 25.08% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:36:42,609]\u001b[0m Trial 1062 finished with value: 18.532241360115606 and parameters: {'n_hidden': 4, 'learning_rate': 0.001174093287782329, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12678982278365497, 'dropout_rate_Layer_2': 0.1965867547185642, 'dropout_rate_Layer_3': 0.21459085342061437, 'dropout_rate_Layer_4': 0.16400530981157513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.691291111557213e-05, 'l1_Layer_2': 0.015395878926903257, 'l1_Layer_3': 0.0026048702089102723, 'l1_Layer_4': 0.002640004394045859, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 220, 'n_units_Layer_4': 230}. Best is trial 996 with value: 17.646504785466238.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:48,847]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:50,856]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:52,108]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:36:56,604]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:02,191]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:05,744]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:06,681]\u001b[0m Trial 1072 finished with value: 18.626783118305706 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036651678975471976, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1245834433929209, 'dropout_rate_Layer_2': 0.20013235755431938, 'dropout_rate_Layer_3': 0.3042754508413968, 'dropout_rate_Layer_4': 0.11211914354021932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.372410158759718e-05, 'l1_Layer_2': 0.0003096801389431579, 'l1_Layer_3': 0.002684745681889189, 'l1_Layer_4': 0.008241306971628063, 'n_units_Layer_1': 155, 'n_units_Layer_2': 70, 'n_units_Layer_3': 240, 'n_units_Layer_4': 235}. Best is trial 996 with value: 17.646504785466238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.63 | sMAPE for Validation Set is: 22.36% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 51.63 | sMAPE for Test Set is: 25.48% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:37:12,588]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:15,258]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:18,574]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:21,853]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:24,034]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:25,633]\u001b[0m Trial 1081 finished with value: 17.90361143358149 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024922255746709513, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1256579079589003, 'dropout_rate_Layer_2': 0.16072437651340643, 'dropout_rate_Layer_3': 0.17626678215867264, 'dropout_rate_Layer_4': 0.15018523287634092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.449809920973032e-05, 'l1_Layer_2': 0.0015545982833898833, 'l1_Layer_3': 0.0026057934393461032, 'l1_Layer_4': 0.0015399432247804195, 'n_units_Layer_1': 195, 'n_units_Layer_2': 70, 'n_units_Layer_3': 250, 'n_units_Layer_4': 225}. Best is trial 996 with value: 17.646504785466238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.90 | sMAPE for Validation Set is: 21.91% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.13 | sMAPE for Test Set is: 24.69% | rMAE for Test Set is: 0.61\n",
      "MAE for Validation Set is: 17.78 | sMAPE for Validation Set is: 21.43% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.85 | sMAPE for Test Set is: 24.84% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:37:30,925]\u001b[0m Trial 1082 finished with value: 17.778915691855232 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018004529651085587, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12348518005552576, 'dropout_rate_Layer_2': 0.17188850426849522, 'dropout_rate_Layer_3': 0.17806853844498055, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.640273895545368e-05, 'l1_Layer_2': 0.00031566694999505363, 'l1_Layer_3': 0.0025146705366842935, 'n_units_Layer_1': 195, 'n_units_Layer_2': 65, 'n_units_Layer_3': 270}. Best is trial 996 with value: 17.646504785466238.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:31,824]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:34,999]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:42,785]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:46,029]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:50,915]\u001b[0m Trial 1090 finished with value: 18.449632876350005 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011255704367662245, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3628479825474973, 'dropout_rate_Layer_2': 0.15680787629990622, 'dropout_rate_Layer_3': 0.29430480435457496, 'dropout_rate_Layer_4': 0.06956374948436489, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0022423227816790662, 'l1_Layer_2': 2.2660774591359658e-05, 'l1_Layer_3': 0.0007054011595791789, 'l1_Layer_4': 4.8427071615979866e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 300, 'n_units_Layer_3': 110, 'n_units_Layer_4': 120}. Best is trial 996 with value: 17.646504785466238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.45 | sMAPE for Validation Set is: 21.97% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 49.88 | sMAPE for Test Set is: 25.12% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:37:51,324]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:51,681]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:37:52,107]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:02,477]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:03,162]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:03,708]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:09,149]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:15,862]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:21,190]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:22,574]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:28,807]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:29,969]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:36,925]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:43,233]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:43,654]\u001b[0m Trial 1099 finished with value: 17.828201001378634 and parameters: {'n_hidden': 3, 'learning_rate': 0.003631668178308458, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21095670190032242, 'dropout_rate_Layer_2': 0.04904436147044773, 'dropout_rate_Layer_3': 0.14886066335014153, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010043137739683195, 'l1_Layer_2': 6.433860297934308e-05, 'l1_Layer_3': 0.005789832168399551, 'n_units_Layer_1': 275, 'n_units_Layer_2': 60, 'n_units_Layer_3': 230}. Best is trial 996 with value: 17.646504785466238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.83 | sMAPE for Validation Set is: 21.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.48 | sMAPE for Test Set is: 25.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:38:48,001]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:48,688]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:49,263]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:50,582]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:55,223]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:38:57,657]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:00,663]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:03,215]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:11,260]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:12,045]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:15,243]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:19,421]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:23,092]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:25,914]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:31,839]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:34,517]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:39,395]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:42,840]\u001b[0m Trial 1120 finished with value: 17.62516512487188 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016260907039713085, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1387405453590818, 'dropout_rate_Layer_2': 0.16762070370137042, 'dropout_rate_Layer_3': 0.13514207268494138, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.416833832682904e-05, 'l1_Layer_2': 0.001361918074015286, 'l1_Layer_3': 0.002313562575254452, 'n_units_Layer_1': 195, 'n_units_Layer_2': 70, 'n_units_Layer_3': 250}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.63 | sMAPE for Validation Set is: 21.67% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 47.50 | sMAPE for Test Set is: 24.12% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:39:45,719]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:39:56,004]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.20 | sMAPE for Validation Set is: 22.16% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 46.00 | sMAPE for Test Set is: 23.85% | rMAE for Test Set is: 0.58\n",
      "MAE for Validation Set is: 17.77 | sMAPE for Validation Set is: 21.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 47.02 | sMAPE for Test Set is: 24.05% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:40:01,470]\u001b[0m Trial 1122 finished with value: 17.772715102010153 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016120452190193316, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13402866270676767, 'dropout_rate_Layer_2': 0.18387119876250085, 'dropout_rate_Layer_3': 0.14853596377144454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4148644312423632e-05, 'l1_Layer_2': 0.0015207761523824627, 'l1_Layer_3': 0.0023689194923254995, 'n_units_Layer_1': 185, 'n_units_Layer_2': 70, 'n_units_Layer_3': 270}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:01,480]\u001b[0m Trial 1129 finished with value: 18.202670109653827 and parameters: {'n_hidden': 3, 'learning_rate': 0.001988205969453259, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13687812693283372, 'dropout_rate_Layer_2': 0.1794933058102025, 'dropout_rate_Layer_3': 0.14944132067179394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5864555663969564e-05, 'l1_Layer_2': 0.0005554340857269185, 'l1_Layer_3': 0.0021838330843991145, 'n_units_Layer_1': 195, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.69 | sMAPE for Validation Set is: 22.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 52.07 | sMAPE for Test Set is: 25.76% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:40:06,030]\u001b[0m Trial 1126 finished with value: 18.68796616532505 and parameters: {'n_hidden': 4, 'learning_rate': 0.001064765314148653, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34375792002943956, 'dropout_rate_Layer_2': 0.16745002740108206, 'dropout_rate_Layer_3': 0.27293782648540843, 'dropout_rate_Layer_4': 0.06808839826248951, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0018402723320952658, 'l1_Layer_2': 2.3567031304813295e-05, 'l1_Layer_3': 0.00036409856616941965, 'l1_Layer_4': 5.6038348418197506e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120, 'n_units_Layer_4': 110}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:09,168]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:09,434]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:13,819]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:17,762]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:18,491]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:21,035]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:22,180]\u001b[0m Trial 1131 finished with value: 18.655475630773513 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010399880613754001, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3468586731516291, 'dropout_rate_Layer_2': 0.16753862794701713, 'dropout_rate_Layer_3': 0.2714084796202199, 'dropout_rate_Layer_4': 0.06778384057496564, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011698388765675322, 'l1_Layer_2': 2.280689172133371e-05, 'l1_Layer_3': 0.0004613121794092817, 'l1_Layer_4': 0.0002541364616581545, 'n_units_Layer_1': 65, 'n_units_Layer_2': 155, 'n_units_Layer_3': 90, 'n_units_Layer_4': 120}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.66 | sMAPE for Validation Set is: 22.08% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 51.77 | sMAPE for Test Set is: 25.59% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:40:28,052]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:40,644]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:42,220]\u001b[0m Trial 1142 finished with value: 19.25156544345717 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006766404424189946, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3454383656119538, 'dropout_rate_Layer_2': 0.16586020083826808, 'dropout_rate_Layer_3': 0.2546316812067542, 'dropout_rate_Layer_4': 0.10928521215818576, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011665030783869622, 'l1_Layer_2': 2.480373119531203e-05, 'l1_Layer_3': 0.0004118817309778866, 'l1_Layer_4': 5.484422785737655e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 290, 'n_units_Layer_3': 90, 'n_units_Layer_4': 115}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.25 | sMAPE for Validation Set is: 22.43% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 54.38 | sMAPE for Test Set is: 26.47% | rMAE for Test Set is: 0.68\n",
      "MAE for Validation Set is: 18.65 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 51.03 | sMAPE for Test Set is: 25.41% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:40:43,788]\u001b[0m Trial 1141 finished with value: 18.653420997136575 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006371106410245547, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3430127243339953, 'dropout_rate_Layer_2': 0.1644228532166263, 'dropout_rate_Layer_3': 0.25171574609491065, 'dropout_rate_Layer_4': 0.07232899576354035, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009727967110675372, 'l1_Layer_2': 2.4881746119564577e-05, 'l1_Layer_3': 0.00036740513942682524, 'l1_Layer_4': 0.0002733056990371711, 'n_units_Layer_1': 80, 'n_units_Layer_2': 300, 'n_units_Layer_3': 85, 'n_units_Layer_4': 110}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:46,925]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:50,633]\u001b[0m Trial 1140 finished with value: 18.139570364077443 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010167834036977, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34388137515092443, 'dropout_rate_Layer_2': 0.16591287588418135, 'dropout_rate_Layer_3': 0.25617307192558175, 'dropout_rate_Layer_4': 0.06901213490996466, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00189359900272863, 'l1_Layer_2': 2.5885715946710788e-05, 'l1_Layer_3': 0.0004603051075158239, 'l1_Layer_4': 0.00027329767483508894, 'n_units_Layer_1': 70, 'n_units_Layer_2': 295, 'n_units_Layer_3': 90, 'n_units_Layer_4': 105}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.14 | sMAPE for Validation Set is: 21.85% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 48.42 | sMAPE for Test Set is: 24.54% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:40:51,404]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:40:52,287]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:00,235]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:00,389]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:00,594]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:00,667]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:13,522]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:13,936]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:14,537]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:18,082]\u001b[0m Trial 1152 finished with value: 18.484310746041977 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016284584735940452, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15035150234880945, 'dropout_rate_Layer_2': 0.18678310663945885, 'dropout_rate_Layer_3': 0.15540083988499076, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7330787170334328e-05, 'l1_Layer_2': 0.0006097561701742993, 'l1_Layer_3': 0.0021924530973248427, 'n_units_Layer_1': 215, 'n_units_Layer_2': 55, 'n_units_Layer_3': 290}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.48 | sMAPE for Validation Set is: 22.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 50.10 | sMAPE for Test Set is: 24.89% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:41:23,612]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:28,126]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:31,688]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:37,888]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:39,147]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:45,387]\u001b[0m Trial 1158 finished with value: 18.82225060659192 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008392633002792445, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.321693353878632, 'dropout_rate_Layer_2': 0.15650951603227603, 'dropout_rate_Layer_3': 0.26522785394577564, 'dropout_rate_Layer_4': 0.07835563757141792, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009250231626355034, 'l1_Layer_2': 2.8185513308351565e-05, 'l1_Layer_3': 0.0002645385034730597, 'l1_Layer_4': 0.0003603856737188211, 'n_units_Layer_1': 50, 'n_units_Layer_2': 300, 'n_units_Layer_3': 85, 'n_units_Layer_4': 105}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.82 | sMAPE for Validation Set is: 22.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 51.78 | sMAPE for Test Set is: 25.69% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:41:46,791]\u001b[0m Trial 1156 finished with value: 19.202044440039487 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007057892944683704, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3317727670335562, 'dropout_rate_Layer_2': 0.15967044207686143, 'dropout_rate_Layer_3': 0.23332411908720635, 'dropout_rate_Layer_4': 0.08311601825252087, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008648097649137592, 'l1_Layer_2': 2.8105780715470753e-05, 'l1_Layer_3': 0.0003392285659598045, 'l1_Layer_4': 0.00028036822878526127, 'n_units_Layer_1': 80, 'n_units_Layer_2': 300, 'n_units_Layer_3': 75, 'n_units_Layer_4': 105}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.20 | sMAPE for Validation Set is: 22.66% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 53.24 | sMAPE for Test Set is: 26.05% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:41:53,064]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:54,162]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:41:56,176]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:02,634]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:03,199]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:09,872]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:13,843]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:14,410]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:18,460]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:19,705]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:23,009]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:25,914]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:30,340]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:39,737]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:40,492]\u001b[0m Trial 1174 finished with value: 17.83683000873809 and parameters: {'n_hidden': 3, 'learning_rate': 0.00426994351429473, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3554985962221817, 'dropout_rate_Layer_2': 0.10480178388657074, 'dropout_rate_Layer_3': 0.15906511570064602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.227161995114718e-05, 'l1_Layer_2': 0.00040510150898901245, 'l1_Layer_3': 0.001630586579131946, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.84 | sMAPE for Validation Set is: 21.73% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 48.34 | sMAPE for Test Set is: 24.41% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:42:46,582]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:47,100]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:51,570]\u001b[0m Trial 1175 finished with value: 19.02765035611513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006182656496440925, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31438948401412176, 'dropout_rate_Layer_2': 0.17196080123047341, 'dropout_rate_Layer_3': 0.28698326278969016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000573118930048772, 'l1_Layer_2': 1.968913532017725e-05, 'l1_Layer_3': 0.00048162176202954895, 'n_units_Layer_1': 90, 'n_units_Layer_2': 290, 'n_units_Layer_3': 75}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.03 | sMAPE for Validation Set is: 22.58% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 52.81 | sMAPE for Test Set is: 25.99% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:42:54,455]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:42:58,479]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:43:04,980]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:43:09,838]\u001b[0m Trial 1180 finished with value: 19.254570663548048 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008984099938297631, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3135968196787236, 'dropout_rate_Layer_2': 0.18813305980785192, 'dropout_rate_Layer_3': 0.2526300393598871, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001126578400899505, 'l1_Layer_2': 1.2814066714129553e-05, 'l1_Layer_3': 0.000474502580941192, 'n_units_Layer_1': 90, 'n_units_Layer_2': 280, 'n_units_Layer_3': 80}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.25 | sMAPE for Validation Set is: 22.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 53.62 | sMAPE for Test Set is: 26.28% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:43:18,345]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:43:19,451]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:43:26,905]\u001b[0m Trial 1185 finished with value: 18.748566537249687 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009540744231800589, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34144214769895576, 'dropout_rate_Layer_2': 0.1671067370180427, 'dropout_rate_Layer_3': 0.2721187568498657, 'dropout_rate_Layer_4': 0.07299802522999355, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001120568742975183, 'l1_Layer_2': 2.166104500074427e-05, 'l1_Layer_3': 0.00030318565925153734, 'l1_Layer_4': 0.0002557706968913684, 'n_units_Layer_1': 65, 'n_units_Layer_2': 265, 'n_units_Layer_3': 95, 'n_units_Layer_4': 120}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.75 | sMAPE for Validation Set is: 22.08% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 51.52 | sMAPE for Test Set is: 25.54% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:43:29,288]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:43:35,135]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:43:44,293]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:43:44,940]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:43:50,685]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:43:51,676]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:43:53,607]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:43:59,096]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:43:59,515]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:05,296]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:11,083]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:14,282]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:21,501]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:24,264]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:28,145]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:32,327]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:33,155]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:43,422]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:44,994]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:50,165]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:51,397]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:44:58,075]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:45:08,494]\u001b[0m Trial 1203 finished with value: 18.407181309228502 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010883903895082471, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35147862146337544, 'dropout_rate_Layer_2': 0.14901016223591637, 'dropout_rate_Layer_3': 0.28148646162357455, 'dropout_rate_Layer_4': 0.09748188348955314, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0016746187120035066, 'l1_Layer_2': 3.2563953108915325e-05, 'l1_Layer_3': 0.0002278620077030268, 'l1_Layer_4': 0.0005224810545351557, 'n_units_Layer_1': 65, 'n_units_Layer_2': 285, 'n_units_Layer_3': 120, 'n_units_Layer_4': 110}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:45:08,526]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.41 | sMAPE for Validation Set is: 21.81% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 49.96 | sMAPE for Test Set is: 25.17% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:45:11,196]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:45:18,937]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:45:21,405]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:45:24,512]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:45:31,538]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:45:41,703]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:45:44,237]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:45:46,961]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:45:50,407]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:45:55,094]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:45:59,424]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:46:05,849]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:46:08,384]\u001b[0m Trial 1189 finished with value: 17.85449802761748 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008844056601392289, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2701534359328345, 'dropout_rate_Layer_2': 0.016463787864936467, 'dropout_rate_Layer_3': 0.02201786585872266, 'dropout_rate_Layer_4': 0.028614619461251302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00011029003748340026, 'l1_Layer_2': 3.2306463001677164e-05, 'l1_Layer_3': 0.0009855551304671316, 'l1_Layer_4': 0.000213579586683135, 'n_units_Layer_1': 205, 'n_units_Layer_2': 140, 'n_units_Layer_3': 255, 'n_units_Layer_4': 120}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.85 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 47.02 | sMAPE for Test Set is: 24.19% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:46:15,642]\u001b[0m Trial 1215 finished with value: 18.420892695577006 and parameters: {'n_hidden': 4, 'learning_rate': 0.001214944423877777, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3537380974317892, 'dropout_rate_Layer_2': 0.14938457384396034, 'dropout_rate_Layer_3': 0.3092009223762372, 'dropout_rate_Layer_4': 0.048711532055761786, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0016695118808237475, 'l1_Layer_2': 3.042591306135146e-05, 'l1_Layer_3': 0.0007303853615830617, 'l1_Layer_4': 0.00045958124610119354, 'n_units_Layer_1': 80, 'n_units_Layer_2': 285, 'n_units_Layer_3': 130, 'n_units_Layer_4': 90}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.42 | sMAPE for Validation Set is: 22.19% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 49.75 | sMAPE for Test Set is: 25.19% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:46:16,656]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:46:16,878]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:46:30,086]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:46:36,027]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:46:39,267]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:46:46,320]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:46:49,338]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:46:54,451]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:46:55,121]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:46:55,731]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:46:55,806]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:47:07,516]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:47:11,236]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:47:11,535]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:47:18,908]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:47:21,157]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:47:25,504]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:47:28,324]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:47:33,615]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:47:39,705]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:47:47,161]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:47:51,934]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:47:53,650]\u001b[0m Trial 1246 finished with value: 17.890070881645993 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022335086190146385, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1830035917910402, 'dropout_rate_Layer_2': 0.11173186294840046, 'dropout_rate_Layer_3': 0.12933339685661988, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.566694582906949e-05, 'l1_Layer_2': 1.1800273484922922e-05, 'l1_Layer_3': 0.002192550194464519, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 265}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.89 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.25 | sMAPE for Test Set is: 24.88% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:48:01,020]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:48:03,446]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:48:04,821]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:48:13,495]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:48:17,045]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:48:22,836]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:48:31,788]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:48:38,728]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:48:45,490]\u001b[0m Trial 1248 finished with value: 17.813336876601923 and parameters: {'n_hidden': 3, 'learning_rate': 0.002626859173896412, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3610920886234228, 'dropout_rate_Layer_2': 0.020636791040599668, 'dropout_rate_Layer_3': 0.1861512578202791, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007449410597289186, 'l1_Layer_2': 2.601877217858269e-05, 'l1_Layer_3': 0.005683613654693401, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 160}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.81 | sMAPE for Validation Set is: 21.63% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 45.30 | sMAPE for Test Set is: 23.54% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:48:50,280]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:48:53,877]\u001b[0m Trial 1254 finished with value: 18.409719162338053 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012547369815549803, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3535422330605311, 'dropout_rate_Layer_2': 0.1612090909263866, 'dropout_rate_Layer_3': 0.30727072612663875, 'dropout_rate_Layer_4': 0.03979624775065758, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0025017375053430144, 'l1_Layer_2': 4.594047173081483e-05, 'l1_Layer_3': 0.0008234316578055902, 'l1_Layer_4': 0.00019709424271556242, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 130, 'n_units_Layer_4': 90}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.41 | sMAPE for Validation Set is: 22.01% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 50.94 | sMAPE for Test Set is: 25.39% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:48:55,024]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:48:56,678]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:49:05,088]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:49:11,762]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:49:17,007]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:49:17,454]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:49:18,669]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:49:18,917]\u001b[0m Trial 1261 finished with value: 17.768998749953184 and parameters: {'n_hidden': 3, 'learning_rate': 0.002329418214189652, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1754575328543977, 'dropout_rate_Layer_2': 0.09764792057700333, 'dropout_rate_Layer_3': 0.13315937903321876, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.3420374322887934e-05, 'l1_Layer_2': 2.171712331374285e-05, 'l1_Layer_3': 0.0022220830554603136, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 265}. Best is trial 1120 with value: 17.62516512487188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.77 | sMAPE for Validation Set is: 21.81% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.87 | sMAPE for Test Set is: 25.01% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:49:27,632]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:49:31,648]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:49:34,162]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:49:34,407]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:49:55,953]\u001b[0m Trial 1272 finished with value: 17.603500748638556 and parameters: {'n_hidden': 3, 'learning_rate': 0.002293023653103341, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17844124626018593, 'dropout_rate_Layer_2': 0.09755969759803534, 'dropout_rate_Layer_3': 0.13055054023096968, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.3811867484723525e-05, 'l1_Layer_2': 1.3047126258340507e-05, 'l1_Layer_3': 0.002298231655349829, 'n_units_Layer_1': 205, 'n_units_Layer_2': 75, 'n_units_Layer_3': 265}. Best is trial 1272 with value: 17.603500748638556.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.60 | sMAPE for Validation Set is: 21.86% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.84 | sMAPE for Test Set is: 24.81% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:49:59,384]\u001b[0m Trial 1273 finished with value: 17.52801804184664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022596365603917263, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1797818576861272, 'dropout_rate_Layer_2': 0.09803094096562295, 'dropout_rate_Layer_3': 0.12398032176680954, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.3778146757925684e-05, 'l1_Layer_2': 1.5517702662150694e-05, 'l1_Layer_3': 0.002317270089803873, 'n_units_Layer_1': 205, 'n_units_Layer_2': 75, 'n_units_Layer_3': 265}. Best is trial 1273 with value: 17.52801804184664.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.53 | sMAPE for Validation Set is: 21.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.44 | sMAPE for Test Set is: 24.67% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:50:02,131]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:50:06,729]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:50:09,703]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.99 | sMAPE for Validation Set is: 21.70% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 48.09 | sMAPE for Test Set is: 24.50% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:50:14,971]\u001b[0m Trial 1271 finished with value: 17.986956809521608 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012589357800663786, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36651136032187953, 'dropout_rate_Layer_2': 0.15788670346701905, 'dropout_rate_Layer_3': 0.30532139934442865, 'dropout_rate_Layer_4': 0.03648576497427823, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002631867763831358, 'l1_Layer_2': 4.743819752468628e-05, 'l1_Layer_3': 0.0007429204726903524, 'l1_Layer_4': 0.0006028061301598789, 'n_units_Layer_1': 70, 'n_units_Layer_2': 295, 'n_units_Layer_3': 125, 'n_units_Layer_4': 90}. Best is trial 1273 with value: 17.52801804184664.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:50:19,628]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:50:19,740]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:50:22,721]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:50:32,802]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:50:40,346]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:50:41,281]\u001b[0m Trial 1270 finished with value: 18.380828395555806 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009608616021017394, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2873079688983842, 'dropout_rate_Layer_2': 0.022321293960358347, 'dropout_rate_Layer_3': 0.1313001317337892, 'dropout_rate_Layer_4': 2.8113725409246093e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008984938409291798, 'l1_Layer_2': 2.497332177969558e-05, 'l1_Layer_3': 0.0008677761119277605, 'l1_Layer_4': 2.6827689292887937e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 115, 'n_units_Layer_3': 245, 'n_units_Layer_4': 110}. Best is trial 1273 with value: 17.52801804184664.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.38 | sMAPE for Validation Set is: 22.04% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 48.75 | sMAPE for Test Set is: 24.72% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:50:46,037]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:50:49,230]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:50:50,534]\u001b[0m Trial 1281 finished with value: 17.590575598610403 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023629329774812946, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.195668728110244, 'dropout_rate_Layer_2': 0.10124261882276943, 'dropout_rate_Layer_3': 0.1306300552508846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.9901084088419166e-05, 'l1_Layer_2': 1.1258230297492717e-05, 'l1_Layer_3': 0.0016684287013371262, 'n_units_Layer_1': 205, 'n_units_Layer_2': 75, 'n_units_Layer_3': 265}. Best is trial 1273 with value: 17.52801804184664.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:50:50,556]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.59 | sMAPE for Validation Set is: 21.23% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 46.35 | sMAPE for Test Set is: 23.79% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:50:58,549]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:50:59,036]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:51:03,664]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:51:09,848]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:51:10,312]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:51:10,619]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:51:18,528]\u001b[0m Trial 1290 finished with value: 18.129898596864393 and parameters: {'n_hidden': 3, 'learning_rate': 0.002357286085901275, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1850324458478054, 'dropout_rate_Layer_2': 0.09744451433468618, 'dropout_rate_Layer_3': 0.12946731642205772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.188908587142245e-05, 'l1_Layer_2': 1.3525240275863903e-05, 'l1_Layer_3': 0.0016084868504452996, 'n_units_Layer_1': 220, 'n_units_Layer_2': 75, 'n_units_Layer_3': 265}. Best is trial 1273 with value: 17.52801804184664.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.13 | sMAPE for Validation Set is: 21.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 45.58 | sMAPE for Test Set is: 23.66% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:51:23,309]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:51:32,863]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:51:35,954]\u001b[0m Trial 1295 finished with value: 18.541150892921888 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012650429849790459, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35419286813028117, 'dropout_rate_Layer_2': 0.14489527891928272, 'dropout_rate_Layer_3': 0.3091919196109384, 'dropout_rate_Layer_4': 0.03563686528527686, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0027847827781282675, 'l1_Layer_2': 5.0426253850603855e-05, 'l1_Layer_3': 0.0008131570577098447, 'l1_Layer_4': 0.0005027250411988978, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 130, 'n_units_Layer_4': 85}. Best is trial 1273 with value: 17.52801804184664.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.54 | sMAPE for Validation Set is: 22.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 49.46 | sMAPE for Test Set is: 25.06% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:51:36,831]\u001b[0m Trial 1293 finished with value: 18.3887625529069 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012798949880832445, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35432816618618507, 'dropout_rate_Layer_2': 0.19422511860703845, 'dropout_rate_Layer_3': 0.3092714505324651, 'dropout_rate_Layer_4': 0.038191690515624474, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0027985762566593137, 'l1_Layer_2': 4.729988913660104e-05, 'l1_Layer_3': 0.001097249492880386, 'l1_Layer_4': 0.0006605137076392957, 'n_units_Layer_1': 70, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130, 'n_units_Layer_4': 90}. Best is trial 1273 with value: 17.52801804184664.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.39 | sMAPE for Validation Set is: 21.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 48.98 | sMAPE for Test Set is: 24.79% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:51:40,617]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:51:46,852]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:51:49,640]\u001b[0m Trial 1294 finished with value: 18.354076300954905 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013421226912850722, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3543041133999957, 'dropout_rate_Layer_2': 0.19131851888602988, 'dropout_rate_Layer_3': 0.30657159719655486, 'dropout_rate_Layer_4': 0.03864267156132506, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002720714258914381, 'l1_Layer_2': 4.743216005021896e-05, 'l1_Layer_3': 0.0011234886323049037, 'l1_Layer_4': 0.0005132869561181531, 'n_units_Layer_1': 70, 'n_units_Layer_2': 295, 'n_units_Layer_3': 130, 'n_units_Layer_4': 95}. Best is trial 1273 with value: 17.52801804184664.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.35 | sMAPE for Validation Set is: 21.84% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 49.88 | sMAPE for Test Set is: 25.07% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:51:52,219]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:52:07,679]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:52:13,235]\u001b[0m Trial 1303 finished with value: 17.757397405444134 and parameters: {'n_hidden': 3, 'learning_rate': 0.003025173361718581, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20236746657846877, 'dropout_rate_Layer_2': 0.08421403988739028, 'dropout_rate_Layer_3': 0.1373945975173353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.597534015133122e-05, 'l1_Layer_2': 1.016594715884225e-05, 'l1_Layer_3': 0.0018048396046556694, 'n_units_Layer_1': 205, 'n_units_Layer_2': 95, 'n_units_Layer_3': 265}. Best is trial 1273 with value: 17.52801804184664.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.76 | sMAPE for Validation Set is: 21.22% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 46.49 | sMAPE for Test Set is: 24.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:52:19,164]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:52:25,331]\u001b[0m Trial 1302 finished with value: 18.25256806402899 and parameters: {'n_hidden': 4, 'learning_rate': 0.001260293176755894, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3547085502416758, 'dropout_rate_Layer_2': 0.19250112855190174, 'dropout_rate_Layer_3': 0.31041892243844044, 'dropout_rate_Layer_4': 0.03446193092154015, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003046108968788203, 'l1_Layer_2': 5.148959989509799e-05, 'l1_Layer_3': 0.001116608382014085, 'l1_Layer_4': 0.0005292945511288927, 'n_units_Layer_1': 70, 'n_units_Layer_2': 295, 'n_units_Layer_3': 130, 'n_units_Layer_4': 90}. Best is trial 1273 with value: 17.52801804184664.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.25 | sMAPE for Validation Set is: 21.98% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 49.89 | sMAPE for Test Set is: 25.04% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:52:34,712]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:52:40,073]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:52:45,023]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:52:48,724]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:52:51,657]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:52:57,610]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:01,233]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:05,524]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:10,021]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:14,285]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.60 | sMAPE for Validation Set is: 21.38% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 46.31 | sMAPE for Test Set is: 23.87% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:53:16,288]\u001b[0m Trial 1306 finished with value: 17.59826483357996 and parameters: {'n_hidden': 3, 'learning_rate': 0.002232186384722501, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25309125410522504, 'dropout_rate_Layer_2': 0.1513309768654216, 'dropout_rate_Layer_3': 0.08884831214692004, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.332957690487711e-05, 'l1_Layer_2': 2.326458741127875e-05, 'l1_Layer_3': 0.008646808862522833, 'n_units_Layer_1': 275, 'n_units_Layer_2': 150, 'n_units_Layer_3': 160}. Best is trial 1273 with value: 17.52801804184664.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:21,218]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:22,347]\u001b[0m Trial 1311 finished with value: 18.445249249007222 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012692142040445142, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3362336709642086, 'dropout_rate_Layer_2': 0.2117984458201515, 'dropout_rate_Layer_3': 0.3153303643562938, 'dropout_rate_Layer_4': 0.03482777487287251, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0019719265328298533, 'l1_Layer_2': 4.8647500594243836e-05, 'l1_Layer_3': 0.0012505135380545625, 'l1_Layer_4': 0.0009541454847341439, 'n_units_Layer_1': 70, 'n_units_Layer_2': 285, 'n_units_Layer_3': 130, 'n_units_Layer_4': 95}. Best is trial 1273 with value: 17.52801804184664.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.45 | sMAPE for Validation Set is: 21.94% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 49.06 | sMAPE for Test Set is: 24.89% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:53:25,335]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:29,947]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:30,844]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:36,594]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:37,751]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:38,317]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:39,741]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:47,218]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:49,115]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:53,328]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:53:55,493]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:00,970]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:03,209]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:06,202]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:11,147]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:14,834]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:16,043]\u001b[0m Trial 1329 finished with value: 17.50339637187606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022334202301746925, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19917351235729805, 'dropout_rate_Layer_2': 0.08311189267045095, 'dropout_rate_Layer_3': 0.132780334905884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2532512342113755e-05, 'l1_Layer_2': 1.035817494420462e-05, 'l1_Layer_3': 0.0017033832238986426, 'n_units_Layer_1': 205, 'n_units_Layer_2': 90, 'n_units_Layer_3': 265}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.50 | sMAPE for Validation Set is: 21.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 44.43 | sMAPE for Test Set is: 23.30% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:54:18,476]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:23,571]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:26,069]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:29,321]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:30,013]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:31,309]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:38,403]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:38,605]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:44,431]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:44,866]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:46,100]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:51,887]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:53,727]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:54:58,780]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:00,515]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:05,292]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:09,396]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:14,846]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:19,700]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:22,695]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:25,034]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:27,976]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:38,465]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:39,410]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:48,389]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:50,134]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:55:55,661]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:01,320]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:03,591]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:04,596]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:07,322]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:16,245]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:20,132]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.72 | sMAPE for Validation Set is: 21.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 46.40 | sMAPE for Test Set is: 23.95% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:56:22,972]\u001b[0m Trial 1367 finished with value: 17.72436785319664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030089777356941626, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19353653396534595, 'dropout_rate_Layer_2': 0.0752318218392215, 'dropout_rate_Layer_3': 0.11417492341811858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6581609111658843e-05, 'l1_Layer_2': 2.501202399012108e-05, 'l1_Layer_3': 0.0007504560178286682, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 285}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:24,462]\u001b[0m Trial 1368 finished with value: 17.787354143629305 and parameters: {'n_hidden': 3, 'learning_rate': 0.002206411311398727, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20916671825457395, 'dropout_rate_Layer_2': 0.10353818807418824, 'dropout_rate_Layer_3': 0.1144200454799458, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6810149395687837e-05, 'l1_Layer_2': 1.2669815375882811e-05, 'l1_Layer_3': 0.0007270302154678751, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 285}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.79 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 46.49 | sMAPE for Test Set is: 23.96% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:56:29,740]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:30,418]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:37,641]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:38,908]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:45,944]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:46,432]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:52,145]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:56:54,405]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:00,094]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:00,632]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:06,140]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:11,431]\u001b[0m Trial 1378 finished with value: 17.630847564396802 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030842544060110766, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.199190448376787, 'dropout_rate_Layer_2': 0.0780411067221471, 'dropout_rate_Layer_3': 0.11379559628175755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7236403380250415e-05, 'l1_Layer_2': 3.684739626243871e-05, 'l1_Layer_3': 0.0008487173063829246, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 295}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.63 | sMAPE for Validation Set is: 21.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 46.03 | sMAPE for Test Set is: 23.74% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:57:14,904]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:17,112]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:24,617]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:29,280]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:33,198]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:33,907]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:42,691]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:43,240]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:49,678]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:55,183]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:57:58,442]\u001b[0m Trial 1391 finished with value: 17.569926678677067 and parameters: {'n_hidden': 3, 'learning_rate': 0.001578115291254569, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1951581242608411, 'dropout_rate_Layer_2': 0.08073310576597566, 'dropout_rate_Layer_3': 0.08485098892824333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2135327037827403e-05, 'l1_Layer_2': 3.260438176803634e-05, 'l1_Layer_3': 0.00045727983714473125, 'n_units_Layer_1': 230, 'n_units_Layer_2': 90, 'n_units_Layer_3': 300}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.57 | sMAPE for Validation Set is: 21.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 44.68 | sMAPE for Test Set is: 23.38% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:58:02,786]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:07,166]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:12,616]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:15,477]\u001b[0m Trial 1380 finished with value: 18.870577461928185 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006324756436495451, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34286751600005344, 'dropout_rate_Layer_2': 0.04805578098751632, 'dropout_rate_Layer_3': 0.037960521075484865, 'dropout_rate_Layer_4': 0.00012820654584503113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006449821545406323, 'l1_Layer_2': 1.8315847647349745e-05, 'l1_Layer_3': 5.2716744942217675e-05, 'l1_Layer_4': 0.000950456122520296, 'n_units_Layer_1': 190, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265, 'n_units_Layer_4': 125}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.87 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 47.83 | sMAPE for Test Set is: 24.55% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:58:19,526]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:24,830]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:25,950]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:26,433]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:32,047]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:32,366]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:39,166]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:39,325]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:40,114]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:40,300]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:48,869]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:53,302]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:56,627]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:58:57,894]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:05,064]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:05,317]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:11,365]\u001b[0m Trial 1411 finished with value: 18.194273644487062 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021580840861329447, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20820184167542174, 'dropout_rate_Layer_2': 0.08614663793140519, 'dropout_rate_Layer_3': 0.11677629092914614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8035206349103243e-05, 'l1_Layer_2': 2.1939214198837718e-05, 'l1_Layer_3': 0.000756173413091163, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 280}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.19 | sMAPE for Validation Set is: 22.05% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 46.64 | sMAPE for Test Set is: 23.90% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:59:11,643]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:19,491]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:22,326]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:31,545]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:35,198]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:38,048]\u001b[0m Trial 1417 finished with value: 17.78410294412762 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018927565815469091, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19487569014308062, 'dropout_rate_Layer_2': 0.07513756602582891, 'dropout_rate_Layer_3': 0.08032681636829578, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0769341187800102e-05, 'l1_Layer_2': 3.0038812872317634e-05, 'l1_Layer_3': 0.0003999688818845617, 'n_units_Layer_1': 220, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.78 | sMAPE for Validation Set is: 21.47% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 45.01 | sMAPE for Test Set is: 23.46% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 16:59:39,120]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:42,914]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:43,134]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:47,980]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:54,696]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 16:59:54,850]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:02,001]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:02,786]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:04,779]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:11,372]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:13,716]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:20,810]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:20,995]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:25,469]\u001b[0m Trial 1430 finished with value: 17.851301808516517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018792542095663017, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19607499407690906, 'dropout_rate_Layer_2': 0.07380592196778271, 'dropout_rate_Layer_3': 0.09620400475306404, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.150377654340375e-05, 'l1_Layer_2': 2.942534205536179e-05, 'l1_Layer_3': 0.0003114328842110371, 'n_units_Layer_1': 215, 'n_units_Layer_2': 80, 'n_units_Layer_3': 285}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.85 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 46.85 | sMAPE for Test Set is: 23.92% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 17:00:28,489]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:31,187]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:42,973]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:50,874]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:55,135]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:00:58,787]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:02,987]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:03,601]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:08,450]\u001b[0m Trial 1438 finished with value: 18.05695737898239 and parameters: {'n_hidden': 3, 'learning_rate': 0.002956939920875656, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27239543987019443, 'dropout_rate_Layer_2': 0.0762038908515638, 'dropout_rate_Layer_3': 0.37244034976239293, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013071614278360947, 'l1_Layer_2': 6.897252218677824e-05, 'l1_Layer_3': 0.008902810095506062, 'n_units_Layer_1': 85, 'n_units_Layer_2': 225, 'n_units_Layer_3': 245}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.06 | sMAPE for Validation Set is: 22.11% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 46.92 | sMAPE for Test Set is: 24.26% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 17:01:16,706]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:21,775]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:26,799]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:27,052]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:28,111]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:36,138]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:42,879]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:49,486]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:52,190]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:55,827]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:01:58,931]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:01,906]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:06,146]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:06,610]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:07,547]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:16,822]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:20,493]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:20,667]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:23,606]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:28,676]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:30,758]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:31,134]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:40,837]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:44,776]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:49,411]\u001b[0m Trial 1433 finished with value: 18.298018366557926 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005016855390465038, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3371119488859781, 'dropout_rate_Layer_2': 0.0196201323177544, 'dropout_rate_Layer_3': 0.008223499507383877, 'dropout_rate_Layer_4': 0.021446596659490433, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004276097250409429, 'l1_Layer_2': 1.3978282426811105e-05, 'l1_Layer_3': 0.0013526116768099472, 'l1_Layer_4': 0.00110547841126864, 'n_units_Layer_1': 175, 'n_units_Layer_2': 155, 'n_units_Layer_3': 260, 'n_units_Layer_4': 110}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:49,477]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.30 | sMAPE for Validation Set is: 22.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 47.85 | sMAPE for Test Set is: 24.45% | rMAE for Test Set is: 0.60\n",
      "MAE for Validation Set is: 17.85 | sMAPE for Validation Set is: 21.44% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 46.26 | sMAPE for Test Set is: 23.84% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 17:02:49,630]\u001b[0m Trial 1466 finished with value: 17.853314639263314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016603764968547603, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15872842165956447, 'dropout_rate_Layer_2': 0.06472044288852527, 'dropout_rate_Layer_3': 0.1393212220753843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3811986161694872e-05, 'l1_Layer_2': 1.0154565228072264e-05, 'l1_Layer_3': 0.00042723742891476104, 'n_units_Layer_1': 230, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:02:52,656]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:03:02,680]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:03:10,249]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:03:17,916]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:03:23,363]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:03:26,080]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:03:51,103]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:03:56,222]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:02,696]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:13,464]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:16,608]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:19,547]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:24,207]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:28,794]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:33,488]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:34,442]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:41,560]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:44,005]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:50,892]\u001b[0m Trial 1482 finished with value: 18.36846159927006 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014613003367469279, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3304607746643259, 'dropout_rate_Layer_2': 0.17455381527379255, 'dropout_rate_Layer_3': 0.3219174885685765, 'dropout_rate_Layer_4': 0.03788800758276607, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032168110834042913, 'l1_Layer_2': 3.0491373220560437e-05, 'l1_Layer_3': 0.0012264049085821311, 'l1_Layer_4': 0.00011893422701431415, 'n_units_Layer_1': 70, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140, 'n_units_Layer_4': 105}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.37 | sMAPE for Validation Set is: 21.76% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 51.12 | sMAPE for Test Set is: 25.44% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 17:04:53,679]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:58,067]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:04:58,704]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:05:04,849]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:05:09,248]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:05:16,214]\u001b[0m Trial 1493 finished with value: 17.951264367942702 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027283334579360856, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21465129881541664, 'dropout_rate_Layer_2': 0.0808791121201499, 'dropout_rate_Layer_3': 0.15071716499538723, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.070019161495128e-05, 'l1_Layer_2': 2.5657308669040233e-05, 'l1_Layer_3': 0.0005548634309883599, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 275}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.95 | sMAPE for Validation Set is: 21.60% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 45.03 | sMAPE for Test Set is: 23.51% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 17:05:16,841]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:05:20,372]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:05:21,820]\u001b[0m Trial 1471 finished with value: 17.999619303919527 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005701375036998331, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2526473849337894, 'dropout_rate_Layer_2': 0.0007455619244497265, 'dropout_rate_Layer_3': 0.013116086979847789, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00429831698765714, 'l1_Layer_2': 1.4663683830471837e-05, 'l1_Layer_3': 0.0014070594168073714, 'n_units_Layer_1': 175, 'n_units_Layer_2': 165, 'n_units_Layer_3': 255}. Best is trial 1329 with value: 17.50339637187606.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.00 | sMAPE for Validation Set is: 21.78% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 47.68 | sMAPE for Test Set is: 24.39% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 17:05:22,153]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 17:05:31,397]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-01-01, MAE is:41.73 & sMAPE is:58.80% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :41.73 & 58.80% & 0.36\n",
      "for 2022-01-02, MAE is:30.10 & sMAPE is:46.95% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :35.91 & 52.87% & 0.30\n",
      "for 2022-01-03, MAE is:39.26 & sMAPE is:79.87% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :37.03 & 61.87% & 0.35\n",
      "for 2022-01-04, MAE is:66.17 & sMAPE is:53.03% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :44.31 & 59.66% & 0.56\n",
      "for 2022-01-05, MAE is:41.59 & sMAPE is:27.05% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :43.77 & 53.14% & 0.66\n",
      "for 2022-01-06, MAE is:69.18 & sMAPE is:37.48% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :48.00 & 50.53% & 0.63\n",
      "for 2022-01-07, MAE is:51.86 & sMAPE is:31.69% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :48.56 & 47.84% & 0.58\n",
      "for 2022-01-08, MAE is:26.22 & sMAPE is:15.52% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :45.76 & 43.80% & 0.55\n",
      "for 2022-01-09, MAE is:47.65 & sMAPE is:35.43% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :45.97 & 42.87% & 0.54\n",
      "for 2022-01-10, MAE is:79.16 & sMAPE is:34.62% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :49.29 & 42.04% & 0.53\n",
      "for 2022-01-11, MAE is:45.21 & sMAPE is:19.10% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :48.92 & 39.96% & 0.52\n",
      "for 2022-01-12, MAE is:22.80 & sMAPE is:9.77% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :46.74 & 37.44% & 0.50\n",
      "for 2022-01-13, MAE is:23.85 & sMAPE is:10.67% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :44.98 & 35.38% & 0.55\n",
      "for 2022-01-14, MAE is:20.96 & sMAPE is:9.44% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :43.27 & 33.53% & 0.55\n",
      "for 2022-01-15, MAE is:23.01 & sMAPE is:11.35% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :41.92 & 32.05% & 0.55\n",
      "for 2022-01-16, MAE is:29.93 & sMAPE is:14.90% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :41.17 & 30.98% & 0.54\n",
      "for 2022-01-17, MAE is:35.69 & sMAPE is:17.69% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :40.84 & 30.20% & 0.54\n",
      "for 2022-01-18, MAE is:30.84 & sMAPE is:13.57% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :40.29 & 29.27% & 0.62\n",
      "for 2022-01-19, MAE is:34.42 & sMAPE is:17.46% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :39.98 & 28.65% & 0.63\n",
      "for 2022-01-20, MAE is:28.66 & sMAPE is:15.63% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :39.41 & 28.00% & 0.64\n",
      "for 2022-01-21, MAE is:18.51 & sMAPE is:9.55% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :38.42 & 27.12% & 0.64\n",
      "for 2022-01-22, MAE is:16.62 & sMAPE is:9.16% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :37.43 & 26.31% & 0.64\n",
      "for 2022-01-23, MAE is:15.18 & sMAPE is:8.21% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :36.46 & 25.52% & 0.64\n",
      "for 2022-01-24, MAE is:49.69 & sMAPE is:21.32% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :37.01 & 25.34% & 0.66\n",
      "for 2022-01-25, MAE is:70.47 & sMAPE is:25.40% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :38.35 & 25.35% & 0.69\n",
      "for 2022-01-26, MAE is:31.63 & sMAPE is:13.93% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :38.09 & 24.91% & 0.70\n",
      "for 2022-01-27, MAE is:33.76 & sMAPE is:19.22% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :37.93 & 24.70% & 0.70\n",
      "for 2022-01-28, MAE is:31.78 & sMAPE is:14.42% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :37.71 & 24.33% & 0.72\n",
      "for 2022-01-29, MAE is:73.83 & sMAPE is:55.91% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :38.96 & 25.42% & 0.73\n",
      "for 2022-01-30, MAE is:53.37 & sMAPE is:31.72% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :39.44 & 25.63% & 0.77\n",
      "for 2022-01-31, MAE is:42.78 & sMAPE is:22.37% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :39.55 & 25.52% & 0.77\n",
      "for 2022-02-01, MAE is:36.02 & sMAPE is:18.61% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :39.44 & 25.31% & 0.76\n",
      "for 2022-02-02, MAE is:28.14 & sMAPE is:16.42% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :39.09 & 25.04% & 0.75\n",
      "for 2022-02-03, MAE is:17.90 & sMAPE is:9.58% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :38.47 & 24.58% & 0.75\n",
      "for 2022-02-04, MAE is:17.62 & sMAPE is:9.52% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :37.87 & 24.15% & 0.74\n",
      "for 2022-02-05, MAE is:67.24 & sMAPE is:58.80% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :38.69 & 25.12% & 0.76\n",
      "for 2022-02-06, MAE is:44.70 & sMAPE is:81.62% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :38.85 & 26.64% & 0.75\n",
      "for 2022-02-07, MAE is:93.38 & sMAPE is:59.55% & rMAE is:3.09 ||| daily mean of MAE & sMAPE & rMAE till now are :40.29 & 27.51% & 0.81\n",
      "for 2022-02-08, MAE is:35.31 & sMAPE is:21.61% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :40.16 & 27.36% & 0.82\n",
      "for 2022-02-09, MAE is:31.19 & sMAPE is:16.94% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :39.94 & 27.10% & 0.83\n",
      "for 2022-02-10, MAE is:30.61 & sMAPE is:16.17% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :39.71 & 26.83% & 0.86\n",
      "for 2022-02-11, MAE is:21.14 & sMAPE is:11.31% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :39.27 & 26.46% & 0.86\n",
      "for 2022-02-12, MAE is:40.17 & sMAPE is:26.97% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :39.29 & 26.47% & 0.86\n",
      "for 2022-02-13, MAE is:64.55 & sMAPE is:64.94% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :39.86 & 27.35% & 0.86\n",
      "for 2022-02-14, MAE is:55.76 & sMAPE is:44.42% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :40.21 & 27.73% & 0.87\n",
      "for 2022-02-15, MAE is:27.33 & sMAPE is:15.43% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :39.93 & 27.46% & 0.87\n",
      "for 2022-02-16, MAE is:39.39 & sMAPE is:28.35% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :39.92 & 27.48% & 0.86\n",
      "for 2022-02-17, MAE is:37.50 & sMAPE is:42.63% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :39.87 & 27.79% & 0.85\n",
      "for 2022-02-18, MAE is:25.10 & sMAPE is:16.87% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :39.57 & 27.57% & 0.85\n",
      "for 2022-02-19, MAE is:45.98 & sMAPE is:48.07% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :39.70 & 27.98% & 0.85\n",
      "for 2022-02-20, MAE is:14.46 & sMAPE is:14.86% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :39.20 & 27.72% & 0.84\n",
      "for 2022-02-21, MAE is:48.39 & sMAPE is:35.16% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :39.38 & 27.87% & 0.85\n",
      "for 2022-02-22, MAE is:25.64 & sMAPE is:17.37% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :39.12 & 27.67% & 0.85\n",
      "for 2022-02-23, MAE is:38.74 & sMAPE is:23.62% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :39.11 & 27.59% & 0.85\n",
      "for 2022-02-24, MAE is:27.67 & sMAPE is:18.32% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :38.91 & 27.42% & 0.84\n",
      "for 2022-02-25, MAE is:88.69 & sMAPE is:36.79% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :39.80 & 27.59% & 0.85\n",
      "for 2022-02-26, MAE is:35.69 & sMAPE is:15.27% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :39.72 & 27.38% & 0.84\n",
      "for 2022-02-27, MAE is:37.39 & sMAPE is:20.15% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :39.68 & 27.25% & 0.83\n",
      "for 2022-02-28, MAE is:57.29 & sMAPE is:26.91% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :39.98 & 27.25% & 0.83\n",
      "for 2022-03-01, MAE is:61.39 & sMAPE is:25.67% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :40.34 & 27.22% & 0.82\n",
      "for 2022-03-02, MAE is:39.99 & sMAPE is:15.53% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :40.33 & 27.03% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-03, MAE is:108.76 & sMAPE is:37.61% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :41.44 & 27.20% & 0.81\n",
      "for 2022-03-04, MAE is:74.54 & sMAPE is:22.77% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :41.96 & 27.13% & 0.81\n",
      "for 2022-03-05, MAE is:43.77 & sMAPE is:12.95% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :41.99 & 26.91% & 0.80\n",
      "for 2022-03-06, MAE is:56.87 & sMAPE is:18.35% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :42.22 & 26.77% & 0.80\n",
      "for 2022-03-07, MAE is:65.11 & sMAPE is:16.61% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :42.57 & 26.62% & 0.79\n",
      "for 2022-03-08, MAE is:170.73 & sMAPE is:41.93% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :44.48 & 26.85% & 0.79\n",
      "for 2022-03-09, MAE is:68.17 & sMAPE is:14.88% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :44.83 & 26.67% & 0.78\n",
      "for 2022-03-10, MAE is:103.20 & sMAPE is:27.38% & rMAE is:2.96 ||| daily mean of MAE & sMAPE & rMAE till now are :45.67 & 26.68% & 0.81\n",
      "for 2022-03-11, MAE is:171.94 & sMAPE is:73.42% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :47.48 & 27.35% & 0.82\n",
      "for 2022-03-12, MAE is:78.02 & sMAPE is:42.06% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :47.91 & 27.56% & 0.81\n",
      "for 2022-03-13, MAE is:111.97 & sMAPE is:82.70% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :48.80 & 28.32% & 0.81\n",
      "for 2022-03-14, MAE is:78.51 & sMAPE is:31.14% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :49.20 & 28.36% & 0.80\n",
      "for 2022-03-15, MAE is:36.95 & sMAPE is:13.05% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :49.04 & 28.16% & 0.80\n",
      "for 2022-03-16, MAE is:29.54 & sMAPE is:10.58% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :48.78 & 27.92% & 0.79\n",
      "for 2022-03-17, MAE is:34.37 & sMAPE is:13.85% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :48.59 & 27.74% & 0.78\n",
      "for 2022-03-18, MAE is:30.83 & sMAPE is:13.41% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :48.36 & 27.55% & 0.78\n",
      "for 2022-03-19, MAE is:93.10 & sMAPE is:72.02% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :48.93 & 28.12% & 0.78\n",
      "for 2022-03-20, MAE is:57.45 & sMAPE is:39.49% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :49.04 & 28.26% & 0.78\n",
      "for 2022-03-21, MAE is:55.17 & sMAPE is:26.72% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :49.12 & 28.24% & 0.78\n",
      "for 2022-03-22, MAE is:40.30 & sMAPE is:17.73% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :49.01 & 28.11% & 0.78\n",
      "for 2022-03-23, MAE is:45.30 & sMAPE is:19.76% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :48.96 & 28.01% & 0.78\n",
      "for 2022-03-24, MAE is:46.60 & sMAPE is:20.04% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :48.93 & 27.92% & 0.79\n",
      "for 2022-03-25, MAE is:64.94 & sMAPE is:29.46% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :49.12 & 27.94% & 0.80\n",
      "for 2022-03-26, MAE is:72.02 & sMAPE is:49.65% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :49.39 & 28.19% & 0.80\n",
      "for 2022-03-27, MAE is:40.61 & sMAPE is:23.93% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :49.29 & 28.14% & 0.80\n",
      "for 2022-03-28, MAE is:32.19 & sMAPE is:14.27% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :49.09 & 27.98% & 0.81\n",
      "for 2022-03-29, MAE is:33.24 & sMAPE is:14.12% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :48.91 & 27.82% & 0.81\n",
      "for 2022-03-30, MAE is:55.09 & sMAPE is:23.03% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :48.98 & 27.77% & 0.82\n",
      "for 2022-03-31, MAE is:62.25 & sMAPE is:25.58% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :49.13 & 27.75% & 0.82\n",
      "for 2022-04-01, MAE is:35.98 & sMAPE is:17.72% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :48.99 & 27.64% & 0.81\n",
      "for 2022-04-02, MAE is:68.16 & sMAPE is:32.23% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :49.20 & 27.69% & 0.81\n",
      "for 2022-04-03, MAE is:70.76 & sMAPE is:27.12% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :49.43 & 27.68% & 0.81\n",
      "for 2022-04-04, MAE is:31.63 & sMAPE is:13.45% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :49.24 & 27.53% & 0.81\n",
      "for 2022-04-05, MAE is:66.41 & sMAPE is:49.16% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :49.42 & 27.76% & 0.82\n",
      "for 2022-04-06, MAE is:62.42 & sMAPE is:45.21% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :49.55 & 27.94% & 0.81\n",
      "for 2022-04-07, MAE is:41.93 & sMAPE is:57.10% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :49.48 & 28.24% & 0.81\n",
      "for 2022-04-08, MAE is:132.90 & sMAPE is:83.31% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :50.33 & 28.80% & 0.82\n",
      "for 2022-04-09, MAE is:75.95 & sMAPE is:71.37% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :50.59 & 29.23% & 0.82\n",
      "for 2022-04-10, MAE is:74.19 & sMAPE is:48.19% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :50.82 & 29.42% & 0.82\n",
      "for 2022-04-11, MAE is:37.34 & sMAPE is:16.97% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :50.69 & 29.30% & 0.82\n",
      "for 2022-04-12, MAE is:37.50 & sMAPE is:17.98% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :50.56 & 29.19% & 0.82\n",
      "for 2022-04-13, MAE is:21.86 & sMAPE is:9.43% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :50.28 & 28.99% & 0.81\n",
      "for 2022-04-14, MAE is:20.14 & sMAPE is:8.91% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :49.99 & 28.80% & 0.81\n",
      "for 2022-04-15, MAE is:22.95 & sMAPE is:11.24% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :49.73 & 28.63% & 0.80\n",
      "for 2022-04-16, MAE is:47.44 & sMAPE is:39.04% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :49.71 & 28.73% & 0.80\n",
      "for 2022-04-17, MAE is:51.75 & sMAPE is:60.63% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :49.73 & 29.03% & 0.80\n",
      "for 2022-04-18, MAE is:34.50 & sMAPE is:29.96% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :49.59 & 29.04% & 0.80\n",
      "for 2022-04-19, MAE is:34.38 & sMAPE is:17.65% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :49.45 & 28.93% & 0.80\n",
      "for 2022-04-20, MAE is:31.17 & sMAPE is:16.59% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :49.28 & 28.82% & 0.80\n",
      "for 2022-04-21, MAE is:20.69 & sMAPE is:10.61% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :49.03 & 28.66% & 0.80\n",
      "for 2022-04-22, MAE is:32.84 & sMAPE is:20.15% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :48.88 & 28.58% & 0.80\n",
      "for 2022-04-23, MAE is:77.94 & sMAPE is:81.30% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :49.14 & 29.05% & 0.81\n",
      "for 2022-04-24, MAE is:54.51 & sMAPE is:78.53% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :49.19 & 29.48% & 0.81\n",
      "for 2022-04-25, MAE is:92.08 & sMAPE is:53.49% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :49.56 & 29.69% & 0.81\n",
      "for 2022-04-26, MAE is:33.36 & sMAPE is:15.67% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :49.42 & 29.57% & 0.81\n",
      "for 2022-04-27, MAE is:16.58 & sMAPE is:7.50% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :49.14 & 29.38% & 0.81\n",
      "for 2022-04-28, MAE is:29.80 & sMAPE is:13.53% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :48.97 & 29.25% & 0.81\n",
      "for 2022-04-29, MAE is:19.54 & sMAPE is:8.63% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :48.73 & 29.07% & 0.81\n",
      "for 2022-04-30, MAE is:14.61 & sMAPE is:7.16% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :48.44 & 28.89% & 0.80\n",
      "for 2022-05-01, MAE is:18.36 & sMAPE is:9.72% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :48.19 & 28.73% & 0.80\n",
      "for 2022-05-02, MAE is:22.08 & sMAPE is:10.20% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :47.98 & 28.58% & 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-03, MAE is:19.54 & sMAPE is:8.96% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :47.75 & 28.42% & 0.81\n",
      "for 2022-05-04, MAE is:25.75 & sMAPE is:11.59% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :47.57 & 28.29% & 0.82\n",
      "for 2022-05-05, MAE is:19.71 & sMAPE is:8.94% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :47.35 & 28.13% & 0.83\n",
      "for 2022-05-06, MAE is:18.09 & sMAPE is:8.02% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :47.12 & 27.97% & 0.84\n",
      "for 2022-05-07, MAE is:16.17 & sMAPE is:7.71% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :46.87 & 27.81% & 0.85\n",
      "for 2022-05-08, MAE is:33.41 & sMAPE is:23.76% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :46.77 & 27.78% & 0.85\n",
      "for 2022-05-09, MAE is:26.16 & sMAPE is:12.43% & rMAE is:3.24 ||| daily mean of MAE & sMAPE & rMAE till now are :46.61 & 27.66% & 0.87\n",
      "for 2022-05-10, MAE is:52.87 & sMAPE is:40.15% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :46.66 & 27.76% & 0.87\n",
      "for 2022-05-11, MAE is:53.61 & sMAPE is:46.45% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :46.71 & 27.90% & 0.87\n",
      "for 2022-05-12, MAE is:25.25 & sMAPE is:15.06% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :46.55 & 27.80% & 0.86\n",
      "for 2022-05-13, MAE is:47.57 & sMAPE is:37.27% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :46.55 & 27.87% & 0.86\n",
      "for 2022-05-14, MAE is:36.27 & sMAPE is:30.99% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :46.48 & 27.90% & 0.86\n",
      "for 2022-05-15, MAE is:37.28 & sMAPE is:32.13% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :46.41 & 27.93% & 0.87\n",
      "for 2022-05-16, MAE is:29.52 & sMAPE is:18.91% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :46.29 & 27.86% & 0.87\n",
      "for 2022-05-17, MAE is:26.46 & sMAPE is:12.35% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :46.14 & 27.75% & 0.87\n",
      "for 2022-05-18, MAE is:27.51 & sMAPE is:13.37% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :46.01 & 27.64% & 0.86\n",
      "for 2022-05-19, MAE is:22.83 & sMAPE is:10.96% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :45.84 & 27.52% & 0.86\n",
      "for 2022-05-20, MAE is:23.16 & sMAPE is:11.71% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :45.68 & 27.41% & 0.86\n",
      "for 2022-05-21, MAE is:49.68 & sMAPE is:35.88% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :45.70 & 27.47% & 0.86\n",
      "for 2022-05-22, MAE is:21.01 & sMAPE is:13.58% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :45.53 & 27.37% & 0.86\n",
      "for 2022-05-23, MAE is:20.33 & sMAPE is:11.13% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :45.35 & 27.26% & 0.86\n",
      "for 2022-05-24, MAE is:21.39 & sMAPE is:12.88% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :45.19 & 27.16% & 0.86\n",
      "for 2022-05-25, MAE is:38.73 & sMAPE is:25.69% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :45.14 & 27.15% & 0.86\n",
      "for 2022-05-26, MAE is:84.40 & sMAPE is:102.35% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :45.41 & 27.67% & 0.86\n",
      "for 2022-05-27, MAE is:63.03 & sMAPE is:101.25% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :45.53 & 28.17% & 0.85\n",
      "for 2022-05-28, MAE is:40.35 & sMAPE is:71.91% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :45.50 & 28.46% & 0.85\n",
      "for 2022-05-29, MAE is:59.88 & sMAPE is:48.45% & rMAE is:3.76 ||| daily mean of MAE & sMAPE & rMAE till now are :45.59 & 28.60% & 0.87\n",
      "for 2022-05-30, MAE is:46.22 & sMAPE is:22.89% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :45.60 & 28.56% & 0.87\n",
      "for 2022-05-31, MAE is:19.06 & sMAPE is:9.05% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :45.42 & 28.43% & 0.87\n",
      "for 2022-06-01, MAE is:18.67 & sMAPE is:8.98% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :45.25 & 28.30% & 0.87\n",
      "for 2022-06-02, MAE is:19.88 & sMAPE is:10.68% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :45.08 & 28.19% & 0.86\n",
      "for 2022-06-03, MAE is:27.48 & sMAPE is:16.27% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :44.97 & 28.11% & 0.86\n",
      "for 2022-06-04, MAE is:31.83 & sMAPE is:33.20% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :44.88 & 28.14% & 0.86\n",
      "for 2022-06-05, MAE is:20.06 & sMAPE is:14.71% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :44.72 & 28.05% & 0.86\n",
      "for 2022-06-06, MAE is:88.44 & sMAPE is:87.71% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :45.00 & 28.43% & 0.85\n",
      "for 2022-06-07, MAE is:27.87 & sMAPE is:17.50% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :44.89 & 28.37% & 0.86\n",
      "for 2022-06-08, MAE is:12.69 & sMAPE is:7.19% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :44.69 & 28.23% & 0.85\n",
      "for 2022-06-09, MAE is:15.01 & sMAPE is:8.82% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :44.50 & 28.11% & 0.85\n",
      "for 2022-06-10, MAE is:17.24 & sMAPE is:9.93% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :44.34 & 28.00% & 0.85\n",
      "for 2022-06-11, MAE is:71.91 & sMAPE is:73.89% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :44.51 & 28.28% & 0.86\n",
      "for 2022-06-12, MAE is:41.91 & sMAPE is:55.23% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :44.49 & 28.45% & 0.86\n",
      "for 2022-06-13, MAE is:23.24 & sMAPE is:15.08% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :44.36 & 28.37% & 0.85\n",
      "for 2022-06-14, MAE is:22.28 & sMAPE is:11.34% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :44.23 & 28.26% & 0.86\n",
      "for 2022-06-15, MAE is:27.56 & sMAPE is:12.89% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :44.13 & 28.17% & 0.86\n",
      "for 2022-06-16, MAE is:37.63 & sMAPE is:16.44% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :44.09 & 28.10% & 0.85\n",
      "for 2022-06-17, MAE is:39.85 & sMAPE is:15.40% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :44.06 & 28.02% & 0.85\n",
      "for 2022-06-18, MAE is:35.37 & sMAPE is:15.78% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :44.01 & 27.95% & 0.85\n",
      "for 2022-06-19, MAE is:64.23 & sMAPE is:39.51% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :44.13 & 28.02% & 0.85\n",
      "for 2022-06-20, MAE is:32.33 & sMAPE is:13.09% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :44.06 & 27.93% & 0.85\n",
      "for 2022-06-21, MAE is:55.20 & sMAPE is:18.38% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :44.12 & 27.88% & 0.85\n",
      "for 2022-06-22, MAE is:48.70 & sMAPE is:17.08% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :44.15 & 27.81% & 0.84\n",
      "for 2022-06-23, MAE is:46.78 & sMAPE is:15.31% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :44.17 & 27.74% & 0.84\n",
      "for 2022-06-24, MAE is:34.37 & sMAPE is:11.04% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :44.11 & 27.65% & 0.84\n",
      "for 2022-06-25, MAE is:20.49 & sMAPE is:8.24% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :43.98 & 27.54% & 0.84\n",
      "for 2022-06-26, MAE is:44.33 & sMAPE is:20.26% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :43.98 & 27.50% & 0.84\n",
      "for 2022-06-27, MAE is:52.04 & sMAPE is:17.77% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :44.02 & 27.44% & 0.84\n",
      "for 2022-06-28, MAE is:44.01 & sMAPE is:13.45% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :44.02 & 27.36% & 0.85\n",
      "for 2022-06-29, MAE is:47.01 & sMAPE is:15.07% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :44.04 & 27.29% & 0.85\n",
      "for 2022-06-30, MAE is:42.65 & sMAPE is:12.59% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :44.03 & 27.21% & 0.85\n",
      "for 2022-07-01, MAE is:37.98 & sMAPE is:12.41% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :44.00 & 27.13% & 0.86\n",
      "for 2022-07-02, MAE is:50.91 & sMAPE is:21.96% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :44.04 & 27.10% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-03, MAE is:59.88 & sMAPE is:31.08% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :44.12 & 27.13% & 0.87\n",
      "for 2022-07-04, MAE is:30.53 & sMAPE is:9.85% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :44.05 & 27.03% & 0.87\n",
      "for 2022-07-05, MAE is:37.10 & sMAPE is:11.64% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :44.01 & 26.95% & 0.87\n",
      "for 2022-07-06, MAE is:26.30 & sMAPE is:7.81% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :43.92 & 26.85% & 0.87\n",
      "for 2022-07-07, MAE is:59.96 & sMAPE is:18.92% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :44.00 & 26.80% & 0.87\n",
      "for 2022-07-08, MAE is:36.23 & sMAPE is:10.41% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :43.96 & 26.72% & 0.87\n",
      "for 2022-07-09, MAE is:81.92 & sMAPE is:30.45% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :44.16 & 26.74% & 0.87\n",
      "for 2022-07-10, MAE is:82.69 & sMAPE is:39.63% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :44.36 & 26.80% & 0.88\n",
      "for 2022-07-11, MAE is:44.30 & sMAPE is:13.02% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :44.36 & 26.73% & 0.88\n",
      "for 2022-07-12, MAE is:53.46 & sMAPE is:14.49% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :44.41 & 26.67% & 0.88\n",
      "for 2022-07-13, MAE is:38.16 & sMAPE is:10.18% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :44.38 & 26.58% & 0.88\n",
      "for 2022-07-14, MAE is:38.38 & sMAPE is:10.29% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :44.35 & 26.50% & 0.88\n",
      "for 2022-07-15, MAE is:46.93 & sMAPE is:12.46% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :44.36 & 26.43% & 0.89\n",
      "for 2022-07-16, MAE is:111.89 & sMAPE is:44.97% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :44.70 & 26.52% & 0.89\n",
      "for 2022-07-17, MAE is:78.12 & sMAPE is:43.37% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :44.87 & 26.61% & 0.90\n",
      "for 2022-07-18, MAE is:81.96 & sMAPE is:19.84% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :45.06 & 26.57% & 0.90\n",
      "for 2022-07-19, MAE is:98.25 & sMAPE is:24.43% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :45.32 & 26.56% & 0.90\n",
      "for 2022-07-20, MAE is:47.34 & sMAPE is:13.76% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :45.33 & 26.50% & 0.90\n",
      "for 2022-07-21, MAE is:36.70 & sMAPE is:11.27% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :45.29 & 26.42% & 0.90\n",
      "for 2022-07-22, MAE is:32.19 & sMAPE is:9.45% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :45.23 & 26.34% & 0.91\n",
      "for 2022-07-23, MAE is:30.96 & sMAPE is:9.98% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :45.16 & 26.26% & 0.90\n",
      "for 2022-07-24, MAE is:95.11 & sMAPE is:47.69% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :45.40 & 26.37% & 0.91\n",
      "for 2022-07-25, MAE is:39.89 & sMAPE is:13.60% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :45.37 & 26.30% & 0.90\n",
      "for 2022-07-26, MAE is:32.31 & sMAPE is:10.36% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :45.31 & 26.23% & 0.90\n",
      "for 2022-07-27, MAE is:60.48 & sMAPE is:17.69% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :45.38 & 26.19% & 0.90\n",
      "for 2022-07-28, MAE is:73.68 & sMAPE is:19.19% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :45.52 & 26.15% & 0.90\n",
      "for 2022-07-29, MAE is:60.70 & sMAPE is:16.08% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :45.59 & 26.10% & 0.90\n",
      "for 2022-07-30, MAE is:59.05 & sMAPE is:17.25% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :45.66 & 26.06% & 0.90\n",
      "for 2022-07-31, MAE is:39.30 & sMAPE is:12.58% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :45.63 & 26.00% & 0.90\n",
      "for 2022-08-01, MAE is:35.80 & sMAPE is:9.56% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :45.58 & 25.92% & 0.90\n",
      "for 2022-08-02, MAE is:121.06 & sMAPE is:47.21% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :45.93 & 26.02% & 0.90\n",
      "for 2022-08-03, MAE is:50.67 & sMAPE is:16.09% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :45.95 & 25.97% & 0.90\n",
      "for 2022-08-04, MAE is:69.14 & sMAPE is:19.10% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :46.06 & 25.94% & 0.90\n",
      "for 2022-08-05, MAE is:58.15 & sMAPE is:14.67% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :46.12 & 25.89% & 0.90\n",
      "for 2022-08-06, MAE is:82.16 & sMAPE is:27.18% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :46.28 & 25.90% & 0.90\n",
      "for 2022-08-07, MAE is:89.67 & sMAPE is:44.34% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :46.48 & 25.98% & 0.90\n",
      "for 2022-08-08, MAE is:45.48 & sMAPE is:13.40% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :46.48 & 25.92% & 0.90\n",
      "for 2022-08-09, MAE is:47.26 & sMAPE is:13.59% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :46.48 & 25.87% & 0.90\n",
      "for 2022-08-10, MAE is:38.67 & sMAPE is:11.86% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :46.44 & 25.80% & 0.90\n",
      "for 2022-08-11, MAE is:46.73 & sMAPE is:13.04% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :46.45 & 25.75% & 0.90\n",
      "for 2022-08-12, MAE is:70.29 & sMAPE is:17.92% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :46.55 & 25.71% & 0.90\n",
      "for 2022-08-13, MAE is:72.76 & sMAPE is:25.64% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :46.67 & 25.71% & 0.90\n",
      "for 2022-08-14, MAE is:78.16 & sMAPE is:30.28% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :46.81 & 25.73% & 0.90\n",
      "for 2022-08-15, MAE is:58.56 & sMAPE is:15.24% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :46.86 & 25.69% & 0.90\n",
      "for 2022-08-16, MAE is:52.96 & sMAPE is:12.30% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :46.89 & 25.63% & 0.90\n",
      "for 2022-08-17, MAE is:77.05 & sMAPE is:15.23% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :47.02 & 25.58% & 0.90\n",
      "for 2022-08-18, MAE is:62.30 & sMAPE is:12.89% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :47.08 & 25.53% & 0.90\n",
      "for 2022-08-19, MAE is:45.85 & sMAPE is:9.64% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :47.08 & 25.46% & 0.89\n",
      "for 2022-08-20, MAE is:58.21 & sMAPE is:13.39% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :47.13 & 25.41% & 0.89\n",
      "for 2022-08-21, MAE is:92.51 & sMAPE is:28.56% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :47.32 & 25.42% & 0.90\n",
      "for 2022-08-22, MAE is:114.72 & sMAPE is:24.00% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :47.61 & 25.41% & 0.90\n",
      "for 2022-08-23, MAE is:102.57 & sMAPE is:18.59% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :47.84 & 25.38% & 0.90\n",
      "for 2022-08-24, MAE is:76.44 & sMAPE is:13.15% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :47.97 & 25.33% & 0.90\n",
      "for 2022-08-25, MAE is:66.95 & sMAPE is:11.97% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :48.05 & 25.28% & 0.90\n",
      "for 2022-08-26, MAE is:111.42 & sMAPE is:17.95% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :48.31 & 25.25% & 0.89\n",
      "for 2022-08-27, MAE is:57.53 & sMAPE is:9.70% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :48.35 & 25.18% & 0.89\n",
      "for 2022-08-28, MAE is:118.03 & sMAPE is:38.02% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :48.64 & 25.23% & 0.89\n",
      "for 2022-08-29, MAE is:127.43 & sMAPE is:22.08% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :48.97 & 25.22% & 0.90\n",
      "for 2022-08-30, MAE is:74.93 & sMAPE is:11.98% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :49.07 & 25.17% & 0.90\n",
      "for 2022-08-31, MAE is:103.19 & sMAPE is:18.60% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :49.30 & 25.14% & 0.90\n",
      "for 2022-09-01, MAE is:87.18 & sMAPE is:17.12% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :49.45 & 25.11% & 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-02, MAE is:116.33 & sMAPE is:24.92% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :49.73 & 25.11% & 0.90\n",
      "for 2022-09-03, MAE is:69.50 & sMAPE is:20.11% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :49.81 & 25.09% & 0.89\n",
      "for 2022-09-04, MAE is:99.73 & sMAPE is:37.11% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :50.01 & 25.13% & 0.89\n",
      "for 2022-09-05, MAE is:88.39 & sMAPE is:25.16% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :50.16 & 25.13% & 0.89\n",
      "for 2022-09-06, MAE is:84.59 & sMAPE is:21.06% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :50.30 & 25.12% & 0.89\n",
      "for 2022-09-07, MAE is:59.19 & sMAPE is:14.11% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :50.34 & 25.07% & 0.89\n",
      "for 2022-09-08, MAE is:50.59 & sMAPE is:12.47% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :50.34 & 25.02% & 0.89\n",
      "for 2022-09-09, MAE is:52.76 & sMAPE is:15.67% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :50.35 & 24.99% & 0.89\n",
      "for 2022-09-10, MAE is:64.11 & sMAPE is:18.19% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :50.40 & 24.96% & 0.89\n",
      "for 2022-09-11, MAE is:57.55 & sMAPE is:16.24% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :50.43 & 24.93% & 0.88\n",
      "for 2022-09-12, MAE is:45.61 & sMAPE is:11.76% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :50.41 & 24.87% & 0.88\n",
      "for 2022-09-13, MAE is:37.06 & sMAPE is:9.34% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :50.36 & 24.81% & 0.88\n",
      "for 2022-09-14, MAE is:48.07 & sMAPE is:11.17% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :50.35 & 24.76% & 0.88\n",
      "for 2022-09-15, MAE is:37.47 & sMAPE is:9.47% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :50.30 & 24.70% & 0.88\n",
      "for 2022-09-16, MAE is:146.72 & sMAPE is:56.26% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :50.67 & 24.82% & 0.88\n",
      "for 2022-09-17, MAE is:126.64 & sMAPE is:87.42% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :50.96 & 25.06% & 0.88\n",
      "for 2022-09-18, MAE is:28.91 & sMAPE is:24.66% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :50.88 & 25.06% & 0.88\n",
      "for 2022-09-19, MAE is:77.85 & sMAPE is:29.06% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :50.98 & 25.08% & 0.88\n",
      "for 2022-09-20, MAE is:62.56 & sMAPE is:19.51% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :51.03 & 25.06% & 0.88\n",
      "for 2022-09-21, MAE is:59.18 & sMAPE is:16.77% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :51.06 & 25.02% & 0.88\n",
      "for 2022-09-22, MAE is:76.84 & sMAPE is:21.85% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :51.15 & 25.01% & 0.88\n",
      "for 2022-09-23, MAE is:47.55 & sMAPE is:13.57% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :51.14 & 24.97% & 0.88\n",
      "for 2022-09-24, MAE is:40.48 & sMAPE is:12.39% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :51.10 & 24.92% & 0.87\n",
      "for 2022-09-25, MAE is:36.53 & sMAPE is:13.76% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :51.05 & 24.88% & 0.87\n",
      "for 2022-09-26, MAE is:69.21 & sMAPE is:28.95% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :51.11 & 24.90% & 0.87\n",
      "for 2022-09-27, MAE is:53.60 & sMAPE is:20.74% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :51.12 & 24.88% & 0.87\n",
      "for 2022-09-28, MAE is:56.51 & sMAPE is:15.09% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :51.14 & 24.84% & 0.87\n",
      "for 2022-09-29, MAE is:71.37 & sMAPE is:18.02% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :51.22 & 24.82% & 0.88\n",
      "for 2022-09-30, MAE is:124.11 & sMAPE is:43.90% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :51.49 & 24.89% & 0.88\n",
      "for 2022-10-01, MAE is:130.70 & sMAPE is:88.31% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :51.77 & 25.12% & 0.88\n",
      "for 2022-10-02, MAE is:46.48 & sMAPE is:25.37% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :51.75 & 25.12% & 0.88\n",
      "for 2022-10-03, MAE is:61.13 & sMAPE is:22.97% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :51.79 & 25.11% & 0.88\n",
      "for 2022-10-04, MAE is:93.83 & sMAPE is:38.12% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :51.94 & 25.16% & 0.88\n",
      "for 2022-10-05, MAE is:75.84 & sMAPE is:50.31% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :52.03 & 25.25% & 0.88\n",
      "for 2022-10-06, MAE is:42.77 & sMAPE is:21.57% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :51.99 & 25.24% & 0.88\n",
      "for 2022-10-07, MAE is:57.55 & sMAPE is:34.60% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :52.01 & 25.27% & 0.88\n",
      "for 2022-10-08, MAE is:70.72 & sMAPE is:59.39% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :52.08 & 25.39% & 0.88\n",
      "for 2022-10-09, MAE is:39.76 & sMAPE is:27.31% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :52.04 & 25.40% & 0.87\n",
      "for 2022-10-10, MAE is:28.80 & sMAPE is:16.65% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :51.95 & 25.37% & 0.87\n",
      "for 2022-10-11, MAE is:70.58 & sMAPE is:27.91% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :52.02 & 25.38% & 0.87\n",
      "for 2022-10-12, MAE is:57.93 & sMAPE is:19.86% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :52.04 & 25.36% & 0.87\n",
      "for 2022-10-13, MAE is:41.41 & sMAPE is:16.66% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :52.00 & 25.33% & 0.87\n",
      "for 2022-10-14, MAE is:51.75 & sMAPE is:21.89% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :52.00 & 25.32% & 0.87\n",
      "for 2022-10-15, MAE is:32.01 & sMAPE is:18.72% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :51.93 & 25.29% & 0.87\n",
      "for 2022-10-16, MAE is:29.30 & sMAPE is:25.36% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :51.85 & 25.29% & 0.87\n",
      "for 2022-10-17, MAE is:20.56 & sMAPE is:12.04% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :51.75 & 25.25% & 0.87\n",
      "for 2022-10-18, MAE is:32.24 & sMAPE is:20.09% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :51.68 & 25.23% & 0.86\n",
      "for 2022-10-19, MAE is:24.22 & sMAPE is:16.16% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :51.59 & 25.20% & 0.86\n",
      "for 2022-10-20, MAE is:22.32 & sMAPE is:24.07% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :51.49 & 25.19% & 0.86\n",
      "for 2022-10-21, MAE is:28.40 & sMAPE is:21.03% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :51.41 & 25.18% & 0.86\n",
      "for 2022-10-22, MAE is:17.36 & sMAPE is:14.24% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :51.29 & 25.14% & 0.86\n",
      "for 2022-10-23, MAE is:12.49 & sMAPE is:12.40% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :51.16 & 25.10% & 0.85\n",
      "for 2022-10-24, MAE is:20.67 & sMAPE is:31.70% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :51.06 & 25.12% & 0.85\n",
      "for 2022-10-25, MAE is:26.40 & sMAPE is:26.32% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :50.98 & 25.13% & 0.85\n",
      "for 2022-10-26, MAE is:18.09 & sMAPE is:19.10% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :50.87 & 25.11% & 0.85\n",
      "for 2022-10-27, MAE is:45.70 & sMAPE is:46.82% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :50.85 & 25.18% & 0.85\n",
      "for 2022-10-28, MAE is:14.02 & sMAPE is:14.27% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :50.73 & 25.14% & 0.85\n",
      "for 2022-10-29, MAE is:20.22 & sMAPE is:23.68% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :50.62 & 25.14% & 0.85\n",
      "for 2022-10-30, MAE is:36.64 & sMAPE is:36.44% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :50.58 & 25.18% & 0.85\n",
      "for 2022-10-31, MAE is:30.78 & sMAPE is:23.73% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :50.51 & 25.17% & 0.85\n",
      "for 2022-11-01, MAE is:34.75 & sMAPE is:43.56% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :50.46 & 25.23% & 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-02, MAE is:29.60 & sMAPE is:51.98% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :50.39 & 25.32% & 0.85\n",
      "for 2022-11-03, MAE is:39.18 & sMAPE is:43.51% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :50.36 & 25.38% & 0.85\n",
      "for 2022-11-04, MAE is:98.18 & sMAPE is:73.16% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :50.51 & 25.53% & 0.85\n",
      "for 2022-11-05, MAE is:21.33 & sMAPE is:15.36% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :50.42 & 25.50% & 0.85\n",
      "for 2022-11-06, MAE is:17.54 & sMAPE is:18.95% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :50.31 & 25.48% & 0.85\n",
      "for 2022-11-07, MAE is:34.47 & sMAPE is:62.12% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :50.26 & 25.60% & 0.85\n",
      "for 2022-11-08, MAE is:35.09 & sMAPE is:40.05% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :50.21 & 25.64% & 0.85\n",
      "for 2022-11-09, MAE is:41.63 & sMAPE is:42.42% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :50.18 & 25.70% & 0.85\n",
      "for 2022-11-10, MAE is:34.84 & sMAPE is:27.96% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :50.14 & 25.70% & 0.85\n",
      "for 2022-11-11, MAE is:33.25 & sMAPE is:37.73% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :50.08 & 25.74% & 0.85\n",
      "for 2022-11-12, MAE is:44.60 & sMAPE is:33.61% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :50.06 & 25.77% & 0.85\n",
      "for 2022-11-13, MAE is:20.72 & sMAPE is:15.19% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :49.97 & 25.73% & 0.85\n",
      "for 2022-11-14, MAE is:33.98 & sMAPE is:18.64% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :49.92 & 25.71% & 0.85\n",
      "for 2022-11-15, MAE is:27.14 & sMAPE is:15.16% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :49.85 & 25.68% & 0.85\n",
      "for 2022-11-16, MAE is:33.47 & sMAPE is:22.50% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :49.80 & 25.67% & 0.85\n",
      "for 2022-11-17, MAE is:48.89 & sMAPE is:43.00% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :49.80 & 25.72% & 0.85\n",
      "for 2022-11-18, MAE is:60.26 & sMAPE is:31.39% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :49.83 & 25.74% & 0.85\n",
      "for 2022-11-19, MAE is:37.43 & sMAPE is:19.74% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :49.79 & 25.72% & 0.85\n",
      "for 2022-11-20, MAE is:18.43 & sMAPE is:9.10% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :49.69 & 25.67% & 0.85\n",
      "for 2022-11-21, MAE is:38.18 & sMAPE is:16.56% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :49.66 & 25.64% & 0.85\n",
      "for 2022-11-22, MAE is:31.75 & sMAPE is:19.38% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :49.60 & 25.62% & 0.85\n",
      "for 2022-11-23, MAE is:37.91 & sMAPE is:20.08% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :49.57 & 25.61% & 0.85\n",
      "for 2022-11-24, MAE is:84.82 & sMAPE is:39.78% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :49.68 & 25.65% & 0.85\n",
      "for 2022-11-25, MAE is:55.51 & sMAPE is:22.17% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :49.69 & 25.64% & 0.85\n",
      "for 2022-11-26, MAE is:26.17 & sMAPE is:11.15% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :49.62 & 25.59% & 0.85\n",
      "for 2022-11-27, MAE is:26.50 & sMAPE is:15.81% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :49.55 & 25.56% & 0.85\n",
      "for 2022-11-28, MAE is:88.27 & sMAPE is:30.51% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :49.67 & 25.58% & 0.85\n",
      "for 2022-11-29, MAE is:98.80 & sMAPE is:28.54% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :49.82 & 25.59% & 0.85\n",
      "for 2022-11-30, MAE is:85.15 & sMAPE is:22.48% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :49.92 & 25.58% & 0.85\n",
      "for 2022-12-01, MAE is:28.39 & sMAPE is:7.21% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :49.86 & 25.52% & 0.84\n",
      "for 2022-12-02, MAE is:33.47 & sMAPE is:9.12% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :49.81 & 25.48% & 0.84\n",
      "for 2022-12-03, MAE is:26.21 & sMAPE is:7.94% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :49.74 & 25.42% & 0.84\n",
      "for 2022-12-04, MAE is:38.06 & sMAPE is:12.72% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :49.70 & 25.39% & 0.84\n",
      "for 2022-12-05, MAE is:35.91 & sMAPE is:9.97% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :49.66 & 25.34% & 0.84\n",
      "for 2022-12-06, MAE is:59.52 & sMAPE is:15.73% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :49.69 & 25.31% & 0.84\n",
      "for 2022-12-07, MAE is:44.61 & sMAPE is:10.94% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :49.68 & 25.27% & 0.84\n",
      "for 2022-12-08, MAE is:23.04 & sMAPE is:5.72% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :49.60 & 25.21% & 0.84\n",
      "for 2022-12-09, MAE is:40.33 & sMAPE is:9.21% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :49.57 & 25.17% & 0.84\n",
      "for 2022-12-10, MAE is:20.86 & sMAPE is:5.44% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :49.49 & 25.11% & 0.84\n",
      "for 2022-12-11, MAE is:19.06 & sMAPE is:5.60% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :49.40 & 25.05% & 0.84\n",
      "for 2022-12-12, MAE is:92.77 & sMAPE is:20.15% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :49.53 & 25.04% & 0.84\n",
      "for 2022-12-13, MAE is:61.74 & sMAPE is:13.28% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :49.56 & 25.00% & 0.84\n",
      "for 2022-12-14, MAE is:50.95 & sMAPE is:11.70% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :49.57 & 24.97% & 0.84\n",
      "for 2022-12-15, MAE is:28.37 & sMAPE is:7.07% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :49.50 & 24.91% & 0.84\n",
      "for 2022-12-16, MAE is:53.70 & sMAPE is:13.20% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :49.52 & 24.88% & 0.84\n",
      "for 2022-12-17, MAE is:59.10 & sMAPE is:18.36% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :49.54 & 24.86% & 0.84\n",
      "for 2022-12-18, MAE is:72.50 & sMAPE is:27.75% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :49.61 & 24.87% & 0.84\n",
      "for 2022-12-19, MAE is:40.28 & sMAPE is:22.63% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :49.58 & 24.86% & 0.84\n",
      "for 2022-12-20, MAE is:33.38 & sMAPE is:20.19% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :49.54 & 24.85% & 0.84\n",
      "for 2022-12-21, MAE is:25.80 & sMAPE is:12.56% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :49.47 & 24.82% & 0.84\n",
      "for 2022-12-22, MAE is:15.29 & sMAPE is:8.09% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :49.37 & 24.77% & 0.84\n",
      "for 2022-12-23, MAE is:22.37 & sMAPE is:13.25% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :49.30 & 24.74% & 0.83\n",
      "for 2022-12-24, MAE is:28.03 & sMAPE is:29.28% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :49.24 & 24.75% & 0.83\n",
      "for 2022-12-25, MAE is:15.19 & sMAPE is:15.39% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :49.14 & 24.72% & 0.83\n",
      "for 2022-12-26, MAE is:42.68 & sMAPE is:59.53% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :49.13 & 24.82% & 0.83\n",
      "for 2022-12-27, MAE is:18.99 & sMAPE is:19.34% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :49.04 & 24.81% & 0.83\n",
      "for 2022-12-28, MAE is:33.47 & sMAPE is:67.69% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :49.00 & 24.92% & 0.83\n",
      "for 2022-12-29, MAE is:30.59 & sMAPE is:94.42% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :48.95 & 25.12% & 0.82\n",
      "for 2022-12-30, MAE is:39.64 & sMAPE is:118.02% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :48.92 & 25.37% & 0.82\n",
      "for 2022-12-31, MAE is:19.04 & sMAPE is:151.27% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :48.84 & 25.72% & 0.82\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.2 - (Calib Year = 3)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:02:22,760]\u001b[0m A new study created in RDB with name: BE_2023\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:02:40,041]\u001b[0m Trial 1 finished with value: 94.54322486731814 and parameters: {'n_hidden': 3, 'learning_rate': 0.09186544872561231, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1045285790075306, 'dropout_rate_Layer_2': 0.33797191775952223, 'dropout_rate_Layer_3': 0.3998565522494065, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1300340601721367e-05, 'l1_Layer_2': 0.03023329836759267, 'l1_Layer_3': 0.006361466509608117, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 120}. Best is trial 1 with value: 94.54322486731814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 94.54 | sMAPE for Validation Set is: 42.26% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 24.84 | sMAPE for Test Set is: 29.50% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:02:43,306]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:02:43,525]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:02:50,223]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:02:55,264]\u001b[0m Trial 0 finished with value: 54.18565297901075 and parameters: {'n_hidden': 3, 'learning_rate': 0.06737544233292408, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38127495952568946, 'dropout_rate_Layer_2': 0.11040442621683111, 'dropout_rate_Layer_3': 0.3235403997421434, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.67753949247323e-05, 'l1_Layer_2': 0.03257753940024242, 'l1_Layer_3': 0.016826802592837673, 'n_units_Layer_1': 185, 'n_units_Layer_2': 225, 'n_units_Layer_3': 110}. Best is trial 0 with value: 54.18565297901075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.19 | sMAPE for Validation Set is: 27.85% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 29.46 | sMAPE for Test Set is: 34.29% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:02:58,904]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:03:00,729]\u001b[0m Trial 3 finished with value: 69.16453199615692 and parameters: {'n_hidden': 3, 'learning_rate': 0.0281361134039096, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05363346029403986, 'dropout_rate_Layer_2': 0.32907473562329775, 'dropout_rate_Layer_3': 0.12879988921365168, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002761205843746387, 'l1_Layer_2': 0.013081933764836453, 'l1_Layer_3': 0.0075181028706392495, 'n_units_Layer_1': 160, 'n_units_Layer_2': 210, 'n_units_Layer_3': 85}. Best is trial 0 with value: 54.18565297901075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 69.16 | sMAPE for Validation Set is: 31.39% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 28.72 | sMAPE for Test Set is: 29.82% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:03:00,842]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:03:07,820]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:03:32,379]\u001b[0m Trial 10 finished with value: 97.52517250772296 and parameters: {'n_hidden': 4, 'learning_rate': 0.03154325972082455, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12746611826376505, 'dropout_rate_Layer_2': 0.3262208047388364, 'dropout_rate_Layer_3': 0.16221744772534372, 'dropout_rate_Layer_4': 0.24187283627428655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012842873624383086, 'l1_Layer_2': 0.009468178831275742, 'l1_Layer_3': 0.003476498114641648, 'l1_Layer_4': 0.00017827354410740538, 'n_units_Layer_1': 165, 'n_units_Layer_2': 65, 'n_units_Layer_3': 90, 'n_units_Layer_4': 240}. Best is trial 0 with value: 54.18565297901075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 97.53 | sMAPE for Validation Set is: 43.85% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 35.69 | sMAPE for Test Set is: 38.52% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:03:35,171]\u001b[0m Trial 9 finished with value: 75.54387151563772 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009659172515574908, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041449412881554085, 'dropout_rate_Layer_2': 0.39667463297563477, 'dropout_rate_Layer_3': 0.21330345237458104, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.001163907043322298, 'l1_Layer_2': 0.0001865747632283017, 'l1_Layer_3': 0.00017565946419080975, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185}. Best is trial 0 with value: 54.18565297901075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.54 | sMAPE for Validation Set is: 34.00% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 25.50 | sMAPE for Test Set is: 30.28% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:03:35,651]\u001b[0m Trial 8 finished with value: 92.58282170277069 and parameters: {'n_hidden': 4, 'learning_rate': 0.014822045042721752, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1340786279127232, 'dropout_rate_Layer_2': 0.17427068071669571, 'dropout_rate_Layer_3': 0.3133266852864471, 'dropout_rate_Layer_4': 0.09363671243237551, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.033247700076414546, 'l1_Layer_2': 8.363923107555828e-05, 'l1_Layer_3': 0.0037052939010116834, 'l1_Layer_4': 0.0074878625872081255, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 175, 'n_units_Layer_4': 55}. Best is trial 0 with value: 54.18565297901075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 92.58 | sMAPE for Validation Set is: 41.10% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 31.25 | sMAPE for Test Set is: 34.55% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:03:36,043]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:03:45,017]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:03:48,162]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:03:48,498]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:03:50,721]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:03:56,432]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:03:59,034]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:03,097]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:03,322]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:08,271]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:08,562]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:10,388]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:16,403]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:21,221]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:24,451]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:29,462]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:31,038]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:33,917]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:35,145]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:38,484]\u001b[0m Trial 25 finished with value: 91.0105432959864 and parameters: {'n_hidden': 4, 'learning_rate': 0.04963629311951998, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25812319652786014, 'dropout_rate_Layer_2': 0.3134530335492334, 'dropout_rate_Layer_3': 0.25851094742568126, 'dropout_rate_Layer_4': 0.07574924050379123, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.7232885331915106e-05, 'l1_Layer_2': 8.3181712510178e-05, 'l1_Layer_3': 0.003274346688338227, 'l1_Layer_4': 0.0008652162665335183, 'n_units_Layer_1': 120, 'n_units_Layer_2': 220, 'n_units_Layer_3': 110, 'n_units_Layer_4': 110}. Best is trial 0 with value: 54.18565297901075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 91.01 | sMAPE for Validation Set is: 40.64% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 31.87 | sMAPE for Test Set is: 33.80% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:04:40,949]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:43,811]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:46,255]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:48,868]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:51,869]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:53,348]\u001b[0m Trial 12 finished with value: 44.28929827499879 and parameters: {'n_hidden': 4, 'learning_rate': 0.002250255570612211, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16076577703094738, 'dropout_rate_Layer_2': 0.041422737934281396, 'dropout_rate_Layer_3': 0.0025718275371741763, 'dropout_rate_Layer_4': 0.13716139421343496, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00029687737378143926, 'l1_Layer_2': 2.406903489108112e-05, 'l1_Layer_3': 1.527550824865452e-05, 'l1_Layer_4': 0.0016127660276819113, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285, 'n_units_Layer_4': 170}. Best is trial 12 with value: 44.28929827499879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.29 | sMAPE for Validation Set is: 23.53% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 17.95 | sMAPE for Test Set is: 23.15% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:04:55,308]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:04:55,742]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:05:04,578]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:05:11,313]\u001b[0m Trial 42 finished with value: 67.93330155242087 and parameters: {'n_hidden': 4, 'learning_rate': 0.016520608010728476, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0657499067962728, 'dropout_rate_Layer_2': 0.06568271191788302, 'dropout_rate_Layer_3': 0.07162113199009305, 'dropout_rate_Layer_4': 0.004168442299970865, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0042819066179769815, 'l1_Layer_2': 0.08758165106350438, 'l1_Layer_3': 0.0017051494714146204, 'l1_Layer_4': 1.4656864882138536e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 205, 'n_units_Layer_3': 140, 'n_units_Layer_4': 250}. Best is trial 12 with value: 44.28929827499879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 67.93 | sMAPE for Validation Set is: 31.47% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 23.63 | sMAPE for Test Set is: 28.53% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:05:15,671]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:05:26,636]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:05:27,013]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:05:34,241]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:05:39,620]\u001b[0m Trial 41 finished with value: 45.86191896239473 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033995182423761775, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20346793351783227, 'dropout_rate_Layer_2': 0.06978039493679286, 'dropout_rate_Layer_3': 7.413230777519875e-06, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.108438090047617e-05, 'l1_Layer_2': 0.00029736639099673295, 'l1_Layer_3': 0.0032342739733071542, 'n_units_Layer_1': 275, 'n_units_Layer_2': 100, 'n_units_Layer_3': 300}. Best is trial 12 with value: 44.28929827499879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.86 | sMAPE for Validation Set is: 24.22% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 18.70 | sMAPE for Test Set is: 23.50% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:05:40,071]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:05:47,666]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:05:50,816]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:05:54,968]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:05:58,817]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:02,141]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:13,314]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:18,084]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:26,182]\u001b[0m Trial 48 finished with value: 46.21788894402914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034101992877017943, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04437707188101653, 'dropout_rate_Layer_2': 0.06294842936231561, 'dropout_rate_Layer_3': 0.1587959656395533, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0937772900836864, 'l1_Layer_2': 0.003338300658223558, 'l1_Layer_3': 0.0005412108173719581, 'n_units_Layer_1': 85, 'n_units_Layer_2': 85, 'n_units_Layer_3': 240}. Best is trial 12 with value: 44.28929827499879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.22 | sMAPE for Validation Set is: 23.89% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 17.81 | sMAPE for Test Set is: 22.54% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:06:30,294]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:33,484]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:36,123]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:39,942]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:42,393]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:45,947]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:47,436]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:50,624]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:52,530]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:56,631]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:06:56,998]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:04,532]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:05,224]\u001b[0m Trial 53 finished with value: 58.6057412535829 and parameters: {'n_hidden': 4, 'learning_rate': 0.004114977040344646, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07013824890402964, 'dropout_rate_Layer_2': 0.37087473371208146, 'dropout_rate_Layer_3': 0.07575421920975267, 'dropout_rate_Layer_4': 0.2871755357160777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002846362563556546, 'l1_Layer_2': 0.012403561837924971, 'l1_Layer_3': 0.031065608271759686, 'l1_Layer_4': 0.00014661704745820613, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 100, 'n_units_Layer_4': 70}. Best is trial 12 with value: 44.28929827499879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.61 | sMAPE for Validation Set is: 27.68% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 20.62 | sMAPE for Test Set is: 24.74% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:07:07,296]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:07,482]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:13,718]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:14,047]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:20,442]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:25,181]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:30,245]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:35,262]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:41,473]\u001b[0m Trial 71 finished with value: 46.15354172548546 and parameters: {'n_hidden': 4, 'learning_rate': 0.004220994203434234, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1198033933709375, 'dropout_rate_Layer_2': 0.17497567539406944, 'dropout_rate_Layer_3': 0.09288481396833968, 'dropout_rate_Layer_4': 0.10455974120026876, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0035001946881652265, 'l1_Layer_2': 5.61161314745006e-05, 'l1_Layer_3': 0.023056567703778376, 'l1_Layer_4': 0.0002873972310170069, 'n_units_Layer_1': 145, 'n_units_Layer_2': 100, 'n_units_Layer_3': 110, 'n_units_Layer_4': 300}. Best is trial 12 with value: 44.28929827499879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.15 | sMAPE for Validation Set is: 24.22% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 19.68 | sMAPE for Test Set is: 24.83% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:07:43,931]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:44,649]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:49,599]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:52,100]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:52,341]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:55,511]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:57,847]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:07:58,893]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:01,359]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:04,928]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:07,396]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:10,456]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:12,502]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:13,345]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.35 | sMAPE for Validation Set is: 23.74% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 18.71 | sMAPE for Test Set is: 23.80% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:08:17,253]\u001b[0m Trial 74 finished with value: 44.35099435675743 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005111793347938371, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04141620447065524, 'dropout_rate_Layer_2': 0.31367025419716327, 'dropout_rate_Layer_3': 0.2930153309006665, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.514229895825891e-05, 'l1_Layer_2': 0.0007340871648558912, 'l1_Layer_3': 0.028286510786690124, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 265}. Best is trial 12 with value: 44.28929827499879.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:22,102]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:24,182]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:28,227]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:28,425]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:29,318]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:35,010]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:35,390]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:39,944]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:42,948]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:08:47,866]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:08,176]\u001b[0m Trial 99 finished with value: 65.8552105440907 and parameters: {'n_hidden': 3, 'learning_rate': 0.031459169457121954, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17843164047968216, 'dropout_rate_Layer_2': 0.03926081208970054, 'dropout_rate_Layer_3': 0.2014524138069156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018508091853944018, 'l1_Layer_2': 3.3368182991913915e-05, 'l1_Layer_3': 0.002507708547392381, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 220}. Best is trial 12 with value: 44.28929827499879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.86 | sMAPE for Validation Set is: 30.84% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 23.68 | sMAPE for Test Set is: 28.61% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:09:11,649]\u001b[0m Trial 104 finished with value: 62.8466609406782 and parameters: {'n_hidden': 4, 'learning_rate': 0.005217250248440885, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07763702139231586, 'dropout_rate_Layer_2': 0.29419038751454657, 'dropout_rate_Layer_3': 0.24036721650035014, 'dropout_rate_Layer_4': 0.057451646947000674, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005016231143806773, 'l1_Layer_2': 0.001995087453509888, 'l1_Layer_3': 0.0020408322402696594, 'l1_Layer_4': 0.005084516458948722, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 155, 'n_units_Layer_4': 205}. Best is trial 12 with value: 44.28929827499879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.85 | sMAPE for Validation Set is: 29.23% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 23.70 | sMAPE for Test Set is: 27.62% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:09:15,776]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:19,308]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:21,176]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:26,114]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:27,939]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:33,411]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:36,342]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:39,787]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:42,203]\u001b[0m Trial 107 finished with value: 60.82103106405481 and parameters: {'n_hidden': 4, 'learning_rate': 0.005226445326441739, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07771344448775118, 'dropout_rate_Layer_2': 0.30853425576998, 'dropout_rate_Layer_3': 0.24745960976610348, 'dropout_rate_Layer_4': 0.08525548972915303, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0036919080899412327, 'l1_Layer_2': 0.001042366335132793, 'l1_Layer_3': 0.0023426796626689686, 'l1_Layer_4': 0.002836622633836263, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 80, 'n_units_Layer_4': 220}. Best is trial 12 with value: 44.28929827499879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.82 | sMAPE for Validation Set is: 28.53% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 23.51 | sMAPE for Test Set is: 28.70% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:09:44,104]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:47,586]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:51,137]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:51,447]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:09:59,177]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:02,901]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:08,430]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:18,734]\u001b[0m Trial 121 finished with value: 62.73290973172285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022775259994415272, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004275989680246367, 'dropout_rate_Layer_2': 0.3617493557933459, 'dropout_rate_Layer_3': 0.3130908956952979, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001283888293689256, 'l1_Layer_2': 0.003925679726613832, 'l1_Layer_3': 0.0004883518914725782, 'n_units_Layer_1': 250, 'n_units_Layer_2': 85, 'n_units_Layer_3': 195}. Best is trial 12 with value: 44.28929827499879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.73 | sMAPE for Validation Set is: 29.19% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 19.47 | sMAPE for Test Set is: 23.54% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:10:25,190]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:27,492]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:29,933]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:31,842]\u001b[0m Trial 124 finished with value: 62.02029405635606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021115970458433523, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013964552903787258, 'dropout_rate_Layer_2': 0.23358726580611414, 'dropout_rate_Layer_3': 0.31121482400739114, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016990646685686888, 'l1_Layer_2': 0.0028063568636922257, 'l1_Layer_3': 0.00045327980075904984, 'n_units_Layer_1': 245, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210}. Best is trial 12 with value: 44.28929827499879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.02 | sMAPE for Validation Set is: 29.00% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 18.35 | sMAPE for Test Set is: 22.69% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:10:34,987]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:36,123]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:37,574]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:41,022]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:45,660]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:48,561]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:53,134]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:55,698]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:10:58,468]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:00,787]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:03,742]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:07,689]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:07,931]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:13,922]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:14,174]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:14,894]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:20,845]\u001b[0m Trial 130 finished with value: 43.830577110083745 and parameters: {'n_hidden': 3, 'learning_rate': 0.002361763541722229, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20336213616578802, 'dropout_rate_Layer_2': 0.08141018498457181, 'dropout_rate_Layer_3': 0.3626098291292945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.628305905330851e-05, 'l1_Layer_2': 0.00874809786306099, 'l1_Layer_3': 1.4930424001751951e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 185, 'n_units_Layer_3': 250}. Best is trial 130 with value: 43.830577110083745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.83 | sMAPE for Validation Set is: 23.17% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 18.52 | sMAPE for Test Set is: 24.10% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:11:21,336]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:26,867]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:30,565]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:30,626]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:34,300]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:37,491]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:41,096]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:45,983]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:46,423]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:51,696]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:51,939]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:11:56,634]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:02,359]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:03,282]\u001b[0m Trial 144 finished with value: 41.75599061800823 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018609452744713145, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00045382364810553355, 'dropout_rate_Layer_2': 0.397676870667338, 'dropout_rate_Layer_3': 0.021828560476480546, 'dropout_rate_Layer_4': 0.002993843442487931, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.5892701759688394e-05, 'l1_Layer_2': 0.0008837609917429129, 'l1_Layer_3': 0.00030416678234840587, 'l1_Layer_4': 0.0041831458651249405, 'n_units_Layer_1': 225, 'n_units_Layer_2': 295, 'n_units_Layer_3': 140, 'n_units_Layer_4': 50}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.76 | sMAPE for Validation Set is: 22.69% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.24 | sMAPE for Test Set is: 21.25% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:12:08,582]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:10,358]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:11,209]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:16,172]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:18,808]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:18,836]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:24,704]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:25,137]\u001b[0m Trial 152 finished with value: 44.20065040800242 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014018161895909848, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22415252040142378, 'dropout_rate_Layer_2': 0.08479385486106485, 'dropout_rate_Layer_3': 0.3886989091827502, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.4471885511537904e-05, 'l1_Layer_2': 0.0034766187219627594, 'l1_Layer_3': 1.2392690184047344e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 225, 'n_units_Layer_3': 230}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.20 | sMAPE for Validation Set is: 23.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 18.38 | sMAPE for Test Set is: 23.40% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:12:27,577]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:29,659]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:32,239]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:36,600]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:38,996]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:42,110]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:45,734]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:49,120]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:50,039]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:51,989]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:53,569]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:12:56,309]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:01,429]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:02,026]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:03,360]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:07,858]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:08,174]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:08,633]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:08,713]\u001b[0m Trial 177 finished with value: 94.32122059065539 and parameters: {'n_hidden': 3, 'learning_rate': 0.03502313403682787, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0021346005332578966, 'dropout_rate_Layer_2': 0.3986233901008838, 'dropout_rate_Layer_3': 0.02036555193058956, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.917542739212077e-05, 'l1_Layer_2': 0.0013217819956512257, 'l1_Layer_3': 0.00018443346032045186, 'n_units_Layer_1': 295, 'n_units_Layer_2': 255, 'n_units_Layer_3': 240}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 94.32 | sMAPE for Validation Set is: 41.97% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 35.79 | sMAPE for Test Set is: 33.34% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:13:16,450]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:16,646]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:17,016]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:17,805]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:24,939]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:27,361]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:28,795]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:32,559]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:32,726]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:35,169]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:40,553]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:44,304]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:13:54,279]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:14:00,061]\u001b[0m Trial 196 finished with value: 46.131969300097815 and parameters: {'n_hidden': 3, 'learning_rate': 0.003768411307094514, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05428186342902141, 'dropout_rate_Layer_2': 0.20788677942270217, 'dropout_rate_Layer_3': 0.1901321223799826, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02793786052495678, 'l1_Layer_2': 0.04969612828290835, 'l1_Layer_3': 0.000248834348978578, 'n_units_Layer_1': 245, 'n_units_Layer_2': 75, 'n_units_Layer_3': 210}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.13 | sMAPE for Validation Set is: 23.75% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.08 | sMAPE for Test Set is: 25.33% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:14:03,925]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:14:05,065]\u001b[0m Trial 198 finished with value: 48.919550339931426 and parameters: {'n_hidden': 3, 'learning_rate': 0.004264056191204536, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3556333305930921, 'dropout_rate_Layer_2': 0.13819438097117134, 'dropout_rate_Layer_3': 0.19834042063475324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005525444763521837, 'l1_Layer_2': 0.008565793351127724, 'l1_Layer_3': 0.03422364254145469, 'n_units_Layer_1': 145, 'n_units_Layer_2': 125, 'n_units_Layer_3': 230}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.92 | sMAPE for Validation Set is: 25.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.16 | sMAPE for Test Set is: 25.47% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:14:06,398]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:14:13,932]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:14:18,421]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:14:24,541]\u001b[0m Trial 202 finished with value: 48.74054994769602 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034498583850560193, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01423964363203302, 'dropout_rate_Layer_2': 0.1250957997594231, 'dropout_rate_Layer_3': 0.1989641069786637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09801503795913137, 'l1_Layer_2': 0.003123124543069037, 'l1_Layer_3': 9.077218985577416e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.74 | sMAPE for Validation Set is: 25.27% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 22.15 | sMAPE for Test Set is: 27.74% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:14:36,968]\u001b[0m Trial 206 finished with value: 52.5724832015153 and parameters: {'n_hidden': 3, 'learning_rate': 0.003230833847506396, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38056849786632624, 'dropout_rate_Layer_2': 0.1286305069247453, 'dropout_rate_Layer_3': 0.3121150649048522, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.74557718060106e-05, 'l1_Layer_2': 0.009642137595817673, 'l1_Layer_3': 0.029556767981308987, 'n_units_Layer_1': 150, 'n_units_Layer_2': 125, 'n_units_Layer_3': 295}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.57 | sMAPE for Validation Set is: 26.30% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.93 | sMAPE for Test Set is: 25.89% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:14:39,213]\u001b[0m Trial 203 finished with value: 43.29609614731462 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034552180877661, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008329642975727431, 'dropout_rate_Layer_2': 0.13263993178550182, 'dropout_rate_Layer_3': 0.19087685824828385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000301531914413147, 'l1_Layer_2': 0.01759618468250848, 'l1_Layer_3': 7.819367519453344e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 90, 'n_units_Layer_3': 250}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.30 | sMAPE for Validation Set is: 23.19% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 23.43 | sMAPE for Test Set is: 31.09% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:14:44,036]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:14:50,145]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:14:50,789]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:14:55,546]\u001b[0m Trial 207 finished with value: 49.02830905781112 and parameters: {'n_hidden': 3, 'learning_rate': 0.002654446549012992, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009376966908514535, 'dropout_rate_Layer_2': 0.13711623675266338, 'dropout_rate_Layer_3': 0.18872653275101442, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0826289907337986, 'l1_Layer_2': 0.094591138108745, 'l1_Layer_3': 5.8593020928988346e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 90, 'n_units_Layer_3': 100}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.03 | sMAPE for Validation Set is: 25.07% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.05 | sMAPE for Test Set is: 24.79% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:14:56,474]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:14:59,986]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:15:02,604]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:15:05,703]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:15:09,637]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:15:10,092]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:15:13,262]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:15:19,380]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:15:23,367]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:15:29,256]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:15:45,646]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:15:48,483]\u001b[0m Trial 216 finished with value: 42.46941153897032 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032135674303115434, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16145516031129212, 'dropout_rate_Layer_2': 0.06513884329830145, 'dropout_rate_Layer_3': 0.08165090600188012, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.840252897794189e-05, 'l1_Layer_2': 2.5454086515223287e-05, 'l1_Layer_3': 0.006253327885884082, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 135}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.47 | sMAPE for Validation Set is: 23.45% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 22.32 | sMAPE for Test Set is: 27.11% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:15:50,945]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:15:55,881]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:16:08,141]\u001b[0m Trial 225 finished with value: 48.792945510022456 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026999110153339946, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03153010326993762, 'dropout_rate_Layer_2': 0.05510839629668465, 'dropout_rate_Layer_3': 0.1603273404956026, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09991196627543843, 'l1_Layer_2': 0.037238811379789565, 'l1_Layer_3': 4.9526230367516275e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 70, 'n_units_Layer_3': 80}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.79 | sMAPE for Validation Set is: 24.94% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.04 | sMAPE for Test Set is: 26.01% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:16:11,061]\u001b[0m Trial 223 finished with value: 45.47419419302842 and parameters: {'n_hidden': 3, 'learning_rate': 0.002709879727860027, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02648916896922647, 'dropout_rate_Layer_2': 0.08158534914904568, 'dropout_rate_Layer_3': 0.16232102495376008, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09358670512125672, 'l1_Layer_2': 0.09504683809122416, 'l1_Layer_3': 3.4772659940190736e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 70, 'n_units_Layer_3': 80}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.47 | sMAPE for Validation Set is: 23.77% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 18.16 | sMAPE for Test Set is: 22.88% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:16:15,512]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:16:16,299]\u001b[0m Trial 219 finished with value: 50.61151829708888 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009882737255087813, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3088782483721891, 'dropout_rate_Layer_2': 0.24797320203824574, 'dropout_rate_Layer_3': 0.07996234508462913, 'dropout_rate_Layer_4': 0.382043043655368, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005140883012448938, 'l1_Layer_2': 0.0005008057439888366, 'l1_Layer_3': 0.0811330458229986, 'l1_Layer_4': 0.07240774373866875, 'n_units_Layer_1': 190, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260, 'n_units_Layer_4': 295}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.61 | sMAPE for Validation Set is: 25.95% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.21 | sMAPE for Test Set is: 24.75% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:16:16,813]\u001b[0m Trial 227 finished with value: 48.390673404654535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027648313710974494, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03230097878680618, 'dropout_rate_Layer_2': 0.0769476459473919, 'dropout_rate_Layer_3': 0.16069622847852072, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09866846572100803, 'l1_Layer_2': 0.04178685296050421, 'l1_Layer_3': 3.699321741158347e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 95, 'n_units_Layer_3': 85}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.39 | sMAPE for Validation Set is: 24.76% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.83 | sMAPE for Test Set is: 24.25% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:16:23,175]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:16:26,000]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:16:28,915]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:16:33,555]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:16:37,655]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:16:43,982]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:16:44,246]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:16:44,647]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:16:51,935]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:16:52,083]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:16:54,027]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:17:01,540]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:17:05,398]\u001b[0m Trial 229 finished with value: 42.039656429684804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035138879225636, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16539112324422992, 'dropout_rate_Layer_2': 0.0868527874625989, 'dropout_rate_Layer_3': 0.0002037040837423185, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.348151647071075e-05, 'l1_Layer_2': 0.0006086427323053435, 'l1_Layer_3': 0.00041360403650795853, 'n_units_Layer_1': 70, 'n_units_Layer_2': 165, 'n_units_Layer_3': 240}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.04 | sMAPE for Validation Set is: 23.46% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 20.99 | sMAPE for Test Set is: 27.42% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:17:06,013]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:17:22,808]\u001b[0m Trial 242 finished with value: 49.57361798367242 and parameters: {'n_hidden': 3, 'learning_rate': 0.001664456701326253, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05093840065031478, 'dropout_rate_Layer_2': 0.08188800817740263, 'dropout_rate_Layer_3': 0.13581102909928827, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026812712649378397, 'l1_Layer_2': 0.0872602621601248, 'l1_Layer_3': 8.622801858762195e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.57 | sMAPE for Validation Set is: 25.20% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.23 | sMAPE for Test Set is: 24.79% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:17:26,704]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:17:29,886]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:17:34,327]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:17:41,031]\u001b[0m Trial 245 finished with value: 43.798518470083984 and parameters: {'n_hidden': 3, 'learning_rate': 0.0043971772080522945, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17220828475270683, 'dropout_rate_Layer_2': 0.08991043807879595, 'dropout_rate_Layer_3': 0.029189724421932305, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.199991326453501e-05, 'l1_Layer_2': 0.0007903555547478087, 'l1_Layer_3': 0.0005377226993135771, 'n_units_Layer_1': 85, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.80 | sMAPE for Validation Set is: 23.89% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 19.04 | sMAPE for Test Set is: 24.58% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:17:44,928]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:17:47,735]\u001b[0m Trial 244 finished with value: 49.746793252338456 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017430086134994883, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05269341990486357, 'dropout_rate_Layer_2': 0.018816102287812247, 'dropout_rate_Layer_3': 0.16803371198595315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.028323504055837907, 'l1_Layer_2': 0.09546547744222957, 'l1_Layer_3': 0.00010050498507001219, 'n_units_Layer_1': 285, 'n_units_Layer_2': 100, 'n_units_Layer_3': 275}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.75 | sMAPE for Validation Set is: 25.00% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.64 | sMAPE for Test Set is: 24.28% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:17:52,232]\u001b[0m Trial 249 finished with value: 48.46646404240605 and parameters: {'n_hidden': 3, 'learning_rate': 0.002671921633612831, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02866791121734404, 'dropout_rate_Layer_2': 0.057038211448488814, 'dropout_rate_Layer_3': 0.15573476401354586, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09946652853067377, 'l1_Layer_2': 0.04218522232812509, 'l1_Layer_3': 0.00011008961188218794, 'n_units_Layer_1': 240, 'n_units_Layer_2': 70, 'n_units_Layer_3': 75}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.47 | sMAPE for Validation Set is: 24.81% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.57 | sMAPE for Test Set is: 25.53% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:17:52,595]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:18:07,197]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:18:13,780]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:18:18,996]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:18:21,183]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:18:25,072]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:18:31,812]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:18:34,314]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:18:37,243]\u001b[0m Trial 252 finished with value: 44.1498685589849 and parameters: {'n_hidden': 3, 'learning_rate': 0.00566104365221442, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15843189857701886, 'dropout_rate_Layer_2': 0.11689452504040995, 'dropout_rate_Layer_3': 0.018171457200142942, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.9839452542605665e-05, 'l1_Layer_2': 0.0009877762665849378, 'l1_Layer_3': 0.0005668018652827815, 'n_units_Layer_1': 85, 'n_units_Layer_2': 155, 'n_units_Layer_3': 250}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.15 | sMAPE for Validation Set is: 24.27% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 23.46 | sMAPE for Test Set is: 30.04% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:18:41,623]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:18:50,075]\u001b[0m Trial 257 finished with value: 47.59648822887427 and parameters: {'n_hidden': 4, 'learning_rate': 0.009462556647355734, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18150936928375905, 'dropout_rate_Layer_2': 0.24016202899782646, 'dropout_rate_Layer_3': 0.25175730843759475, 'dropout_rate_Layer_4': 0.1745623486413605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005585927812616219, 'l1_Layer_2': 0.004468125364129236, 'l1_Layer_3': 0.0005965680865335169, 'l1_Layer_4': 0.0003898742894917131, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 260, 'n_units_Layer_4': 180}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.60 | sMAPE for Validation Set is: 25.03% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.08 | sMAPE for Test Set is: 25.63% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:18:52,861]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:18:55,050]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:18:58,062]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:18:59,714]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:00,588]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:06,291]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:06,722]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:07,047]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:13,783]\u001b[0m Trial 264 finished with value: 47.32819669773237 and parameters: {'n_hidden': 4, 'learning_rate': 0.008849699751910722, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3206823608302968, 'dropout_rate_Layer_2': 0.2313681357741008, 'dropout_rate_Layer_3': 0.24001225367846563, 'dropout_rate_Layer_4': 0.17631359107682687, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008918582362487215, 'l1_Layer_2': 0.00488402176275594, 'l1_Layer_3': 0.0005660842890345316, 'l1_Layer_4': 0.00020002111992787055, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 260, 'n_units_Layer_4': 175}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.33 | sMAPE for Validation Set is: 24.48% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 19.00 | sMAPE for Test Set is: 23.51% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:19:14,039]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:14,302]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:18,885]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:22,728]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:23,113]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:27,073]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:27,616]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:32,503]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:34,499]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:34,942]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:35,619]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:37,767]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:44,703]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:19:51,818]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:20:05,197]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:20:08,538]\u001b[0m Trial 283 finished with value: 48.46330695783626 and parameters: {'n_hidden': 4, 'learning_rate': 0.013127608015211758, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19452678372342588, 'dropout_rate_Layer_2': 0.26636397770781584, 'dropout_rate_Layer_3': 0.24501944735259257, 'dropout_rate_Layer_4': 0.17647597337727028, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0070367047755861955, 'l1_Layer_2': 0.0005165504773931145, 'l1_Layer_3': 0.00033870106050962174, 'l1_Layer_4': 0.0003013287529617706, 'n_units_Layer_1': 120, 'n_units_Layer_2': 190, 'n_units_Layer_3': 280, 'n_units_Layer_4': 175}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.46 | sMAPE for Validation Set is: 25.00% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.92 | sMAPE for Test Set is: 27.78% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:20:16,031]\u001b[0m Trial 284 finished with value: 43.223742612927765 and parameters: {'n_hidden': 3, 'learning_rate': 0.003228428420691525, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16080664041596662, 'dropout_rate_Layer_2': 0.27837686754843527, 'dropout_rate_Layer_3': 0.03768785010582393, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.136197295079207e-05, 'l1_Layer_2': 0.00036962645669848737, 'l1_Layer_3': 0.00018548668880362387, 'n_units_Layer_1': 95, 'n_units_Layer_2': 160, 'n_units_Layer_3': 235}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.22 | sMAPE for Validation Set is: 23.39% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.73 | sMAPE for Test Set is: 23.30% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:20:18,427]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:20:21,501]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:20:22,271]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:20:22,531]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:20:32,336]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:20:34,884]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:20:41,622]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:20:41,934]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:20:47,798]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:20:49,510]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:20:55,156]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:21:06,852]\u001b[0m Trial 296 finished with value: 49.15259750591309 and parameters: {'n_hidden': 4, 'learning_rate': 0.010460524516465071, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1654515083299503, 'dropout_rate_Layer_2': 0.34386569643054293, 'dropout_rate_Layer_3': 0.29179126077626877, 'dropout_rate_Layer_4': 0.2609701921902948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07780285771588037, 'l1_Layer_2': 0.003465720833410975, 'l1_Layer_3': 5.754862108585279e-05, 'l1_Layer_4': 0.00011208220109019116, 'n_units_Layer_1': 210, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300, 'n_units_Layer_4': 135}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.15 | sMAPE for Validation Set is: 24.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.51 | sMAPE for Test Set is: 25.03% | rMAE for Test Set is: 0.73\n",
      "MAE for Validation Set is: 48.73 | sMAPE for Validation Set is: 24.81% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.96 | sMAPE for Test Set is: 26.09% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:21:09,093]\u001b[0m Trial 300 finished with value: 48.726597073198015 and parameters: {'n_hidden': 3, 'learning_rate': 0.002535718994314009, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025532740322191088, 'dropout_rate_Layer_2': 0.05632458336123279, 'dropout_rate_Layer_3': 0.15736144802132424, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07202206326512464, 'l1_Layer_2': 0.0305692285655296, 'l1_Layer_3': 2.063211809777935e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 70, 'n_units_Layer_3': 105}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:21:12,161]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:21:13,867]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:21:22,520]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:21:27,830]\u001b[0m Trial 288 finished with value: 48.84164490835625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009908342729314844, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0003454481153793709, 'dropout_rate_Layer_2': 0.15219956164686965, 'dropout_rate_Layer_3': 0.1805981421589032, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06928416887423339, 'l1_Layer_2': 0.06511535321841774, 'l1_Layer_3': 3.9063106937879235e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 75, 'n_units_Layer_3': 135}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.84 | sMAPE for Validation Set is: 25.00% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.35 | sMAPE for Test Set is: 25.23% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:21:28,659]\u001b[0m Trial 302 finished with value: 43.50444288164987 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021981176647694707, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11009776687403444, 'dropout_rate_Layer_2': 0.292709287629464, 'dropout_rate_Layer_3': 0.010591981048652959, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.0129941392026934e-05, 'l1_Layer_2': 0.000718286010216842, 'l1_Layer_3': 0.002914699760615584, 'n_units_Layer_1': 70, 'n_units_Layer_2': 165, 'n_units_Layer_3': 235}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.50 | sMAPE for Validation Set is: 23.17% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 16.93 | sMAPE for Test Set is: 21.75% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:21:33,390]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:21:38,463]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:21:43,923]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:21:45,909]\u001b[0m Trial 307 finished with value: 48.21739665098917 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024274704542087172, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01831762356444714, 'dropout_rate_Layer_2': 0.03650221676372628, 'dropout_rate_Layer_3': 0.1998697215491373, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06842466227058552, 'l1_Layer_2': 0.00811554028728025, 'l1_Layer_3': 1.887965477704753e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 75, 'n_units_Layer_3': 105}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.22 | sMAPE for Validation Set is: 24.85% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 20.98 | sMAPE for Test Set is: 26.12% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:21:49,710]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:21:49,867]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:21:51,480]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:21:54,560]\u001b[0m Trial 306 finished with value: 43.03093346269437 and parameters: {'n_hidden': 3, 'learning_rate': 0.001923979644819501, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.159181355363573, 'dropout_rate_Layer_2': 0.3014794616006821, 'dropout_rate_Layer_3': 0.009610518124068854, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.102210096559943e-05, 'l1_Layer_2': 0.0006949770772799757, 'l1_Layer_3': 0.0001434087712985531, 'n_units_Layer_1': 100, 'n_units_Layer_2': 135, 'n_units_Layer_3': 120}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.03 | sMAPE for Validation Set is: 23.38% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 20.28 | sMAPE for Test Set is: 25.99% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:21:58,838]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:22:01,056]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:22:04,078]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:22:04,324]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:22:06,194]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:22:12,561]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:22:22,426]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:22:30,609]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:22:41,895]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:22:52,356]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:22:57,345]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:22:58,032]\u001b[0m Trial 324 finished with value: 42.075381721131635 and parameters: {'n_hidden': 3, 'learning_rate': 0.004074121345306135, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024985792587384776, 'dropout_rate_Layer_2': 0.0011190679318680147, 'dropout_rate_Layer_3': 0.1968927506424132, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014761131782271175, 'l1_Layer_2': 0.030051364677996805, 'l1_Layer_3': 1.0264050966656656e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 60}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.08 | sMAPE for Validation Set is: 22.62% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.03 | sMAPE for Test Set is: 25.44% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:23:09,290]\u001b[0m Trial 320 finished with value: 43.069685441217835 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020363500069516577, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14064332389880219, 'dropout_rate_Layer_2': 0.09367679877255254, 'dropout_rate_Layer_3': 0.0335762453849832, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4955141063941355e-05, 'l1_Layer_2': 0.0007415651803006614, 'l1_Layer_3': 0.0030632460300013837, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 225}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.07 | sMAPE for Validation Set is: 23.10% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.31 | sMAPE for Test Set is: 21.87% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:23:09,514]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:23:16,579]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:23:18,675]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:23:21,776]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:23:25,306]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:23:25,932]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:23:31,859]\u001b[0m Trial 328 finished with value: 42.54471901262051 and parameters: {'n_hidden': 3, 'learning_rate': 0.004343095581181586, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04531741403078117, 'dropout_rate_Layer_2': 0.0018174879094411656, 'dropout_rate_Layer_3': 0.1970335595993332, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.001398756903652e-05, 'l1_Layer_2': 0.019043603521591016, 'l1_Layer_3': 1.1487980134206597e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 105, 'n_units_Layer_3': 60}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.54 | sMAPE for Validation Set is: 22.57% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.60 | sMAPE for Test Set is: 25.51% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:23:36,013]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:23:37,567]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:23:41,813]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:23:44,673]\u001b[0m Trial 331 finished with value: 45.367794954292826 and parameters: {'n_hidden': 3, 'learning_rate': 0.004196455957081042, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07365119715832073, 'dropout_rate_Layer_2': 0.013893740032375613, 'dropout_rate_Layer_3': 0.19726279491466703, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.157396521905377e-05, 'l1_Layer_2': 0.0506787268454634, 'l1_Layer_3': 1.0110242205022665e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 105, 'n_units_Layer_3': 65}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.37 | sMAPE for Validation Set is: 23.69% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.23 | sMAPE for Test Set is: 25.26% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:23:47,692]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:24:05,080]\u001b[0m Trial 341 finished with value: 43.934179741213 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016316067560315283, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2040203253063113, 'dropout_rate_Layer_2': 0.16146752966927427, 'dropout_rate_Layer_3': 0.03079111975044764, 'dropout_rate_Layer_4': 0.01979631363521166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.8301502274710244e-05, 'l1_Layer_2': 0.0013596099420483858, 'l1_Layer_3': 0.0005484340071218129, 'l1_Layer_4': 1.9095487967849673e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 70, 'n_units_Layer_3': 145, 'n_units_Layer_4': 55}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.93 | sMAPE for Validation Set is: 23.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 16.42 | sMAPE for Test Set is: 21.09% | rMAE for Test Set is: 0.56\n",
      "MAE for Validation Set is: 43.31 | sMAPE for Validation Set is: 22.95% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 18.82 | sMAPE for Test Set is: 24.02% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:24:05,242]\u001b[0m Trial 338 finished with value: 43.31158720185192 and parameters: {'n_hidden': 3, 'learning_rate': 0.004662767528039761, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04164721801001736, 'dropout_rate_Layer_2': 0.014412106544236856, 'dropout_rate_Layer_3': 0.23543458054651556, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.481841734367591e-05, 'l1_Layer_2': 0.048718753843528126, 'l1_Layer_3': 7.170353515886495e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 105, 'n_units_Layer_3': 60}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:24:05,693]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:24:14,621]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:24:15,722]\u001b[0m Trial 342 finished with value: 42.27911433256316 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015302915179219183, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20925850669112045, 'dropout_rate_Layer_2': 0.13069083517074154, 'dropout_rate_Layer_3': 0.02062011634590189, 'dropout_rate_Layer_4': 0.006190988105770175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.138373069419194e-05, 'l1_Layer_2': 0.0014812651836628157, 'l1_Layer_3': 0.0005634656520178981, 'l1_Layer_4': 1.2331792599318705e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 60, 'n_units_Layer_3': 140, 'n_units_Layer_4': 55}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.28 | sMAPE for Validation Set is: 22.61% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 15.96 | sMAPE for Test Set is: 20.77% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:24:22,512]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:24:29,215]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:24:34,412]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:24:38,407]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:24:38,725]\u001b[0m Trial 343 finished with value: 44.83601669840751 and parameters: {'n_hidden': 3, 'learning_rate': 0.004171054061097665, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.096063524305646, 'dropout_rate_Layer_2': 0.017578095377209883, 'dropout_rate_Layer_3': 0.23341999527157553, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.1179607275690205e-05, 'l1_Layer_2': 0.010565457204581177, 'l1_Layer_3': 1.3510078350920452e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 105, 'n_units_Layer_3': 60}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.84 | sMAPE for Validation Set is: 24.11% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 23.72 | sMAPE for Test Set is: 30.82% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:24:45,085]\u001b[0m Trial 346 finished with value: 44.57904094606361 and parameters: {'n_hidden': 3, 'learning_rate': 0.004272380882110291, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09608585763832678, 'dropout_rate_Layer_2': 0.04033157135420211, 'dropout_rate_Layer_3': 0.23175152935595383, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.343889281250246e-05, 'l1_Layer_2': 0.011287559995815663, 'l1_Layer_3': 1.2492056042980173e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 105, 'n_units_Layer_3': 60}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.58 | sMAPE for Validation Set is: 23.82% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 21.24 | sMAPE for Test Set is: 26.94% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:24:48,358]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:24:55,006]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:24:57,065]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:24:58,292]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:25:09,591]\u001b[0m Trial 356 finished with value: 129.22258402639372 and parameters: {'n_hidden': 4, 'learning_rate': 0.0672053824463547, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04967005371765579, 'dropout_rate_Layer_2': 0.26845714234623175, 'dropout_rate_Layer_3': 0.16774625102132878, 'dropout_rate_Layer_4': 0.12620721500887644, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00462406714675259, 'l1_Layer_2': 0.00206147572335307, 'l1_Layer_3': 0.0003984770242839056, 'l1_Layer_4': 0.0008510639551498802, 'n_units_Layer_1': 130, 'n_units_Layer_2': 155, 'n_units_Layer_3': 260, 'n_units_Layer_4': 205}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 129.22 | sMAPE for Validation Set is: 75.40% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 74.31 | sMAPE for Test Set is: 105.69% | rMAE for Test Set is: 2.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:25:11,906]\u001b[0m Trial 352 finished with value: 46.11636809791711 and parameters: {'n_hidden': 3, 'learning_rate': 0.004445585185789948, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09782138959366754, 'dropout_rate_Layer_2': 0.012207273299264763, 'dropout_rate_Layer_3': 0.23869725711969, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.029891396238981e-05, 'l1_Layer_2': 0.05393103382199902, 'l1_Layer_3': 1.2656335270398111e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.12 | sMAPE for Validation Set is: 23.93% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.64 | sMAPE for Test Set is: 26.32% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:25:16,016]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:25:23,906]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:25:29,512]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:25:34,597]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:25:37,277]\u001b[0m Trial 357 finished with value: 43.927591261148336 and parameters: {'n_hidden': 3, 'learning_rate': 0.002292261877851556, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10720967871001777, 'dropout_rate_Layer_2': 0.2852070307459168, 'dropout_rate_Layer_3': 0.01978060404818894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.981765608398457e-05, 'l1_Layer_2': 2.9935570292087758e-05, 'l1_Layer_3': 1.009654443013289e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 135, 'n_units_Layer_3': 235}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.93 | sMAPE for Validation Set is: 23.12% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 17.98 | sMAPE for Test Set is: 23.45% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:25:41,265]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:25:47,620]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:25:48,077]\u001b[0m Trial 360 finished with value: 43.92342278228514 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010163833293185055, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2876987720475175, 'dropout_rate_Layer_2': 0.17882972318952187, 'dropout_rate_Layer_3': 0.028086664905784885, 'dropout_rate_Layer_4': 0.0021511813060760866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.608480919838024e-05, 'l1_Layer_2': 0.00028850683447891794, 'l1_Layer_3': 0.0021324984463180156, 'l1_Layer_4': 3.21724319657832e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 65, 'n_units_Layer_3': 190, 'n_units_Layer_4': 300}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.92 | sMAPE for Validation Set is: 23.13% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 16.69 | sMAPE for Test Set is: 21.67% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:25:54,495]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:25:57,429]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:26:02,310]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:26:09,118]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:26:12,726]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:26:20,357]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:26:27,473]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.66 | sMAPE for Validation Set is: 23.37% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 17.90 | sMAPE for Test Set is: 22.59% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:26:27,659]\u001b[0m Trial 368 finished with value: 44.66181710078896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021404699131580664, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12108176905184605, 'dropout_rate_Layer_2': 0.30168746940859015, 'dropout_rate_Layer_3': 0.027005681110986588, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.480882562597565e-05, 'l1_Layer_2': 2.8235019426911143e-05, 'l1_Layer_3': 1.5738873581607965e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 230}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:26:35,440]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:26:47,459]\u001b[0m Trial 371 finished with value: 43.24518413763693 and parameters: {'n_hidden': 3, 'learning_rate': 0.0046392649970772165, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08403865583434515, 'dropout_rate_Layer_2': 0.036030956229665234, 'dropout_rate_Layer_3': 0.24511438190825174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.5253631848067514e-05, 'l1_Layer_2': 0.005332121254531032, 'l1_Layer_3': 1.403288511344502e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 110, 'n_units_Layer_3': 50}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.25 | sMAPE for Validation Set is: 23.15% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 18.96 | sMAPE for Test Set is: 24.56% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:26:52,496]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:26:52,825]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:26:58,440]\u001b[0m Trial 376 finished with value: 44.880567240013534 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009145954510746328, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18667574733048764, 'dropout_rate_Layer_2': 0.06054958669804014, 'dropout_rate_Layer_3': 0.02964400840328916, 'dropout_rate_Layer_4': 0.07594518341876952, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.047011122135491e-05, 'l1_Layer_2': 8.599845985561223e-05, 'l1_Layer_3': 0.0006641175695213211, 'l1_Layer_4': 1.636641658615991e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 125, 'n_units_Layer_3': 240, 'n_units_Layer_4': 170}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.88 | sMAPE for Validation Set is: 23.49% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 17.97 | sMAPE for Test Set is: 22.87% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:26:59,449]\u001b[0m Trial 372 finished with value: 42.50670720313014 and parameters: {'n_hidden': 3, 'learning_rate': 0.005002433545889716, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10866898394250016, 'dropout_rate_Layer_2': 0.00026688424166817744, 'dropout_rate_Layer_3': 0.24136730648549037, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.6857591585040654e-05, 'l1_Layer_2': 0.005261742948056179, 'l1_Layer_3': 1.3801589819991554e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.51 | sMAPE for Validation Set is: 22.88% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.69 | sMAPE for Test Set is: 24.05% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:27:07,022]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:27:11,959]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:27:21,635]\u001b[0m Trial 378 finished with value: 48.47028653821466 and parameters: {'n_hidden': 4, 'learning_rate': 0.011809936863619233, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19108743973116357, 'dropout_rate_Layer_2': 0.29607630651412203, 'dropout_rate_Layer_3': 0.2403957540519226, 'dropout_rate_Layer_4': 0.18591075941380658, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00849955455918186, 'l1_Layer_2': 0.00046429847981139995, 'l1_Layer_3': 0.0008838729953945121, 'l1_Layer_4': 0.0003692636781444475, 'n_units_Layer_1': 135, 'n_units_Layer_2': 200, 'n_units_Layer_3': 280, 'n_units_Layer_4': 170}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.47 | sMAPE for Validation Set is: 24.94% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 18.90 | sMAPE for Test Set is: 23.05% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:27:22,127]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:27:22,839]\u001b[0m Trial 380 finished with value: 47.64878473961597 and parameters: {'n_hidden': 4, 'learning_rate': 0.01193608515542224, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19696452274767057, 'dropout_rate_Layer_2': 0.2867965554238429, 'dropout_rate_Layer_3': 0.24528865003154532, 'dropout_rate_Layer_4': 0.189529207695019, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007370457866728839, 'l1_Layer_2': 0.0005165801406688266, 'l1_Layer_3': 0.0008783706682156043, 'l1_Layer_4': 0.00047910927715561245, 'n_units_Layer_1': 130, 'n_units_Layer_2': 195, 'n_units_Layer_3': 280, 'n_units_Layer_4': 170}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.65 | sMAPE for Validation Set is: 24.42% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.71 | sMAPE for Test Set is: 25.97% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:27:28,951]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:27:35,632]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:27:40,675]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:27:41,190]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:27:49,071]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:27:54,539]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:27:59,054]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:28:01,618]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:28:06,443]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:28:06,962]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:28:13,699]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:28:14,243]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:28:20,951]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:28:22,242]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.69 | sMAPE for Validation Set is: 23.34% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 19.91 | sMAPE for Test Set is: 24.65% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:28:23,740]\u001b[0m Trial 393 finished with value: 44.68731293951777 and parameters: {'n_hidden': 3, 'learning_rate': 0.005933538488929518, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11277492445002252, 'dropout_rate_Layer_2': 0.04539764588610157, 'dropout_rate_Layer_3': 0.2784570978699604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.212729689003055e-05, 'l1_Layer_2': 0.005757804740243118, 'l1_Layer_3': 1.775968873526836e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 130, 'n_units_Layer_3': 50}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:28:27,723]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:28:32,287]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:28:39,659]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:28:43,280]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:28:51,503]\u001b[0m Trial 404 finished with value: 92.05146761723738 and parameters: {'n_hidden': 4, 'learning_rate': 0.019423497514069504, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24984758578846314, 'dropout_rate_Layer_2': 0.3227078314714871, 'dropout_rate_Layer_3': 0.33091360030737843, 'dropout_rate_Layer_4': 0.22970812646539518, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015217763073241994, 'l1_Layer_2': 6.29607577543631e-05, 'l1_Layer_3': 0.0013381179744002024, 'l1_Layer_4': 0.0032633390316040753, 'n_units_Layer_1': 160, 'n_units_Layer_2': 215, 'n_units_Layer_3': 200, 'n_units_Layer_4': 130}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 92.05 | sMAPE for Validation Set is: 40.90% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 47.11 | sMAPE for Test Set is: 41.51% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:28:52,689]\u001b[0m Trial 402 finished with value: 44.2277727575109 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055305751356690795, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11492837869315173, 'dropout_rate_Layer_2': 0.03045105012579605, 'dropout_rate_Layer_3': 0.2650879207568525, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001269473703489821, 'l1_Layer_2': 0.011574025256533135, 'l1_Layer_3': 1.0197697865861211e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 120, 'n_units_Layer_3': 65}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.23 | sMAPE for Validation Set is: 23.61% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 18.34 | sMAPE for Test Set is: 23.93% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:28:55,316]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:00,991]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:04,558]\u001b[0m Trial 401 finished with value: 42.88397386795426 and parameters: {'n_hidden': 3, 'learning_rate': 0.005411243120683693, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11779669213950553, 'dropout_rate_Layer_2': 0.030814566548914422, 'dropout_rate_Layer_3': 0.26926782626871626, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.050066895110968e-05, 'l1_Layer_2': 0.0053265348062420835, 'l1_Layer_3': 1.7482959488419397e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 160, 'n_units_Layer_3': 65}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.88 | sMAPE for Validation Set is: 23.38% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 19.04 | sMAPE for Test Set is: 24.50% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:29:07,162]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:10,166]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:13,122]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:13,283]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:20,290]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:25,111]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:28,976]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:29,595]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:29,695]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:35,004]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:35,735]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:41,539]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:41,658]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:41,816]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:49,842]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:52,027]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:29:57,276]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:00,862]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:01,324]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:09,168]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:14,899]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:15,051]\u001b[0m Trial 420 finished with value: 42.712094163868564 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013208810128915469, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12582500435719546, 'dropout_rate_Layer_2': 0.2968893221358372, 'dropout_rate_Layer_3': 0.2511886198348623, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.229766520042348e-05, 'l1_Layer_2': 2.0939001705868035e-05, 'l1_Layer_3': 1.6042837861007774e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 245}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.71 | sMAPE for Validation Set is: 22.68% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.35 | sMAPE for Test Set is: 22.08% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:30:24,200]\u001b[0m Trial 422 finished with value: 42.55397882007853 and parameters: {'n_hidden': 3, 'learning_rate': 0.004827576316554131, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10614618296441712, 'dropout_rate_Layer_2': 0.02264099755568417, 'dropout_rate_Layer_3': 0.25034410418536623, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.8665358236554927e-05, 'l1_Layer_2': 0.009150683096068188, 'l1_Layer_3': 1.446133547002121e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 130, 'n_units_Layer_3': 65}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.55 | sMAPE for Validation Set is: 23.37% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.07 | sMAPE for Test Set is: 25.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:30:24,512]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:29,221]\u001b[0m Trial 432 finished with value: 202.2179748989972 and parameters: {'n_hidden': 4, 'learning_rate': 0.006076547407385927, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3056605493997589, 'dropout_rate_Layer_2': 0.372861451597606, 'dropout_rate_Layer_3': 0.39956144866770893, 'dropout_rate_Layer_4': 0.2265219300999416, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0042020431545422695, 'l1_Layer_2': 0.00020608785734323518, 'l1_Layer_3': 0.0020236699343786674, 'l1_Layer_4': 3.82080965248521e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 235, 'n_units_Layer_3': 300, 'n_units_Layer_4': 195}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 202.22 | sMAPE for Validation Set is: 126.25% | rMAE for Validation Set is: 2.53\n",
      "MAE for Test Set is: 67.50 | sMAPE for Test Set is: 82.63% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:30:32,150]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:34,676]\u001b[0m Trial 428 finished with value: 43.25748805299151 and parameters: {'n_hidden': 3, 'learning_rate': 0.004875035984112517, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10429648516733489, 'dropout_rate_Layer_2': 0.02599541706079822, 'dropout_rate_Layer_3': 0.25335007980953583, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9587666266609934e-05, 'l1_Layer_2': 0.009371127259190691, 'l1_Layer_3': 2.0564503462274263e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 130, 'n_units_Layer_3': 65}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.26 | sMAPE for Validation Set is: 23.24% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 20.47 | sMAPE for Test Set is: 26.26% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:30:38,234]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:40,843]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:44,347]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:47,089]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:50,296]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:52,915]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:30:57,761]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:31:01,581]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:31:05,174]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:31:05,540]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:31:13,102]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:31:13,682]\u001b[0m Trial 444 finished with value: 102.17169377231953 and parameters: {'n_hidden': 4, 'learning_rate': 0.025164420998853625, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08395861412216848, 'dropout_rate_Layer_2': 0.1699478636796352, 'dropout_rate_Layer_3': 0.26327376785298234, 'dropout_rate_Layer_4': 0.08746578724007661, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.041259830640352414, 'l1_Layer_2': 9.94583356976351e-05, 'l1_Layer_3': 0.001956390958690212, 'l1_Layer_4': 0.00015024778062882279, 'n_units_Layer_1': 85, 'n_units_Layer_2': 165, 'n_units_Layer_3': 115, 'n_units_Layer_4': 230}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 102.17 | sMAPE for Validation Set is: 45.75% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 65.61 | sMAPE for Test Set is: 63.94% | rMAE for Test Set is: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:31:19,217]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:31:19,460]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:31:26,364]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:31:26,657]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:31:36,189]\u001b[0m Trial 434 finished with value: 42.18522883393134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013488396747534698, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1194575187056316, 'dropout_rate_Layer_2': 0.3002807364560489, 'dropout_rate_Layer_3': 0.38314772820233406, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.70016578569037e-05, 'l1_Layer_2': 0.007479513731808463, 'l1_Layer_3': 2.0661409543554276e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 245}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.19 | sMAPE for Validation Set is: 22.45% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.22 | sMAPE for Test Set is: 23.19% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:31:40,274]\u001b[0m Trial 447 finished with value: 44.4407994306487 and parameters: {'n_hidden': 3, 'learning_rate': 0.004893086575293682, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14267814491584724, 'dropout_rate_Layer_2': 0.06447560821593223, 'dropout_rate_Layer_3': 0.256701550995107, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1692038894520831e-05, 'l1_Layer_2': 0.006982359787659104, 'l1_Layer_3': 1.4912481094318702e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.44 | sMAPE for Validation Set is: 24.32% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.61 | sMAPE for Test Set is: 26.27% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:31:44,468]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:31:48,776]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:31:53,377]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:31:56,899]\u001b[0m Trial 454 finished with value: 42.17347283093928 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010266887796709621, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13894371429108784, 'dropout_rate_Layer_2': 0.05475419145007817, 'dropout_rate_Layer_3': 0.08851142926685962, 'dropout_rate_Layer_4': 0.0005331820412247945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001412728987390794, 'l1_Layer_2': 0.000724251908449044, 'l1_Layer_3': 0.0005118296062922691, 'l1_Layer_4': 2.3265413992502163e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 95, 'n_units_Layer_3': 195, 'n_units_Layer_4': 125}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.17 | sMAPE for Validation Set is: 22.57% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.33 | sMAPE for Test Set is: 23.91% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:32:00,277]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:00,332]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:01,098]\u001b[0m Trial 453 finished with value: 42.640811916931604 and parameters: {'n_hidden': 3, 'learning_rate': 0.003496688699151584, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12379334436718308, 'dropout_rate_Layer_2': 0.027958497479788957, 'dropout_rate_Layer_3': 0.28822005766398884, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0539486814725915e-05, 'l1_Layer_2': 0.008824561233159878, 'l1_Layer_3': 3.0066939299642332e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 130, 'n_units_Layer_3': 55}. Best is trial 144 with value: 41.75599061800823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.64 | sMAPE for Validation Set is: 23.07% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.23 | sMAPE for Test Set is: 25.02% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:32:09,201]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:09,379]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:18,265]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:18,960]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:19,176]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.74 | sMAPE for Validation Set is: 22.31% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.72 | sMAPE for Test Set is: 22.60% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:32:24,653]\u001b[0m Trial 460 finished with value: 41.74219490678173 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027549352846297673, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13124445068624335, 'dropout_rate_Layer_2': 0.019385048033601374, 'dropout_rate_Layer_3': 0.07997323947275997, 'dropout_rate_Layer_4': 0.04388200325250621, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013361032401950642, 'l1_Layer_2': 0.0007150751444419535, 'l1_Layer_3': 0.00022970181657645575, 'l1_Layer_4': 6.198766072587815e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 90, 'n_units_Layer_3': 190, 'n_units_Layer_4': 70}. Best is trial 460 with value: 41.74219490678173.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:29,553]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:30,313]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:31,160]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:36,641]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:42,363]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:42,934]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:43,603]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:49,533]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:51,585]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:53,706]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:57,829]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:32:58,446]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:03,212]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:03,809]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:04,057]\u001b[0m Trial 473 finished with value: 42.36386011135048 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026447257322838565, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20648066736434295, 'dropout_rate_Layer_2': 0.03496208045205078, 'dropout_rate_Layer_3': 0.0001889775310733241, 'dropout_rate_Layer_4': 0.034069512096485954, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00037981581090151746, 'l1_Layer_2': 0.000702202026521654, 'l1_Layer_3': 0.00010727193376119752, 'l1_Layer_4': 0.00022488676282042704, 'n_units_Layer_1': 245, 'n_units_Layer_2': 75, 'n_units_Layer_3': 185, 'n_units_Layer_4': 70}. Best is trial 460 with value: 41.74219490678173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.36 | sMAPE for Validation Set is: 22.49% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.39 | sMAPE for Test Set is: 23.03% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:33:11,309]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:14,731]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:18,359]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:20,142]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:23,772]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:26,461]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:28,617]\u001b[0m Trial 484 finished with value: 43.881305311243956 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028333099799537206, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12962384226325008, 'dropout_rate_Layer_2': 0.029228502462658703, 'dropout_rate_Layer_3': 0.01227278942313418, 'dropout_rate_Layer_4': 0.0452379893121942, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00036929759472678576, 'l1_Layer_2': 0.0006537143171615393, 'l1_Layer_3': 0.00011813503804684068, 'l1_Layer_4': 0.00020981566032370158, 'n_units_Layer_1': 285, 'n_units_Layer_2': 50, 'n_units_Layer_3': 190, 'n_units_Layer_4': 70}. Best is trial 460 with value: 41.74219490678173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.88 | sMAPE for Validation Set is: 23.50% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 18.29 | sMAPE for Test Set is: 23.13% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:33:29,099]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:33,319]\u001b[0m Trial 476 finished with value: 41.997229366335795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017154210908312192, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16607929000162502, 'dropout_rate_Layer_2': 0.09693605615902531, 'dropout_rate_Layer_3': 0.023008625244630043, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6244395082622692e-05, 'l1_Layer_2': 0.0008028051922752354, 'l1_Layer_3': 1.0443177105765278e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 170, 'n_units_Layer_3': 230}. Best is trial 460 with value: 41.74219490678173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.00 | sMAPE for Validation Set is: 22.71% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 16.79 | sMAPE for Test Set is: 21.75% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:33:37,180]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:41,777]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:44,582]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:47,343]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:50,769]\u001b[0m Trial 491 finished with value: 42.9376353186172 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031075988674571777, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13046083619626372, 'dropout_rate_Layer_2': 0.04015953494701438, 'dropout_rate_Layer_3': 0.011105260471320724, 'dropout_rate_Layer_4': 0.0384456636349997, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003374591170594788, 'l1_Layer_2': 0.0007039657992701935, 'l1_Layer_3': 0.00010507536874585734, 'l1_Layer_4': 0.0002504421564305879, 'n_units_Layer_1': 285, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215, 'n_units_Layer_4': 70}. Best is trial 460 with value: 41.74219490678173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.94 | sMAPE for Validation Set is: 23.37% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.76 | sMAPE for Test Set is: 23.53% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:33:51,451]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:33:58,015]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:02,615]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:03,078]\u001b[0m Trial 489 finished with value: 44.374512954890385 and parameters: {'n_hidden': 3, 'learning_rate': 0.005403454815287991, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16117821773844515, 'dropout_rate_Layer_2': 0.022620462284345378, 'dropout_rate_Layer_3': 0.30121187365150354, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002874639544391631, 'l1_Layer_2': 0.004938869754364853, 'l1_Layer_3': 2.4633334041004797e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 65}. Best is trial 460 with value: 41.74219490678173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.37 | sMAPE for Validation Set is: 23.32% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.00 | sMAPE for Test Set is: 24.87% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:34:10,513]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:19,320]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:22,939]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:26,426]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:30,298]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:34,659]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:40,748]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:46,653]\u001b[0m Trial 499 finished with value: 42.78707993101585 and parameters: {'n_hidden': 3, 'learning_rate': 0.003537724469072314, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.044058309257051835, 'dropout_rate_Layer_2': 0.00026947530750984217, 'dropout_rate_Layer_3': 0.2737643557433828, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.23101317302547e-05, 'l1_Layer_2': 0.010339479631530021, 'l1_Layer_3': 1.1250139572755203e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 115, 'n_units_Layer_3': 55}. Best is trial 460 with value: 41.74219490678173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.79 | sMAPE for Validation Set is: 22.87% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.01 | sMAPE for Test Set is: 23.60% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:34:47,732]\u001b[0m Trial 504 finished with value: 48.40758462689664 and parameters: {'n_hidden': 4, 'learning_rate': 0.0100819826450975, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25299232373452324, 'dropout_rate_Layer_2': 0.300773284190813, 'dropout_rate_Layer_3': 0.18717691450118543, 'dropout_rate_Layer_4': 0.2137812928920271, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002547202830939304, 'l1_Layer_2': 0.0007448455526875737, 'l1_Layer_3': 0.0011064825264111725, 'l1_Layer_4': 0.0001874177260074464, 'n_units_Layer_1': 115, 'n_units_Layer_2': 210, 'n_units_Layer_3': 270, 'n_units_Layer_4': 175}. Best is trial 460 with value: 41.74219490678173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.41 | sMAPE for Validation Set is: 24.62% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.70 | sMAPE for Test Set is: 23.55% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:34:49,829]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:51,378]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:53,310]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:57,286]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:58,152]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:34:58,389]\u001b[0m Trial 498 finished with value: 41.61811753374905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014675768328982952, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17071785090274474, 'dropout_rate_Layer_2': 0.07283964675276312, 'dropout_rate_Layer_3': 0.03394193881085351, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.62315513725027e-05, 'l1_Layer_2': 0.0006529360663660099, 'l1_Layer_3': 9.874011963171245e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 205}. Best is trial 498 with value: 41.61811753374905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.62 | sMAPE for Validation Set is: 22.53% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.64 | sMAPE for Test Set is: 21.65% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:35:02,781]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:06,779]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:09,959]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:15,039]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:15,422]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:21,746]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:25,502]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:29,357]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:32,424]\u001b[0m Trial 514 finished with value: 41.13330544739795 and parameters: {'n_hidden': 3, 'learning_rate': 0.002982971965585071, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0834413867993189, 'dropout_rate_Layer_2': 0.03477857830045747, 'dropout_rate_Layer_3': 0.2851351885080239, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.022451292274998e-05, 'l1_Layer_2': 0.0033667910801820525, 'l1_Layer_3': 1.6621154330109885e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 55}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.13 | sMAPE for Validation Set is: 22.25% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 17.80 | sMAPE for Test Set is: 23.87% | rMAE for Test Set is: 0.60\n",
      "MAE for Validation Set is: 43.41 | sMAPE for Validation Set is: 23.34% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 18.07 | sMAPE for Test Set is: 23.57% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:35:32,562]\u001b[0m Trial 517 finished with value: 43.41034965279825 and parameters: {'n_hidden': 3, 'learning_rate': 0.005279804732988301, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0805621814488864, 'dropout_rate_Layer_2': 0.03721851571505153, 'dropout_rate_Layer_3': 0.29772946078920504, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.255960787926175e-05, 'l1_Layer_2': 0.0033283473932865463, 'l1_Layer_3': 1.71192327784899e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 100, 'n_units_Layer_3': 70}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:36,981]\u001b[0m Trial 521 finished with value: 41.27989581795635 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022604128642361595, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12542650773513117, 'dropout_rate_Layer_2': 0.018808378592958006, 'dropout_rate_Layer_3': 0.04868390318305107, 'dropout_rate_Layer_4': 0.028934319215881434, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00014331615573161916, 'l1_Layer_2': 0.0005827070190928538, 'l1_Layer_3': 0.00018485127437728907, 'l1_Layer_4': 0.00014868236256365664, 'n_units_Layer_1': 50, 'n_units_Layer_2': 85, 'n_units_Layer_3': 250, 'n_units_Layer_4': 95}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.28 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.79 | sMAPE for Test Set is: 23.63% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:35:38,150]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:39,438]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:44,927]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:47,107]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:47,549]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:48,243]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:54,158]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:35:57,335]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:01,642]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:06,115]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:11,105]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:11,653]\u001b[0m Trial 529 finished with value: 47.045889463420245 and parameters: {'n_hidden': 4, 'learning_rate': 0.005762268154008354, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2664026615382845, 'dropout_rate_Layer_2': 0.3067638100052108, 'dropout_rate_Layer_3': 0.1873583662823011, 'dropout_rate_Layer_4': 0.22150893389750526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002503881860086524, 'l1_Layer_2': 0.0006866900951082392, 'l1_Layer_3': 0.0008046562524503965, 'l1_Layer_4': 0.00019527459368522585, 'n_units_Layer_1': 105, 'n_units_Layer_2': 210, 'n_units_Layer_3': 265, 'n_units_Layer_4': 190}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.05 | sMAPE for Validation Set is: 24.33% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 18.13 | sMAPE for Test Set is: 22.88% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:36:11,837]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:19,921]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:20,222]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:24,525]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:28,085]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:30,422]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:34,249]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:38,420]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:41,023]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:43,274]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:46,101]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:48,382]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:48,592]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:36:59,312]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:03,355]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:03,522]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:09,879]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:10,114]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:14,482]\u001b[0m Trial 544 finished with value: 42.519148061370934 and parameters: {'n_hidden': 3, 'learning_rate': 0.00521219959278784, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07831716136513084, 'dropout_rate_Layer_2': 0.018353766731705135, 'dropout_rate_Layer_3': 0.2621013387772738, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011005703482925289, 'l1_Layer_2': 0.01187961063599197, 'l1_Layer_3': 1.6203080638621852e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 120, 'n_units_Layer_3': 55}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.52 | sMAPE for Validation Set is: 23.15% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.22 | sMAPE for Test Set is: 25.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:37:16,685]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:17,501]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:17,621]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:18,469]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:26,526]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:27,389]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:29,228]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:33,116]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:36,374]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:36,869]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:42,023]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:44,186]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:47,325]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:48,979]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:54,278]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:59,224]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:37:59,698]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:06,769]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:07,172]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:12,418]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:16,336]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:16,936]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:21,781]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:34,412]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:37,252]\u001b[0m Trial 568 finished with value: 42.3610675080326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011250402138058462, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07329784278946794, 'dropout_rate_Layer_2': 0.030985961357989394, 'dropout_rate_Layer_3': 0.013978374952509963, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.125639787393263e-05, 'l1_Layer_2': 2.2554859627129734e-05, 'l1_Layer_3': 1.4019993774179776e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 215, 'n_units_Layer_3': 225}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.36 | sMAPE for Validation Set is: 22.46% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.43 | sMAPE for Test Set is: 22.04% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:38:39,962]\u001b[0m Trial 581 finished with value: 197.26560347580156 and parameters: {'n_hidden': 4, 'learning_rate': 0.04776192490238173, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13273498478934004, 'dropout_rate_Layer_2': 0.24717765647187823, 'dropout_rate_Layer_3': 0.2589771620658732, 'dropout_rate_Layer_4': 0.2837446825955795, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.03274247232976801, 'l1_Layer_2': 0.0020087638989974986, 'l1_Layer_3': 0.00022916419173899975, 'l1_Layer_4': 0.0005578893135292534, 'n_units_Layer_1': 75, 'n_units_Layer_2': 230, 'n_units_Layer_3': 270, 'n_units_Layer_4': 195}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 197.27 | sMAPE for Validation Set is: 120.48% | rMAE for Validation Set is: 2.47\n",
      "MAE for Test Set is: 62.90 | sMAPE for Test Set is: 74.93% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:38:40,625]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:40,695]\u001b[0m Trial 566 finished with value: 41.750885480990846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011286058182214459, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10571220988668803, 'dropout_rate_Layer_2': 0.03407157278756242, 'dropout_rate_Layer_3': 0.38101325147611825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.0144132759273626e-05, 'l1_Layer_2': 2.2954378556496863e-05, 'l1_Layer_3': 0.0009285202351622854, 'n_units_Layer_1': 95, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.75 | sMAPE for Validation Set is: 22.46% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.63 | sMAPE for Test Set is: 21.58% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:38:45,701]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:52,063]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:52,179]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:52,446]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:38:52,715]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:00,195]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:00,717]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:03,205]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:03,247]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:08,122]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:08,521]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:09,869]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:13,345]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:15,784]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:18,719]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:21,063]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:28,088]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:30,210]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:35,499]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:36,035]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:41,602]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:42,330]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:42,852]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:47,617]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:52,109]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:54,538]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:39:56,782]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:01,123]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:04,310]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:05,194]\u001b[0m Trial 607 finished with value: 42.10927214603739 and parameters: {'n_hidden': 4, 'learning_rate': 0.001988592288635124, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13042138989293284, 'dropout_rate_Layer_2': 0.04424548352440487, 'dropout_rate_Layer_3': 0.04196110704839561, 'dropout_rate_Layer_4': 0.029194837445775952, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00047412347207304186, 'l1_Layer_2': 0.0007557696957326356, 'l1_Layer_3': 0.0003391324379275015, 'l1_Layer_4': 0.00033234049354614686, 'n_units_Layer_1': 285, 'n_units_Layer_2': 85, 'n_units_Layer_3': 225, 'n_units_Layer_4': 65}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.11 | sMAPE for Validation Set is: 22.47% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.22 | sMAPE for Test Set is: 23.42% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:40:10,528]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:10,934]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.51 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.30 | sMAPE for Test Set is: 22.77% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:40:14,376]\u001b[0m Trial 612 finished with value: 42.50918846961874 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026930638160360984, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.133832271321939, 'dropout_rate_Layer_2': 0.03888919330027904, 'dropout_rate_Layer_3': 0.043669575353799915, 'dropout_rate_Layer_4': 0.023638581639849023, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007625804113237425, 'l1_Layer_2': 0.0007586526825241111, 'l1_Layer_3': 9.638220127865006e-05, 'l1_Layer_4': 0.0005100579353474966, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 225, 'n_units_Layer_4': 65}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:18,881]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:19,052]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:20,003]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:26,216]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:26,939]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:31,821]\u001b[0m Trial 611 finished with value: 46.78992711993348 and parameters: {'n_hidden': 4, 'learning_rate': 0.006113139123979185, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23797243942801372, 'dropout_rate_Layer_2': 0.32571026890835963, 'dropout_rate_Layer_3': 0.2238271350162887, 'dropout_rate_Layer_4': 0.21502786307356997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0034439934761339485, 'l1_Layer_2': 0.0007471268538925737, 'l1_Layer_3': 1.4583414729799015e-05, 'l1_Layer_4': 0.0001954150646842606, 'n_units_Layer_1': 115, 'n_units_Layer_2': 215, 'n_units_Layer_3': 270, 'n_units_Layer_4': 180}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.79 | sMAPE for Validation Set is: 24.16% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 18.91 | sMAPE for Test Set is: 23.16% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:40:32,171]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:34,458]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:38,881]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:42,456]\u001b[0m Trial 622 finished with value: 42.665815759466014 and parameters: {'n_hidden': 4, 'learning_rate': 0.00205487818649292, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17092689771781266, 'dropout_rate_Layer_2': 0.0149618548460041, 'dropout_rate_Layer_3': 0.0690874210991134, 'dropout_rate_Layer_4': 0.053690094240324504, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005608256457533815, 'l1_Layer_2': 0.0014377147265003244, 'l1_Layer_3': 0.00042559836153662335, 'l1_Layer_4': 0.00010877800762738098, 'n_units_Layer_1': 245, 'n_units_Layer_2': 75, 'n_units_Layer_3': 255, 'n_units_Layer_4': 90}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.67 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.34 | sMAPE for Test Set is: 22.79% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:40:43,283]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:47,439]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:47,746]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:54,233]\u001b[0m Trial 626 finished with value: 42.556271175220814 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019444287353367691, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.062490412877322044, 'dropout_rate_Layer_2': 0.012342662530384456, 'dropout_rate_Layer_3': 0.07156661572123227, 'dropout_rate_Layer_4': 0.019591241055055712, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002493218669186104, 'l1_Layer_2': 0.0001615397328087498, 'l1_Layer_3': 0.0003873475998658272, 'l1_Layer_4': 0.0001234512956615052, 'n_units_Layer_1': 245, 'n_units_Layer_2': 75, 'n_units_Layer_3': 250, 'n_units_Layer_4': 90}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.56 | sMAPE for Validation Set is: 22.58% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.88 | sMAPE for Test Set is: 22.56% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:40:58,532]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:40:58,979]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:06,393]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:10,177]\u001b[0m Trial 625 finished with value: 43.07931533231409 and parameters: {'n_hidden': 3, 'learning_rate': 0.004846638088397203, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0784544110471629, 'dropout_rate_Layer_2': 0.052151527871172096, 'dropout_rate_Layer_3': 0.20722246606194192, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.9032634243590996e-05, 'l1_Layer_2': 0.01153531791100192, 'l1_Layer_3': 1.722660815720422e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 115, 'n_units_Layer_3': 55}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.08 | sMAPE for Validation Set is: 22.94% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.87 | sMAPE for Test Set is: 23.56% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:41:13,956]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:17,636]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:19,945]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:25,083]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:25,734]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:30,574]\u001b[0m Trial 631 finished with value: 42.19774946918812 and parameters: {'n_hidden': 3, 'learning_rate': 0.003199650092582262, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07769902991945503, 'dropout_rate_Layer_2': 0.04938755302689772, 'dropout_rate_Layer_3': 0.2844089848719591, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016479084177542776, 'l1_Layer_2': 0.0059481974097247365, 'l1_Layer_3': 3.56717876278543e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 115, 'n_units_Layer_3': 180}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.20 | sMAPE for Validation Set is: 22.86% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.34 | sMAPE for Test Set is: 24.24% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:41:32,834]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:34,012]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:36,785]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:40,282]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:40,566]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:41,094]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:41,308]\u001b[0m Trial 635 finished with value: 47.91569110164429 and parameters: {'n_hidden': 4, 'learning_rate': 0.003474567587348164, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24235574987896766, 'dropout_rate_Layer_2': 0.3733768337564861, 'dropout_rate_Layer_3': 0.11865821611968551, 'dropout_rate_Layer_4': 0.20983359302760363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0029828598465555557, 'l1_Layer_2': 0.0014113055160555174, 'l1_Layer_3': 2.6448883234246305e-05, 'l1_Layer_4': 2.4033009287187584e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 225, 'n_units_Layer_3': 240, 'n_units_Layer_4': 155}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.92 | sMAPE for Validation Set is: 24.60% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 18.34 | sMAPE for Test Set is: 22.75% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:41:48,594]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:48,835]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:49,757]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:49,882]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:57,036]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:41:57,119]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:03,930]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:04,110]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:04,216]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:11,456]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:12,398]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:15,226]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:17,719]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:18,957]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:20,252]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:20,919]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:25,522]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:29,263]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:29,934]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:31,860]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:35,649]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:39,716]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:40,539]\u001b[0m Trial 664 finished with value: 42.966994959006655 and parameters: {'n_hidden': 4, 'learning_rate': 0.002572735464996883, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13842102454330993, 'dropout_rate_Layer_2': 0.028862035203346466, 'dropout_rate_Layer_3': 0.037265566502624706, 'dropout_rate_Layer_4': 0.029106070855574203, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005371299201814977, 'l1_Layer_2': 0.0008346002335158332, 'l1_Layer_3': 9.105569621246618e-05, 'l1_Layer_4': 0.000542235434495698, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 225, 'n_units_Layer_4': 60}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.97 | sMAPE for Validation Set is: 23.02% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.64 | sMAPE for Test Set is: 22.68% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:42:40,944]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:45,481]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:49,786]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:50,275]\u001b[0m Trial 669 finished with value: 42.617384742799764 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014891348498770397, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14200982218755956, 'dropout_rate_Layer_2': 0.0023741273176898017, 'dropout_rate_Layer_3': 0.045690232872077366, 'dropout_rate_Layer_4': 0.02943277160620443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008168226598029759, 'l1_Layer_2': 0.0008904105357373105, 'l1_Layer_3': 0.00011571485023677698, 'l1_Layer_4': 0.00044145639477202985, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230, 'n_units_Layer_4': 65}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.62 | sMAPE for Validation Set is: 22.75% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 20.22 | sMAPE for Test Set is: 24.09% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:42:50,708]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:56,478]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:42:57,403]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:03,211]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:11,675]\u001b[0m Trial 679 finished with value: 47.087646938684486 and parameters: {'n_hidden': 4, 'learning_rate': 0.006292985560389475, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20717340253904523, 'dropout_rate_Layer_2': 0.324142053127091, 'dropout_rate_Layer_3': 0.21919081079948202, 'dropout_rate_Layer_4': 0.20795463209690868, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0047041480545218705, 'l1_Layer_2': 0.0002951428649767272, 'l1_Layer_3': 2.8790343806275116e-05, 'l1_Layer_4': 0.001454190127580435, 'n_units_Layer_1': 120, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260, 'n_units_Layer_4': 185}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.09 | sMAPE for Validation Set is: 24.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.32 | sMAPE for Test Set is: 28.79% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:43:12,102]\u001b[0m Trial 674 finished with value: 46.88317619907124 and parameters: {'n_hidden': 4, 'learning_rate': 0.007252352810079105, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39653388951999335, 'dropout_rate_Layer_2': 0.32982781164775005, 'dropout_rate_Layer_3': 0.2228481014322906, 'dropout_rate_Layer_4': 0.20286012273902976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005663023819936783, 'l1_Layer_2': 0.00032841032006887755, 'l1_Layer_3': 1.572530717849305e-05, 'l1_Layer_4': 0.0013821683787528533, 'n_units_Layer_1': 125, 'n_units_Layer_2': 245, 'n_units_Layer_3': 260, 'n_units_Layer_4': 50}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.88 | sMAPE for Validation Set is: 24.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.03 | sMAPE for Test Set is: 25.60% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:43:12,641]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:20,718]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:26,927]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:27,720]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:33,332]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:36,739]\u001b[0m Trial 683 finished with value: 43.97973614889053 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027556064856387916, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12304067339044164, 'dropout_rate_Layer_2': 0.020138931015435943, 'dropout_rate_Layer_3': 0.043200311398606125, 'dropout_rate_Layer_4': 0.0004921699714000409, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00029776078419363987, 'l1_Layer_2': 0.0012195111912721003, 'l1_Layer_3': 4.1097946770572067e-05, 'l1_Layer_4': 0.0002968457324434613, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 185, 'n_units_Layer_4': 80}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.98 | sMAPE for Validation Set is: 23.28% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 21.47 | sMAPE for Test Set is: 25.09% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:43:38,368]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:39,113]\u001b[0m Trial 678 finished with value: 42.55104032253919 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022435601110836314, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023094595828351605, 'dropout_rate_Layer_2': 0.02734026336646729, 'dropout_rate_Layer_3': 0.26485397729344873, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.372567009818463e-05, 'l1_Layer_2': 0.005819454940857557, 'l1_Layer_3': 1.4602328484259956e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.55 | sMAPE for Validation Set is: 22.97% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.57 | sMAPE for Test Set is: 24.42% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:43:46,903]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:50,268]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:51,116]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:52,978]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:56,974]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:43:58,069]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:00,163]\u001b[0m Trial 686 finished with value: 43.94621714844606 and parameters: {'n_hidden': 3, 'learning_rate': 0.003496169789664642, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09581998146895182, 'dropout_rate_Layer_2': 0.03075657661386967, 'dropout_rate_Layer_3': 0.2829452567855996, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5014648844426295e-05, 'l1_Layer_2': 0.004285863190217438, 'l1_Layer_3': 2.212131820465166e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 130, 'n_units_Layer_3': 50}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.95 | sMAPE for Validation Set is: 23.46% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 19.14 | sMAPE for Test Set is: 23.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:44:00,388]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:07,684]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:11,715]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:12,139]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:17,870]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:18,256]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:25,353]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:25,551]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:29,879]\u001b[0m Trial 700 finished with value: 44.20504771946529 and parameters: {'n_hidden': 3, 'learning_rate': 0.003675711050408765, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21488517793224474, 'dropout_rate_Layer_2': 0.3205536925506033, 'dropout_rate_Layer_3': 0.3131872204525229, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003125629131506738, 'l1_Layer_2': 0.0006700233077771901, 'l1_Layer_3': 2.7803918896048263e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.21 | sMAPE for Validation Set is: 23.16% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 17.01 | sMAPE for Test Set is: 22.06% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:44:32,326]\u001b[0m Trial 696 finished with value: 42.68596524370782 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028637340952059995, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03170342920264861, 'dropout_rate_Layer_2': 0.008824633863745563, 'dropout_rate_Layer_3': 0.27108233168448564, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.7590655562157637e-05, 'l1_Layer_2': 0.005719466744394649, 'l1_Layer_3': 1.5164782682658789e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 120, 'n_units_Layer_3': 60}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.69 | sMAPE for Validation Set is: 22.90% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.70 | sMAPE for Test Set is: 23.07% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:44:35,137]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:38,524]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:38,598]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:39,641]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:40,755]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:48,659]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:53,551]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:53,688]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:44:54,103]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:01,536]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:03,396]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:04,501]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:06,518]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:11,156]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:11,872]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:14,443]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:14,530]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:20,062]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:20,505]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:24,943]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:27,861]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:27,983]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:29,343]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:34,349]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:37,073]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:37,314]\u001b[0m Trial 725 finished with value: 42.973359614837655 and parameters: {'n_hidden': 4, 'learning_rate': 0.002090022294963117, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06014085075488615, 'dropout_rate_Layer_2': 0.012639474085883047, 'dropout_rate_Layer_3': 0.07074804078476954, 'dropout_rate_Layer_4': 0.014147622680961713, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00044603339632586127, 'l1_Layer_2': 0.000170930977658293, 'l1_Layer_3': 0.00044493603916958505, 'l1_Layer_4': 0.00012644402243988575, 'n_units_Layer_1': 245, 'n_units_Layer_2': 70, 'n_units_Layer_3': 245, 'n_units_Layer_4': 90}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.97 | sMAPE for Validation Set is: 22.84% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 19.27 | sMAPE for Test Set is: 23.42% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:45:43,277]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:43,527]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:49,383]\u001b[0m Trial 730 finished with value: 41.73771257571391 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019933276212039056, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.056842765175466256, 'dropout_rate_Layer_2': 0.011234735889233554, 'dropout_rate_Layer_3': 0.06743837187770532, 'dropout_rate_Layer_4': 0.015337065125046262, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00025164259838502794, 'l1_Layer_2': 0.00014118041394869867, 'l1_Layer_3': 0.0004732709833591934, 'l1_Layer_4': 0.0001380100140600521, 'n_units_Layer_1': 245, 'n_units_Layer_2': 75, 'n_units_Layer_3': 210, 'n_units_Layer_4': 90}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.74 | sMAPE for Validation Set is: 22.19% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.59 | sMAPE for Test Set is: 22.85% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:45:49,921]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:53,978]\u001b[0m Trial 732 finished with value: 42.8683451090889 and parameters: {'n_hidden': 3, 'learning_rate': 0.003754968275991338, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2106441736293294, 'dropout_rate_Layer_2': 0.37359148164960343, 'dropout_rate_Layer_3': 0.3307791904750659, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.132669369642462e-05, 'l1_Layer_2': 0.0002945416576109516, 'l1_Layer_3': 2.786617432882658e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.87 | sMAPE for Validation Set is: 23.05% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 18.58 | sMAPE for Test Set is: 23.74% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:45:54,561]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:58,643]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:45:59,006]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:02,667]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:03,308]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:10,092]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:17,775]\u001b[0m Trial 741 finished with value: 42.20144272053236 and parameters: {'n_hidden': 4, 'learning_rate': 0.001392737729388772, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11517803313190612, 'dropout_rate_Layer_2': 0.07325833552796393, 'dropout_rate_Layer_3': 0.05146100468890949, 'dropout_rate_Layer_4': 0.023827105591214245, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002711859839816716, 'l1_Layer_2': 2.236377406385384e-05, 'l1_Layer_3': 0.0007412684430929401, 'l1_Layer_4': 0.00038401394196165386, 'n_units_Layer_1': 235, 'n_units_Layer_2': 210, 'n_units_Layer_3': 210, 'n_units_Layer_4': 115}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.20 | sMAPE for Validation Set is: 22.62% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.77 | sMAPE for Test Set is: 23.42% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 43.32 | sMAPE for Validation Set is: 24.11% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 22.53 | sMAPE for Test Set is: 28.59% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:46:20,672]\u001b[0m Trial 743 finished with value: 43.32338206390207 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038663513293925836, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24596209765831653, 'dropout_rate_Layer_2': 0.38720377602654976, 'dropout_rate_Layer_3': 0.305003358347217, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.413970716554672e-05, 'l1_Layer_2': 0.0006182999892519604, 'l1_Layer_3': 2.956651723720482e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 285, 'n_units_Layer_3': 290}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.78 | sMAPE for Validation Set is: 22.74% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.25 | sMAPE for Test Set is: 23.37% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:46:20,954]\u001b[0m Trial 742 finished with value: 42.77859861818106 and parameters: {'n_hidden': 4, 'learning_rate': 0.001362808126478334, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0012160353468735452, 'dropout_rate_Layer_2': 0.19117219058388882, 'dropout_rate_Layer_3': 0.052584685565019634, 'dropout_rate_Layer_4': 0.020969263681820248, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001356916009080346, 'l1_Layer_2': 0.0001281080083122246, 'l1_Layer_3': 0.0011405476676672544, 'l1_Layer_4': 1.2065067000153627e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 80, 'n_units_Layer_3': 175, 'n_units_Layer_4': 115}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:23,914]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:25,471]\u001b[0m Trial 745 finished with value: 41.805089054431924 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014148293311675606, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006054403372378462, 'dropout_rate_Layer_2': 0.0033254541291426673, 'dropout_rate_Layer_3': 0.047465198545449325, 'dropout_rate_Layer_4': 0.027021340984930805, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013011511157547763, 'l1_Layer_2': 2.4799769730646434e-05, 'l1_Layer_3': 0.0006432164124854621, 'l1_Layer_4': 0.00021324562405058606, 'n_units_Layer_1': 215, 'n_units_Layer_2': 85, 'n_units_Layer_3': 205, 'n_units_Layer_4': 160}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.81 | sMAPE for Validation Set is: 22.22% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 20.58 | sMAPE for Test Set is: 24.31% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:46:28,759]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:29,016]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:31,696]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:38,206]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:39,663]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:41,393]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:44,127]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:47,105]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:51,633]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:52,376]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:52,986]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:55,359]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:46:57,215]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:02,069]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:03,180]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:05,398]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:09,404]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:09,508]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:09,904]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:14,535]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:20,073]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:20,172]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:21,125]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:27,688]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:28,388]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:34,115]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:34,943]\u001b[0m Trial 767 finished with value: 42.14517331005252 and parameters: {'n_hidden': 3, 'learning_rate': 0.004024508042013053, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2237182171164414, 'dropout_rate_Layer_2': 0.38630808339207756, 'dropout_rate_Layer_3': 0.32321933070448916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.5979363002243344e-05, 'l1_Layer_2': 0.0006417902823692934, 'l1_Layer_3': 2.7115812615393348e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 285, 'n_units_Layer_3': 290}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.15 | sMAPE for Validation Set is: 23.28% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 22.65 | sMAPE for Test Set is: 27.95% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:47:39,690]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:39,932]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:46,521]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:50,232]\u001b[0m Trial 771 finished with value: 42.527435446323715 and parameters: {'n_hidden': 3, 'learning_rate': 0.004643825827048016, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03785418524034739, 'dropout_rate_Layer_2': 0.03991949636740329, 'dropout_rate_Layer_3': 0.17350252012888792, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.456204612458916e-05, 'l1_Layer_2': 0.0056683501647641805, 'l1_Layer_3': 3.035160995300214e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 100, 'n_units_Layer_3': 65}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.53 | sMAPE for Validation Set is: 23.32% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.85 | sMAPE for Test Set is: 25.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:47:50,625]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:57,999]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:47:58,687]\u001b[0m Trial 779 finished with value: 42.45045787651002 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036752239155765274, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21479330751154996, 'dropout_rate_Layer_2': 0.3880145090141504, 'dropout_rate_Layer_3': 0.32720461557795116, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.44438662210572e-05, 'l1_Layer_2': 0.0010137344015780088, 'l1_Layer_3': 2.690185619754796e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 285, 'n_units_Layer_3': 295}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.45 | sMAPE for Validation Set is: 22.70% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.87 | sMAPE for Test Set is: 24.48% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:48:04,667]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:48:05,557]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:48:09,755]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:48:12,958]\u001b[0m Trial 775 finished with value: 44.15350152610282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013152424129443622, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10775780998954632, 'dropout_rate_Layer_2': 0.071371907090108, 'dropout_rate_Layer_3': 0.026942221705791095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.954416525245739e-05, 'l1_Layer_2': 0.0008385167707115648, 'l1_Layer_3': 0.003664369689982162, 'n_units_Layer_1': 95, 'n_units_Layer_2': 170, 'n_units_Layer_3': 230}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.15 | sMAPE for Validation Set is: 23.28% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 17.39 | sMAPE for Test Set is: 22.72% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:48:17,668]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:48:20,254]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:48:26,178]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:48:26,291]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:48:33,731]\u001b[0m Trial 787 finished with value: 41.61502712453308 and parameters: {'n_hidden': 4, 'learning_rate': 0.001346178923448777, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11406555419186848, 'dropout_rate_Layer_2': 0.01070372555126839, 'dropout_rate_Layer_3': 0.03127231199449766, 'dropout_rate_Layer_4': 0.009536509993938486, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00041443356915028145, 'l1_Layer_2': 5.940266625824169e-05, 'l1_Layer_3': 0.0006814064361712918, 'l1_Layer_4': 0.0002264730095587573, 'n_units_Layer_1': 225, 'n_units_Layer_2': 240, 'n_units_Layer_3': 190, 'n_units_Layer_4': 100}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.62 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.96 | sMAPE for Test Set is: 21.94% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:48:40,528]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:48:45,442]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.71 | sMAPE for Validation Set is: 22.19% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.26 | sMAPE for Test Set is: 23.48% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:48:47,992]\u001b[0m Trial 791 finished with value: 41.70504749844971 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012804175503271324, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011095235091992103, 'dropout_rate_Layer_2': 0.015411720568654011, 'dropout_rate_Layer_3': 0.03139733780135007, 'dropout_rate_Layer_4': 0.03928185283037738, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003806445637915873, 'l1_Layer_2': 1.9060154542929368e-05, 'l1_Layer_3': 0.0007174723870959736, 'l1_Layer_4': 0.00021884235130828605, 'n_units_Layer_1': 265, 'n_units_Layer_2': 100, 'n_units_Layer_3': 190, 'n_units_Layer_4': 100}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:48:52,380]\u001b[0m Trial 792 finished with value: 42.45769602211383 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013405768860561972, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009280561117998465, 'dropout_rate_Layer_2': 0.009070399951709347, 'dropout_rate_Layer_3': 0.02886118872792781, 'dropout_rate_Layer_4': 0.042110339520751564, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003798888079686309, 'l1_Layer_2': 1.2771989462993668e-05, 'l1_Layer_3': 0.0006473303320302248, 'l1_Layer_4': 0.00020078320568852348, 'n_units_Layer_1': 220, 'n_units_Layer_2': 100, 'n_units_Layer_3': 190, 'n_units_Layer_4': 100}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.46 | sMAPE for Validation Set is: 22.71% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.45 | sMAPE for Test Set is: 22.28% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:48:56,136]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:49:01,037]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:49:01,275]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:49:07,897]\u001b[0m Trial 781 finished with value: 41.91852883758714 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013295595855265753, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08892843293808544, 'dropout_rate_Layer_2': 0.03984449149928958, 'dropout_rate_Layer_3': 0.13913798904006416, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4288788233023312e-05, 'l1_Layer_2': 0.0010862856406422526, 'l1_Layer_3': 1.2094166732720749e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 145, 'n_units_Layer_3': 125}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.92 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.59 | sMAPE for Test Set is: 21.30% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:49:08,467]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:49:09,297]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:49:14,392]\u001b[0m Trial 797 finished with value: 42.037600572823486 and parameters: {'n_hidden': 4, 'learning_rate': 0.001110213720013646, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02511390745540776, 'dropout_rate_Layer_2': 0.020431491925089654, 'dropout_rate_Layer_3': 0.05431514231235829, 'dropout_rate_Layer_4': 0.012638997239868428, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002763292215018165, 'l1_Layer_2': 1.8142929251877273e-05, 'l1_Layer_3': 0.0009489975775204453, 'l1_Layer_4': 0.0002679477984431346, 'n_units_Layer_1': 260, 'n_units_Layer_2': 245, 'n_units_Layer_3': 195, 'n_units_Layer_4': 120}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.04 | sMAPE for Validation Set is: 22.34% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.03 | sMAPE for Test Set is: 23.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:49:25,523]\u001b[0m Trial 801 finished with value: 42.01957012079947 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010834113153845935, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0021160371682531036, 'dropout_rate_Layer_2': 0.02164145924307136, 'dropout_rate_Layer_3': 0.06132403892391504, 'dropout_rate_Layer_4': 0.011881121626308635, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005935236978427136, 'l1_Layer_2': 1.6000399288963153e-05, 'l1_Layer_3': 0.0008859437716812971, 'l1_Layer_4': 0.00027995989104254404, 'n_units_Layer_1': 195, 'n_units_Layer_2': 240, 'n_units_Layer_3': 195, 'n_units_Layer_4': 120}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.02 | sMAPE for Validation Set is: 22.31% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.34 | sMAPE for Test Set is: 22.63% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:49:30,587]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:49:34,690]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:49:34,974]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:49:35,561]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:49:43,207]\u001b[0m Trial 804 finished with value: 42.389709567707065 and parameters: {'n_hidden': 3, 'learning_rate': 0.003726154752408605, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03574221113048218, 'dropout_rate_Layer_2': 0.013437654574842983, 'dropout_rate_Layer_3': 0.18524910317193682, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.71411681735293e-05, 'l1_Layer_2': 0.006549477874334391, 'l1_Layer_3': 3.196700159121516e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 100, 'n_units_Layer_3': 55}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.39 | sMAPE for Validation Set is: 22.72% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.46 | sMAPE for Test Set is: 24.44% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:49:43,885]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:49:45,994]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:49:49,620]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:49:53,614]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:50:01,298]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:50:06,399]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:50:10,029]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:50:15,896]\u001b[0m Trial 808 finished with value: 43.96886101165006 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013028891390083229, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08370710135999179, 'dropout_rate_Layer_2': 0.04714699489831592, 'dropout_rate_Layer_3': 0.017977021897623086, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.867020098672984e-05, 'l1_Layer_2': 3.398568095540863e-05, 'l1_Layer_3': 0.0017980088103040305, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 125}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.97 | sMAPE for Validation Set is: 23.03% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 18.55 | sMAPE for Test Set is: 22.88% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:50:18,447]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:50:20,136]\u001b[0m Trial 812 finished with value: 41.25477148020581 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032785418122336834, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022160694037553018, 'dropout_rate_Layer_2': 0.04804244724009941, 'dropout_rate_Layer_3': 0.17411704189537902, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011958715925795678, 'l1_Layer_2': 0.007372757433044004, 'l1_Layer_3': 1.8331528171783264e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 110, 'n_units_Layer_3': 150}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.25 | sMAPE for Validation Set is: 22.45% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.32 | sMAPE for Test Set is: 23.43% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:50:26,870]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:50:31,568]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:50:31,940]\u001b[0m Trial 813 finished with value: 42.45264846307633 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032567068068345174, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05554960777638164, 'dropout_rate_Layer_2': 0.04368351654688271, 'dropout_rate_Layer_3': 0.16919708091513713, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011160425830167879, 'l1_Layer_2': 0.007711162907967536, 'l1_Layer_3': 4.1788386968933785e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 110, 'n_units_Layer_3': 145}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.45 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 16.95 | sMAPE for Test Set is: 22.67% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:50:38,838]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:50:39,036]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:50:45,777]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:50:54,279]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:50:58,516]\u001b[0m Trial 825 finished with value: 42.657129139935726 and parameters: {'n_hidden': 3, 'learning_rate': 0.003688599214935603, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22490758702949606, 'dropout_rate_Layer_2': 0.39119367196255544, 'dropout_rate_Layer_3': 0.31969082381047187, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.5354774624817096e-05, 'l1_Layer_2': 0.001030185872732798, 'l1_Layer_3': 3.1824765407369855e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 285, 'n_units_Layer_3': 290}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.66 | sMAPE for Validation Set is: 22.90% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.28 | sMAPE for Test Set is: 24.01% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:50:59,180]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:50:59,946]\u001b[0m Trial 819 finished with value: 42.21971759495761 and parameters: {'n_hidden': 3, 'learning_rate': 0.001149309836732384, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0605913095850925, 'dropout_rate_Layer_2': 0.04721614898489723, 'dropout_rate_Layer_3': 0.018420295219912584, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.748461750703042e-05, 'l1_Layer_2': 3.526976737791556e-05, 'l1_Layer_3': 0.001631577686220168, 'n_units_Layer_1': 295, 'n_units_Layer_2': 135, 'n_units_Layer_3': 125}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.22 | sMAPE for Validation Set is: 22.38% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 16.33 | sMAPE for Test Set is: 21.33% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:51:06,449]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:51:10,286]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:51:10,600]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:51:16,888]\u001b[0m Trial 821 finished with value: 42.796870746250704 and parameters: {'n_hidden': 3, 'learning_rate': 0.001352117486747706, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06980717493769488, 'dropout_rate_Layer_2': 0.03946791612261947, 'dropout_rate_Layer_3': 0.019810432796137777, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0505964572468723e-05, 'l1_Layer_2': 2.714507759184689e-05, 'l1_Layer_3': 0.0022375541590339055, 'n_units_Layer_1': 280, 'n_units_Layer_2': 145, 'n_units_Layer_3': 130}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.80 | sMAPE for Validation Set is: 22.89% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.71 | sMAPE for Test Set is: 23.14% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:51:27,562]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:51:32,219]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:51:36,855]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:51:37,088]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:51:45,006]\u001b[0m Trial 832 finished with value: 42.65678353869881 and parameters: {'n_hidden': 3, 'learning_rate': 0.004424843236782835, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08283432255595828, 'dropout_rate_Layer_2': 0.07533727880892788, 'dropout_rate_Layer_3': 0.19913015564819214, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.325997710969368e-05, 'l1_Layer_2': 0.009516499208629497, 'l1_Layer_3': 1.9921154930509476e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 125, 'n_units_Layer_3': 195}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.66 | sMAPE for Validation Set is: 23.51% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.50 | sMAPE for Test Set is: 26.02% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:51:45,398]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:51:57,551]\u001b[0m Trial 838 finished with value: 42.18809161932219 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009328219281281954, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00047647670585422575, 'dropout_rate_Layer_2': 0.0280117255240319, 'dropout_rate_Layer_3': 0.07705160189110385, 'dropout_rate_Layer_4': 0.010701342959527531, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00018025102896541747, 'l1_Layer_2': 1.468195572465552e-05, 'l1_Layer_3': 0.0005043111200476572, 'l1_Layer_4': 0.0002733875009948811, 'n_units_Layer_1': 275, 'n_units_Layer_2': 220, 'n_units_Layer_3': 190, 'n_units_Layer_4': 130}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.19 | sMAPE for Validation Set is: 22.60% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.54 | sMAPE for Test Set is: 22.42% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:51:58,602]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:52:03,865]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:52:10,105]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:52:14,762]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:52:17,505]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:52:22,456]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:52:29,095]\u001b[0m Trial 844 finished with value: 41.48042165792632 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026536162807480413, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20638397067457886, 'dropout_rate_Layer_2': 0.3780303258537964, 'dropout_rate_Layer_3': 0.3475622972976903, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.759872680747884e-05, 'l1_Layer_2': 0.001512821986530533, 'l1_Layer_3': 4.1187734268884915e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 290}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.48 | sMAPE for Validation Set is: 22.95% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.91 | sMAPE for Test Set is: 26.00% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:52:33,512]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:52:38,036]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:52:38,244]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:52:44,414]\u001b[0m Trial 845 finished with value: 42.35929589712308 and parameters: {'n_hidden': 3, 'learning_rate': 0.003528485259567844, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07242757886308829, 'dropout_rate_Layer_2': 0.04190523729042804, 'dropout_rate_Layer_3': 0.19905783252887602, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.89604074129653e-05, 'l1_Layer_2': 0.008056291722618321, 'l1_Layer_3': 1.2432014359501278e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 115, 'n_units_Layer_3': 195}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.36 | sMAPE for Validation Set is: 23.15% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.63 | sMAPE for Test Set is: 25.02% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:52:46,943]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:52:50,038]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:52:58,297]\u001b[0m Trial 847 finished with value: 42.18809904193398 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024353728463421182, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.062351823876627896, 'dropout_rate_Layer_2': 0.05351540985999006, 'dropout_rate_Layer_3': 0.20955472621734092, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.0441815649916864e-05, 'l1_Layer_2': 0.011157957564935823, 'l1_Layer_3': 1.6429402833584132e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 105, 'n_units_Layer_3': 155}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.19 | sMAPE for Validation Set is: 23.27% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.13 | sMAPE for Test Set is: 24.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:53:06,936]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:53:14,013]\u001b[0m Trial 855 finished with value: 42.136764645399715 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018632316565776726, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022730469169437325, 'dropout_rate_Layer_2': 0.01119463071375116, 'dropout_rate_Layer_3': 0.05337230759869635, 'dropout_rate_Layer_4': 0.02724745789970623, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00015030706514353499, 'l1_Layer_2': 1.023911480397133e-05, 'l1_Layer_3': 0.0006613881080528068, 'l1_Layer_4': 0.00011006436221059836, 'n_units_Layer_1': 215, 'n_units_Layer_2': 180, 'n_units_Layer_3': 200, 'n_units_Layer_4': 115}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.14 | sMAPE for Validation Set is: 22.52% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.07 | sMAPE for Test Set is: 22.54% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:53:18,088]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:53:27,041]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:53:37,469]\u001b[0m Trial 853 finished with value: 41.67200100034308 and parameters: {'n_hidden': 3, 'learning_rate': 0.002355045711468071, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06129685626828803, 'dropout_rate_Layer_2': 0.05734696781416682, 'dropout_rate_Layer_3': 0.2086455048369774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015936798011823987, 'l1_Layer_2': 0.008901412267322308, 'l1_Layer_3': 1.645181337056559e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 120, 'n_units_Layer_3': 195}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.67 | sMAPE for Validation Set is: 22.84% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.53 | sMAPE for Test Set is: 23.52% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:53:56,485]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:54:01,092]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:54:03,404]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:54:04,745]\u001b[0m Trial 859 finished with value: 42.47563602333656 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014607476494151762, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.051478744385621555, 'dropout_rate_Layer_2': 0.062147830134846566, 'dropout_rate_Layer_3': 0.03663673541197364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.269597006074319e-05, 'l1_Layer_2': 4.027689119118492e-05, 'l1_Layer_3': 1.3377259260587344e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 155, 'n_units_Layer_3': 115}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.48 | sMAPE for Validation Set is: 22.69% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.49 | sMAPE for Test Set is: 22.20% | rMAE for Test Set is: 0.59\n",
      "MAE for Validation Set is: 42.80 | sMAPE for Validation Set is: 22.90% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.23 | sMAPE for Test Set is: 22.57% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:54:13,951]\u001b[0m Trial 860 finished with value: 42.79991397691838 and parameters: {'n_hidden': 3, 'learning_rate': 0.001474905105827274, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17648827116389215, 'dropout_rate_Layer_2': 0.06322871781176256, 'dropout_rate_Layer_3': 0.03704895394841287, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.714017694460996e-05, 'l1_Layer_2': 4.18012727692714e-05, 'l1_Layer_3': 1.260086427747665e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 165, 'n_units_Layer_3': 115}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:54:22,471]\u001b[0m Trial 863 finished with value: 41.9149583409796 and parameters: {'n_hidden': 3, 'learning_rate': 0.002549414796596733, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2053228497300272, 'dropout_rate_Layer_2': 0.39996784595426826, 'dropout_rate_Layer_3': 0.34840300586769357, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.3472935835201495e-05, 'l1_Layer_2': 0.0018071030110700167, 'l1_Layer_3': 4.3879003723852496e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 290}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.91 | sMAPE for Validation Set is: 22.72% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.16 | sMAPE for Test Set is: 23.20% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:54:31,362]\u001b[0m Trial 862 finished with value: 42.402991845516944 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021778896980531462, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05542748379964865, 'dropout_rate_Layer_2': 0.06797583756576085, 'dropout_rate_Layer_3': 0.2083427354146648, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001359188045270628, 'l1_Layer_2': 0.008270719652041087, 'l1_Layer_3': 2.5775946302861683e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 120, 'n_units_Layer_3': 205}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.40 | sMAPE for Validation Set is: 22.99% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.73 | sMAPE for Test Set is: 23.75% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:54:40,040]\u001b[0m Trial 864 finished with value: 41.652017276855375 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022139947965622224, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.057235596624393634, 'dropout_rate_Layer_2': 0.062402538458086014, 'dropout_rate_Layer_3': 0.20982530798081286, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017624191425654633, 'l1_Layer_2': 0.008392194667737085, 'l1_Layer_3': 2.6333637821447503e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 120, 'n_units_Layer_3': 200}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.65 | sMAPE for Validation Set is: 22.83% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.38 | sMAPE for Test Set is: 24.60% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:54:44,141]\u001b[0m Trial 865 finished with value: 41.72455898722735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025523714866511767, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.055121545538082004, 'dropout_rate_Layer_2': 0.06764742958116658, 'dropout_rate_Layer_3': 0.18970888225088695, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001913964674137337, 'l1_Layer_2': 0.008446899661905993, 'l1_Layer_3': 2.623245556867878e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 120, 'n_units_Layer_3': 200}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.72 | sMAPE for Validation Set is: 22.51% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.09 | sMAPE for Test Set is: 22.72% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:54:47,043]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:54:58,681]\u001b[0m Trial 867 finished with value: 41.96372869636385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025171569985330787, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06833779131566807, 'dropout_rate_Layer_2': 0.06453971580179331, 'dropout_rate_Layer_3': 0.2095955826355427, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018815804596061206, 'l1_Layer_2': 0.007358583129539924, 'l1_Layer_3': 2.7006931896634392e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 125, 'n_units_Layer_3': 200}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.96 | sMAPE for Validation Set is: 23.01% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.78 | sMAPE for Test Set is: 23.48% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:55:04,396]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:09,714]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:12,651]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:13,898]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:17,118]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:19,018]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:19,699]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:21,188]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:29,463]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:32,531]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:48,562]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:51,341]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:55,105]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:55:55,654]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:02,395]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:02,804]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:07,648]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:11,565]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:13,386]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:14,817]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:16,984]\u001b[0m Trial 881 finished with value: 43.18292041750428 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016669759862447903, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16686799250604012, 'dropout_rate_Layer_2': 0.044452045773508045, 'dropout_rate_Layer_3': 0.04566334929832036, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.918536820675809e-05, 'l1_Layer_2': 2.3095951226916494e-05, 'l1_Layer_3': 1.708353283150059e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 160, 'n_units_Layer_3': 135}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.18 | sMAPE for Validation Set is: 22.97% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 18.80 | sMAPE for Test Set is: 24.27% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:56:18,239]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:18,733]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:23,557]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:28,649]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:33,917]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:38,433]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:45,849]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:46,506]\u001b[0m Trial 895 finished with value: 42.13048658700823 and parameters: {'n_hidden': 4, 'learning_rate': 0.001980816242184488, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009764203214810507, 'dropout_rate_Layer_2': 0.011735850910299985, 'dropout_rate_Layer_3': 0.00956554783084838, 'dropout_rate_Layer_4': 0.022077788440998274, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006178834355663913, 'l1_Layer_2': 1.3297048299951768e-05, 'l1_Layer_3': 0.001060994562290699, 'l1_Layer_4': 0.00018884168269083112, 'n_units_Layer_1': 215, 'n_units_Layer_2': 180, 'n_units_Layer_3': 225, 'n_units_Layer_4': 110}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.13 | sMAPE for Validation Set is: 22.60% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.85 | sMAPE for Test Set is: 22.74% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:56:46,660]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:55,271]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:55,499]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:56:57,177]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:05,093]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:05,383]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:11,997]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:12,920]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:13,267]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:13,608]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:17,952]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:23,627]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:23,671]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:24,717]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:30,653]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:31,673]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:33,817]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:36,587]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:40,543]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:42,311]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:47,280]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:57:47,448]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:58:08,270]\u001b[0m Trial 914 finished with value: 42.6244601072679 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018988193492747293, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.059904316315114566, 'dropout_rate_Layer_2': 0.07068979741034004, 'dropout_rate_Layer_3': 0.21876661502696013, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016069515027180604, 'l1_Layer_2': 0.007012177230987491, 'l1_Layer_3': 2.458397383396608e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 120, 'n_units_Layer_3': 200}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.62 | sMAPE for Validation Set is: 22.93% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.07 | sMAPE for Test Set is: 22.26% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:58:13,250]\u001b[0m Trial 921 finished with value: 42.931259271401494 and parameters: {'n_hidden': 3, 'learning_rate': 0.002650661957059528, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2501463863802848, 'dropout_rate_Layer_2': 0.0730567216594164, 'dropout_rate_Layer_3': 0.20394329449620777, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010681315339721562, 'l1_Layer_2': 0.009549046734241404, 'l1_Layer_3': 2.093460112193369e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 130, 'n_units_Layer_3': 195}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.93 | sMAPE for Validation Set is: 23.15% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 18.63 | sMAPE for Test Set is: 24.46% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:58:15,179]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.80 | sMAPE for Validation Set is: 23.28% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 18.82 | sMAPE for Test Set is: 24.63% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:58:15,840]\u001b[0m Trial 922 finished with value: 42.804753318278586 and parameters: {'n_hidden': 3, 'learning_rate': 0.002488741238719043, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07143291043384957, 'dropout_rate_Layer_2': 0.06302961844376354, 'dropout_rate_Layer_3': 0.2029548630198709, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010929042452879503, 'l1_Layer_2': 0.009399905267163649, 'l1_Layer_3': 2.404288448086473e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 130, 'n_units_Layer_3': 190}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:58:22,779]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:58:28,235]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:58:29,013]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:58:32,707]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:58:38,190]\u001b[0m Trial 918 finished with value: 43.849514191458105 and parameters: {'n_hidden': 3, 'learning_rate': 0.001539434227677177, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1703743435834044, 'dropout_rate_Layer_2': 0.08291169321686856, 'dropout_rate_Layer_3': 0.04630082759326313, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.812772076206831e-05, 'l1_Layer_2': 6.163333568982202e-05, 'l1_Layer_3': 1.2637952302460827e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 150, 'n_units_Layer_3': 125}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.85 | sMAPE for Validation Set is: 23.85% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 23.18 | sMAPE for Test Set is: 29.78% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:58:38,965]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:58:44,728]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:58:45,867]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:58:50,341]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:58:51,961]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:58:54,092]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:58:57,602]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:59:06,546]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:59:10,870]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:59:15,292]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:59:18,992]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:59:21,604]\u001b[0m Trial 936 finished with value: 42.163050745243915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023167057286515385, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1833427631863387, 'dropout_rate_Layer_2': 0.38957989925062514, 'dropout_rate_Layer_3': 0.34057893233606046, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.876984789754168e-05, 'l1_Layer_2': 0.0009551713938288149, 'l1_Layer_3': 4.146199916823748e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 285}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.16 | sMAPE for Validation Set is: 22.78% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.93 | sMAPE for Test Set is: 23.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:59:25,928]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:59:26,629]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:59:26,967]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:59:35,250]\u001b[0m Trial 929 finished with value: 42.400872774159666 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014561860142279447, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07351003497624554, 'dropout_rate_Layer_2': 0.07958726540135934, 'dropout_rate_Layer_3': 0.022871373941766714, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.2779921099663154e-05, 'l1_Layer_2': 6.750804163841085e-05, 'l1_Layer_3': 1.7240110086179394e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.40 | sMAPE for Validation Set is: 23.12% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.78 | sMAPE for Test Set is: 23.52% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 18:59:35,684]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:59:36,757]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:59:44,407]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:59:45,157]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 18:59:51,886]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:00:02,021]\u001b[0m Trial 950 finished with value: 42.87315373993897 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014947399137362081, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1548086283598508, 'dropout_rate_Layer_2': 0.3859015947750502, 'dropout_rate_Layer_3': 0.3353127819153165, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.064448724791851e-05, 'l1_Layer_2': 0.0010068646004190774, 'l1_Layer_3': 2.1896448454993438e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.87 | sMAPE for Validation Set is: 22.91% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.29 | sMAPE for Test Set is: 22.69% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:00:16,699]\u001b[0m Trial 952 finished with value: 42.08284514694379 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018270681273728146, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06845902881366363, 'dropout_rate_Layer_2': 0.29095618806960505, 'dropout_rate_Layer_3': 0.01945265950626443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4419566080826625e-05, 'l1_Layer_2': 5.4962657428125956e-05, 'l1_Layer_3': 2.0471594037748087e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 145, 'n_units_Layer_3': 265}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.08 | sMAPE for Validation Set is: 22.97% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.83 | sMAPE for Test Set is: 23.85% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:00:17,104]\u001b[0m Trial 951 finished with value: 42.0793121905815 and parameters: {'n_hidden': 3, 'learning_rate': 0.00180508902779362, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06610358426061928, 'dropout_rate_Layer_2': 0.09093935663456758, 'dropout_rate_Layer_3': 0.017613918563241772, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010139394926213324, 'l1_Layer_2': 5.9961430625777635e-05, 'l1_Layer_3': 2.182686026322211e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 160, 'n_units_Layer_3': 265}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.08 | sMAPE for Validation Set is: 22.91% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.65 | sMAPE for Test Set is: 22.86% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:00:22,931]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:00:27,902]\u001b[0m Trial 947 finished with value: 41.44483872319012 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017358168456726509, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18607693505928655, 'dropout_rate_Layer_2': 0.08933478012070582, 'dropout_rate_Layer_3': 0.01673227423895986, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.698251364438171e-05, 'l1_Layer_2': 9.249579140686355e-05, 'l1_Layer_3': 1.9826990169377503e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 160, 'n_units_Layer_3': 255}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.44 | sMAPE for Validation Set is: 22.95% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.77 | sMAPE for Test Set is: 24.64% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:00:34,373]\u001b[0m Trial 955 finished with value: 41.804679016912125 and parameters: {'n_hidden': 4, 'learning_rate': 0.001988023300390225, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06485329519453331, 'dropout_rate_Layer_2': 0.015361943004534123, 'dropout_rate_Layer_3': 0.04447933411967307, 'dropout_rate_Layer_4': 0.008228849221754785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00020664102956695484, 'l1_Layer_2': 1.848945039991632e-05, 'l1_Layer_3': 0.0004568670949567016, 'l1_Layer_4': 0.0002394996201096217, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190, 'n_units_Layer_4': 115}. Best is trial 514 with value: 41.13330544739795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.80 | sMAPE for Validation Set is: 22.50% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.74 | sMAPE for Test Set is: 21.60% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:00:38,727]\u001b[0m Trial 953 finished with value: 41.08198375842078 and parameters: {'n_hidden': 3, 'learning_rate': 0.001526647054191866, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07693790317271992, 'dropout_rate_Layer_2': 0.07949935800023177, 'dropout_rate_Layer_3': 0.010150556461503493, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.279096529231974e-05, 'l1_Layer_2': 6.475702590634848e-05, 'l1_Layer_3': 2.23717360733926e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.08 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 17.17 | sMAPE for Test Set is: 22.65% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:00:39,129]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:00:39,599]\u001b[0m Trial 956 finished with value: 42.85360249802886 and parameters: {'n_hidden': 4, 'learning_rate': 0.002012834695751617, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016183009996898583, 'dropout_rate_Layer_2': 0.015461433065733887, 'dropout_rate_Layer_3': 0.04619699431900837, 'dropout_rate_Layer_4': 0.009057139191786212, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00022830660763748398, 'l1_Layer_2': 1.1108614538509645e-05, 'l1_Layer_3': 0.00046508498731002035, 'l1_Layer_4': 0.00015344175281667053, 'n_units_Layer_1': 210, 'n_units_Layer_2': 180, 'n_units_Layer_3': 190, 'n_units_Layer_4': 115}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.85 | sMAPE for Validation Set is: 22.81% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 18.65 | sMAPE for Test Set is: 23.67% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:00:49,424]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:00:53,601]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:00:54,057]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:00:54,469]\u001b[0m Trial 957 finished with value: 42.50495092419235 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019375743909453133, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009779454137381377, 'dropout_rate_Layer_2': 0.010736073859900474, 'dropout_rate_Layer_3': 0.04815830552880691, 'dropout_rate_Layer_4': 0.00883740396118031, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00023769823857102296, 'l1_Layer_2': 1.9067562223621285e-05, 'l1_Layer_3': 0.000761866639361639, 'l1_Layer_4': 6.620312703758878e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 175, 'n_units_Layer_3': 205, 'n_units_Layer_4': 115}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.50 | sMAPE for Validation Set is: 22.75% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.54 | sMAPE for Test Set is: 24.01% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:01:07,285]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:01:11,328]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:01:15,187]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:01:20,535]\u001b[0m Trial 965 finished with value: 42.779277252520494 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015046755643172648, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15440578628084883, 'dropout_rate_Layer_2': 0.39981776471643543, 'dropout_rate_Layer_3': 0.33951909773857364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.3123019771224515e-05, 'l1_Layer_2': 0.0009228915568634407, 'l1_Layer_3': 2.0825968259648584e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.78 | sMAPE for Validation Set is: 23.01% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.27 | sMAPE for Test Set is: 22.68% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:01:23,283]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:01:27,914]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:01:31,113]\u001b[0m Trial 963 finished with value: 42.49823242425974 and parameters: {'n_hidden': 3, 'learning_rate': 0.003053903182399258, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08579231273796808, 'dropout_rate_Layer_2': 0.07516835059221869, 'dropout_rate_Layer_3': 0.1975162687058638, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.80696209182575e-05, 'l1_Layer_2': 0.008603736370924086, 'l1_Layer_3': 1.9853194356775277e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 125, 'n_units_Layer_3': 190}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.50 | sMAPE for Validation Set is: 22.91% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.63 | sMAPE for Test Set is: 24.35% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:01:38,362]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:01:38,946]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:01:44,747]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:01:47,299]\u001b[0m Trial 967 finished with value: 42.062706752942816 and parameters: {'n_hidden': 3, 'learning_rate': 0.003085726620366914, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07795788762635258, 'dropout_rate_Layer_2': 0.0762111034961594, 'dropout_rate_Layer_3': 0.1963146412179139, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.191220258196582e-05, 'l1_Layer_2': 0.008078183951389803, 'l1_Layer_3': 1.917106412270964e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 125, 'n_units_Layer_3': 155}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.06 | sMAPE for Validation Set is: 22.87% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.90 | sMAPE for Test Set is: 23.36% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:01:51,601]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:01:59,789]\u001b[0m Trial 971 finished with value: 41.95754367052233 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020496241058527856, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06928400769412875, 'dropout_rate_Layer_2': 0.3119949098646265, 'dropout_rate_Layer_3': 0.020501853128149103, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010401548343059677, 'l1_Layer_2': 5.387897020327816e-05, 'l1_Layer_3': 2.1501479382689614e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.96 | sMAPE for Validation Set is: 22.86% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.57 | sMAPE for Test Set is: 22.71% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:02:03,416]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:02:08,708]\u001b[0m Trial 975 finished with value: 42.22215258537058 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015427135050824852, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07276573115767052, 'dropout_rate_Layer_2': 0.07866633760348649, 'dropout_rate_Layer_3': 0.02546007050154183, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.120275994563257e-05, 'l1_Layer_2': 5.3145639270749936e-05, 'l1_Layer_3': 2.7195157598802416e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.22 | sMAPE for Validation Set is: 22.87% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.29 | sMAPE for Test Set is: 23.66% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:02:09,026]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:02:17,164]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:02:20,680]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:02:24,663]\u001b[0m Trial 976 finished with value: 42.44608713345987 and parameters: {'n_hidden': 3, 'learning_rate': 0.002680204146647875, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07700912459323614, 'dropout_rate_Layer_2': 0.07857742921212611, 'dropout_rate_Layer_3': 0.1738613900116562, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.082516552027447e-05, 'l1_Layer_2': 0.006368759759836369, 'l1_Layer_3': 1.420270263246092e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 125, 'n_units_Layer_3': 150}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.45 | sMAPE for Validation Set is: 23.12% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.05 | sMAPE for Test Set is: 23.84% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:02:25,174]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:02:32,580]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:02:36,750]\u001b[0m Trial 979 finished with value: 42.33831780451247 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030852003399095204, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07637123524356289, 'dropout_rate_Layer_2': 0.07105114725165415, 'dropout_rate_Layer_3': 0.1763904662736036, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.498619511906594e-05, 'l1_Layer_2': 0.00646015573978791, 'l1_Layer_3': 1.3771329985450612e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 125, 'n_units_Layer_3': 155}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.34 | sMAPE for Validation Set is: 22.56% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.69 | sMAPE for Test Set is: 22.92% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:02:44,805]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:02:45,950]\u001b[0m Trial 982 finished with value: 41.35378226932479 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022359647818086664, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18405861772466944, 'dropout_rate_Layer_2': 0.3986906353137769, 'dropout_rate_Layer_3': 0.3797234505130553, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.934040402688792e-05, 'l1_Layer_2': 0.001720699034043532, 'l1_Layer_3': 4.488318323506584e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 300, 'n_units_Layer_3': 275}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.35 | sMAPE for Validation Set is: 22.84% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.91 | sMAPE for Test Set is: 24.00% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:02:50,621]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:07,583]\u001b[0m Trial 987 finished with value: 41.88781024741998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014612931650273705, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05034465758369667, 'dropout_rate_Layer_2': 0.3143856031578164, 'dropout_rate_Layer_3': 0.00036992825231454377, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001589872591889349, 'l1_Layer_2': 5.4728389145354614e-05, 'l1_Layer_3': 2.5788568051633328e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.89 | sMAPE for Validation Set is: 23.09% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.12 | sMAPE for Test Set is: 24.04% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:03:12,974]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:15,956]\u001b[0m Trial 989 finished with value: 42.80676972497983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030004571398687947, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07656692746633552, 'dropout_rate_Layer_2': 0.08861638391755382, 'dropout_rate_Layer_3': 0.17560020516003425, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.483544244540078e-05, 'l1_Layer_2': 0.004557638297458891, 'l1_Layer_3': 1.4395517065114361e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 125, 'n_units_Layer_3': 150}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.81 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.62 | sMAPE for Test Set is: 23.43% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:03:18,751]\u001b[0m Trial 990 finished with value: 42.7812755496675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022338230275263066, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14410180024594818, 'dropout_rate_Layer_2': 0.3529505838937416, 'dropout_rate_Layer_3': 0.37683645996949455, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.167001435615383e-05, 'l1_Layer_2': 0.001770705411346617, 'l1_Layer_3': 4.074810892277607e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 295, 'n_units_Layer_3': 275}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.78 | sMAPE for Validation Set is: 23.10% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.40 | sMAPE for Test Set is: 22.84% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:03:22,977]\u001b[0m Trial 988 finished with value: 41.86035029917234 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020870493071931586, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18654698855932675, 'dropout_rate_Layer_2': 0.3539464135684315, 'dropout_rate_Layer_3': 0.3749041770275199, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.510471154785103e-05, 'l1_Layer_2': 0.0017894273116749893, 'l1_Layer_3': 4.119190305007614e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 295, 'n_units_Layer_3': 275}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.86 | sMAPE for Validation Set is: 22.75% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.85 | sMAPE for Test Set is: 23.92% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:03:23,490]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:29,572]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:29,945]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:30,799]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:38,177]\u001b[0m Trial 993 finished with value: 42.338230816749665 and parameters: {'n_hidden': 3, 'learning_rate': 0.002196947155854817, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18532769371346391, 'dropout_rate_Layer_2': 0.39959058288827054, 'dropout_rate_Layer_3': 0.3825299812269089, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.510345941093918e-05, 'l1_Layer_2': 0.0021763750686946922, 'l1_Layer_3': 4.4408608886639194e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 290, 'n_units_Layer_3': 280}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.34 | sMAPE for Validation Set is: 22.86% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.99 | sMAPE for Test Set is: 23.14% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:03:38,890]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:39,386]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:39,543]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:44,536]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:51,546]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:52,120]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:57,704]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:03:59,785]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:04:15,326]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:04:19,712]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:04:24,718]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:04:25,057]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:04:31,553]\u001b[0m Trial 1004 finished with value: 42.08665554624259 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023432524172129956, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09370053951371404, 'dropout_rate_Layer_2': 0.06414203640258026, 'dropout_rate_Layer_3': 0.19193503353571956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.9999257237404975e-05, 'l1_Layer_2': 0.0055570256673272275, 'l1_Layer_3': 1.2595947583316494e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 110, 'n_units_Layer_3': 160}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.09 | sMAPE for Validation Set is: 22.81% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.63 | sMAPE for Test Set is: 23.67% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:04:37,142]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:04:44,253]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:04:48,687]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:04:53,059]\u001b[0m Trial 1011 finished with value: 42.760264636679956 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016584448019828163, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0630474428439021, 'dropout_rate_Layer_2': 0.32476165507667293, 'dropout_rate_Layer_3': 0.035604161558413255, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.536605886593804e-05, 'l1_Layer_2': 4.501345476681946e-05, 'l1_Layer_3': 5.109277057316662e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.76 | sMAPE for Validation Set is: 22.90% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.50 | sMAPE for Test Set is: 23.99% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:05:00,170]\u001b[0m Trial 1014 finished with value: 41.89763580441697 and parameters: {'n_hidden': 3, 'learning_rate': 0.001846302302245568, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16566928731576236, 'dropout_rate_Layer_2': 0.36296122601722325, 'dropout_rate_Layer_3': 0.3859014955084575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.278866778245949e-05, 'l1_Layer_2': 0.0038579363270626935, 'l1_Layer_3': 5.3915878750722255e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:00,280]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.90 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.11 | sMAPE for Test Set is: 23.68% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:05:00,511]\u001b[0m Trial 1013 finished with value: 41.4694138002662 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018616220014767715, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16597827928626505, 'dropout_rate_Layer_2': 0.3429917959019767, 'dropout_rate_Layer_3': 0.3834541890361972, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.0802863070238e-05, 'l1_Layer_2': 0.006449695058491446, 'l1_Layer_3': 5.28306674245713e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.47 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.17 | sMAPE for Test Set is: 22.64% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:05:09,131]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:11,825]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:16,979]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:17,701]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:18,071]\u001b[0m Trial 1016 finished with value: 42.4865869143139 and parameters: {'n_hidden': 3, 'learning_rate': 0.002251914138693388, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07621002669852991, 'dropout_rate_Layer_2': 0.0697431193227231, 'dropout_rate_Layer_3': 0.1982088016893893, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.1128266060060636e-05, 'l1_Layer_2': 0.003932766068813543, 'l1_Layer_3': 1.1339626049436478e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 100, 'n_units_Layer_3': 155}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.49 | sMAPE for Validation Set is: 22.87% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.95 | sMAPE for Test Set is: 23.53% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:05:25,320]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:25,854]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:25,927]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:25,972]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:30,646]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:37,553]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:38,508]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:38,650]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:40,547]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:46,344]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:46,810]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:48,110]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:56,541]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:57,531]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:05:59,085]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:06:06,091]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:06:24,406]\u001b[0m Trial 1038 finished with value: 41.93395992302583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026582120699094568, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1648942858542855, 'dropout_rate_Layer_2': 0.35892808011806204, 'dropout_rate_Layer_3': 0.3854376559200592, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.00341329981905e-05, 'l1_Layer_2': 0.011035424988567476, 'l1_Layer_3': 5.680970314139984e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 285}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.93 | sMAPE for Validation Set is: 23.07% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.72 | sMAPE for Test Set is: 25.41% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:06:28,054]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:06:29,168]\u001b[0m Trial 1034 finished with value: 41.60530734267315 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007755278418882907, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16727829365207111, 'dropout_rate_Layer_2': 0.3597313785573098, 'dropout_rate_Layer_3': 0.3901560185577197, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.994181016848949e-05, 'l1_Layer_2': 0.0033004778382826156, 'l1_Layer_3': 6.507450353111414e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.61 | sMAPE for Validation Set is: 22.88% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.06 | sMAPE for Test Set is: 24.67% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 41.41 | sMAPE for Validation Set is: 22.50% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.54 | sMAPE for Test Set is: 23.72% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:06:30,964]\u001b[0m Trial 1040 finished with value: 41.41263829400946 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023141417104137045, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08012917094807184, 'dropout_rate_Layer_2': 0.05488533037314319, 'dropout_rate_Layer_3': 0.15985093013078136, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.520651715161339e-05, 'l1_Layer_2': 0.00614506646537439, 'l1_Layer_3': 1.6200411681394596e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 160}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:06:42,277]\u001b[0m Trial 1041 finished with value: 42.338798901587445 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022931161334743184, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07138126204878578, 'dropout_rate_Layer_2': 0.054512824203649, 'dropout_rate_Layer_3': 0.19098294520186093, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.616997698338294e-05, 'l1_Layer_2': 0.006274306219983591, 'l1_Layer_3': 1.6450202900364858e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 160}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.34 | sMAPE for Validation Set is: 22.75% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.31 | sMAPE for Test Set is: 25.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:06:54,839]\u001b[0m Trial 1043 finished with value: 41.178788582921804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017601321455408203, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06950748935587457, 'dropout_rate_Layer_2': 0.06963625761587429, 'dropout_rate_Layer_3': 0.0005768835981855425, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7129086296714066e-05, 'l1_Layer_2': 5.4432824826549276e-05, 'l1_Layer_3': 3.5070238383631765e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 260}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.18 | sMAPE for Validation Set is: 22.72% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 18.10 | sMAPE for Test Set is: 23.66% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:06:56,073]\u001b[0m Trial 1045 finished with value: 42.03231985474903 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028468739052271057, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0786548021864405, 'dropout_rate_Layer_2': 0.05499922466883171, 'dropout_rate_Layer_3': 0.14857410539171126, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.904949069719738e-05, 'l1_Layer_2': 0.00662354632158981, 'l1_Layer_3': 1.7083544419839165e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 160}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.03 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.94 | sMAPE for Test Set is: 23.76% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:07:00,531]\u001b[0m Trial 1044 finished with value: 42.16578156231086 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026945304373537544, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17332006066438888, 'dropout_rate_Layer_2': 0.3535626644003231, 'dropout_rate_Layer_3': 0.39095370289694514, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015269356101335897, 'l1_Layer_2': 0.003609268567720969, 'l1_Layer_3': 0.0001379063434498679, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 300}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.17 | sMAPE for Validation Set is: 22.87% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.90 | sMAPE for Test Set is: 25.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:07:15,338]\u001b[0m Trial 1046 finished with value: 42.2249944220346 and parameters: {'n_hidden': 3, 'learning_rate': 0.00240582300279187, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08055620544061243, 'dropout_rate_Layer_2': 0.05619846722583651, 'dropout_rate_Layer_3': 0.15919722895432692, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.809363678153114e-05, 'l1_Layer_2': 0.006559368728312111, 'l1_Layer_3': 2.0018122868430654e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 160}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.22 | sMAPE for Validation Set is: 23.15% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.61 | sMAPE for Test Set is: 23.61% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:07:16,694]\u001b[0m Trial 1048 finished with value: 42.14524138228104 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009466747050664042, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 5.9005410143829484e-05, 'dropout_rate_Layer_2': 0.03932076149436927, 'dropout_rate_Layer_3': 0.03811312213038092, 'dropout_rate_Layer_4': 0.30459488997040096, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010820711559880316, 'l1_Layer_2': 1.7830219054193913e-05, 'l1_Layer_3': 0.0002996087055135106, 'l1_Layer_4': 0.00027125038626072247, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 205, 'n_units_Layer_4': 110}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.15 | sMAPE for Validation Set is: 22.48% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.61 | sMAPE for Test Set is: 22.32% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:07:18,037]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:07:18,769]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:07:20,275]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:07:28,371]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:07:32,789]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:07:35,849]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:07:40,093]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:07:40,617]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:07:46,039]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:07:48,873]\u001b[0m Trial 1054 finished with value: 42.587693275014 and parameters: {'n_hidden': 4, 'learning_rate': 0.002226000186759098, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021147299213297055, 'dropout_rate_Layer_2': 0.006192772132744436, 'dropout_rate_Layer_3': 0.08114420555128035, 'dropout_rate_Layer_4': 0.03980152503523923, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002922406917613892, 'l1_Layer_2': 0.00011240486277684914, 'l1_Layer_3': 0.0006824264766524095, 'l1_Layer_4': 8.893969626270379e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 285, 'n_units_Layer_3': 185, 'n_units_Layer_4': 55}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.59 | sMAPE for Validation Set is: 22.55% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.53 | sMAPE for Test Set is: 23.32% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:07:53,689]\u001b[0m Trial 1052 finished with value: 42.66685346639121 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013576430851723795, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01955949783855722, 'dropout_rate_Layer_2': 0.0012094754773113187, 'dropout_rate_Layer_3': 0.080417825077719, 'dropout_rate_Layer_4': 0.03901849844655884, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002773197206724852, 'l1_Layer_2': 0.00020238106441238999, 'l1_Layer_3': 0.0006744716577426513, 'l1_Layer_4': 8.077917042311297e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 290, 'n_units_Layer_3': 185, 'n_units_Layer_4': 130}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.67 | sMAPE for Validation Set is: 23.02% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.21 | sMAPE for Test Set is: 23.65% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:07:57,740]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:08:02,874]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:08:05,948]\u001b[0m Trial 1058 finished with value: 41.88801091814396 and parameters: {'n_hidden': 3, 'learning_rate': 0.002987040012902149, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.141228417845142, 'dropout_rate_Layer_2': 0.3641045540921786, 'dropout_rate_Layer_3': 0.3608141520931565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.098530748882395e-05, 'l1_Layer_2': 0.014862523007774938, 'l1_Layer_3': 7.895394659570724e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 300, 'n_units_Layer_3': 285}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.89 | sMAPE for Validation Set is: 22.97% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.58 | sMAPE for Test Set is: 25.54% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:08:14,534]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:08:16,914]\u001b[0m Trial 1061 finished with value: 41.22691946779772 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020446202582337604, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07250156548211456, 'dropout_rate_Layer_2': 0.06931694530391598, 'dropout_rate_Layer_3': 0.007255658383856925, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.490049700914342e-05, 'l1_Layer_2': 8.627048133646099e-05, 'l1_Layer_3': 2.2851195143199724e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 100, 'n_units_Layer_3': 260}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.23 | sMAPE for Validation Set is: 22.40% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.98 | sMAPE for Test Set is: 22.41% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:08:19,293]\u001b[0m Trial 1060 finished with value: 41.95115928766836 and parameters: {'n_hidden': 3, 'learning_rate': 0.002451318690096829, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06962588785343408, 'dropout_rate_Layer_2': 0.07605864988821967, 'dropout_rate_Layer_3': 0.1560476481839386, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.573273581274769e-05, 'l1_Layer_2': 0.004831407922446373, 'l1_Layer_3': 1.7723572322917336e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 110, 'n_units_Layer_3': 155}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.95 | sMAPE for Validation Set is: 22.67% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.51 | sMAPE for Test Set is: 24.57% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:08:20,224]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:08:21,339]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:08:27,198]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:08:28,283]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:08:33,864]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:08:39,301]\u001b[0m Trial 1064 finished with value: 42.072092878884554 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020648000600974907, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07496914337411976, 'dropout_rate_Layer_2': 0.0711273960575442, 'dropout_rate_Layer_3': 0.010033080994315356, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3388997334772524e-05, 'l1_Layer_2': 8.085562449339128e-05, 'l1_Layer_3': 5.3141076364420435e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 105, 'n_units_Layer_3': 255}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.07 | sMAPE for Validation Set is: 23.21% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.28 | sMAPE for Test Set is: 22.50% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:08:48,343]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:08:53,134]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:08:54,376]\u001b[0m Trial 1073 finished with value: 42.210533723421605 and parameters: {'n_hidden': 4, 'learning_rate': 0.000968399191703866, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003309848930781789, 'dropout_rate_Layer_2': 0.32781909737374526, 'dropout_rate_Layer_3': 0.03625044026222278, 'dropout_rate_Layer_4': 0.3739313728517998, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001183852472538177, 'l1_Layer_2': 1.9517293516942193e-05, 'l1_Layer_3': 0.0002869114265343625, 'l1_Layer_4': 0.00029241309652489457, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 205, 'n_units_Layer_4': 110}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.21 | sMAPE for Validation Set is: 22.61% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.44 | sMAPE for Test Set is: 22.66% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:08:59,993]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:00,834]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:07,798]\u001b[0m Trial 1071 finished with value: 41.65585230342516 and parameters: {'n_hidden': 3, 'learning_rate': 0.002251398110688187, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09504336761169152, 'dropout_rate_Layer_2': 0.06681013525246318, 'dropout_rate_Layer_3': 0.1564860437347105, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.955742373635145e-05, 'l1_Layer_2': 0.006376908453903421, 'l1_Layer_3': 1.8734632204180225e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 115, 'n_units_Layer_3': 150}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:07,926]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.66 | sMAPE for Validation Set is: 22.70% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.85 | sMAPE for Test Set is: 23.23% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:09:13,825]\u001b[0m Trial 1074 finished with value: 43.26432666238682 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018477607256729765, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13262643402981328, 'dropout_rate_Layer_2': 0.3674651360790127, 'dropout_rate_Layer_3': 0.36051338666552524, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.84919769397209e-05, 'l1_Layer_2': 0.015762414672107358, 'l1_Layer_3': 6.87904341658534e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 300, 'n_units_Layer_3': 275}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.26 | sMAPE for Validation Set is: 23.12% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 19.87 | sMAPE for Test Set is: 25.47% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:09:17,719]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:17,988]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:23,933]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:28,890]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:32,120]\u001b[0m Trial 1081 finished with value: 41.62011620842711 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012332902667384275, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010334477023370625, 'dropout_rate_Layer_2': 0.032744715292639996, 'dropout_rate_Layer_3': 0.056518785209370745, 'dropout_rate_Layer_4': 0.007423013636527049, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.276871359034404e-05, 'l1_Layer_2': 2.1830694302136897e-05, 'l1_Layer_3': 0.0003401920461537608, 'l1_Layer_4': 0.00019019131150174956, 'n_units_Layer_1': 230, 'n_units_Layer_2': 195, 'n_units_Layer_3': 90, 'n_units_Layer_4': 115}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.62 | sMAPE for Validation Set is: 22.15% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.28 | sMAPE for Test Set is: 22.54% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:09:35,126]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:38,123]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:39,181]\u001b[0m Trial 1079 finished with value: 41.97642925798442 and parameters: {'n_hidden': 3, 'learning_rate': 0.002280936432713111, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07089560475576161, 'dropout_rate_Layer_2': 0.06427020646742872, 'dropout_rate_Layer_3': 0.15527239298023615, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.985184350524973e-05, 'l1_Layer_2': 0.006494902906915433, 'l1_Layer_3': 1.9022063300989726e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 115, 'n_units_Layer_3': 170}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.98 | sMAPE for Validation Set is: 22.84% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.25 | sMAPE for Test Set is: 22.84% | rMAE for Test Set is: 0.58\n",
      "MAE for Validation Set is: 41.85 | sMAPE for Validation Set is: 22.27% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.62 | sMAPE for Test Set is: 22.78% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:09:40,970]\u001b[0m Trial 1085 finished with value: 41.846502511438594 and parameters: {'n_hidden': 4, 'learning_rate': 0.001236915742640723, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00091147007172879, 'dropout_rate_Layer_2': 0.03525405267910229, 'dropout_rate_Layer_3': 0.05872898255180627, 'dropout_rate_Layer_4': 0.19939235717629408, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006618569833958939, 'l1_Layer_2': 2.2948536352433798e-05, 'l1_Layer_3': 0.0003179032288768161, 'l1_Layer_4': 0.0002661328435605437, 'n_units_Layer_1': 230, 'n_units_Layer_2': 195, 'n_units_Layer_3': 205, 'n_units_Layer_4': 115}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:46,124]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:47,309]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:51,203]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:51,964]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:57,708]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:09:59,066]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:10:06,464]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:10:10,438]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:10:13,543]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:10:18,510]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:10:21,620]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:10:34,002]\u001b[0m Trial 1094 finished with value: 42.08863310255152 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017570391173506988, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0638171765695158, 'dropout_rate_Layer_2': 0.06149183242781975, 'dropout_rate_Layer_3': 0.14635219344838174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010420240721056662, 'l1_Layer_2': 0.0051141854751264575, 'l1_Layer_3': 1.6183150170892947e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 110, 'n_units_Layer_3': 170}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.09 | sMAPE for Validation Set is: 22.69% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.45 | sMAPE for Test Set is: 23.02% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:10:37,590]\u001b[0m Trial 1097 finished with value: 41.531187266255806 and parameters: {'n_hidden': 3, 'learning_rate': 0.001816444889745757, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09069294924539405, 'dropout_rate_Layer_2': 0.05897246399854704, 'dropout_rate_Layer_3': 9.000443803738357e-05, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4155616205960944e-05, 'l1_Layer_2': 3.9707016953242796e-05, 'l1_Layer_3': 2.7170214169382677e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 110, 'n_units_Layer_3': 265}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.53 | sMAPE for Validation Set is: 22.42% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.44 | sMAPE for Test Set is: 22.67% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:10:38,603]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:10:41,252]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:10:44,043]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:10:46,629]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:10:57,186]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:00,253]\u001b[0m Trial 1102 finished with value: 42.31684190857558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018332245608483875, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0791570958359103, 'dropout_rate_Layer_2': 0.06241989383749543, 'dropout_rate_Layer_3': 0.14283368820508763, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.98854274832949e-05, 'l1_Layer_2': 0.007189693941982142, 'l1_Layer_3': 2.3963488171761848e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 115, 'n_units_Layer_3': 170}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.32 | sMAPE for Validation Set is: 22.75% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.11 | sMAPE for Test Set is: 22.58% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:11:00,543]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:06,180]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:06,614]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:12,177]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:12,682]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:19,734]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:19,888]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:24,657]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:28,729]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:32,973]\u001b[0m Trial 1110 finished with value: 41.63312104325721 and parameters: {'n_hidden': 3, 'learning_rate': 0.002180515181345756, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07904737251635406, 'dropout_rate_Layer_2': 0.07032232064898654, 'dropout_rate_Layer_3': 0.010394763733986623, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6497652175749397e-05, 'l1_Layer_2': 5.300896127696785e-05, 'l1_Layer_3': 2.5694802436193994e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 110, 'n_units_Layer_3': 260}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.63 | sMAPE for Validation Set is: 22.46% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.32 | sMAPE for Test Set is: 22.77% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:11:37,799]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:42,487]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:42,683]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:53,341]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:11:57,594]\u001b[0m Trial 1116 finished with value: 41.355817513625865 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016515002782197402, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09154891116102096, 'dropout_rate_Layer_2': 0.05461228805903706, 'dropout_rate_Layer_3': 0.00861060700095357, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0156948896127e-05, 'l1_Layer_2': 5.018253611944121e-05, 'l1_Layer_3': 4.0871534656945936e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 110, 'n_units_Layer_3': 260}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.36 | sMAPE for Validation Set is: 22.80% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.15 | sMAPE for Test Set is: 22.91% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:12:01,745]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:12:06,551]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:12:07,861]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:12:13,709]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:12:17,420]\u001b[0m Trial 1119 finished with value: 41.27454272215634 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015066495688183888, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08028897248600732, 'dropout_rate_Layer_2': 0.08356310645938127, 'dropout_rate_Layer_3': 0.1300297383201302, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.244379758527022e-05, 'l1_Layer_2': 0.0063425296451698554, 'l1_Layer_3': 1.999630855009502e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 120, 'n_units_Layer_3': 165}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.27 | sMAPE for Validation Set is: 22.34% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.87 | sMAPE for Test Set is: 23.87% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:12:21,771]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:12:28,946]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:12:29,852]\u001b[0m Trial 1124 finished with value: 41.80621585654424 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018250803435882201, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08044802531826095, 'dropout_rate_Layer_2': 0.0658495587293799, 'dropout_rate_Layer_3': 0.13379403865468142, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.949999169824173e-05, 'l1_Layer_2': 0.008383833654664097, 'l1_Layer_3': 1.8502798467572022e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 120, 'n_units_Layer_3': 165}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.81 | sMAPE for Validation Set is: 22.38% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.77 | sMAPE for Test Set is: 22.21% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:12:34,872]\u001b[0m Trial 1127 finished with value: 43.277009157983514 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010959738936737677, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11744674299672844, 'dropout_rate_Layer_2': 0.3789371051484513, 'dropout_rate_Layer_3': 0.38592071078125784, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.904043802464211e-05, 'l1_Layer_2': 0.003881897546867986, 'l1_Layer_3': 0.00010389222902400504, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.28 | sMAPE for Validation Set is: 22.91% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.30 | sMAPE for Test Set is: 21.91% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:12:37,720]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:12:38,866]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:12:39,057]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:12:47,197]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:12:47,899]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:12:54,869]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:12:55,410]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:00,957]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:03,756]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:07,469]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:11,219]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:11,667]\u001b[0m Trial 1136 finished with value: 42.03663617208295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018359854854170174, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09016790561106416, 'dropout_rate_Layer_2': 0.08536773689004634, 'dropout_rate_Layer_3': 0.11385809827063441, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.858809809821796e-05, 'l1_Layer_2': 0.0011041809512609881, 'l1_Layer_3': 2.05685508329603e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 115, 'n_units_Layer_3': 175}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.04 | sMAPE for Validation Set is: 22.53% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.49 | sMAPE for Test Set is: 23.40% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:13:16,264]\u001b[0m Trial 1134 finished with value: 41.413100070997764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012717225996209144, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19387232482669878, 'dropout_rate_Layer_2': 0.3427991162782937, 'dropout_rate_Layer_3': 0.3511034334339079, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2622646314818953e-05, 'l1_Layer_2': 0.005845618015796095, 'l1_Layer_3': 7.944712553434534e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.41 | sMAPE for Validation Set is: 22.52% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.01 | sMAPE for Test Set is: 23.70% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:13:19,995]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:20,644]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:26,452]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:30,307]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:32,901]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:35,671]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:44,757]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:45,395]\u001b[0m Trial 1144 finished with value: 41.25967702704879 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013311449370164304, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19761801464929504, 'dropout_rate_Layer_2': 0.11363683194984095, 'dropout_rate_Layer_3': 0.3555096434169342, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001487951522458914, 'l1_Layer_2': 0.007029941521621001, 'l1_Layer_3': 5.249929792717596e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.26 | sMAPE for Validation Set is: 22.48% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.86 | sMAPE for Test Set is: 23.18% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:13:46,902]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:52,211]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:54,644]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:58,508]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:13:59,587]\u001b[0m Trial 1152 finished with value: 42.21216508706359 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015967400894250363, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08979031165350843, 'dropout_rate_Layer_2': 0.049147445428544656, 'dropout_rate_Layer_3': 0.10904726441073781, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020233033209408625, 'l1_Layer_2': 0.000692956871517081, 'l1_Layer_3': 2.1336053990072596e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 115, 'n_units_Layer_3': 170}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.21 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.49 | sMAPE for Test Set is: 22.83% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:14:07,465]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:14:08,737]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:14:14,375]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:14:16,764]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:14:22,302]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:14:26,197]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:14:32,955]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:14:39,855]\u001b[0m Trial 1157 finished with value: 42.061514916117794 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017127099970820666, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09019187536484848, 'dropout_rate_Layer_2': 0.06543120017468235, 'dropout_rate_Layer_3': 0.15451405246494385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001953431747005267, 'l1_Layer_2': 0.003352863462385517, 'l1_Layer_3': 2.563893486355572e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 120, 'n_units_Layer_3': 165}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.06 | sMAPE for Validation Set is: 22.50% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 16.76 | sMAPE for Test Set is: 22.56% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:14:40,803]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:14:45,688]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:14:45,723]\u001b[0m Trial 1158 finished with value: 41.528196185940466 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008478799296247736, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1988095716662557, 'dropout_rate_Layer_2': 0.07051765855056327, 'dropout_rate_Layer_3': 0.34875877310246706, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011255560797937355, 'l1_Layer_2': 0.005126651327589679, 'l1_Layer_3': 8.046846446769697e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.53 | sMAPE for Validation Set is: 22.29% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.09 | sMAPE for Test Set is: 22.25% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:14:46,631]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:14:47,842]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:14:55,063]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:00,049]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:02,371]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:06,313]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:06,551]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:12,625]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:13,253]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:14,348]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:19,097]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:21,956]\u001b[0m Trial 1171 finished with value: 41.18908161958059 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017543162897855468, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08855012768873528, 'dropout_rate_Layer_2': 0.08698030259204916, 'dropout_rate_Layer_3': 0.01249532479224232, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.590458752690529e-05, 'l1_Layer_2': 4.8819469874837384e-05, 'l1_Layer_3': 2.2063200418190807e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 170, 'n_units_Layer_3': 250}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.19 | sMAPE for Validation Set is: 22.55% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 17.81 | sMAPE for Test Set is: 23.87% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:15:24,347]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:24,690]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:30,132]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:33,562]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:37,924]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:42,640]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:42,925]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:47,161]\u001b[0m Trial 1185 finished with value: 42.26435493226825 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017856341699629022, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025681601737331236, 'dropout_rate_Layer_2': 0.018842497220740467, 'dropout_rate_Layer_3': 0.0005440292479063948, 'dropout_rate_Layer_4': 0.046966829449142516, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.2248815299072956e-05, 'l1_Layer_2': 1.3360306041983098e-05, 'l1_Layer_3': 0.00048343389379788983, 'l1_Layer_4': 0.0003392682126693765, 'n_units_Layer_1': 220, 'n_units_Layer_2': 245, 'n_units_Layer_3': 195, 'n_units_Layer_4': 90}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.26 | sMAPE for Validation Set is: 22.66% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 20.28 | sMAPE for Test Set is: 24.33% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:15:50,220]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:54,534]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:15:55,615]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:01,444]\u001b[0m Trial 1181 finished with value: 42.22556814694205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016314986931757628, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09906446681844455, 'dropout_rate_Layer_2': 0.06531427702175503, 'dropout_rate_Layer_3': 0.14680730635977704, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026336255128032657, 'l1_Layer_2': 0.001287481965987359, 'l1_Layer_3': 2.4314510543495827e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 120, 'n_units_Layer_3': 180}. Best is trial 953 with value: 41.08198375842078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.23 | sMAPE for Validation Set is: 22.90% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.17 | sMAPE for Test Set is: 24.91% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:16:02,821]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:07,971]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:13,181]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:17,090]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:20,370]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:23,632]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:26,705]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:28,396]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:30,023]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:33,081]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:33,250]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:36,573]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:41,868]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:43,076]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:43,553]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:48,693]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:52,436]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:55,491]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:16:59,895]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:04,782]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:05,330]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:12,003]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:16,761]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:21,262]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:23,919]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:27,319]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:31,888]\u001b[0m Trial 1212 finished with value: 40.91294781977182 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015495453952936423, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1110979016170363, 'dropout_rate_Layer_2': 0.04892626848015699, 'dropout_rate_Layer_3': 0.15798619371806544, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016616663287350638, 'l1_Layer_2': 0.0017998767853473871, 'l1_Layer_3': 2.3254767829896515e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 110, 'n_units_Layer_3': 170}. Best is trial 1212 with value: 40.91294781977182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.91 | sMAPE for Validation Set is: 21.92% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 17.42 | sMAPE for Test Set is: 23.27% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:17:32,255]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:34,287]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:40,726]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:43,496]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:47,436]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:47,681]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:52,069]\u001b[0m Trial 1211 finished with value: 41.411686851751874 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009135518937229163, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19340769003383249, 'dropout_rate_Layer_2': 0.1028613756490859, 'dropout_rate_Layer_3': 0.36991311461967086, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001043794072429028, 'l1_Layer_2': 0.005160220559758842, 'l1_Layer_3': 0.00017429073535167014, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165}. Best is trial 1212 with value: 40.91294781977182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.41 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.98 | sMAPE for Test Set is: 22.32% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:17:54,222]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:57,488]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:17:57,550]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:04,185]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:04,948]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:05,305]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:12,284]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:13,759]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:17,176]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:17,839]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:24,200]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:27,014]\u001b[0m Trial 1228 finished with value: 41.188415309537056 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012136661952677269, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0945466076876893, 'dropout_rate_Layer_2': 0.04573028340866206, 'dropout_rate_Layer_3': 0.03493083588050272, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013848268783634148, 'l1_Layer_2': 1.0449114252660707e-05, 'l1_Layer_3': 3.205212671481468e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 150}. Best is trial 1212 with value: 40.91294781977182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.19 | sMAPE for Validation Set is: 22.31% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 17.59 | sMAPE for Test Set is: 23.79% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:18:28,652]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:30,532]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:31,980]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:32,186]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:40,127]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:41,921]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:48,958]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:52,126]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:57,627]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:18:58,039]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:19:00,845]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:19:06,042]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:19:07,377]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:19:07,569]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:19:13,299]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:19:18,856]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:19:23,576]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:19:24,728]\u001b[0m Trial 1252 finished with value: 41.93571211985342 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011024307142293685, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00011243528171773348, 'dropout_rate_Layer_2': 0.013068213894054822, 'dropout_rate_Layer_3': 0.051404421258291505, 'dropout_rate_Layer_4': 0.29196388797648726, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.561684590890529e-05, 'l1_Layer_2': 2.1494724972516306e-05, 'l1_Layer_3': 0.0003136036197737474, 'l1_Layer_4': 0.00011421054115662975, 'n_units_Layer_1': 260, 'n_units_Layer_2': 180, 'n_units_Layer_3': 230, 'n_units_Layer_4': 105}. Best is trial 1212 with value: 40.91294781977182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.94 | sMAPE for Validation Set is: 22.27% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.86 | sMAPE for Test Set is: 22.41% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:19:29,994]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:19:34,425]\u001b[0m Trial 1254 finished with value: 41.10936337847131 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015160207978512426, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018427675944524293, 'dropout_rate_Layer_2': 0.026440436864079705, 'dropout_rate_Layer_3': 0.2376258354954, 'dropout_rate_Layer_4': 0.30359498356131764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005781979027357093, 'l1_Layer_2': 1.7681967963327417e-05, 'l1_Layer_3': 0.00016702554580927937, 'l1_Layer_4': 0.00012141444810612916, 'n_units_Layer_1': 240, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180, 'n_units_Layer_4': 110}. Best is trial 1212 with value: 40.91294781977182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.11 | sMAPE for Validation Set is: 22.12% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 17.06 | sMAPE for Test Set is: 21.95% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:19:38,559]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:19:40,135]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:19:42,115]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:19:50,661]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:20:00,372]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:20:01,722]\u001b[0m Trial 1262 finished with value: 41.841233891761505 and parameters: {'n_hidden': 3, 'learning_rate': 0.00222210564933742, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08407454423741173, 'dropout_rate_Layer_2': 0.052976295959156046, 'dropout_rate_Layer_3': 0.0060181713215773595, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6230451073148904e-05, 'l1_Layer_2': 7.422328812237647e-05, 'l1_Layer_3': 2.6438416817179503e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 180, 'n_units_Layer_3': 90}. Best is trial 1212 with value: 40.91294781977182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.84 | sMAPE for Validation Set is: 22.76% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.34 | sMAPE for Test Set is: 23.83% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:20:08,496]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:20:18,766]\u001b[0m Trial 1265 finished with value: 42.437081501711184 and parameters: {'n_hidden': 3, 'learning_rate': 0.002124139625731418, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08144439388458483, 'dropout_rate_Layer_2': 0.07352937451791489, 'dropout_rate_Layer_3': 0.005700749299048409, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.905937043992484e-05, 'l1_Layer_2': 6.240756274046916e-05, 'l1_Layer_3': 2.5443640231540547e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 175, 'n_units_Layer_3': 270}. Best is trial 1212 with value: 40.91294781977182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.44 | sMAPE for Validation Set is: 22.77% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.47 | sMAPE for Test Set is: 23.08% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:20:23,440]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:20:28,845]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:20:33,667]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:20:38,813]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:20:39,469]\u001b[0m Trial 1266 finished with value: 41.032161948693954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012448405105018893, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08361583276513794, 'dropout_rate_Layer_2': 0.047777009238772004, 'dropout_rate_Layer_3': 0.03052402708582705, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.025093192494593e-05, 'l1_Layer_2': 0.00011866683070025784, 'l1_Layer_3': 3.454737633287428e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 210, 'n_units_Layer_3': 250}. Best is trial 1212 with value: 40.91294781977182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.03 | sMAPE for Validation Set is: 22.46% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.80 | sMAPE for Test Set is: 22.35% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:20:41,885]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:20:45,914]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:20:49,179]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:20:51,567]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:20:56,269]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:02,131]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:05,998]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:17,621]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:18,605]\u001b[0m Trial 1255 finished with value: 41.77470710157544 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011338650804133554, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019270445128202376, 'dropout_rate_Layer_2': 0.05285580609302778, 'dropout_rate_Layer_3': 0.05103039844825408, 'dropout_rate_Layer_4': 0.3229678163362471, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004260903447183084, 'l1_Layer_2': 0.0008339494031456029, 'l1_Layer_3': 0.0001630072509924041, 'l1_Layer_4': 0.00327889689791411, 'n_units_Layer_1': 230, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180, 'n_units_Layer_4': 125}. Best is trial 1212 with value: 40.91294781977182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.77 | sMAPE for Validation Set is: 22.33% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.20 | sMAPE for Test Set is: 22.47% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:21:24,304]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:26,096]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:30,403]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:30,776]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:36,158]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:39,872]\u001b[0m Trial 1280 finished with value: 41.48880961584645 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011933397481375355, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19800319240125747, 'dropout_rate_Layer_2': 0.12341091808556909, 'dropout_rate_Layer_3': 0.362683278694472, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010871326091070323, 'l1_Layer_2': 0.0034120234909673086, 'l1_Layer_3': 3.833425092661938e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 290, 'n_units_Layer_3': 190}. Best is trial 1212 with value: 40.91294781977182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.49 | sMAPE for Validation Set is: 22.74% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.57 | sMAPE for Test Set is: 24.16% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:21:41,227]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:45,416]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:50,176]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:52,009]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:55,726]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:55,953]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:21:56,999]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:22:03,839]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:22:04,325]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:22:16,529]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:22:16,853]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:22:22,989]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:22:23,470]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:22:29,742]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:22:32,698]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:22:36,552]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:22:38,097]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:22:44,776]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:22:58,227]\u001b[0m Trial 1303 finished with value: 42.74552203614841 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016001791603638882, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07566316020222603, 'dropout_rate_Layer_2': 0.19667405730932258, 'dropout_rate_Layer_3': 0.00812009654777032, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3507319110853888e-05, 'l1_Layer_2': 9.343343234560052e-05, 'l1_Layer_3': 3.3630057492206527e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 200, 'n_units_Layer_3': 260}. Best is trial 1212 with value: 40.91294781977182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.75 | sMAPE for Validation Set is: 22.97% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.98 | sMAPE for Test Set is: 23.41% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:23:01,638]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:23:04,636]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:23:08,019]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:23:11,199]\u001b[0m Trial 1307 finished with value: 42.04535760001986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016313273829188968, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07476460911744932, 'dropout_rate_Layer_2': 0.056606399870946664, 'dropout_rate_Layer_3': 0.012351679857420998, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6093246768492833e-05, 'l1_Layer_2': 7.881394889519542e-05, 'l1_Layer_3': 3.774156093464316e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 215, 'n_units_Layer_3': 160}. Best is trial 1212 with value: 40.91294781977182.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.05 | sMAPE for Validation Set is: 22.94% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.32 | sMAPE for Test Set is: 24.26% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:23:11,844]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:23:13,931]\u001b[0m Trial 1304 finished with value: 40.83800654770554 and parameters: {'n_hidden': 3, 'learning_rate': 0.001632071569540835, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09365628569557488, 'dropout_rate_Layer_2': 0.09162994721377887, 'dropout_rate_Layer_3': 0.019142905593265213, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4017780879247376e-05, 'l1_Layer_2': 7.445122683659235e-05, 'l1_Layer_3': 2.1950972258558827e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 220, 'n_units_Layer_3': 65}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.84 | sMAPE for Validation Set is: 22.47% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.63 | sMAPE for Test Set is: 22.18% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:23:21,616]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:23:24,939]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:23:25,094]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:23:26,002]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:23:33,457]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:23:33,520]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:23:39,391]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:23:43,068]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:23:53,939]\u001b[0m Trial 1312 finished with value: 42.67221003406555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021637122313967316, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05209381694821504, 'dropout_rate_Layer_2': 0.05850328954935689, 'dropout_rate_Layer_3': 0.14319363358305637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015083165547956072, 'l1_Layer_2': 0.002700087449914078, 'l1_Layer_3': 1.8336474854740363e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 125, 'n_units_Layer_3': 165}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.67 | sMAPE for Validation Set is: 23.40% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.63 | sMAPE for Test Set is: 26.39% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:23:58,902]\u001b[0m Trial 1318 finished with value: 41.59149044212571 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020764483259742223, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06673724841892924, 'dropout_rate_Layer_2': 0.07109104029720598, 'dropout_rate_Layer_3': 0.1407690700468565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015527507365833805, 'l1_Layer_2': 0.005630832534752449, 'l1_Layer_3': 3.982375928914309e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 140}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.59 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.92 | sMAPE for Test Set is: 23.87% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:24:03,551]\u001b[0m Trial 1321 finished with value: 43.2096168732657 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021749448396133656, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06865816278212453, 'dropout_rate_Layer_2': 0.06930480982678848, 'dropout_rate_Layer_3': 0.14306431144416218, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001501817848572265, 'l1_Layer_2': 0.002027374509024906, 'l1_Layer_3': 1.0145371829124282e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 160}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.21 | sMAPE for Validation Set is: 22.77% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.77 | sMAPE for Test Set is: 23.34% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:24:04,010]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:07,706]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:12,889]\u001b[0m Trial 1322 finished with value: 41.59762560310643 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017217247779095133, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08356662218421937, 'dropout_rate_Layer_2': 0.049560806323124394, 'dropout_rate_Layer_3': 0.013892055389237733, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.611884842168757e-05, 'l1_Layer_2': 0.0001213372515720177, 'l1_Layer_3': 3.0506061116314414e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 220, 'n_units_Layer_3': 95}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.60 | sMAPE for Validation Set is: 22.78% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.55 | sMAPE for Test Set is: 23.31% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:24:15,568]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:20,462]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:23,290]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:27,388]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:32,252]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:35,825]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:38,902]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:42,254]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:44,840]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:48,092]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:52,305]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:56,401]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:24:59,418]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:01,732]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:04,232]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:08,917]\u001b[0m Trial 1331 finished with value: 41.69855227206339 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015631656345232881, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06028598412025071, 'dropout_rate_Layer_2': 0.2203421014831208, 'dropout_rate_Layer_3': 0.11344346867083221, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012145274126452791, 'l1_Layer_2': 0.008507135742483404, 'l1_Layer_3': 4.192704154972022e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 85, 'n_units_Layer_3': 195}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.70 | sMAPE for Validation Set is: 22.29% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.83 | sMAPE for Test Set is: 22.39% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:25:09,828]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:16,600]\u001b[0m Trial 1336 finished with value: 42.10011221184266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020056233128260873, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09623530447548673, 'dropout_rate_Layer_2': 0.06006775464308124, 'dropout_rate_Layer_3': 0.006898412644158912, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4164098335894214e-05, 'l1_Layer_2': 8.980645158487746e-05, 'l1_Layer_3': 6.473284002755716e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 70}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.10 | sMAPE for Validation Set is: 22.87% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.34 | sMAPE for Test Set is: 22.82% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:25:19,385]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:22,517]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:25,063]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:29,485]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:32,649]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:33,346]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:38,765]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:38,954]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:39,701]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:39,843]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:47,790]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:52,655]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:25:52,914]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:26:02,543]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:26:07,095]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:26:16,235]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:26:19,459]\u001b[0m Trial 1355 finished with value: 42.21908433435443 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014323963641494379, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07480110836657557, 'dropout_rate_Layer_2': 0.11844941783358237, 'dropout_rate_Layer_3': 0.15283405410504916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.225628538624939e-05, 'l1_Layer_2': 0.007772883886473451, 'l1_Layer_3': 3.1309776641089216e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 80, 'n_units_Layer_3': 155}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.22 | sMAPE for Validation Set is: 22.48% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.72 | sMAPE for Test Set is: 22.56% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:26:19,914]\u001b[0m Trial 1354 finished with value: 42.23582293481134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010833790435079013, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17692173683653734, 'dropout_rate_Layer_2': 0.08287850720158656, 'dropout_rate_Layer_3': 0.33525881961340664, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003395148921042158, 'l1_Layer_2': 0.006908571027256939, 'l1_Layer_3': 6.383428518047411e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 80}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.24 | sMAPE for Validation Set is: 22.75% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 17.41 | sMAPE for Test Set is: 22.64% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:26:27,409]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:26:30,806]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:26:35,403]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:26:43,401]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:26:44,760]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:26:45,529]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:26:48,401]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:26:52,644]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:26:52,970]\u001b[0m Trial 1362 finished with value: 41.449583204365034 and parameters: {'n_hidden': 3, 'learning_rate': 0.001857580466406137, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08166161826180754, 'dropout_rate_Layer_2': 0.05920906283632842, 'dropout_rate_Layer_3': 0.005509700931328286, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6383427617010163e-05, 'l1_Layer_2': 0.00010085287729707902, 'l1_Layer_3': 4.7344264304564637e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 230, 'n_units_Layer_3': 80}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.45 | sMAPE for Validation Set is: 22.80% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.35 | sMAPE for Test Set is: 24.27% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:26:53,214]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:27:02,151]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:27:02,716]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:27:03,071]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:27:11,621]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:27:17,100]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:27:22,156]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:27:26,145]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:27:26,353]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:27:27,339]\u001b[0m Trial 1371 finished with value: 41.09198883652909 and parameters: {'n_hidden': 3, 'learning_rate': 0.002477250918102086, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09852592676224578, 'dropout_rate_Layer_2': 0.11162583964933485, 'dropout_rate_Layer_3': 0.022155382050719312, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0035928384251118464, 'l1_Layer_2': 7.49187001017088e-05, 'l1_Layer_3': 6.725045772712062e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 235, 'n_units_Layer_3': 70}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.09 | sMAPE for Validation Set is: 22.36% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.45 | sMAPE for Test Set is: 21.81% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:27:35,990]\u001b[0m Trial 1375 finished with value: 41.76632565914364 and parameters: {'n_hidden': 3, 'learning_rate': 0.001968109455850881, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16072089895789649, 'dropout_rate_Layer_2': 0.08997438754629859, 'dropout_rate_Layer_3': 0.38474435240506133, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010112288902877383, 'l1_Layer_2': 0.0033725256540195494, 'l1_Layer_3': 4.628212795477518e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.77 | sMAPE for Validation Set is: 22.69% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.51 | sMAPE for Test Set is: 23.09% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:27:47,184]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:27:53,184]\u001b[0m Trial 1384 finished with value: 41.92101237618945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019406328698703351, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1563566001207444, 'dropout_rate_Layer_2': 0.08944581254133503, 'dropout_rate_Layer_3': 0.36996627185287784, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010053464307931142, 'l1_Layer_2': 0.003163403405317002, 'l1_Layer_3': 4.747722742386345e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 275, 'n_units_Layer_3': 180}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.92 | sMAPE for Validation Set is: 22.58% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.30 | sMAPE for Test Set is: 22.30% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:27:56,397]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:27:58,126]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:02,998]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:06,951]\u001b[0m Trial 1382 finished with value: 41.75785837303882 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016664953423520745, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16768969089660585, 'dropout_rate_Layer_2': 0.08366631317212872, 'dropout_rate_Layer_3': 0.386840762285258, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.864746199611117e-05, 'l1_Layer_2': 0.010263081248196092, 'l1_Layer_3': 3.404905718223428e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 290, 'n_units_Layer_3': 180}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.76 | sMAPE for Validation Set is: 22.93% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.21 | sMAPE for Test Set is: 23.84% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:28:07,137]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:11,543]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:12,824]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:17,763]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:22,834]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:27,977]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:31,930]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:36,034]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:36,419]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:42,494]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:46,713]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:47,226]\u001b[0m Trial 1391 finished with value: 42.50918081506061 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023935593788310173, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08819454145655391, 'dropout_rate_Layer_2': 0.11253818635053296, 'dropout_rate_Layer_3': 0.020157545711939603, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.947550632632602e-05, 'l1_Layer_2': 5.817358477441277e-05, 'l1_Layer_3': 3.792515188015508e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 215, 'n_units_Layer_3': 85}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.51 | sMAPE for Validation Set is: 23.22% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.58 | sMAPE for Test Set is: 24.44% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:28:52,393]\u001b[0m Trial 1392 finished with value: 41.23055046004734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016587374715589661, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21848746128823232, 'dropout_rate_Layer_2': 0.06436951924316286, 'dropout_rate_Layer_3': 0.3771663166053427, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013489150531802123, 'l1_Layer_2': 0.008944695708075323, 'l1_Layer_3': 3.684963323376575e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.23 | sMAPE for Validation Set is: 22.44% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.21 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:28:56,492]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:28:56,794]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:06,127]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:06,655]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.96 | sMAPE for Validation Set is: 22.69% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.11 | sMAPE for Test Set is: 23.90% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:29:11,550]\u001b[0m Trial 1398 finished with value: 41.956795463565626 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025424881209984737, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0563297791287987, 'dropout_rate_Layer_2': 0.25080625627018577, 'dropout_rate_Layer_3': 0.15948504674876773, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001667772878775, 'l1_Layer_2': 0.007109695490266548, 'l1_Layer_3': 3.857572362928516e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 120, 'n_units_Layer_3': 155}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:14,742]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.81 | sMAPE for Validation Set is: 22.81% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.34 | sMAPE for Test Set is: 24.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:29:17,408]\u001b[0m Trial 1401 finished with value: 41.80896818442274 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017199538435293852, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09629137440733679, 'dropout_rate_Layer_2': 0.09342044283579226, 'dropout_rate_Layer_3': 0.0001222539730155979, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.211495916431839e-05, 'l1_Layer_2': 7.541507958871384e-05, 'l1_Layer_3': 2.552798673445185e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 225, 'n_units_Layer_3': 65}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:20,707]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:22,093]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:23,106]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:26,725]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:29,168]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:30,706]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:32,469]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:39,550]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:40,287]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:42,021]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:46,470]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:49,321]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:54,297]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:54,672]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:57,111]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:29:58,107]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:06,429]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:06,914]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:11,886]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:15,225]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:15,386]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:18,948]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:23,034]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:24,192]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:25,014]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:31,903]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:37,005]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:37,213]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:40,183]\u001b[0m Trial 1424 finished with value: 41.766436336797625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017480733975276462, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08921806449486355, 'dropout_rate_Layer_2': 0.0906290654074837, 'dropout_rate_Layer_3': 0.012073140864415317, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0841247070173988e-05, 'l1_Layer_2': 0.00013127748953945006, 'l1_Layer_3': 2.571491984456266e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 225, 'n_units_Layer_3': 65}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.77 | sMAPE for Validation Set is: 23.15% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.77 | sMAPE for Test Set is: 23.57% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:30:46,080]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:46,355]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:48,048]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:51,870]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:57,093]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:57,319]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:30:58,889]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:06,675]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:07,466]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:07,468]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:07,722]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:15,945]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:20,324]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:24,751]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:25,348]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:32,204]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:37,159]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:38,086]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:40,138]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:44,250]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:48,561]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:49,180]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:53,896]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:57,009]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:59,359]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:31:59,675]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:02,167]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:07,371]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:08,051]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:09,889]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:10,591]\u001b[0m Trial 1450 finished with value: 41.62534916617795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008189498682208107, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1503655263573021, 'dropout_rate_Layer_2': 0.08719967235488939, 'dropout_rate_Layer_3': 0.3494310612005348, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026884739707298594, 'l1_Layer_2': 0.004754211322164487, 'l1_Layer_3': 2.2323196891757214e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 270, 'n_units_Layer_3': 170}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.63 | sMAPE for Validation Set is: 22.66% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.16 | sMAPE for Test Set is: 22.72% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:32:17,995]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:20,412]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:26,318]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:33,986]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:34,176]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:39,653]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:39,839]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:45,233]\u001b[0m Trial 1470 finished with value: 41.27234328383397 and parameters: {'n_hidden': 3, 'learning_rate': 0.001674233569697236, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08800297464597695, 'dropout_rate_Layer_2': 0.07655656249702252, 'dropout_rate_Layer_3': 0.018543106645219014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.047525358850853e-05, 'l1_Layer_2': 7.55226846522822e-05, 'l1_Layer_3': 3.684933707217889e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 220, 'n_units_Layer_3': 95}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.27 | sMAPE for Validation Set is: 22.30% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.96 | sMAPE for Test Set is: 22.28% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:32:47,909]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:48,297]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:53,023]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:55,365]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:32:55,814]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:03,408]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:11,334]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:15,861]\u001b[0m Trial 1476 finished with value: 41.68201802722569 and parameters: {'n_hidden': 3, 'learning_rate': 0.00154413422839205, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0867642608042817, 'dropout_rate_Layer_2': 0.06264319480983252, 'dropout_rate_Layer_3': 0.14016890986537942, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.860461510468635e-05, 'l1_Layer_2': 6.619772537205852e-05, 'l1_Layer_3': 4.1468844193909605e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 170}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.68 | sMAPE for Validation Set is: 22.60% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.19 | sMAPE for Test Set is: 25.35% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-13 19:33:19,054]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:21,720]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:22,620]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:29,009]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:29,315]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:29,725]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:32,065]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:39,567]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:41,588]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:42,126]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:43,071]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:51,148]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:51,427]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:58,014]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:33:58,080]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:34:00,317]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-13 19:34:11,725]\u001b[0m Trial 1496 finished with value: 41.8718500817377 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010376785983552115, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19712617933433074, 'dropout_rate_Layer_2': 0.06883605318055566, 'dropout_rate_Layer_3': 0.3518483688278737, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027713478488028463, 'l1_Layer_2': 0.005499331298110043, 'l1_Layer_3': 3.2275851797801556e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 280, 'n_units_Layer_3': 165}. Best is trial 1304 with value: 40.83800654770554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.87 | sMAPE for Validation Set is: 22.61% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.03 | sMAPE for Test Set is: 22.32% | rMAE for Test Set is: 0.58\n",
      "for 2023-01-01, MAE is:14.63 & sMAPE is:128.34% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.63 & 128.34% & 0.15\n",
      "for 2023-01-02, MAE is:82.92 & sMAPE is:98.50% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :48.77 & 113.42% & 0.80\n",
      "for 2023-01-03, MAE is:18.12 & sMAPE is:14.08% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :38.56 & 80.30% & 0.75\n",
      "for 2023-01-04, MAE is:28.27 & sMAPE is:40.62% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :35.99 & 70.38% & 0.75\n",
      "for 2023-01-05, MAE is:62.88 & sMAPE is:65.62% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :41.36 & 69.43% & 0.74\n",
      "for 2023-01-06, MAE is:18.73 & sMAPE is:15.47% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :37.59 & 60.44% & 0.65\n",
      "for 2023-01-07, MAE is:14.92 & sMAPE is:18.70% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :34.35 & 54.48% & 0.58\n",
      "for 2023-01-08, MAE is:44.26 & sMAPE is:92.68% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :35.59 & 59.25% & 0.61\n",
      "for 2023-01-09, MAE is:31.95 & sMAPE is:27.69% & rMAE is:2.97 ||| daily mean of MAE & sMAPE & rMAE till now are :35.19 & 55.74% & 0.87\n",
      "for 2023-01-10, MAE is:20.36 & sMAPE is:16.79% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :33.70 & 51.85% & 0.89\n",
      "for 2023-01-11, MAE is:27.43 & sMAPE is:55.77% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :33.13 & 52.21% & 0.97\n",
      "for 2023-01-12, MAE is:26.37 & sMAPE is:49.51% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :32.57 & 51.98% & 0.94\n",
      "for 2023-01-13, MAE is:27.19 & sMAPE is:48.27% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :32.16 & 51.70% & 0.91\n",
      "for 2023-01-14, MAE is:16.66 & sMAPE is:27.23% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :31.05 & 49.95% & 0.89\n",
      "for 2023-01-15, MAE is:20.00 & sMAPE is:66.89% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :30.31 & 51.08% & 0.87\n",
      "for 2023-01-16, MAE is:46.75 & sMAPE is:39.29% & rMAE is:2.98 ||| daily mean of MAE & sMAPE & rMAE till now are :31.34 & 50.34% & 1.00\n",
      "for 2023-01-17, MAE is:27.60 & sMAPE is:15.14% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :31.12 & 48.27% & 0.97\n",
      "for 2023-01-18, MAE is:20.13 & sMAPE is:12.52% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :30.51 & 46.28% & 0.94\n",
      "for 2023-01-19, MAE is:58.30 & sMAPE is:36.78% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :31.97 & 45.78% & 0.92\n",
      "for 2023-01-20, MAE is:16.77 & sMAPE is:9.44% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :31.21 & 43.97% & 0.88\n",
      "for 2023-01-21, MAE is:6.33 & sMAPE is:4.09% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :30.03 & 42.07% & 0.84\n",
      "for 2023-01-22, MAE is:34.18 & sMAPE is:22.15% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :30.22 & 41.16% & 0.81\n",
      "for 2023-01-23, MAE is:17.15 & sMAPE is:8.24% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :29.65 & 39.73% & 0.79\n",
      "for 2023-01-24, MAE is:17.12 & sMAPE is:8.62% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :29.13 & 38.43% & 0.78\n",
      "for 2023-01-25, MAE is:26.26 & sMAPE is:13.35% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :29.01 & 37.43% & 0.78\n",
      "for 2023-01-26, MAE is:11.12 & sMAPE is:6.32% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :28.32 & 36.23% & 0.78\n",
      "for 2023-01-27, MAE is:11.29 & sMAPE is:6.84% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :27.69 & 35.15% & 0.78\n",
      "for 2023-01-28, MAE is:10.86 & sMAPE is:7.14% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :27.09 & 34.15% & 0.80\n",
      "for 2023-01-29, MAE is:17.97 & sMAPE is:12.48% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :26.78 & 33.40% & 0.79\n",
      "for 2023-01-30, MAE is:33.11 & sMAPE is:24.95% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :26.99 & 33.12% & 0.78\n",
      "for 2023-01-31, MAE is:16.61 & sMAPE is:10.92% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :26.65 & 32.40% & 0.77\n",
      "for 2023-02-01, MAE is:12.31 & sMAPE is:8.56% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :26.21 & 31.66% & 0.75\n",
      "for 2023-02-02, MAE is:11.61 & sMAPE is:7.96% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :25.76 & 30.94% & 0.74\n",
      "for 2023-02-03, MAE is:7.79 & sMAPE is:5.45% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :25.23 & 30.19% & 0.73\n",
      "for 2023-02-04, MAE is:24.83 & sMAPE is:17.67% & rMAE is:2.90 ||| daily mean of MAE & sMAPE & rMAE till now are :25.22 & 29.83% & 0.79\n",
      "for 2023-02-05, MAE is:11.57 & sMAPE is:8.67% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :24.84 & 29.24% & 0.79\n",
      "for 2023-02-06, MAE is:16.12 & sMAPE is:9.80% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :24.61 & 28.72% & 0.78\n",
      "for 2023-02-07, MAE is:15.25 & sMAPE is:8.29% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :24.36 & 28.18% & 0.77\n",
      "for 2023-02-08, MAE is:27.68 & sMAPE is:15.91% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :24.45 & 27.86% & 0.78\n",
      "for 2023-02-09, MAE is:18.88 & sMAPE is:12.17% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :24.31 & 27.47% & 0.78\n",
      "for 2023-02-10, MAE is:13.34 & sMAPE is:8.86% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :24.04 & 27.02% & 0.78\n",
      "for 2023-02-11, MAE is:35.86 & sMAPE is:26.71% & rMAE is:3.93 ||| daily mean of MAE & sMAPE & rMAE till now are :24.32 & 27.01% & 0.86\n",
      "for 2023-02-12, MAE is:17.96 & sMAPE is:13.78% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :24.17 & 26.70% & 0.87\n",
      "for 2023-02-13, MAE is:20.20 & sMAPE is:11.86% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :24.08 & 26.37% & 0.90\n",
      "for 2023-02-14, MAE is:20.80 & sMAPE is:12.82% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :24.01 & 26.07% & 0.90\n",
      "for 2023-02-15, MAE is:14.77 & sMAPE is:9.52% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :23.81 & 25.71% & 0.90\n",
      "for 2023-02-16, MAE is:18.39 & sMAPE is:13.94% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :23.69 & 25.46% & 0.90\n",
      "for 2023-02-17, MAE is:12.20 & sMAPE is:10.11% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :23.45 & 25.14% & 0.89\n",
      "for 2023-02-18, MAE is:13.50 & sMAPE is:12.73% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :23.25 & 24.88% & 0.88\n",
      "for 2023-02-19, MAE is:26.21 & sMAPE is:26.74% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :23.31 & 24.92% & 0.88\n",
      "for 2023-02-20, MAE is:34.02 & sMAPE is:26.91% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :23.52 & 24.96% & 0.88\n",
      "for 2023-02-21, MAE is:19.14 & sMAPE is:14.83% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :23.44 & 24.76% & 0.89\n",
      "for 2023-02-22, MAE is:13.35 & sMAPE is:8.72% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :23.25 & 24.46% & 0.91\n",
      "for 2023-02-23, MAE is:11.50 & sMAPE is:8.15% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :23.03 & 24.16% & 0.92\n",
      "for 2023-02-24, MAE is:19.87 & sMAPE is:14.85% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :22.97 & 23.99% & 0.92\n",
      "for 2023-02-25, MAE is:19.66 & sMAPE is:17.65% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :22.91 & 23.88% & 0.93\n",
      "for 2023-02-26, MAE is:12.26 & sMAPE is:11.98% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :22.73 & 23.67% & 0.92\n",
      "for 2023-02-27, MAE is:15.52 & sMAPE is:10.61% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :22.60 & 23.44% & 0.91\n",
      "for 2023-02-28, MAE is:10.95 & sMAPE is:7.00% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :22.40 & 23.16% & 0.92\n",
      "for 2023-03-01, MAE is:15.66 & sMAPE is:10.46% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :22.29 & 22.95% & 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-02, MAE is:17.75 & sMAPE is:12.29% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :22.22 & 22.78% & 0.92\n",
      "for 2023-03-03, MAE is:20.50 & sMAPE is:15.12% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :22.19 & 22.65% & 0.93\n",
      "for 2023-03-04, MAE is:18.17 & sMAPE is:14.54% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :22.13 & 22.53% & 0.94\n",
      "for 2023-03-05, MAE is:25.71 & sMAPE is:21.24% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :22.18 & 22.50% & 0.94\n",
      "for 2023-03-06, MAE is:21.85 & sMAPE is:13.51% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :22.18 & 22.37% & 0.95\n",
      "for 2023-03-07, MAE is:11.02 & sMAPE is:7.89% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :22.01 & 22.15% & 0.94\n",
      "for 2023-03-08, MAE is:10.36 & sMAPE is:7.09% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :21.83 & 21.92% & 0.94\n",
      "for 2023-03-09, MAE is:16.90 & sMAPE is:12.46% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :21.76 & 21.78% & 0.94\n",
      "for 2023-03-10, MAE is:6.83 & sMAPE is:5.56% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :21.54 & 21.55% & 0.93\n",
      "for 2023-03-11, MAE is:35.46 & sMAPE is:34.70% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :21.74 & 21.74% & 0.94\n",
      "for 2023-03-12, MAE is:20.58 & sMAPE is:18.98% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :21.73 & 21.70% & 0.93\n",
      "for 2023-03-13, MAE is:75.10 & sMAPE is:109.54% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :22.47 & 22.92% & 0.93\n",
      "for 2023-03-14, MAE is:38.81 & sMAPE is:65.81% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :22.69 & 23.50% & 0.93\n",
      "for 2023-03-15, MAE is:17.19 & sMAPE is:12.32% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :22.62 & 23.35% & 0.93\n",
      "for 2023-03-16, MAE is:21.14 & sMAPE is:17.99% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :22.60 & 23.28% & 0.93\n",
      "for 2023-03-17, MAE is:18.39 & sMAPE is:18.21% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :22.54 & 23.22% & 0.94\n",
      "for 2023-03-18, MAE is:33.65 & sMAPE is:36.39% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :22.69 & 23.39% & 0.95\n",
      "for 2023-03-19, MAE is:15.92 & sMAPE is:16.78% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :22.60 & 23.30% & 0.95\n",
      "for 2023-03-20, MAE is:15.03 & sMAPE is:12.74% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :22.50 & 23.17% & 0.94\n",
      "for 2023-03-21, MAE is:12.46 & sMAPE is:10.25% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :22.38 & 23.01% & 0.93\n",
      "for 2023-03-22, MAE is:19.55 & sMAPE is:20.34% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :22.34 & 22.97% & 0.93\n",
      "for 2023-03-23, MAE is:21.58 & sMAPE is:28.27% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :22.33 & 23.04% & 0.93\n",
      "for 2023-03-24, MAE is:23.53 & sMAPE is:45.50% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :22.35 & 23.31% & 0.92\n",
      "for 2023-03-25, MAE is:38.65 & sMAPE is:141.89% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :22.54 & 24.72% & 0.91\n",
      "for 2023-03-26, MAE is:18.32 & sMAPE is:26.84% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :22.49 & 24.75% & 0.91\n",
      "for 2023-03-27, MAE is:15.83 & sMAPE is:12.62% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :22.42 & 24.60% & 0.91\n",
      "for 2023-03-28, MAE is:18.85 & sMAPE is:14.36% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :22.37 & 24.49% & 0.92\n",
      "for 2023-03-29, MAE is:11.47 & sMAPE is:10.14% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :22.25 & 24.32% & 0.91\n",
      "for 2023-03-30, MAE is:19.90 & sMAPE is:30.88% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :22.22 & 24.40% & 0.91\n",
      "for 2023-03-31, MAE is:12.96 & sMAPE is:16.50% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :22.12 & 24.31% & 0.90\n",
      "for 2023-04-01, MAE is:14.57 & sMAPE is:23.54% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :22.04 & 24.30% & 0.90\n",
      "for 2023-04-02, MAE is:18.62 & sMAPE is:27.48% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :22.00 & 24.34% & 0.90\n",
      "for 2023-04-03, MAE is:14.62 & sMAPE is:12.70% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :21.92 & 24.21% & 0.90\n",
      "for 2023-04-04, MAE is:8.92 & sMAPE is:6.42% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :21.78 & 24.02% & 0.89\n",
      "for 2023-04-05, MAE is:14.35 & sMAPE is:10.11% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :21.71 & 23.88% & 0.89\n",
      "for 2023-04-06, MAE is:11.89 & sMAPE is:8.23% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :21.60 & 23.71% & 0.88\n",
      "for 2023-04-07, MAE is:21.07 & sMAPE is:17.68% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :21.60 & 23.65% & 0.88\n",
      "for 2023-04-08, MAE is:10.91 & sMAPE is:11.07% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :21.49 & 23.52% & 0.87\n",
      "for 2023-04-09, MAE is:10.35 & sMAPE is:10.01% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :21.38 & 23.39% & 0.87\n",
      "for 2023-04-10, MAE is:40.72 & sMAPE is:75.95% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :21.57 & 23.91% & 0.86\n",
      "for 2023-04-11, MAE is:34.65 & sMAPE is:58.83% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :21.70 & 24.26% & 0.86\n",
      "for 2023-04-12, MAE is:18.48 & sMAPE is:19.63% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :21.67 & 24.21% & 0.86\n",
      "for 2023-04-13, MAE is:16.37 & sMAPE is:14.85% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :21.62 & 24.12% & 0.86\n",
      "for 2023-04-14, MAE is:15.07 & sMAPE is:12.62% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :21.55 & 24.01% & 0.87\n",
      "for 2023-04-15, MAE is:10.69 & sMAPE is:12.77% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :21.45 & 23.90% & 0.87\n",
      "for 2023-04-16, MAE is:19.25 & sMAPE is:21.41% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :21.43 & 23.88% & 0.87\n",
      "for 2023-04-17, MAE is:22.41 & sMAPE is:19.43% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :21.44 & 23.84% & 0.87\n",
      "for 2023-04-18, MAE is:6.20 & sMAPE is:5.50% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :21.30 & 23.67% & 0.86\n",
      "for 2023-04-19, MAE is:30.24 & sMAPE is:49.59% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :21.38 & 23.91% & 0.86\n",
      "for 2023-04-20, MAE is:16.71 & sMAPE is:16.16% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :21.34 & 23.84% & 0.86\n",
      "for 2023-04-21, MAE is:8.54 & sMAPE is:7.71% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :21.22 & 23.69% & 0.86\n",
      "for 2023-04-22, MAE is:12.06 & sMAPE is:14.48% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :21.14 & 23.61% & 0.86\n",
      "for 2023-04-23, MAE is:17.38 & sMAPE is:32.69% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :21.11 & 23.69% & 0.86\n",
      "for 2023-04-24, MAE is:18.98 & sMAPE is:16.75% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :21.09 & 23.63% & 0.86\n",
      "for 2023-04-25, MAE is:9.02 & sMAPE is:7.75% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :20.98 & 23.49% & 0.86\n",
      "for 2023-04-26, MAE is:9.95 & sMAPE is:8.26% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :20.89 & 23.36% & 0.85\n",
      "for 2023-04-27, MAE is:8.91 & sMAPE is:8.34% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :20.79 & 23.23% & 0.85\n",
      "for 2023-04-28, MAE is:6.30 & sMAPE is:6.04% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :20.66 & 23.08% & 0.85\n",
      "for 2023-04-29, MAE is:21.63 & sMAPE is:27.40% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :20.67 & 23.12% & 0.86\n",
      "for 2023-04-30, MAE is:12.34 & sMAPE is:27.78% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :20.60 & 23.16% & 0.86\n",
      "for 2023-05-01, MAE is:18.46 & sMAPE is:37.72% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :20.58 & 23.28% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-02, MAE is:44.70 & sMAPE is:58.10% & rMAE is:4.15 ||| daily mean of MAE & sMAPE & rMAE till now are :20.78 & 23.56% & 0.88\n",
      "for 2023-05-03, MAE is:16.17 & sMAPE is:17.52% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :20.74 & 23.52% & 0.88\n",
      "for 2023-05-04, MAE is:7.46 & sMAPE is:7.94% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :20.64 & 23.39% & 0.88\n",
      "for 2023-05-05, MAE is:16.69 & sMAPE is:19.55% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :20.60 & 23.36% & 0.89\n",
      "for 2023-05-06, MAE is:15.85 & sMAPE is:21.81% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :20.57 & 23.35% & 0.89\n",
      "for 2023-05-07, MAE is:16.47 & sMAPE is:22.77% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :20.53 & 23.34% & 0.89\n",
      "for 2023-05-08, MAE is:13.37 & sMAPE is:15.71% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :20.48 & 23.28% & 0.89\n",
      "for 2023-05-09, MAE is:25.69 & sMAPE is:28.21% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :20.52 & 23.32% & 0.90\n",
      "for 2023-05-10, MAE is:42.33 & sMAPE is:50.94% & rMAE is:2.88 ||| daily mean of MAE & sMAPE & rMAE till now are :20.69 & 23.53% & 0.92\n",
      "for 2023-05-11, MAE is:27.82 & sMAPE is:27.89% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :20.74 & 23.57% & 0.92\n",
      "for 2023-05-12, MAE is:20.24 & sMAPE is:23.44% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :20.74 & 23.57% & 0.93\n",
      "for 2023-05-13, MAE is:10.64 & sMAPE is:23.46% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :20.66 & 23.56% & 0.93\n",
      "for 2023-05-14, MAE is:7.80 & sMAPE is:41.57% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :20.57 & 23.70% & 0.92\n",
      "for 2023-05-15, MAE is:9.15 & sMAPE is:8.62% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :20.48 & 23.59% & 0.92\n",
      "for 2023-05-16, MAE is:12.83 & sMAPE is:19.49% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :20.42 & 23.56% & 0.92\n",
      "for 2023-05-17, MAE is:17.93 & sMAPE is:24.65% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :20.41 & 23.57% & 0.92\n",
      "for 2023-05-18, MAE is:22.72 & sMAPE is:32.76% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :20.42 & 23.63% & 0.92\n",
      "for 2023-05-19, MAE is:8.46 & sMAPE is:11.96% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :20.34 & 23.55% & 0.92\n",
      "for 2023-05-20, MAE is:19.29 & sMAPE is:59.50% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :20.33 & 23.80% & 0.91\n",
      "for 2023-05-21, MAE is:21.06 & sMAPE is:97.11% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :20.34 & 24.32% & 0.91\n",
      "for 2023-05-22, MAE is:9.44 & sMAPE is:11.34% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :20.26 & 24.23% & 0.91\n",
      "for 2023-05-23, MAE is:11.38 & sMAPE is:16.76% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :20.20 & 24.18% & 0.91\n",
      "for 2023-05-24, MAE is:6.11 & sMAPE is:6.92% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :20.10 & 24.06% & 0.91\n",
      "for 2023-05-25, MAE is:17.75 & sMAPE is:28.87% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :20.08 & 24.09% & 0.92\n",
      "for 2023-05-26, MAE is:16.06 & sMAPE is:35.13% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :20.05 & 24.17% & 0.92\n",
      "for 2023-05-27, MAE is:20.48 & sMAPE is:60.13% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :20.06 & 24.41% & 0.92\n",
      "for 2023-05-28, MAE is:19.90 & sMAPE is:76.72% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :20.06 & 24.77% & 0.92\n",
      "for 2023-05-29, MAE is:26.00 & sMAPE is:85.34% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :20.10 & 25.17% & 0.91\n",
      "for 2023-05-30, MAE is:22.64 & sMAPE is:31.14% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :20.11 & 25.21% & 0.93\n",
      "for 2023-05-31, MAE is:16.90 & sMAPE is:41.93% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :20.09 & 25.32% & 0.92\n",
      "for 2023-06-01, MAE is:14.95 & sMAPE is:28.74% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :20.06 & 25.35% & 0.93\n",
      "for 2023-06-02, MAE is:8.31 & sMAPE is:12.53% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :19.98 & 25.26% & 0.93\n",
      "for 2023-06-03, MAE is:17.67 & sMAPE is:57.27% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :19.97 & 25.47% & 0.94\n",
      "for 2023-06-04, MAE is:17.80 & sMAPE is:65.46% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :19.95 & 25.73% & 0.94\n",
      "for 2023-06-05, MAE is:10.04 & sMAPE is:12.23% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :19.89 & 25.64% & 0.93\n",
      "for 2023-06-06, MAE is:6.35 & sMAPE is:7.46% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :19.80 & 25.53% & 0.93\n",
      "for 2023-06-07, MAE is:6.34 & sMAPE is:7.02% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :19.72 & 25.41% & 0.93\n",
      "for 2023-06-08, MAE is:7.89 & sMAPE is:9.79% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :19.64 & 25.31% & 0.92\n",
      "for 2023-06-09, MAE is:6.66 & sMAPE is:7.74% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :19.56 & 25.20% & 0.92\n",
      "for 2023-06-10, MAE is:7.85 & sMAPE is:17.29% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :19.49 & 25.15% & 0.92\n",
      "for 2023-06-11, MAE is:18.73 & sMAPE is:56.03% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :19.48 & 25.34% & 0.92\n",
      "for 2023-06-12, MAE is:9.60 & sMAPE is:9.66% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :19.42 & 25.25% & 0.92\n",
      "for 2023-06-13, MAE is:10.67 & sMAPE is:11.80% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :19.37 & 25.17% & 0.92\n",
      "for 2023-06-14, MAE is:18.30 & sMAPE is:19.00% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :19.36 & 25.13% & 0.93\n",
      "for 2023-06-15, MAE is:25.15 & sMAPE is:24.12% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :19.40 & 25.12% & 0.93\n",
      "for 2023-06-16, MAE is:24.64 & sMAPE is:20.83% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :19.43 & 25.10% & 0.92\n",
      "for 2023-06-17, MAE is:16.24 & sMAPE is:17.46% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :19.41 & 25.05% & 0.92\n",
      "for 2023-06-18, MAE is:12.39 & sMAPE is:17.77% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :19.37 & 25.01% & 0.92\n",
      "for 2023-06-19, MAE is:16.81 & sMAPE is:14.12% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :19.35 & 24.94% & 0.92\n",
      "for 2023-06-20, MAE is:11.30 & sMAPE is:9.41% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :19.31 & 24.85% & 0.92\n",
      "for 2023-06-21, MAE is:16.71 & sMAPE is:13.28% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :19.29 & 24.79% & 0.91\n",
      "for 2023-06-22, MAE is:148.15 & sMAPE is:136.53% & rMAE is:11.34 ||| daily mean of MAE & sMAPE & rMAE till now are :20.04 & 25.43% & 0.97\n",
      "for 2023-06-23, MAE is:15.84 & sMAPE is:14.63% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :20.01 & 25.37% & 0.97\n",
      "for 2023-06-24, MAE is:17.29 & sMAPE is:39.96% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :20.00 & 25.45% & 0.97\n",
      "for 2023-06-25, MAE is:21.65 & sMAPE is:63.36% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :20.01 & 25.67% & 0.97\n",
      "for 2023-06-26, MAE is:19.98 & sMAPE is:19.74% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :20.01 & 25.63% & 0.97\n",
      "for 2023-06-27, MAE is:8.18 & sMAPE is:7.80% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :19.94 & 25.53% & 0.97\n",
      "for 2023-06-28, MAE is:12.80 & sMAPE is:12.03% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :19.90 & 25.46% & 0.97\n",
      "for 2023-06-29, MAE is:12.58 & sMAPE is:11.82% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :19.86 & 25.38% & 0.97\n",
      "for 2023-06-30, MAE is:7.35 & sMAPE is:7.32% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :19.79 & 25.28% & 0.97\n",
      "CPU times: total: 2d 10h 24min 46s\n",
      "Wall time: 1d 1h 28min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for zone in zones:\n",
    "    large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
